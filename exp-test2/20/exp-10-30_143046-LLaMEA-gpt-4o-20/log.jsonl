{"id": "26aee497-20f1-4d2f-bfd9-591478e4ce55", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  # Crossover rate for DE\n        self.f = 0.8   # Mutation factor for DE\n        self.w = 0.5   # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]", "name": "DE_PSO_Optimizer", "description": "A hybrid differential evolution and particle swarm optimization (DE-PSO) algorithm for robust exploration and exploitation in diverse optimization landscapes.", "configspace": "", "generation": 0, "fitness": 0.2814723244654728, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.28.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8865739496332, 0.8788893187539866, 0.8952187104265327, 0.1904582085387766, 0.8637120213627044, 0.19108931914566152, 0.8729241513531614, 0.18287545720708787, 0.882976904156589, 0.07601357663787567, 0.7665276265514442, 0.6501216619048111, 0.04703333539416621, 9.999999999998899e-05, 0.7796687007384093, 0.7427848546634677, 0.7559541187160495, 0.7663773236506551, 0.1324603393897814, 0.1267898956459934, 0.14837178430025832, 0.06383685878687773, 0.17814791206673086, 0.14166714264653968, 0.16959926516959511, 0.06626952316242618, 0.11060485332971381, 0.15524491398985596, 0.10379470323277107, 0.13015829480300312, 0.1339876952274941, 0.14933008453995789, 0.11174992074901491, 0.11000466035818168, 0.11681690347750884, 0.11466274894972306, 0.9928285982780318, 0.9912563881878205, 0.9927857385872202, 0.9909317554052479, 0.99258085231718, 0.99059620847265, 0.9909482746463729, 0.9928254246855058, 0.9941182822967826, 0.7432028513689659, 0.06009821619840039, 0.7533745178028937, 0.17592979882587734, 0.7344407560287902, 0.15159297285079976, 0.08739436926698962, 0.758591185434224, 0.0883181128829843, 0.8269774136060711, 0.3831246432448786, 0.8130039468477023, 0.9001064110247516, 0.2781640146611213, 0.8497947059787283, 0.11591969985585016, 0.12795055942043965, 0.10914262960568177, 0.3367334728156214, 0.1272140191124217, 0.25215057390503126, 0.11819141570975933, 0.10135027860161339, 9.999999999998899e-05, 0.28269897991238147, 9.999999999998899e-05, 0.23908133336414406, 0.13193520804942815, 0.24539810911311077, 0.24730466715041133, 0.27321712325278513, 0.26889770321431294, 0.27826429694486543, 0.034031445935131854, 0.22639939623053063, 0.11329216229897343, 0.0005464581336184215, 0.0028274564175295724, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011824303895055732, 9.999999999998899e-05, 0.07734540503686005, 0.051825206644266264, 0.053755427355450025, 9.999999999998899e-05, 0.016997772659760435, 0.01856504569161721, 0.035138864361645705, 0.11793013858287393, 0.03702725627910186, 0.04997410380844247, 9.999999999998899e-05, 0.0355170764714714, 9.999999999998899e-05, 0.12811144880249703, 0.09381712145946208, 9.999999999998899e-05, 0.16303331099464013, 0.06798504904875458, 0.08630294451187714, 9.999999999998899e-05, 0.04551544026748611, 0.0792111997546936, 0.28958672963969345, 0.08497027109190514, 0.04916768542927452, 0.06896128146588909, 0.0811848467318772, 0.5453680246326386, 0.6059374564463781, 0.5482036416767506, 0.574201051986207, 0.5444807775511731, 0.5464293701109685, 0.5640266581412341, 0.606257169102498, 0.5707435203957928, 0.09804896932340923, 0.1270800465786791, 0.06356829575061906, 0.09281248318206092, 0.1097143799194491, 0.11934960097584768, 0.13452058688890978, 0.08852928799520665, 0.7521006607588321, 0.19011728893528268, 0.29285661241674377, 0.17061644223963157, 0.22697723694056104, 0.15924519539602588, 0.16489411896900497, 0.18841175697543833, 0.21859936573518113, 0.1741680983935856, 0.35316282062233584, 0.35505010574496976, 0.2576098597928467, 0.2411176537156674, 0.44061141526673164, 0.5058683832030331, 0.28683496984583134, 0.6620524756533267, 0.6096550024309486, 0.1698152745710122, 0.1999176452336764, 0.22219103500377813, 0.14869904352528573, 0.28269159156624146, 0.2438364566933091, 0.27595153170051634, 0.20072300624254125, 0.2717183922659586, 0.20072950678380053, 0.2202348957897583, 0.21661329936574936, 0.22178552189010425, 0.25051264265022577, 0.21947326122672173, 0.19300181363154045, 0.21587623656224464, 0.19784749355685283, 0.24981020660140196, 0.2212770493447498, 0.824056904812713, 0.22311815182926986, 0.24375292476063293, 0.1860792653763268, 0.19937435856907304, 0.7857148855301456, 0.19007947749365173, 0.17157759764176483, 0.14248253343273753, 0.9247654868607449, 0.17717936097829934, 0.1684810884069704, 0.1722702719465824, 0.16929626833120348, 0.16782717372717237, 0.12581223086879034, 0.11250519256676106, 0.110281448188003, 0.810161847592476, 0.15369723012120162, 0.1532978401194277, 0.16750522831231807, 0.16314013961371876, 0.12632882696875203, 0.20251799059177378, 0.20823784154963088, 0.1964035658630987, 0.19452889324004508, 0.21045825125930373, 0.21797262762157865, 0.1814849952436821, 0.19943190296959956, 0.20751514670402404, 0.18587789684870615, 0.09032111181973557, 0.09170493818214931, 0.10534887486715505, 0.0970331712778083, 0.11769785310509562, 0.09733108224656595, 0.10682638206787631, 0.09565054232814874, 0.10758949821991537]}, "mutation_prompt": null}
{"id": "a0cbaf2d-ad74-4378-92de-c52bb86d88af", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  # Crossover rate for DE\n        self.f = 0.8   # Mutation factor for DE\n        self.w = 0.5   # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.evaluations = 0\n        self.elite_size = 2  # Number of elites\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n        self._update_elites()\n\n    def _update_elites(self):\n        elite_idxs = np.argsort(self.personal_best_values)[:self.elite_size]\n        for idx in elite_idxs:\n            if self.personal_best_values[idx] < self.global_best_value:\n                self.global_best_value = self.personal_best_values[idx]\n                self.global_best = self.personal_best[idx]", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm enhanced with adaptive parameters and elitism for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.2814723244654728, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.28.", "error": "", "parent_id": "26aee497-20f1-4d2f-bfd9-591478e4ce55", "metadata": {"aucs": [0.8865739496332, 0.8788893187539866, 0.8952187104265327, 0.1904582085387766, 0.8637120213627044, 0.19108931914566152, 0.8729241513531614, 0.18287545720708787, 0.882976904156589, 0.07601357663787567, 0.7665276265514442, 0.6501216619048111, 0.04703333539416621, 9.999999999998899e-05, 0.7796687007384093, 0.7427848546634677, 0.7559541187160495, 0.7663773236506551, 0.1324603393897814, 0.1267898956459934, 0.14837178430025832, 0.06383685878687773, 0.17814791206673086, 0.14166714264653968, 0.16959926516959511, 0.06626952316242618, 0.11060485332971381, 0.15524491398985596, 0.10379470323277107, 0.13015829480300312, 0.1339876952274941, 0.14933008453995789, 0.11174992074901491, 0.11000466035818168, 0.11681690347750884, 0.11466274894972306, 0.9928285982780318, 0.9912563881878205, 0.9927857385872202, 0.9909317554052479, 0.99258085231718, 0.99059620847265, 0.9909482746463729, 0.9928254246855058, 0.9941182822967826, 0.7432028513689659, 0.06009821619840039, 0.7533745178028937, 0.17592979882587734, 0.7344407560287902, 0.15159297285079976, 0.08739436926698962, 0.758591185434224, 0.0883181128829843, 0.8269774136060711, 0.3831246432448786, 0.8130039468477023, 0.9001064110247516, 0.2781640146611213, 0.8497947059787283, 0.11591969985585016, 0.12795055942043965, 0.10914262960568177, 0.3367334728156214, 0.1272140191124217, 0.25215057390503126, 0.11819141570975933, 0.10135027860161339, 9.999999999998899e-05, 0.28269897991238147, 9.999999999998899e-05, 0.23908133336414406, 0.13193520804942815, 0.24539810911311077, 0.24730466715041133, 0.27321712325278513, 0.26889770321431294, 0.27826429694486543, 0.034031445935131854, 0.22639939623053063, 0.11329216229897343, 0.0005464581336184215, 0.0028274564175295724, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011824303895055732, 9.999999999998899e-05, 0.07734540503686005, 0.051825206644266264, 0.053755427355450025, 9.999999999998899e-05, 0.016997772659760435, 0.01856504569161721, 0.035138864361645705, 0.11793013858287393, 0.03702725627910186, 0.04997410380844247, 9.999999999998899e-05, 0.0355170764714714, 9.999999999998899e-05, 0.12811144880249703, 0.09381712145946208, 9.999999999998899e-05, 0.16303331099464013, 0.06798504904875458, 0.08630294451187714, 9.999999999998899e-05, 0.04551544026748611, 0.0792111997546936, 0.28958672963969345, 0.08497027109190514, 0.04916768542927452, 0.06896128146588909, 0.0811848467318772, 0.5453680246326386, 0.6059374564463781, 0.5482036416767506, 0.574201051986207, 0.5444807775511731, 0.5464293701109685, 0.5640266581412341, 0.606257169102498, 0.5707435203957928, 0.09804896932340923, 0.1270800465786791, 0.06356829575061906, 0.09281248318206092, 0.1097143799194491, 0.11934960097584768, 0.13452058688890978, 0.08852928799520665, 0.7521006607588321, 0.19011728893528268, 0.29285661241674377, 0.17061644223963157, 0.22697723694056104, 0.15924519539602588, 0.16489411896900497, 0.18841175697543833, 0.21859936573518113, 0.1741680983935856, 0.35316282062233584, 0.35505010574496976, 0.2576098597928467, 0.2411176537156674, 0.44061141526673164, 0.5058683832030331, 0.28683496984583134, 0.6620524756533267, 0.6096550024309486, 0.1698152745710122, 0.1999176452336764, 0.22219103500377813, 0.14869904352528573, 0.28269159156624146, 0.2438364566933091, 0.27595153170051634, 0.20072300624254125, 0.2717183922659586, 0.20072950678380053, 0.2202348957897583, 0.21661329936574936, 0.22178552189010425, 0.25051264265022577, 0.21947326122672173, 0.19300181363154045, 0.21587623656224464, 0.19784749355685283, 0.24981020660140196, 0.2212770493447498, 0.824056904812713, 0.22311815182926986, 0.24375292476063293, 0.1860792653763268, 0.19937435856907304, 0.7857148855301456, 0.19007947749365173, 0.17157759764176483, 0.14248253343273753, 0.9247654868607449, 0.17717936097829934, 0.1684810884069704, 0.1722702719465824, 0.16929626833120348, 0.16782717372717237, 0.12581223086879034, 0.11250519256676106, 0.110281448188003, 0.810161847592476, 0.15369723012120162, 0.1532978401194277, 0.16750522831231807, 0.16314013961371876, 0.12632882696875203, 0.20251799059177378, 0.20823784154963088, 0.1964035658630987, 0.19452889324004508, 0.21045825125930373, 0.21797262762157865, 0.1814849952436821, 0.19943190296959956, 0.20751514670402404, 0.18587789684870615, 0.09032111181973557, 0.09170493818214931, 0.10534887486715505, 0.0970331712778083, 0.11769785310509562, 0.09733108224656595, 0.10682638206787631, 0.09565054232814874, 0.10758949821991537]}, "mutation_prompt": null}
{"id": "967b6213-67ec-46a8-b053-908aa6b44b4b", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  # Crossover rate for DE\n        self.f = 0.8   # Mutation factor for DE\n        self.w = 0.5   # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n        self.f = max(0.5, self.f * 0.99)  # Adaptive mutation factor\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n        self.w = max(0.2, self.w * 0.99)  # Adaptive inertia weight", "name": "DE_PSO_Optimizer", "description": "An improved hybrid DE-PSO algorithm with adaptive parameters to enhance convergence and solution quality.", "configspace": "", "generation": 2, "fitness": 0.26271163461533126, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.27.", "error": "", "parent_id": "26aee497-20f1-4d2f-bfd9-591478e4ce55", "metadata": {"aucs": [0.9086842127574356, 0.9152041746950408, 0.9167165241560653, 0.19085215800099053, 0.9142045109106849, 0.1911939790240612, 0.9020676558386839, 0.8963404288562616, 0.9111807367376143, 0.8203765120442095, 0.07781377043009507, 9.999999999998899e-05, 0.04732225843863125, 0.814773773102445, 0.8074876161996769, 0.8122763584382664, 0.8222646107388991, 0.8073507330626265, 0.14218617335033645, 0.09198199435195498, 0.14465250066079083, 0.0662785587071576, 0.12315046532167895, 0.12156814912620362, 0.11294667197729535, 0.14121035491105105, 0.14410153016827787, 0.04969225329566829, 0.10891943389537462, 0.11966744281479258, 0.11210381555286353, 0.0806031134539773, 0.061949244215004584, 0.12967835034117592, 0.13018170492661096, 0.15319781883850514, 0.9928262989427238, 0.9912373185276375, 0.9927858073219232, 0.9909295394914551, 0.9925809627007401, 0.9905925541343731, 0.9909508406609482, 0.9928249682314239, 0.994117482252385, 0.808849296220814, 0.060158247257258934, 0.8429857766643691, 0.15357892117877858, 0.1752559022201593, 0.15071813458755046, 0.08758833720630521, 0.08796187696762858, 0.08869567642807086, 0.17091872011299725, 0.22753966761236355, 0.22266649260901772, 0.2139045821987362, 0.27721980310311556, 0.20743735400669905, 0.1160150525105268, 0.12853239236576597, 0.09472058901011282, 0.13081534785573345, 0.1308093556083273, 0.24280740888968388, 0.15200317301145438, 0.13070189402670584, 9.999999999998899e-05, 0.24978756563603233, 0.11751068203573145, 0.24873482435495597, 0.26500103984960166, 0.21225047567051358, 0.24394697169001023, 0.2927705836705917, 0.2685569359446811, 0.2819701361345458, 0.10273849533475787, 0.21825034927662212, 0.11367062904690572, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015868331939452585, 9.999999999998899e-05, 0.18566688373954543, 9.999999999998899e-05, 0.0779048164909183, 0.15272037379705106, 0.02381743423344873, 9.999999999998899e-05, 0.03034071696609464, 0.015914061326165352, 0.03746228164963161, 0.027639639442453512, 0.03107156123919852, 0.05058485079463948, 9.999999999998899e-05, 0.05331080738023852, 0.10890204434682982, 0.17010661058316712, 0.20278635539820733, 9.999999999998899e-05, 0.32815163269254355, 0.0734983890464711, 0.1124166547531058, 0.0592977949904544, 0.04267237098433052, 0.07903200526285858, 0.17248990304255163, 0.30707127462808814, 0.0484608476938172, 0.04913576951749743, 0.08285537291231482, 0.5780137313700873, 0.5370952326766973, 0.5435200972859534, 0.5379945867237697, 0.5819633564943787, 0.5853378008544734, 0.59004308136004, 0.572204096098315, 0.5706948856870814, 0.11557750609007456, 0.10072980738753323, 0.050097456245143945, 0.11098495451633339, 0.10453416762313827, 0.14867439961671114, 0.1270894412070378, 0.10871303721661751, 0.11373085698997454, 0.17027454709064493, 0.1647125848670128, 0.14864507137405925, 0.24584607727139896, 0.1626548902493039, 0.1520500795869355, 0.18964729003220238, 0.17789992514760855, 0.18756748867766204, 0.23540610086560831, 0.4563984895654376, 0.2263908103846629, 0.3497470199472842, 0.3336650917143045, 0.20050809441630935, 0.45223623326893114, 0.30977107910460655, 0.1763769816552916, 0.2435885709198491, 0.18885938848898332, 0.2386846120038948, 0.1281676578041493, 0.2806740763076362, 0.3985912402754308, 0.2544670467772009, 0.15551842849833664, 0.28365575506349994, 0.16751958003740997, 0.22847309015515171, 0.22383126247526897, 0.1854355591800274, 0.2306938674989456, 0.2971950773356, 0.2156982314645055, 0.22314394851516706, 0.17598714903884516, 0.24970506416993, 0.20980922838186655, 0.2485001420981695, 0.2503341427339153, 0.21501441003360677, 0.1951897999406479, 0.20103800129798133, 0.18765475379894814, 0.21001230271243043, 0.1416313349000451, 0.1418409462306789, 0.9304892706045897, 0.17723131502276446, 0.16862386575700206, 0.17800008813586088, 0.1694189362191344, 0.11621426790788791, 0.12006601620320323, 0.10867437149587877, 0.11071788465748922, 0.8662711640705849, 0.15363337904837848, 0.15407469903124182, 0.15379956953678775, 0.0934228144899758, 0.852712447785479, 0.1935851336916704, 0.2472730341733652, 0.18405726823447255, 0.20122168454935274, 0.20722855482502356, 0.1968215408000329, 0.2199456823241548, 0.20765762635123974, 0.18309128473924996, 0.21881413031287744, 0.10028915729071364, 0.07573880835192615, 0.09106580907165585, 0.04882956672663874, 0.09860476112960403, 0.09639989068557353, 0.07591676188491325, 0.09670720329890048, 0.09920873169648059]}, "mutation_prompt": null}
{"id": "bc76d129-e5ab-4384-b030-26fcc846daf1", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  # Crossover rate for DE\n        self.f = 0.8   # Mutation factor for DE\n        self.w = 0.5   # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]", "name": "DE_PSO_Optimizer", "description": "A hybrid differential evolution and particle swarm optimization (DE-PSO) algorithm for robust exploration and exploitation in diverse optimization landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "26aee497-20f1-4d2f-bfd9-591478e4ce55", "metadata": {"aucs": [0.8865739496332, 0.8788893187539866, 0.8952187104265327, 0.1904582085387766, 0.8637120213627044, 0.19108931914566152, 0.8729241513531614, 0.18287545720708787, 0.882976904156589, 0.07601357663787567, 0.7665276265514442, 0.6501216619048111, 0.04703333539416621, 9.999999999998899e-05, 0.7796687007384093, 0.7427848546634677, 0.7559541187160495, 0.7663773236506551, 0.1324603393897814, 0.1267898956459934, 0.14837178430025832, 0.06383685878687773, 0.17814791206673086, 0.14166714264653968, 0.16959926516959511, 0.06626952316242618, 0.11060485332971381, 0.15524491398985596, 0.10379470323277107, 0.13015829480300312, 0.1339876952274941, 0.14933008453995789, 0.11174992074901491, 0.11000466035818168, 0.11681690347750884, 0.11466274894972306, 0.9928285982780318, 0.9912563881878205, 0.9927857385872202, 0.9909317554052479, 0.99258085231718, 0.99059620847265, 0.9909482746463729, 0.9928254246855058, 0.9941182822967826, 0.7432028513689659, 0.06009821619840039, 0.7533745178028937, 0.17592979882587734, 0.7344407560287902, 0.15159297285079976, 0.08739436926698962, 0.758591185434224, 0.0883181128829843, 0.8269774136060711, 0.3831246432448786, 0.8130039468477023, 0.9001064110247516, 0.2781640146611213, 0.8497947059787283, 0.11591969985585016, 0.12795055942043965, 0.10914262960568177, 0.3367334728156214, 0.1272140191124217, 0.25215057390503126, 0.11819141570975933, 0.10135027860161339, 9.999999999998899e-05, 0.28269897991238147, 9.999999999998899e-05, 0.23908133336414406, 0.13193520804942815, 0.24539810911311077, 0.24730466715041133, 0.27321712325278513, 0.26889770321431294, 0.27826429694486543, 0.034031445935131854, 0.22639939623053063, 0.11329216229897343, 0.0005464581336184215, 0.0028274564175295724, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011824303895055732, 9.999999999998899e-05, 0.07734540503686005, 0.051825206644266264, 0.053755427355450025, 9.999999999998899e-05, 0.016997772659760435, 0.01856504569161721, 0.035138864361645705, 0.11793013858287393, 0.03702725627910186, 0.04997410380844247, 9.999999999998899e-05, 0.0355170764714714, 9.999999999998899e-05, 0.12811144880249703, 0.09381712145946208, 9.999999999998899e-05, 0.16303331099464013, 0.06798504904875458, 0.08630294451187714, 9.999999999998899e-05, 0.04551544026748611, 0.0792111997546936, 0.28958672963969345, 0.08497027109190514, 0.04916768542927452, 0.06896128146588909, 0.0811848467318772, 0.5453680246326386, 0.6059374564463781, 0.5482036416767506, 0.574201051986207, 0.5444807775511731, 0.5464293701109685, 0.5640266581412341, 0.606257169102498, 0.5707435203957928, 0.09804896932340923, 0.1270800465786791, 0.06356829575061906, 0.09281248318206092, 0.1097143799194491, 0.11934960097584768, 0.13452058688890978, 0.08852928799520665, 0.7521006607588321, 0.19011728893528268, 0.29285661241674377, 0.17061644223963157, 0.22697723694056104, 0.15924519539602588, 0.16489411896900497, 0.18841175697543833, 0.21859936573518113, 0.1741680983935856, 0.35316282062233584, 0.35505010574496976, 0.2576098597928467, 0.2411176537156674, 0.44061141526673164, 0.5058683832030331, 0.28683496984583134, 0.6620524756533267, 0.6096550024309486, 0.1698152745710122, 0.1999176452336764, 0.22219103500377813, 0.14869904352528573, 0.28269159156624146, 0.2438364566933091, 0.27595153170051634, 0.20072300624254125, 0.2717183922659586, 0.20072950678380053, 0.2202348957897583, 0.21661329936574936, 0.22178552189010425, 0.25051264265022577, 0.21947326122672173, 0.19300181363154045, 0.21587623656224464, 0.19784749355685283, 0.24981020660140196, 0.2212770493447498, 0.824056904812713, 0.22311815182926986, 0.24375292476063293, 0.1860792653763268, 0.19937435856907304, 0.7857148855301456, 0.19007947749365173, 0.17157759764176483, 0.14248253343273753, 0.9247654868607449, 0.17717936097829934, 0.1684810884069704, 0.1722702719465824, 0.16929626833120348, 0.16782717372717237, 0.12581223086879034, 0.11250519256676106, 0.110281448188003, 0.810161847592476, 0.15369723012120162, 0.1532978401194277, 0.16750522831231807, 0.16314013961371876, 0.12632882696875203, 0.20251799059177378, 0.20823784154963088, 0.1964035658630987, 0.19452889324004508, 0.21045825125930373, 0.21797262762157865, 0.1814849952436821, 0.19943190296959956, 0.20751514670402404, 0.18587789684870615, 0.09032111181973557, 0.09170493818214931, 0.10534887486715505, 0.0970331712778083, 0.11769785310509562, 0.09733108224656595, 0.10682638206787631, 0.09565054232814874, 0.10758949821991537]}, "mutation_prompt": null}
{"id": "9b61dd34-7af9-454b-bb25-d78176e98665", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  # Crossover rate for DE\n        self.f = 0.8   # Mutation factor for DE\n        self.w = 0.5   # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]", "name": "DE_PSO_Optimizer", "description": "A hybrid differential evolution and particle swarm optimization (DE-PSO) algorithm for robust exploration and exploitation in diverse optimization landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "26aee497-20f1-4d2f-bfd9-591478e4ce55", "metadata": {"aucs": [0.8865739496332, 0.8788893187539866, 0.8952187104265327, 0.1904582085387766, 0.8637120213627044, 0.19108931914566152, 0.8729241513531614, 0.18287545720708787, 0.882976904156589, 0.07601357663787567, 0.7665276265514442, 0.6501216619048111, 0.04703333539416621, 9.999999999998899e-05, 0.7796687007384093, 0.7427848546634677, 0.7559541187160495, 0.7663773236506551, 0.1324603393897814, 0.1267898956459934, 0.14837178430025832, 0.06383685878687773, 0.17814791206673086, 0.14166714264653968, 0.16959926516959511, 0.06626952316242618, 0.11060485332971381, 0.15524491398985596, 0.10379470323277107, 0.13015829480300312, 0.1339876952274941, 0.14933008453995789, 0.11174992074901491, 0.11000466035818168, 0.11681690347750884, 0.11466274894972306, 0.9928285982780318, 0.9912563881878205, 0.9927857385872202, 0.9909317554052479, 0.99258085231718, 0.99059620847265, 0.9909482746463729, 0.9928254246855058, 0.9941182822967826, 0.7432028513689659, 0.06009821619840039, 0.7533745178028937, 0.17592979882587734, 0.7344407560287902, 0.15159297285079976, 0.08739436926698962, 0.758591185434224, 0.0883181128829843, 0.8269774136060711, 0.3831246432448786, 0.8130039468477023, 0.9001064110247516, 0.2781640146611213, 0.8497947059787283, 0.11591969985585016, 0.12795055942043965, 0.10914262960568177, 0.3367334728156214, 0.1272140191124217, 0.25215057390503126, 0.11819141570975933, 0.10135027860161339, 9.999999999998899e-05, 0.28269897991238147, 9.999999999998899e-05, 0.23908133336414406, 0.13193520804942815, 0.24539810911311077, 0.24730466715041133, 0.27321712325278513, 0.26889770321431294, 0.27826429694486543, 0.034031445935131854, 0.22639939623053063, 0.11329216229897343, 0.0005464581336184215, 0.0028274564175295724, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011824303895055732, 9.999999999998899e-05, 0.07734540503686005, 0.051825206644266264, 0.053755427355450025, 9.999999999998899e-05, 0.016997772659760435, 0.01856504569161721, 0.035138864361645705, 0.11793013858287393, 0.03702725627910186, 0.04997410380844247, 9.999999999998899e-05, 0.0355170764714714, 9.999999999998899e-05, 0.12811144880249703, 0.09381712145946208, 9.999999999998899e-05, 0.16303331099464013, 0.06798504904875458, 0.08630294451187714, 9.999999999998899e-05, 0.04551544026748611, 0.0792111997546936, 0.28958672963969345, 0.08497027109190514, 0.04916768542927452, 0.06896128146588909, 0.0811848467318772, 0.5453680246326386, 0.6059374564463781, 0.5482036416767506, 0.574201051986207, 0.5444807775511731, 0.5464293701109685, 0.5640266581412341, 0.606257169102498, 0.5707435203957928, 0.09804896932340923, 0.1270800465786791, 0.06356829575061906, 0.09281248318206092, 0.1097143799194491, 0.11934960097584768, 0.13452058688890978, 0.08852928799520665, 0.7521006607588321, 0.19011728893528268, 0.29285661241674377, 0.17061644223963157, 0.22697723694056104, 0.15924519539602588, 0.16489411896900497, 0.18841175697543833, 0.21859936573518113, 0.1741680983935856, 0.35316282062233584, 0.35505010574496976, 0.2576098597928467, 0.2411176537156674, 0.44061141526673164, 0.5058683832030331, 0.28683496984583134, 0.6620524756533267, 0.6096550024309486, 0.1698152745710122, 0.1999176452336764, 0.22219103500377813, 0.14869904352528573, 0.28269159156624146, 0.2438364566933091, 0.27595153170051634, 0.20072300624254125, 0.2717183922659586, 0.20072950678380053, 0.2202348957897583, 0.21661329936574936, 0.22178552189010425, 0.25051264265022577, 0.21947326122672173, 0.19300181363154045, 0.21587623656224464, 0.19784749355685283, 0.24981020660140196, 0.2212770493447498, 0.824056904812713, 0.22311815182926986, 0.24375292476063293, 0.1860792653763268, 0.19937435856907304, 0.7857148855301456, 0.19007947749365173, 0.17157759764176483, 0.14248253343273753, 0.9247654868607449, 0.17717936097829934, 0.1684810884069704, 0.1722702719465824, 0.16929626833120348, 0.16782717372717237, 0.12581223086879034, 0.11250519256676106, 0.110281448188003, 0.810161847592476, 0.15369723012120162, 0.1532978401194277, 0.16750522831231807, 0.16314013961371876, 0.12632882696875203, 0.20251799059177378, 0.20823784154963088, 0.1964035658630987, 0.19452889324004508, 0.21045825125930373, 0.21797262762157865, 0.1814849952436821, 0.19943190296959956, 0.20751514670402404, 0.18587789684870615, 0.09032111181973557, 0.09170493818214931, 0.10534887486715505, 0.0970331712778083, 0.11769785310509562, 0.09733108224656595, 0.10682638206787631, 0.09565054232814874, 0.10758949821991537]}, "mutation_prompt": null}
{"id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.31067467730988807, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "26aee497-20f1-4d2f-bfd9-591478e4ce55", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "39914d9e-f0ac-4cc0-b563-4756354d45db", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "e266c75b-caa2-4cc6-90a2-813f06478b75", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "5bfc003e-e385-42b6-9ddf-8f972b688646", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._enhanced_local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _enhanced_local_search(self, func):\n        if self.evaluations < self.budget:\n            levy_step = self._levy_flight(self.dim)\n            local_candidate = self.global_best + levy_step\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta *\n                  2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm with enhanced local search using Lvy flights for escaping local optima.", "configspace": "", "generation": 8, "fitness": 0.2877572049813412, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.27.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8743019766348268, 0.8652395942765002, 0.875550274739587, 0.8668020361578125, 0.8580698614569922, 0.7584366028256716, 0.8826805446196104, 0.8113367907895205, 0.8746843373911112, 0.7495881972541361, 0.041699490673049566, 0.7193878085581287, 0.727331199669885, 0.04647845400136952, 0.7637437669805385, 0.05849755576498106, 0.05063128476030865, 0.7622845682529542, 0.1762480501789856, 0.11530429704774547, 0.15107764878269303, 0.1128502236033484, 0.12704207131787348, 0.07195269615866362, 0.18081912972017233, 0.10852223709311293, 0.14969937144138534, 0.13609156112258047, 0.0975745015156061, 0.13838058159177213, 0.12292429686958362, 0.14122539434444448, 0.09721692963530948, 0.1290481360359199, 0.12969183547637209, 0.10588518351725795, 0.9926411637883098, 0.9934298529619527, 0.9930179974086036, 0.990635926279496, 0.9938762470805284, 0.9940152851634679, 0.9932551618077384, 0.9898483100090144, 0.9869190145122511, 0.7239252559529687, 0.7496578756303208, 0.7651968114169636, 0.7516590436226146, 0.15374525027008878, 0.1537137796924719, 0.7370969507590446, 0.5447532248996899, 0.351853978276526, 0.729738169963163, 0.8339529300509967, 0.22729408411998075, 0.15808327998491223, 0.1548249638191157, 0.21235033593057895, 0.15182742216853384, 0.16220839377179275, 0.1762404917202881, 0.2609821363608624, 0.28832815520066046, 0.13083178854763755, 0.2697159088571863, 0.10498937534186537, 0.13230430023222162, 0.12579406264064252, 0.2737974086839803, 0.24159534709353403, 0.23869875454106737, 0.34131215933875536, 0.23187193300867348, 0.2507912158397888, 0.2902600721716141, 0.27426252047788235, 0.2749576737326026, 0.13209940738150594, 0.2850293631711893, 0.02834699962540832, 0.00020687457517598595, 0.001041192350032194, 9.999999999998899e-05, 9.999999999998899e-05, 0.10262362698504457, 9.999999999998899e-05, 0.0007717950756636061, 0.03516848298114983, 0.02874223144104071, 0.05688610695263285, 0.0764420776843101, 0.022640263685478224, 0.0005113581824293112, 0.020191631747525807, 0.0450716978940362, 0.10152010778339371, 0.09590698408026799, 9.999999999998899e-05, 0.20058042780954388, 0.04737205382843657, 0.07666077302323504, 0.07688647301578733, 0.09435547102997355, 0.09909310081903855, 0.11003071362828087, 0.1405143270320789, 0.1677118050288463, 0.06343632576206526, 0.05097848492264345, 0.07497394165141902, 0.07424901486648938, 0.18529907265755752, 0.049634624037360076, 0.05662190469498585, 0.08661367715838753, 0.5476635562939989, 0.5732457720001551, 0.5653210800711945, 0.570251963718318, 0.5476368363175796, 0.5929225276821487, 0.5842640182209288, 0.6192269088036382, 0.5844192306400304, 0.0987800944494287, 0.07904319645028313, 0.07267187743832715, 0.09073693799172522, 0.18413432630203452, 0.11938384391887702, 0.06806391284051094, 0.17300814584536817, 0.11022119449067902, 0.2577359444538081, 0.25273245143627365, 0.15976936243362894, 0.27148080726086565, 0.22729219714355287, 0.219947328496495, 0.26647748968272944, 0.11506434574483115, 0.3566154801461796, 0.2931268214581785, 0.33591119323062735, 0.18491141736238537, 0.46237030494653597, 0.17838899654104512, 0.2765117352058081, 0.6843274749959539, 0.4106477803971794, 0.2591274245637931, 0.2378510420010087, 0.2652538965846174, 0.17166870397502154, 0.2558014422116486, 0.19308048399294753, 0.22301153214164737, 0.2507844209852319, 0.28102173038953127, 0.18112463450552274, 0.2284013850291029, 0.2364809710196475, 0.22954634910993255, 0.20745220699503053, 0.21396758299500984, 0.2003936707044105, 0.2916669926275792, 0.2124822605321497, 0.19277704696933162, 0.20977998115454388, 0.2031591651388086, 0.24423026297226702, 0.1869686702297978, 0.20371477729845178, 0.20634382277274377, 0.24660355165708403, 0.20709393274103582, 0.2029042902466046, 0.20016811798657763, 0.16507406342366415, 0.13587243978370078, 0.9086336166437927, 0.17906325719608196, 0.18810351961526317, 0.18531216828654618, 0.16833923634706283, 0.9152764435995574, 0.16648808320799102, 0.2118257922144966, 0.16828231630427126, 0.12142348525853686, 0.12732657384961732, 0.1534567989936786, 0.210050663736696, 0.15483855279026792, 0.8451022270066691, 0.20364844699046714, 0.1870140566523102, 0.19504611932750704, 0.18370428769483116, 0.21086474079241524, 0.18552937848003537, 0.22060253116015083, 0.20852455094835343, 0.18558782654589367, 0.08012568121328045, 0.09577643440876493, 0.10417484430733182, 0.0896234478292618, 0.09734263872389382, 0.09775634140643485, 0.08089786949878164, 0.08535427063263212, 0.0991817712044809]}, "mutation_prompt": null}
{"id": "f3e7ac9d-8f56-4db6-96aa-39bc0eaec758", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9\n        self.f = 0.8\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._dynamic_population()\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _dynamic_population(self):\n        if self.evaluations < self.budget // 2:\n            self.population_size = min(50, self.population_size + 2)\n            self.pop = np.vstack((self.pop, np.random.uniform(-5, 5, (2, self.dim))))\n            self.velocity = np.vstack((self.velocity, np.zeros((2, self.dim))))\n            self.personal_best = np.vstack((self.personal_best, self.pop[-2:]))\n            self.personal_best_values = np.hstack((self.personal_best_values, np.full(2, np.inf)))\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm with dynamic population resizing and adaptive parameter tuning for improved exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.2809045621563592, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.7904848881874966, 0.8211519926010802, 0.808047180645542, 0.8106914568615101, 0.817713672670968, 0.8180517395565617, 0.8174020745974802, 0.8062310326039775, 0.7598922295411199, 0.07312046902998603, 0.5370324988143802, 0.2211864427102781, 0.05914785302077874, 0.5212650803160902, 0.48389822493303636, 0.5508406821032616, 0.4356040520739711, 0.5177215893689155, 0.15509657842942237, 0.14689233838398652, 0.12861782513225184, 0.1255316265407873, 0.15590092093932761, 0.16234543468802476, 0.13960028128605695, 0.16112083654987763, 0.12023285929022842, 0.10468831207212037, 0.11840267019566342, 0.14790644686938104, 0.134115263723673, 0.1180572012156641, 0.11568230822708103, 0.1087997998013901, 0.11383021068164034, 0.12657621431246813, 0.9925812552249329, 0.9929895983321221, 0.9880527067359255, 0.9930040488580936, 0.991904297175105, 0.9887039645888648, 0.9929699881168451, 0.9934279595771509, 0.990119893352158, 0.49846724318593016, 0.4834521299892559, 0.5105960985040402, 0.5183181997397752, 0.4456961547636734, 0.523755946691083, 0.4896352771558309, 0.48883111256442524, 0.5054659941953952, 0.17163295965006986, 0.22069965139045167, 0.5549884043119631, 0.11707536428276288, 0.1872306132289573, 0.21811457169002246, 0.23634300879148673, 0.36252775563665796, 0.7013751451385025, 0.21729631909649327, 0.21156696376203477, 0.09425158650744603, 0.1301867944451044, 0.18200492177886662, 0.10722716894210371, 0.1261747279066351, 0.19985643841116085, 0.2085807983972775, 0.2242628614481107, 0.2053492914041798, 0.21397914922105177, 0.2035366339391259, 0.17356621195817057, 0.12861716406152446, 0.19974034508414795, 0.23639697989612574, 0.1327799003241833, 0.00025814532767931553, 9.999999999998899e-05, 9.999999999998899e-05, 0.025565548859965537, 0.0002236047715862277, 0.014629481167042657, 9.999999999998899e-05, 0.005243471577992764, 9.999999999998899e-05, 0.05717495900229408, 0.04049170725155893, 0.0851248089003731, 0.044884389278796344, 0.0004802998510958778, 0.052210530298535174, 0.04313307456040216, 0.016708063286923425, 0.13210838011635861, 0.03245878937549673, 0.08905088411953477, 0.20230569142131571, 0.07730803614343551, 0.15732783208514034, 0.07446877344276293, 0.09282734317747798, 0.06429518149457869, 0.08906013852977757, 0.0756416630409702, 0.15912054082915295, 0.042194990995834125, 0.09692915541731018, 0.12581859295099296, 0.09463445167178874, 0.055343901426329056, 0.08867558782981289, 0.0818834595502147, 0.5019556988751607, 0.5420510566636352, 0.5560679506630164, 0.5624807887496668, 0.5329039049505548, 0.5273125259634802, 0.5299961312798722, 0.5476602220342768, 0.5359482303895444, 0.10664070183567509, 0.1555087211792079, 0.11086614044145371, 0.12479109458487714, 0.10499570597354069, 0.14451432099681316, 0.07953859486739023, 0.09333501960547497, 0.07984772391989514, 0.32873784115941374, 0.14961750487997338, 0.22887262417319953, 0.28883918888075877, 0.27644652258349434, 0.30047638554290856, 0.22026343678168536, 0.18660659974070704, 0.20569316521224634, 0.3250605638799917, 0.30636757568548323, 0.34831939442887083, 0.382912503341154, 0.29600431421784124, 0.2618190076966985, 0.28187088632302604, 0.32520056688086607, 0.21049604076799333, 0.23177656950988534, 0.33517277023324754, 0.2712420058047562, 0.23808131168969238, 0.2209582729235714, 0.29916451262631594, 0.2029302149633866, 0.24819941872353457, 0.2507632942118134, 0.2167082052703052, 0.1996443460185383, 0.2295132040157125, 0.19916605580503932, 0.21816604829018216, 0.2041545443783982, 0.20852375867547557, 0.19531541294365484, 0.2518921754149319, 0.21319471973958426, 0.24391870442662655, 0.21467581311830208, 0.20234405773817976, 0.2151662202186082, 0.20962482072056177, 0.4726204504315079, 0.21897400736101846, 0.21540868007573633, 0.17004322788634563, 0.15978847304257238, 0.8134793548473873, 0.17830275911886873, 0.2084551644288798, 0.8251226998972913, 0.8382048082148821, 0.12516159163633278, 0.2102900228445782, 0.15488992858961903, 0.12524502081150346, 0.49970177894249546, 0.16831084507725447, 0.20553919658884867, 0.6135234630500639, 0.7810319301302925, 0.12758540382860484, 0.15381804029904012, 0.18064310135073536, 0.21436188857387384, 0.1921215815490367, 0.18498017576242975, 0.2046722853495082, 0.21150618748821404, 0.19116165343885871, 0.1982240785625835, 0.17661537238052627, 0.09500554774359449, 0.0893224430859858, 0.09123276897853394, 0.0902118756313186, 0.07958838136653867, 0.0825781846157948, 0.08091581982428475, 0.08256231722838347, 0.079674437946883]}, "mutation_prompt": null}
{"id": "ce5f212e-1553-4e98-85a7-628913bbf4f4", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "262af687-d4da-4ca4-8b3c-c9d426874e05", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "89bd20d1-190f-40c2-9f80-32b5d730a90c", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "ce78411a-cfe2-4825-ab2c-1ede001dc68f", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "cedd0b95-5c4d-4826-99ff-ddebe4289c88", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "bef13e5d-da1f-43f7-bb48-275d36bbaeea", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "27915359-ec4b-4c13-bb32-0f9f37570748", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "a2f26f39-a082-4900-a601-baf2bced16ce", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "80c2342d-a4c7-49ef-b7f0-5e687ac9534a", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "06a27d3d-1af2-4ae9-abdb-59c53cc723cf", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.9  # Adaptive inertia weight\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._update_inertia_weight()  # Update inertia weight\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _update_inertia_weight(self):\n        diversity = np.mean(np.std(self.pop, axis=0))\n        self.w = 0.9 - 0.5 * (diversity / self.dim)", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm with adaptive inertia weight and diversity preservation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.20157415820947186, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.45743377428787513, 0.47506806846675687, 0.41697804638086844, 0.41713768325820255, 0.39108129515427403, 0.4253065524632339, 0.4328544810521723, 0.4958505913649991, 0.42220319816642937, 0.02735196990681199, 0.03882963384957783, 0.03140250213509421, 0.0879722979356573, 0.07594624105471992, 0.05052173750260158, 0.07953164790174427, 0.01938174783823121, 0.039923832557071215, 0.10011384644549814, 0.11326119590362071, 0.12465041116559727, 0.11956016129837277, 0.11745764530929714, 0.10765761659234885, 0.1297268666664726, 0.10271056986977056, 0.10324126747269169, 0.12741684349763438, 0.10479495301171815, 0.0959596368111455, 0.0428862889810121, 0.11467850206968722, 0.1096429243531255, 0.10845595827671206, 0.10989583968698624, 0.09557973093228922, 0.9930358170044669, 0.9940326656141606, 0.9929518729901864, 0.9909264022442357, 0.9939532739354614, 0.994007232401053, 0.9913843023460467, 0.9939210920594593, 0.9919682715366477, 0.23343678511979993, 0.24527577822595448, 0.20756171913020705, 0.26605714322925245, 0.2609406999644541, 0.16547599783630162, 0.20731672411375002, 0.25147569719407814, 0.23838576008121803, 0.2192843333054849, 0.21914257625471112, 0.22812860758547493, 0.26495452472788994, 0.26677550330540656, 0.20535861298728064, 0.16451602508257002, 0.15027553904543656, 0.22289494328883763, 0.13830472122372972, 0.13857520832564874, 0.1313861506512931, 0.12262015345940158, 0.13808122824623992, 0.1226364686534216, 0.12499268851902512, 0.12357463547382197, 0.18202477478696244, 0.09878728863595787, 0.12396822775067706, 0.16004301104161145, 0.10771632154922028, 0.13278687984957227, 0.12233948219685276, 0.1465616164942799, 0.16977800436556623, 0.13320139283004717, 0.026403917802848675, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02838576516543978, 0.05244585302846627, 0.06014959062831626, 0.027601763125350565, 0.025752765337054728, 0.0017835781222192981, 0.0742322451246007, 0.06418459051740133, 0.08409906641560772, 9.999999999998899e-05, 0.013729500601779132, 9.999999999998899e-05, 0.001730799321816301, 9.999999999998899e-05, 0.0260577755939867, 0.05033375220793079, 0.03801696217683015, 0.00028938818103196873, 0.05592316935145736, 0.03586888362331064, 0.07813422816587956, 0.0571127985600991, 0.00561906288223657, 0.03478011579988782, 0.12191391621207348, 0.06445272068209051, 0.06765764633066096, 0.3668321784221884, 0.42435170945123113, 0.39184940912013966, 0.36133599703679997, 0.3707433071805363, 0.40543182078981, 0.3986125212085738, 0.4050158440737195, 0.4118922169955286, 0.1162082513041458, 0.1084920534426328, 0.08790513258920907, 0.0846581161826514, 0.13151509554103757, 0.10477054076871595, 0.11658316960110371, 0.13343080082481917, 0.12552142852969905, 0.18040347084006603, 0.17038828101512915, 0.16764514124811503, 0.16890362977343343, 0.19667613036397802, 0.16000458000431772, 0.24616444678867622, 0.16482306428430837, 0.22484399467816163, 0.2916243840511079, 0.27250338169148713, 0.2187024374328681, 0.2255818304738415, 0.19313837513209797, 0.2791619616354255, 0.30115103042384794, 0.33453206185202167, 0.28390412980142554, 0.20081323717917, 0.20123208715502783, 0.20262439870186089, 0.18232377521964094, 0.18379264126426742, 0.22174497703393004, 0.16848549035065175, 0.1948462689279482, 0.20963567779702674, 0.1898206730973, 0.22627372653040922, 0.18017452732380657, 0.216361519039724, 0.18821223664543152, 0.17939653899597507, 0.1476267429242818, 0.19426663658329513, 0.18309574251850014, 0.20459955280708642, 0.23274475659914418, 0.19173602863094852, 0.1992589007728086, 0.19629829855486092, 0.17996917924101186, 0.1890189561998915, 0.19560122208781572, 0.19552407409445027, 0.19926832139926354, 0.5184130375705369, 0.7937575885501242, 0.17429736816351016, 0.1763918708377551, 0.17611965081709424, 0.18647955018131612, 0.18655879914917295, 0.15672788559979456, 0.16757079151771925, 0.19892851618795182, 0.24585545126769826, 0.12314989205907878, 0.12783221785972676, 0.14353435792695124, 0.2095462036046698, 0.34896236958860316, 0.3109467404948033, 0.20060425330212894, 0.18262351247138964, 0.20021227527003815, 0.18562549213188917, 0.19261464813512263, 0.18503135237931223, 0.18276629025089208, 0.19016708630541024, 0.19732562561622713, 0.09489291070262185, 0.07731782887633487, 0.06897354250934118, 0.07702728111395096, 0.0730331675426269, 0.07653378386833609, 0.07576233036631697, 0.08445556198421422, 0.08888925757304911]}, "mutation_prompt": null}
{"id": "00d38001-a2a1-47ae-8905-27e7707b2648", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "69c52cb6-2439-47dc-8797-a9818fbfb83c", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n        self.elite_archive = []  # New elite archive\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.5) * (b - c), -5, 5)  # Slightly increased F range\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n                self.elite_archive.append(trial)  # Storing new elite solution\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n                self.elite_archive.append(self.pop[i])  # Storing new elite solution\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            if self.elite_archive:\n                elite_candidate = self.elite_archive[np.random.randint(len(self.elite_archive))]  # Random elite\n                local_candidate = elite_candidate + np.random.uniform(-0.1, 0.1, self.dim)\n            else:\n                local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm with adaptive parameters, improved local search, and an elite archive for enhanced exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.28789675124374586, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.28.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8888304388101416, 0.879847089705357, 0.8793801546891787, 0.8811685603144563, 0.8570612005939593, 0.866063039421832, 0.8553123008693112, 0.8778340313886067, 0.8774155904651771, 0.7526343817228681, 0.7389089002627081, 0.7629005452812129, 0.7412423813369686, 0.7265240324489207, 0.7387251852964273, 0.017535858959855766, 0.05164727157657001, 0.0062708171577807725, 0.112584028725083, 0.13794090877116416, 0.1213234400391513, 0.12079469221540384, 0.1807835460984325, 0.110149946904321, 0.052401174457499256, 0.14451787661450566, 0.05566421826333312, 0.09812465137451365, 0.12791640781062774, 0.11327001811310633, 0.1286304781646488, 0.11727530770803751, 0.10695110566965327, 0.10487419368259632, 0.1512513253504425, 0.12491805076257256, 0.9931421827321636, 0.9954025155802667, 0.9907875597755293, 0.990536134109953, 0.9951163144641707, 0.994091989332637, 0.9909496802258714, 0.9939219413644462, 0.9934450977065884, 0.6976344590134291, 0.7230883249689355, 0.6145735543092807, 0.7010019758487365, 0.7230826658609024, 0.7238963299073317, 0.6282667020645694, 0.7364341103051221, 0.7044329593683375, 0.6445023129027202, 0.8234287486293801, 0.22208356161954068, 0.1918623020445659, 0.16032393213481522, 0.2114096952872434, 0.24272977466851486, 0.12034042496035213, 0.23361603092115402, 0.2403215428396991, 0.2428496832160898, 0.23822970126080378, 0.13289417289288885, 0.2535704603593636, 0.1302853973621868, 0.21828705072873966, 0.2754589242740393, 0.24089722353671228, 0.10876876073757535, 0.2355972220415361, 0.23471121542062956, 0.22182072577559075, 0.2618943886292091, 0.28070908822511165, 0.1346807113979156, 0.1070529792291749, 0.281573579695802, 9.999999999998899e-05, 0.06868745706045598, 0.0891980002841607, 9.999999999998899e-05, 0.004417785711603894, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02284543584793952, 0.042433169067091714, 0.006699446298616185, 0.0071288963082289936, 0.005525797711242952, 0.04537087830914466, 0.028333133877371464, 0.10750175128659012, 0.05270085871763874, 0.035641524647077816, 0.07583705412412511, 0.036591014747124784, 0.0747632789070487, 0.08241060992406624, 0.09085225032580635, 0.09736103607135538, 0.15332730529879468, 0.2437812925275492, 0.042199420228363094, 0.07484064553811043, 0.1947136596454474, 0.07497770878071242, 0.23742688278202873, 0.13362793346242885, 0.053839359158753486, 0.056944628230597094, 0.0571573395566205, 0.5549578463077103, 0.5147288873054747, 0.5618136152474061, 0.5533590616974245, 0.5926025863881301, 0.5923800307521179, 0.5757704418368741, 0.5646248197549978, 0.6204174949222958, 0.11140322653870494, 0.05155943777596328, 0.11968769379482513, 0.10484711390324408, 0.12579104135137764, 0.14293921449188185, 0.12160932038206096, 0.12973068724559322, 0.10888050041637543, 0.1673185388764732, 0.20720204767435746, 0.2223454968070505, 0.23739353586070588, 0.22740284675542954, 0.18180237066265115, 0.2431982660646964, 0.18793389526776172, 0.20381513459180156, 0.1635240982652223, 0.2647400335140796, 0.4258658866657633, 0.20904513869625663, 0.13948213645166907, 0.5613696281611962, 0.1817765092726541, 0.5263464239670063, 0.5150773954320472, 0.24994860512822759, 0.18704763303398975, 0.1540621280305109, 0.19207606509908726, 0.2247794267204999, 0.21377501962180645, 0.27999307397956785, 0.25796261840285184, 0.38179543313316666, 0.19545642783200623, 0.21329869562000026, 0.22985680340667847, 0.18505603959093297, 0.20716484455560713, 0.19511971821283247, 0.1595062354209431, 0.24411974468290776, 0.21832266623272012, 0.19203041753566397, 0.19717523668466164, 0.21988876220739495, 0.19803285058329012, 0.2101517841231595, 0.18394364086911474, 0.17136294092440874, 0.20791975627778714, 0.20315059851361106, 0.19983065554146484, 0.17274661053169382, 0.16172742690440067, 0.18485772608354245, 0.17845764469309489, 0.18766562198843584, 0.18829822900445692, 0.1460465239870835, 0.9064495450538503, 0.1680664674609097, 0.16705226440672505, 0.6411636421143543, 0.12385288732606148, 0.12809703257230998, 0.15379950308440038, 0.20956509884800134, 0.12792435132795232, 0.12753423080294146, 0.1993826700521688, 0.19089331692690725, 0.18263571703651904, 0.19604867526952818, 0.18550039381936745, 0.19244875656686278, 0.1765281250937284, 0.19526716082592188, 0.18909275598146325, 0.106402353573129, 0.100692273537755, 0.08215069156212251, 0.08392934598005364, 0.08677026457370607, 0.10690430742983625, 0.08561447306915337, 0.09229818503031206, 0.08815095787403349]}, "mutation_prompt": null}
{"id": "7f2ae59c-2f25-4d4b-982a-09e2d3a6719d", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._dynamic_strategy_adjustment(func)\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n        return self.global_best_value, self.global_best\n\n    def _dynamic_strategy_adjustment(self, func):\n        self.f = 0.5 + 0.5 * np.sin(0.5 * np.pi * self.evaluations / self.budget)  # Dynamic F adaptation\n        if self.evaluations % (self.budget // 10) == 0:  # Periodic chaos-based local search\n            self._chaos_local_search(func)\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)  # Updated F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _chaos_local_search(self, func):\n        local_candidate = self.global_best + np.random.uniform(-0.05, 0.05, self.dim) * np.sin(self.evaluations)\n        local_candidate = np.clip(local_candidate, -5, 5)\n        f_local = func(local_candidate)\n        self.evaluations += 1\n        if f_local < self.global_best_value:\n            self.global_best_value = f_local\n            self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm with dynamic strategy adaptation and chaos-based local search for enhanced exploration and convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\")", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {}, "mutation_prompt": null}
{"id": "e172de73-86cf-457d-9d34-1d05591c0ef8", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "f45ac71b-bb1e-438e-8867-e39da7fdda16", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n        self.f_min, self.f_max = 0.5, 1.0  # Added for adaptive F\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_fractal_search(func)  # Replaced local search\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            self.f = np.random.uniform(self.f_min, self.f_max)  # Adaptive F\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_fractal_search(self, func):  # Replaced local search\n        if self.evaluations < self.budget:\n            step_size = np.random.uniform(0.01, 0.1, self.dim)\n            candidate = self.global_best + step_size * np.random.normal(size=self.dim)\n            candidate = np.clip(candidate, -5, 5)\n            f_candidate = func(candidate)\n            self.evaluations += 1\n            if f_candidate < self.global_best_value:\n                self.global_best_value = f_candidate\n                self.global_best = candidate", "name": "DE_PSO_Optimizer", "description": "A DE-PSO variant with self-adaptive parameter tuning and stochastic fractal search for enhanced exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.29592999595202163, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.28.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8798785025217737, 0.8812834210054767, 0.8746636315672763, 0.8862896248609758, 0.8898400815971819, 0.8845920303625056, 0.8741353618571635, 0.8822410142482653, 0.8788467404308157, 0.1710345158062262, 0.7473100909925672, 0.7664289542639312, 0.0471693789992772, 0.7159761695041991, 0.7448255655177061, 0.01823801490391619, 0.7025576237146618, 0.7582567211580888, 0.10373957236894871, 0.1257318893751368, 0.1612694625663238, 0.0707482088824305, 0.11527817670340101, 0.12994216040157902, 0.17371653450295943, 0.11410532744325119, 0.7115766715293996, 0.15309647782951175, 0.09710630788271446, 0.1035469401557284, 0.11025009624763948, 0.11259300605341249, 0.1185347126564168, 0.11165863879989446, 0.07140748350057369, 0.09666028636388269, 0.9929548765924102, 0.9934298529619527, 0.9929843641510939, 0.9936367472092449, 0.9937781065446022, 0.9940152851634679, 0.9904932670682202, 0.989851762895595, 0.9830237356877802, 0.7667661705066097, 0.7541728853504764, 0.7563433351061343, 0.7500839179176226, 0.766477785137587, 0.7040303423204772, 0.7587114358178408, 0.7063433649231625, 0.7219800203030895, 0.21448005752580757, 0.22434645482478277, 0.2132732812489333, 0.2112589320409547, 0.16092070101650846, 0.20670430624815372, 0.17627301466198553, 0.11596766042562501, 0.1766359543078606, 0.12487801866236592, 0.257538665533386, 0.25442150106332784, 0.1331896711777072, 0.13361830915591977, 0.25993276227193196, 0.25654652955000223, 0.24998140866594254, 0.24380271434765577, 0.13205031280798307, 0.26447305091833295, 0.24340228863989977, 0.1496119180173775, 0.27628334831675205, 0.29597938361815856, 0.1310910546165429, 0.2911319779222157, 0.1345886380663085, 0.05072879315451295, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06526329959014876, 9.999999999998899e-05, 0.038218575807242305, 0.0019584672485001287, 0.05258556163767658, 0.04942799853336255, 0.06239602226549901, 0.01695945215859007, 0.0017454286624480897, 0.00860673002467649, 0.06290902231599516, 0.19214269507563253, 0.1836479156872559, 0.27271449156521543, 0.13372393454746812, 0.049774084168912824, 0.07489350076856593, 0.07661052809711022, 0.09364532486242638, 0.10636413032917169, 0.0981069517154527, 0.09198907962205616, 0.19852604329365386, 0.04308347844546956, 0.071883451855696, 0.21666565764218393, 0.20875293315337395, 0.08977271407121112, 0.08249713722659957, 0.08346450847448361, 0.059690084617298855, 0.5590797824229728, 0.5626389615638676, 0.6107636015102671, 0.5624937618217507, 0.6034898519836123, 0.5646005911300395, 0.6241766486456457, 0.5616161916313684, 0.5729681006922545, 0.11983067667378744, 0.1088603729840042, 0.08216112006587861, 0.068469852102094, 0.08114737458645982, 0.13929956299494484, 0.13219706740103843, 0.15257753555343612, 0.14362004532912775, 0.14511920940559264, 0.1800611092935176, 0.16186505944779472, 0.24119437808760968, 0.2373204160525515, 0.19188859580039985, 0.23965447070739487, 0.1168229647156368, 0.20309199357322316, 0.20552138818344767, 0.4291474564148019, 0.23503275189441408, 0.44254678310113027, 0.2361242007664025, 0.37216081689952485, 0.602303166427941, 0.5776728509592237, 0.397956221659032, 0.2906657564458762, 0.25111035539598003, 0.17350489160105176, 0.17719472910762013, 0.22545372219119808, 0.2082255872691492, 0.36071198605067856, 0.2608153392045679, 0.3496538836420676, 0.2038275827191084, 0.22317594131009433, 0.2556145878919609, 0.20737696918602455, 0.2320715149284417, 0.20463384560979359, 0.18872966464156948, 0.21509676071228911, 0.23045176890443986, 0.19003232701639527, 0.22159121148339345, 0.22502076619836953, 0.20366796810860266, 0.2199102191624459, 0.20052516448309377, 0.19500248495650885, 0.1976865148048681, 0.20052230181310504, 0.19920261032012354, 0.16524891251961038, 0.18396148414308833, 0.17784439482796877, 0.18777731304541057, 0.18814813603687164, 0.1878954500949298, 0.168549787556999, 0.21235349475907261, 0.16858407202737713, 0.21089361754592795, 0.1550076775281264, 0.12708334717650682, 0.12862579559271414, 0.1544470124460433, 0.1680632463750411, 0.8870007620499744, 0.7753075279471128, 0.21151928294617606, 0.1829748977083594, 0.19127631065724227, 0.19646266054373873, 0.22076643249223737, 0.17481279754081902, 0.20506392806984453, 0.20371014901199525, 0.18553399082226174, 0.09953538925454797, 0.10240354809739871, 0.09752672204798074, 0.08760526850197836, 0.09513895384701321, 0.09209795584828628, 0.09568163819944908, 0.07408016447554178, 0.11570905175511814]}, "mutation_prompt": null}
{"id": "65b442d4-26a9-4c0d-9118-b6c0fae38fa9", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "b1a8015e-850e-47fa-a6d3-c9c31312a8b6", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "9872f618-3eae-4b55-8d81-71a49eb4184d", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "f2c73578-c4bb-4685-9296-82f46783655a", "solution": "import numpy as np\n\nclass Enhanced_DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.9  # Changed initial inertia weight\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        inertia_decrement = (0.9 - 0.4) / self.budget  # Nonlinear inertia adjustment\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            self.w -= inertia_decrement  # Update inertia weight\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "Enhanced_DE_PSO_Optimizer", "description": "Enhanced DE-PSO with nonlinear inertia weight adjustment and boundary correction to boost convergence and stability.", "configspace": "", "generation": 28, "fitness": 0.19781470679844101, "feedback": "The algorithm Enhanced_DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.21.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.5854838176298142, 0.5318928315190385, 0.45215911750118953, 0.5021228633923444, 0.5102144404905998, 0.5291044320224902, 0.4699691016388218, 0.5599417609229697, 0.5988360723761648, 0.09334213249647749, 9.999999999998899e-05, 0.054449028625804696, 0.11452679731610804, 0.03750920848959849, 0.08339332575941372, 0.022627276050395606, 9.999999999998899e-05, 0.09804425774472803, 0.12520490881272583, 0.10803118152417879, 0.07577371305670655, 0.12637374518528233, 0.06823098622816592, 0.10386769819998132, 0.11256565850800304, 0.047351453328479565, 0.1076690301982327, 0.11093380199537661, 0.10523068496882593, 0.12316613868905935, 0.08387016253939639, 0.10515027807701094, 0.07879719493075643, 0.08357650882476353, 0.0771043095141769, 0.09225045453548386, 0.9934862662968292, 0.9940348812773182, 0.9929553015230389, 0.9906549697030391, 0.9939532739354614, 0.9939993534828446, 0.9935928514895249, 0.9939210920594593, 0.9918915522060088, 0.16930089510543767, 0.2885941597579891, 0.2778271522951986, 0.30406699708240736, 0.2768502051242111, 0.21665210934446633, 0.23604236983897586, 0.31949716253328964, 0.24029773361201934, 0.1294332341467923, 0.1331121161227764, 0.38855009496019643, 0.15231120384731256, 0.15227849306486174, 0.1808749640492333, 0.1504991509539263, 0.10483765768534525, 0.20900209913525514, 0.13681845817689287, 0.1550621217049415, 0.13669624234043132, 0.11685948446225847, 0.11675428216185757, 0.11314290107497638, 0.14637197520392875, 0.10752766281310033, 0.11093921995892797, 0.09364409170274379, 0.1359389814657641, 0.12226498429100952, 0.11644361992092778, 0.09448497719975801, 0.07931455542115873, 0.12238012142838028, 0.08608343370331717, 0.1050729236101009, 0.021319253645364578, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06162722115994934, 0.04024259207030845, 0.04474820091512355, 0.048036671406484266, 0.019709253824024886, 0.028348295777492427, 0.05614261253145014, 0.06952745005253547, 0.07158619449937142, 0.01499929946774936, 0.015587104487302494, 0.017231760015605335, 0.037782066935843295, 0.025344194553143407, 0.03162693756754309, 0.03257536647930881, 0.05857817735791737, 0.037224916399024366, 0.028677517919031947, 0.09409376286343829, 0.037574243074166014, 0.10134458238086241, 0.05221677050093587, 0.06950598673235364, 0.08196318018478743, 0.06819357798136938, 0.076937527143349, 0.3917704249647479, 0.35577590893444344, 0.3535396987771102, 0.4205479382090591, 0.38523601036985533, 0.41159835255892363, 0.3566405942372255, 0.3598556620508795, 0.41917110915306766, 0.0774966539759846, 0.053594579981768975, 0.06768458091619867, 0.07375955251583766, 0.08087205190613789, 0.10717809640077813, 0.0738863248467132, 0.0955177616799916, 0.08381625048453312, 0.15315382191824178, 0.21761413850010247, 0.1510412678639026, 0.20694476609640255, 0.15036609893920938, 0.1617511649506772, 0.29368608760889137, 0.1723457214108992, 0.1761754247146835, 0.2712643117649559, 0.28124084624553713, 0.2725239591252121, 0.27193236759531014, 0.19977502696262095, 0.26378365741210985, 0.23253464797293932, 0.19870157039976477, 0.23517969941989514, 0.16225986444542484, 0.19363846047708422, 0.16916035187924172, 0.1897529571316925, 0.17640677085262835, 0.19073028969574224, 0.18877697950233818, 0.12750695394906475, 0.19808900906334226, 0.21089207797198628, 0.18750831951636615, 0.1710596071317546, 0.18341896319408157, 0.182109864968781, 0.20911070858358605, 0.1680899792111159, 0.1794342928945234, 0.1915250865228414, 0.17190697614993755, 0.19364190621670818, 0.17517931032240064, 0.18804954724943768, 0.19197592564907606, 0.1872907585455481, 0.18335110205500738, 0.16711762135805597, 0.19108651217523243, 0.187257444146128, 0.16358472892447296, 0.16525294058721463, 0.18399467148066884, 0.17311273880489353, 0.18578650024003596, 0.186271255837536, 0.18559606843727872, 0.5471714067100488, 0.19461992375568038, 0.16766994738125685, 0.22710609344615573, 0.12279919050909571, 0.1259812839856449, 0.12594308182344194, 0.20740420312390317, 0.4146223712330679, 0.41914552076555145, 0.19578767319448487, 0.1792127497843159, 0.18243029510082953, 0.19996904228458035, 0.20365926242730525, 0.17959130083138097, 0.22646820270442714, 0.19627055928036352, 0.20724183899553195, 0.08170346675624807, 0.06527379688552704, 0.07377485220238233, 0.08099440042297423, 0.07381982661376585, 0.07823493364985101, 0.07204188456869032, 0.07386946400527428, 0.08046095169354084]}, "mutation_prompt": null}
{"id": "36d20c58-99ac-45be-9ea3-d38411d7e046", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "75ad08f6-b113-4acc-81d3-830086f398c9", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "b4d0b56f-9386-4386-9587-0ccc3389c2aa", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "793f2bb2-d9dd-43e7-8361-058fbc7cae94", "solution": "import numpy as np\n\nclass Improved_DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9\n        self.f = 0.8\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._chaotic_local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            self.f = 0.5 + (0.9 - 0.5) * (self.global_best_value / max(self.personal_best_values[i], 1e-8))  # Adaptive F\n            mutant = np.clip(a + self.f * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _chaotic_local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + 0.01 * np.cos(np.random.uniform(0, 2 * np.pi, self.dim))\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "Improved_DE_PSO_Optimizer", "description": "An improved DE-PSO optimizer incorporating fitness-based adaptive parameters and chaotic local search for enhanced exploration and exploitation.", "configspace": "", "generation": 32, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {}, "mutation_prompt": null}
{"id": "e4a4debf-3257-4d1f-9081-6f98486f967f", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "3d7f2853-4634-44ad-a7da-b682c006973e", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._levy_local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _levy_local_search(self, func):\n        if self.evaluations < self.budget:\n            step = np.random.standard_cauchy(self.dim) * 0.01  # Lvy-like step\n            local_candidate = self.global_best + step\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An improved DE-PSO algorithm with enhanced local search by incorporating a Lvy flight strategy for better exploration and convergence.", "configspace": "", "generation": 34, "fitness": 0.3061754954090508, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8656744284808036, 0.8928408518831994, 0.8737691011416835, 0.8883925048505561, 0.8681001659655813, 0.8508108691964693, 0.8392528061574616, 0.8557517128450336, 0.8841155464387742, 0.7552836354730312, 0.7222764840420869, 0.7302843715944599, 0.7353869958107797, 0.7552601668406247, 0.7496763078879483, 0.7479975397985426, 0.5965810363092259, 0.753939848129463, 0.13154661226569475, 0.18075339336527285, 0.17956352894668193, 0.07163373221609892, 0.0633760218795989, 0.15349941226310582, 0.13097249542996559, 0.12110509228412247, 0.11619320662943577, 0.12876258166691423, 0.10696160817509259, 0.09410022573694532, 0.14013716452453684, 0.18025450304609913, 0.11409279746716672, 0.1402362907181498, 0.07104613780427571, 0.1310222007369961, 0.9907442043813213, 0.9934298529619527, 0.9929882797367054, 0.9906498590761078, 0.9937781065446022, 0.9940152851634679, 0.9932551618077384, 0.9898483100090144, 0.9869190834095455, 0.684463782246179, 0.7667220555957334, 0.778052491853325, 0.753794087036534, 0.7770731270840956, 0.7525953156203942, 0.6893009603358351, 0.75466691091019, 0.708398178485022, 0.06002347601710101, 0.3849170941887431, 0.3765542392335105, 0.15953591776875087, 0.15509675867327388, 0.2124654428876166, 0.1484034432542578, 0.17130689051342252, 0.14839016207939182, 0.11522411356206408, 0.2659331841786917, 0.13265885606670358, 0.265189873188339, 0.13208109843862004, 0.12919264742826542, 0.25556368638355964, 0.3948177805195633, 0.24333849811297115, 0.2588385289425028, 0.2544684341501725, 0.23824086810557688, 0.1330439675448919, 0.26252936324362974, 0.28018138374273316, 0.2709273835918249, 0.13016014695328926, 0.2858389024971121, 0.008285976237172865, 0.018143258993419287, 9.999999999998899e-05, 0.00019915414547522214, 0.00010524369024655922, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025502771216163955, 0.03191709957442801, 0.039507753158551484, 0.07471145958238556, 0.036369511181443936, 0.00010013958404109236, 0.00278351104767538, 0.039050717543828606, 0.10585119658475017, 0.0436611137204902, 0.03402486203763533, 0.09959691375189672, 0.0943554342383226, 0.07432082196712286, 0.08531814570969598, 0.2518028797794586, 0.0975474934337539, 0.10974015875194687, 0.1065137172083318, 0.0595775422746494, 0.08269187898334762, 0.04862892416667841, 0.046388928046946054, 0.09749762515495441, 0.09202472667095951, 0.05710146711643427, 0.05765708490510424, 0.057563795105389004, 0.5445042575017945, 0.580721916093779, 0.5999323348546941, 0.5366992199784386, 0.574747369072147, 0.5553051105763683, 0.5864257622392396, 0.6171062625477137, 0.596849692298702, 0.12931146763794132, 0.07943440794302092, 0.09219839724074685, 0.1335260455268915, 0.13029783337915468, 0.13001399925301071, 0.12143340372538647, 0.13115802080693373, 0.14446990667582382, 0.31191157450786045, 0.3355279692624408, 0.16105179304613104, 0.1627891624104807, 0.21763195127463408, 0.2208376179055509, 0.15586112338233982, 0.1387044817210079, 0.4115935748401298, 0.28239831450580044, 0.3044167785479489, 0.21284727808229986, 0.24924754908809243, 0.17755671853969035, 0.3502331884301363, 0.5561381741320142, 0.6026996996864374, 0.5725417008616842, 0.20804125309912402, 0.23782437012525137, 0.17293774668435713, 0.23085632928156263, 0.20008774555774922, 0.1706482816651942, 0.184445188659772, 0.27668321671668583, 0.2295465606575946, 0.22837950927600792, 0.2364809710196475, 0.22954634910993255, 0.25114183170657123, 0.21396758299500984, 0.19057742062419714, 0.20120495703518215, 0.21251922926877198, 0.18423365652413226, 0.22268640730665468, 0.24064542318819426, 0.20783490641262214, 0.20361958580676864, 0.1906708861657921, 0.20642960670681787, 0.20312128013486686, 0.1974072571057176, 0.193389250888243, 0.19939597390605635, 0.16537834268002338, 0.13603308773738865, 0.9193411290182394, 0.1786548049093677, 0.1883701114649894, 0.1875872821631609, 0.16865275959820336, 0.21184775502162279, 0.16858999982054845, 0.20997650382496902, 0.20943729034731928, 0.21144488628364078, 0.2069710861774644, 0.15441118344550064, 0.7699218635515626, 0.8617837864973158, 0.7944635780916789, 0.20364844699046714, 0.19859726734037042, 0.19954357951676838, 0.19564809216251255, 0.22480534618894643, 0.21069559033910856, 0.228152220374932, 0.20852455094835343, 0.18809772437079653, 0.08476601423780827, 0.09153954438836809, 0.09733900814889418, 0.10803755480240995, 0.08352208742872991, 0.08766961462070577, 0.09331608294095128, 0.10030027945768194, 0.0991818411703127]}, "mutation_prompt": null}
{"id": "cccf4702-836c-442d-b53b-8427e5ea793a", "solution": "import numpy as np\n\nclass Enhanced_DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.9  # Adaptive inertia weight, start high\n        self.c1 = 2.0  # Increase cognitive component\n        self.c2 = 2.0  # Increase social component\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self.w = 0.4 + 0.5 * (1 - self.evaluations / self.budget)  # Adaptive w\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5) \n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        elite_candidate = self.global_best + np.random.uniform(-0.05, 0.05, self.dim)\n        elite_candidate = np.clip(elite_candidate, -5, 5)\n        f_elite = func(elite_candidate)\n        self.evaluations += 1\n        if f_elite < self.global_best_value:\n            self.global_best_value = f_elite\n            self.global_best = elite_candidate", "name": "Enhanced_DE_PSO_Optimizer", "description": "Hybrid DE-PSO algorithm with adaptive inertia weight and elite strategy to enhance exploration-exploitation balance.", "configspace": "", "generation": 35, "fitness": 0.19407142436813368, "feedback": "The algorithm Enhanced_DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.21.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.5982214145908074, 0.4849966311357241, 0.4614140363389654, 0.5797941995367071, 0.49692140419954567, 0.49756354751465515, 0.48326871780498337, 0.5052732783541722, 0.498852156715766, 0.018350414173342156, 0.12196109633593788, 0.08676049554113163, 0.040003560005173466, 0.06312673017822945, 0.08017935916397712, 0.09386280499936783, 0.11348515161948691, 0.10061969824491768, 0.13828362053747711, 0.039590714197554, 0.11699607309225246, 0.16586912449009328, 0.06899083633254699, 0.11191812349341923, 0.10134093921686493, 0.09259039535989944, 0.04627679549595054, 0.07307111833097457, 0.08633230865599839, 0.08381708285774203, 0.085433424150817, 0.09649625059960332, 0.04218376693175019, 0.10641892485511284, 0.08643456094179514, 0.1193657256365892, 0.9935115211422881, 0.9954069805761588, 0.9944049652970511, 0.9933479242269, 0.9939773358829049, 0.9947616015512266, 0.9935969554528449, 0.9940085916218725, 0.9930087258292896, 0.20183458121329012, 0.25773785171370345, 0.2363171678945376, 0.23058588940062796, 0.20746224008733638, 0.2028958063647629, 0.23376730461051598, 0.2529238413998869, 0.20642734952970188, 0.12444537246680176, 0.195316023678204, 0.23685010846140775, 0.2321797371702834, 0.14475904954607688, 0.1947083218002229, 0.2495548319892179, 0.09935202374202579, 0.39705964181580433, 0.1519662490338196, 0.1284189371331821, 0.15267292342283545, 0.1258022246837318, 0.0862313479009772, 0.10221861162121804, 0.09787744129437104, 0.1086995015942479, 0.14179319858619477, 0.09582037124218712, 0.10142396274951393, 0.1073201700893216, 0.10780324284472842, 0.1239517311923577, 0.043585784615560064, 0.05866163610385633, 0.09429768586379139, 0.11419040696533844, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00026370487906024476, 0.00026828222594466045, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.044603639342440826, 0.06926261148802937, 0.07881975706724165, 0.01780379135543031, 9.999999999998899e-05, 0.06679205177529712, 0.05045052336634159, 0.019041343209002082, 0.05916517762456319, 0.01650191664305345, 0.039105531484709855, 0.01721998636369859, 0.039644724476309734, 0.03238752093784203, 0.03198764726787706, 0.03324495958481899, 0.03879656147042476, 0.032981181508465074, 0.019460578968239828, 0.027918612533158527, 0.060391172023843476, 0.03860826447589372, 0.03997393755113754, 0.04349600324937364, 0.04410905961356015, 0.06270092915173697, 0.044824317063784314, 0.36532493253046083, 0.35560435243246324, 0.38166700680615573, 0.4023740651242711, 0.38100000433998327, 0.3494986792498296, 0.3336309045102448, 0.35336959584240535, 0.3986253298753384, 0.09625915124803874, 0.04934864664318883, 0.0839401279112002, 0.09509347291213033, 0.07364469939734208, 0.07424657451853567, 0.08457910925964607, 0.08738431547208525, 0.07920704918127519, 0.1712559930076799, 0.26649170078998086, 0.1461491088675897, 0.17705488585795226, 0.2331148870584986, 0.2119526138156541, 0.1602968433795381, 0.13603977086586383, 0.21366516970768112, 0.26374760843951517, 0.1775717992520104, 0.21880461223723402, 0.23405298064580915, 0.18910817852455108, 0.2073440614503005, 0.2746878749381422, 0.23468602471329925, 0.2815717575543387, 0.19390335057040597, 0.13783401223290892, 0.15769129194842701, 0.16451660540517699, 0.1785045878529914, 0.1741003956372943, 0.2008931831167554, 0.18490911096654317, 0.22581905458130558, 0.18246579880871627, 0.16569719995937016, 0.17888074398702758, 0.1678728173509051, 0.15672138589855877, 0.17032435942162794, 0.17769124325939412, 0.16861156398046528, 0.16184887763378242, 0.16150824971919975, 0.16364279180917707, 0.1792774981457269, 0.16508598444430522, 0.18929794114475018, 0.1865169033380868, 0.2173166515817656, 0.17108893298595718, 0.1817136359012833, 0.1413448697894606, 0.6527138846634133, 0.20384262980505163, 0.20418053259059787, 0.18327208046280052, 0.17469613158775332, 0.6551026915282985, 0.14464849040357108, 0.18286277442523224, 0.16648856164786996, 0.16620187709974343, 0.183964420391583, 0.11969146557962618, 0.12410486122460829, 0.30901547704044374, 0.20575687672653953, 0.14901066298756083, 0.12540143413809257, 0.19451545104170864, 0.18513161674582612, 0.18628070690883336, 0.19151011772941784, 0.18510848010326064, 0.18453921066547208, 0.19932057769337108, 0.20887151258193493, 0.19463574634574266, 0.0783658427405971, 0.07268505033102779, 0.06995020534888885, 0.07494439421973997, 0.07954406972799444, 0.06265150678621845, 0.07691650261520389, 0.05863886717587752, 0.06776458288858755]}, "mutation_prompt": null}
{"id": "746767e3-9470-4293-819a-288f39e75941", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "ff860b8b-ec18-4767-a32c-b6d39203031d", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialize with random velocity\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.9  # Start with higher inertia weight\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_inertia_weight()  # Adapt inertia weight\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_inertia_weight(self):\n        # Reduce inertia weight over time to focus more on exploitation\n        self.w = 0.4 + (0.5 * (1 - self.evaluations / self.budget))", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm with adaptive inertia weight and diversity preservation for improved exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.22911999277766323, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.6381325724433222, 0.5893658745336732, 0.6305312867306032, 0.6415165207287756, 0.6542429409855285, 0.6416082985896358, 0.6559666008065439, 0.6156192086639245, 0.6275351079640141, 0.024551137622078945, 0.2898637307717207, 0.023953032276890163, 0.38256619211267084, 0.32661201279248453, 0.02710901873541882, 0.011261896360203916, 0.03998955574825447, 0.3507374374704535, 0.12737817519881678, 0.10798562003173806, 0.14307208518115744, 0.11974906679391062, 0.05433991193394372, 0.10169805189898784, 0.13002126758925203, 0.05173210458603428, 0.14235252848414637, 0.026951023407676966, 0.12095925180914036, 0.10545384064189234, 0.0991550597046631, 0.12423991585413163, 0.09714404988645164, 0.12348700815628433, 0.09868011396242915, 0.09812676754457339, 0.9942557536744897, 0.9946875013795693, 0.9894916060183382, 0.9861083344539635, 0.9942275378218186, 0.9906707987728494, 0.9851422074416452, 0.9850968261353229, 0.9921551934366588, 0.4167911380518331, 0.4044476480765302, 0.38901195788366627, 0.3729960755902906, 0.4392115431579996, 0.38261946147266457, 0.4316067280660112, 0.41215012612129154, 0.43719177108231655, 0.1331628998901806, 0.5972775355363377, 0.5997188051265072, 0.21570891507023215, 0.1985893561699591, 0.19640142424296259, 0.12180873708162376, 0.19112636342076283, 0.19506124733325092, 0.1513273250611652, 0.15360209649635215, 0.20325969219965212, 0.11208782480221036, 0.16664378419787773, 0.11255530746734144, 0.14289481175914154, 0.1628280937528902, 0.1410790222390781, 0.07966305469761337, 0.10439534270958939, 0.10504351872094708, 0.17841347160538534, 0.09809489382591585, 0.11376887470022434, 0.19821827862728691, 0.1355234685383523, 0.0905758449339431, 0.00041048374643470886, 9.999999999998899e-05, 0.03651656456026653, 9.999999999998899e-05, 0.00033076509147389466, 9.999999999998899e-05, 9.999999999998899e-05, 0.004989065364390588, 9.999999999998899e-05, 0.025932722861400914, 0.05294039011267726, 0.07222050625104981, 0.024786893352473638, 0.006831263454584069, 0.01606035866422517, 0.049326170916545786, 0.05923861706254607, 0.08767794842624776, 0.02362624231697863, 0.026002129302841626, 0.02483505729040103, 0.055737799072577365, 0.049241345204376175, 0.05017965058050666, 0.0453733649272996, 0.07052588616644062, 0.05309299460028227, 0.04343875813097531, 0.05360244552200433, 0.04931548573372402, 0.12717947801847973, 0.05761598663710743, 0.05036039899676348, 0.07971196159841853, 0.04393273788170138, 0.05051209546776847, 0.4455084307619106, 0.4430315140153155, 0.41196341951349114, 0.5119336222622096, 0.4545718470707242, 0.44704703600047646, 0.48847924015839617, 0.4313475743298657, 0.41779991829064334, 0.050353796164547715, 0.05878375020548832, 0.0736539394497151, 0.128630007943359, 0.11173982156687379, 0.12454943532998441, 0.14153543481627062, 0.1074915251080305, 0.09083194507436687, 0.18754479184526474, 0.1516201580494142, 0.1421383275851945, 0.18324221530055151, 0.14266990338956043, 0.16212760329324738, 0.23174970439631892, 0.2642851929529737, 0.15799529083034125, 0.12030693440137841, 0.33504521581000923, 0.3060359823739611, 0.20500745764783945, 0.2046527634735954, 0.19608674694292805, 0.2596860994310487, 0.1678260104289735, 0.3286683750140674, 0.2153956633732479, 0.15210895678789416, 0.21989121087832175, 0.18601911891332468, 0.16826119360585057, 0.16314701882093818, 0.1279564970828465, 0.14525189677212524, 0.2176271678333661, 0.1817256123607034, 0.1789803937810922, 0.1990165377298806, 0.18479907677541918, 0.1465590662295626, 0.19774860683380158, 0.17933180295221574, 0.18992224470138364, 0.1838888031920688, 0.45529183779352844, 0.18263420863272073, 0.20373733364230417, 0.19560330445228513, 0.19319662256574677, 0.192132322447496, 0.19171912249365008, 0.20442945617915398, 0.2162211176020995, 0.20423355859804826, 0.6837967985425719, 0.2098501346171282, 0.1217236782635186, 0.18314596177912512, 0.7803141953043865, 0.18847264662373941, 0.20256123902208978, 0.5707975637996328, 0.15166867537932993, 0.1677071165752808, 0.38695865651007666, 0.1226100832448046, 0.2051176733674438, 0.5466319072870939, 0.11159885232861433, 0.14707470418859703, 0.14652217842755977, 0.1987752778630003, 0.18372162111381907, 0.18270169200556496, 0.1945399451360703, 0.1856045831085663, 0.1956535644679709, 0.1744507907643803, 0.2074013034999953, 0.21052241863980847, 0.08895472926885772, 0.07754127504645691, 0.08220485413100065, 0.07377748232913761, 0.07672178348717662, 0.08543728776779769, 0.08250772911948756, 0.08853922435978834, 0.07911399418754284]}, "mutation_prompt": null}
{"id": "200dab23-6d11-4b8a-8e62-c6698659db35", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)  # Adaptive F\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO algorithm incorporating adaptive parameters and a local search strategy for improved convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.8707343991734173, 0.8714411718097219, 0.8756532286486028, 0.8803971383948864, 0.8792957820100513, 0.8990153253343744, 0.8594382587861216, 0.8950294953447588, 0.8692828388030219, 0.7186355625197058, 0.7569226689430404, 0.7409700814772364, 0.7715286512050994, 0.7222968048855268, 0.04723565470484847, 0.5001607666888005, 0.0519146581136698, 0.7156728671943209, 0.15880890864330655, 0.15189661686021738, 0.1532386762528286, 0.1567719606159499, 0.1551563713207864, 0.1386306942921226, 0.11802761773924053, 0.11415858728560235, 0.15647934822930598, 0.1034933133135677, 0.14152969214324163, 0.12504665617142585, 0.07728126253517109, 0.11095878255968239, 0.08177082013907289, 0.09232791745494984, 0.1164765817561334, 0.18059985372380982, 0.9930237579381139, 0.9937995242577148, 0.9929190093176344, 0.9909307033624398, 0.9939532739354614, 0.9940152851634679, 0.9910028511729302, 0.9939210920594593, 0.990946010643083, 0.752726344103555, 0.7233895399044012, 0.7278836470495156, 0.697144458901481, 0.7124998966682001, 0.680945187909116, 0.6658265152910583, 0.7643706312062849, 0.719073518940177, 0.16649091571395058, 0.7316878938603759, 0.2521070218028796, 0.21032888530500415, 0.0713871449559802, 0.21197316012667988, 0.22626337186013945, 0.11466818183893024, 0.17640293639445137, 0.27804019011192316, 0.39989445793500267, 0.2941316646880019, 0.1348465930132534, 0.13159387934682487, 0.11494613387281283, 0.24297238043353964, 0.2568123625939397, 0.308152410504112, 0.244872713011817, 0.20487497374485086, 0.13120836394094948, 0.11381138744090535, 0.2615169298752973, 0.251224823238117, 0.26118174130134053, 0.2728801860617788, 0.27324872176843873, 0.058486142208648007, 0.005824837199266186, 0.0026498590152385093, 0.00013778107598749756, 9.999999999998899e-05, 0.09666243638284888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061578869350633614, 0.048831897639404986, 0.06091937527274205, 0.0333380620121414, 0.031097246485529473, 0.08405866847803012, 0.06602470808999839, 0.07188970092932323, 0.12612391372788656, 0.05618888683508394, 0.034829354558966075, 0.04873330997517911, 0.07693901947760384, 0.08004970970414793, 0.11818791440320331, 0.12296017616372823, 0.18369976505369856, 0.1012304883552666, 0.14204084315353716, 0.07493857729819775, 0.14312315615680837, 0.043112441979807015, 0.3401686646979236, 0.09321645037807869, 0.12385743688628625, 0.33678048951385176, 0.1483738765894339, 0.5652717943465613, 0.5325727284506249, 0.5441002401566388, 0.5473730219031832, 0.6113363064947701, 0.5790022556820419, 0.5756432284466438, 0.5816588326146652, 0.5694014530449378, 0.15614483544928648, 0.08442899341743015, 0.12019427719904086, 0.07577104813756486, 0.10766316524113628, 0.08767624395437701, 0.07641978734484, 0.09563657975715556, 0.06893693473297247, 0.14512527739806225, 0.212156835175364, 0.22671064058667068, 0.25564483518774095, 0.16297680873146692, 0.20184763135201744, 0.19230610163223627, 0.27617808013193423, 0.22352161576927942, 0.35672898655274243, 0.5849245891071548, 0.26053452157545876, 0.26998918899834057, 0.20014465586946317, 0.39571248937724246, 0.6078707225716455, 0.2626579209006584, 0.2333071239679979, 0.17384554596529267, 0.247503493364149, 0.2795485033957138, 0.3022115290842239, 0.23208264737891582, 0.37030219213626403, 0.17244852098199315, 0.30145009585638605, 0.2560197658860075, 0.2394826459763032, 0.21697309626811756, 0.22839644044664265, 0.22005032696867854, 0.20263722191443667, 0.22027663442063972, 0.1960362015200342, 0.20203313022796487, 0.2201862131111051, 0.20615695550186997, 0.20566486048124522, 0.17111298389487895, 0.24725014371761656, 0.8265411240208467, 0.20610250239263328, 0.18976899737579012, 0.18856174509903745, 0.22654224528247413, 0.19999365647167922, 0.9218077098876308, 0.16570444711772436, 0.9026335174221466, 0.1782125393953804, 0.18800576322524398, 0.18748629422908192, 0.16583462884209166, 0.8937819401130229, 0.16818478468594455, 0.1685930950054546, 0.127269462310312, 0.12782271654978106, 0.12863267917356425, 0.16690332619384007, 0.21121573934439708, 0.8792112409963752, 0.8658944841390964, 0.18952093910229584, 0.17844069163913723, 0.19444195274326637, 0.19584622962668008, 0.23325791230668935, 0.1918346780099981, 0.20113061743537763, 0.19134196768238987, 0.19404872893243397, 0.0972313856349234, 0.10282000598833763, 0.09209674617654273, 0.09134219419496936, 0.08649960633021914, 0.10979422654209625, 0.09679097844195805, 0.10926188653180524, 0.11546226589783104]}, "mutation_prompt": null}
{"id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 39, "fitness": 0.31669904149916017, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.29.", "error": "", "parent_id": "644ebdf7-19e5-44b6-97e3-5df8f59648bf", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "35263060-1552-4f86-bdbf-e522bcc0f3ef", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "312c1819-851e-47d8-b5fd-bcd469b00c2a", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "55048cef-a8af-4118-a2db-643313b94fad", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "b5da1099-5ce3-4e4a-9b1f-ae2e7a0388c8", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  \n        self.cr_decay = 0.995  \n        self.evaluations = 0\n        self.elite_fraction = 0.1  # Preserve a fraction of elite solutions\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()\n            self._preserve_elite()\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            adapt_lr = np.random.uniform(0.1, 0.5)  # Adaptive learning rate\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * adapt_lr * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * adapt_lr * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _preserve_elite(self):\n        num_elites = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(self.personal_best_values)[:num_elites]\n        for idx in elite_indices:\n            self.pop[idx] = self.personal_best[idx]  # Preserve elite solutions", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO utilizing elite preservation and adaptive learning rates for improved global optimization.", "configspace": "", "generation": 43, "fitness": 0.26934037609369427, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.26.", "error": "", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9349779598594787, 0.9255268361004959, 0.9375277735942112, 0.8609810132969659, 0.9301853165145285, 0.9269200093122828, 0.9327572395921967, 0.9338713540411578, 0.9237602006447628, 9.999999999998899e-05, 0.10331694308618222, 0.23870636122877942, 0.30943770945035654, 0.4244210756849308, 0.00848181366750178, 0.0708764592730764, 0.10160386752414563, 0.034678580425530514, 0.11860941942462999, 0.0926560127898427, 0.13547374699283865, 0.09661513691545387, 0.1194430063064621, 0.16188587507767316, 0.10241080916420853, 0.13475876177238155, 0.06080542959119317, 0.08063021220188493, 0.09110751642119408, 0.08890284372647916, 0.11238688413759368, 0.0623839920765793, 0.06715105759835005, 0.16289092099980096, 0.11070872514579533, 0.07732349694661766, 0.9648886470979361, 0.9535245162832195, 0.9866377381194735, 0.9639834043996135, 0.9870017169723211, 0.9723214282707421, 0.9719198811823284, 0.9494736569445443, 0.9314860210629914, 0.14013660318220644, 0.2428576964161292, 0.29475759964367965, 0.3385104645597111, 0.5777450471437178, 0.2731586355702148, 0.21184925848458436, 0.19762170117799704, 0.22704839209184924, 0.2294236023828975, 0.21056932805944262, 0.9432001154659702, 0.27903451308226546, 0.3866984740403201, 0.1941649710887109, 0.23699078926765138, 0.2379618328877252, 0.338482180040942, 0.13368687073613506, 0.14656612967807692, 0.3745274057998824, 0.13080157012208726, 0.20088152903618794, 0.11446457870413107, 0.12916237619060866, 0.17965492393204874, 0.2765813329243437, 0.1318589009565747, 0.20670958438460052, 0.17542959571745453, 0.16182938759450538, 0.18090151056362513, 0.15201750748669418, 0.1549201936355865, 0.12900434246175063, 0.18311586275295866, 9.999999999998899e-05, 0.05412462404458129, 9.999999999998899e-05, 9.999999999998899e-05, 0.08146723008600654, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10258117968114655, 0.06581870965168057, 0.10604860434246366, 0.10724960359219804, 0.025437856829004568, 0.02500015537624045, 0.16760192694218967, 0.07362091728076725, 0.07794421497199633, 0.19273103735077846, 0.08339133921242914, 0.25246288191834476, 0.05265943372435977, 0.16623022759791561, 0.08293974005347793, 0.1791207013356787, 0.18132021589162273, 0.26583495465574014, 0.07885227648239546, 0.3666905098301343, 0.13527445650138104, 0.12178788049355993, 0.06724879891943147, 0.08603493154216213, 0.043144346974322234, 0.1607442910971313, 0.05780314503554984, 0.14138177403760055, 0.4475486392235285, 0.4961690912236818, 0.5239984072060664, 0.44899277461787146, 0.4926011695835564, 0.4612589460650691, 0.5263641086129223, 0.48308872176370743, 0.5041101692419818, 0.18805185930312962, 0.1110838388742772, 0.16179251218093071, 0.15829832350153805, 0.11667200835020253, 0.0858922202748168, 0.11655206673438079, 0.13992113139688356, 0.06598893806242356, 0.16499004231990677, 0.27211267501956515, 0.19084408824774968, 0.14656658950858215, 0.2079693654007021, 0.23406298158158412, 0.18400920943432364, 0.2923127261025795, 0.2965774431551925, 0.45398101902188215, 0.3379598706643644, 0.2598132005351702, 0.3984895832552936, 0.2635204098355848, 0.27474871633949394, 0.2605639370972679, 0.29300219947128636, 0.27750221326687585, 0.3107680749409486, 0.1394998813690712, 0.21275551528689063, 0.26428703168665824, 0.23695241125154143, 0.28824482702259235, 0.17813967198022962, 0.24871179024493195, 0.14474313970266817, 0.23207203943226806, 0.2311150510236818, 0.2197885564098533, 0.2673436690462667, 0.2615395658660181, 0.21476762753431922, 0.2265309656569019, 0.2526507070800371, 0.27494168019240595, 0.19453171232989153, 0.17880965004493687, 0.1881428283540454, 0.20215899077744348, 0.1850107349905682, 0.17472963703116529, 0.1863444761616989, 0.18591868861962235, 0.18741159120034367, 0.12715709896507232, 0.9457815823253094, 0.14725711853714785, 0.7783847011180782, 0.15756599342645383, 0.9280255057086203, 0.18899298451641744, 0.679488178839991, 0.16609957486049776, 0.42072600663061244, 0.2129882161499198, 0.5977783740798752, 0.1131279113565673, 0.16720147401820673, 0.6361109928868922, 0.3738636960613366, 0.15594405516852694, 0.1273343505980642, 0.20289494991722334, 0.20050842185676943, 0.202751439500789, 0.18630775869964078, 0.18217138310934256, 0.19447945720437376, 0.1837797369449491, 0.17894315789071535, 0.18146384963223117, 0.06734800020046627, 0.0803307919355879, 0.10024678589328195, 0.09172334271150517, 0.13890316523822022, 0.10099446990979144, 0.08968699436078509, 0.09025594919083646, 0.07459791144820904]}, "mutation_prompt": null}
{"id": "23c0fa60-1f3d-46aa-962b-0fef46c30ebb", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._adaptive_population_reduction()\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _adaptive_population_reduction(self):\n        if self.evaluations > self.budget / 2:\n            self.population_size = max(5, int(self.population_size * 0.9))\n            self.pop = self.pop[:self.population_size]\n            self.velocity = self.velocity[:self.population_size]\n            self.personal_best = self.personal_best[:self.population_size]\n            self.personal_best_values = self.personal_best_values[:self.population_size]\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim) + np.random.normal(0, 0.05, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "Enhanced DE_PSO_Optimizer with adaptive population size and local mutation for improved convergence.", "configspace": "", "generation": 44, "fitness": 0.3002976073233303, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.29.", "error": "", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9103860133984809, 0.901251112723596, 0.8912679593818323, 0.9191558912487019, 0.9080687946195621, 0.9147453837253403, 0.9044101021297639, 0.8915194510211005, 0.9139598223410711, 0.06006077447603164, 0.8153517020379697, 0.837558367585686, 0.8203875511037526, 0.8083988997789997, 0.8061947857526325, 0.06707986278188582, 0.05372278927058183, 0.8167536304167932, 0.13009718289002048, 0.13122392065086297, 0.14363624611916093, 0.06904628405363056, 0.1049669880683397, 0.12485539602816675, 0.1308391838221854, 0.14116903889844512, 0.18593958609612682, 0.13200650872917086, 0.1374816442259531, 0.1391323313445033, 0.11180484291668946, 0.09091053534690696, 0.11258060001358317, 0.11555158813356337, 0.11993984891160436, 0.111110390223085, 0.9929562962520061, 0.9934298583148725, 0.992983474051869, 0.9936382003885992, 0.9937772198656357, 0.9940155616257754, 0.9904929258194488, 0.9898430927742718, 0.9831096919962719, 0.8019869300698672, 0.8169804454085843, 0.827573972518052, 0.8197524357902558, 0.8099795530117939, 0.8030111809388157, 0.8076242534991476, 0.7883054373127933, 0.7785256919922877, 0.07144764974329432, 0.2251087651480066, 0.22689675054168434, 0.1594573611175163, 0.16042259063197417, 0.1918226962613948, 0.17670536638386147, 0.11680366088682681, 0.15214277450299796, 0.09837094715934724, 0.22805731371652505, 0.23359944032696756, 0.17985044544780415, 0.13437750640331347, 0.2648541632214261, 0.23478098168998385, 0.23236760419741664, 0.225694926095246, 0.22748169465782397, 0.24695585317131985, 0.22578257149452985, 0.16056240772462205, 0.1318685279092573, 0.22065860477934096, 0.27224868994567886, 0.2736247914195409, 0.23464973322265537, 0.06217950500888059, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11097147314429145, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04553860135488197, 0.018397043856692052, 0.05373578404440682, 0.03726601388133621, 0.009619357170363996, 9.999999999998899e-05, 0.05288024326947016, 0.021851548694561074, 0.04337913708598895, 0.17347891147235517, 0.13195427753616007, 0.04918122500102906, 0.07978342209068778, 0.07949671545335424, 0.09816648224732705, 0.10491061579065131, 0.10491895754969371, 0.07630945535832268, 0.2636516381565016, 0.08770618444678435, 0.09371652539546083, 0.1488436837896785, 0.12868997543623517, 0.03934125814993583, 0.09554159142016594, 0.08345248262436145, 0.05735128018776037, 0.5363857586440246, 0.5230294426152942, 0.5835882607648775, 0.5741967149009667, 0.5400420108805359, 0.5339965350248641, 0.5618168996436299, 0.6041177828663451, 0.5825395697877636, 0.07873115310036849, 0.10930332563017198, 0.06917553689273048, 0.0926829232438724, 0.13151788533349995, 0.13395684192399804, 0.0875569575460946, 0.11448669347852192, 0.11495581444545877, 0.35419329332337646, 0.25931642139393973, 0.23613323897348792, 0.20090345983536895, 0.2082325180653175, 0.3013420898387169, 0.20374397007749845, 0.29019975179150437, 0.20310009443429966, 0.2410237052679709, 0.5883598728027833, 0.25333743780819495, 0.29653851152552957, 0.19209405255878964, 0.3225259786043385, 0.37451552599341353, 0.30454752135050445, 0.2616939728606049, 0.17196124800863477, 0.22484526638029234, 0.17622568231342972, 0.2517698267970724, 0.2252647257248963, 0.4016270641787201, 0.2025270874446069, 0.3028506720376708, 0.2577015969299802, 0.2097653130374274, 0.22282026311534997, 0.2225028769614068, 0.2309574172663792, 0.22317273701439821, 0.20128291481073302, 0.21857957950906826, 0.21113985120367806, 0.22038361382812832, 0.214936413729922, 0.20087066293135236, 0.22532223210760727, 0.24875920696684461, 0.19226227784098593, 0.19012099292838203, 0.252634783324725, 0.8303012704015725, 0.20820154477234787, 0.1691547493582859, 0.16537717601583113, 0.18588054765908735, 0.17775689289082397, 0.18758567377994118, 0.18853283150329914, 0.18841134051239306, 0.16838553844942217, 0.21210074143663726, 0.16872008281674278, 0.21089165617975203, 0.15527926461445818, 0.1276963028603133, 0.12850257234915574, 0.15379083796367488, 0.7698913990983294, 0.8922814094401376, 0.8477801015202678, 0.2008369898457253, 0.18794832896807157, 0.18344224780007068, 0.20815305876676993, 0.1854816579228541, 0.25638064383458836, 0.1781075974451427, 0.20361523709493445, 0.20068669986876453, 0.0932687241275606, 0.10206228915694304, 0.09560972853156235, 0.09438627901806107, 0.09071397905391332, 0.09123916560506984, 0.07881225057464802, 0.10408463773531473, 0.0985074639327006]}, "mutation_prompt": null}
{"id": "f03efc4e-8270-4b25-99b8-90be6205640a", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "7aeedbed-15c7-4a0a-8654-3dbf33a047f4", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "5ceb8634-57ab-4a9b-a419-dd821ee219f1", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "7b21c5d7-1fe2-42a9-997f-0af48b31fa7f", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._local_search(func)\n            self._adapt_parameters()  # Adapt parameters\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _local_search(self, func):\n        if self.evaluations < self.budget:\n            local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive inertia and crossover rate for better exploration and exploitation.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9048388341160895, 0.8917010779225538, 0.9062793871458922, 0.9145652977977035, 0.8970645706805394, 0.9163429370665653, 0.9019907204273383, 0.9108638904199113, 0.9103317741370139, 0.7993488716026906, 0.7909511065705496, 0.8266707505418729, 0.8147752394354038, 0.7446800730454859, 0.8208755571765168, 0.8301378951778942, 0.0525639058631685, 0.8115793699561705, 0.11654218407965367, 0.14580090693732073, 0.14279431620657212, 0.15933051421170208, 0.0722638218867716, 0.1587439859383175, 0.14056925512894103, 0.11284993347030525, 0.18322659217743886, 0.14088149574290365, 0.14139258615011752, 0.12378246221048794, 0.1277192079533459, 0.1111418595849214, 0.06524985265885042, 0.06322508129400428, 0.1028351321333546, 0.12052163509626934, 0.9930228431598709, 0.9937991858332237, 0.9929188739993892, 0.9909309578694918, 0.9939532739354614, 0.9940155616257754, 0.9909975510800316, 0.9939210920594593, 0.9909078742026699, 0.7940425841030531, 0.828687589618709, 0.8195191675446923, 0.7935626066869069, 0.8126525380758999, 0.8012683699341321, 0.7681730938499337, 0.792445160630262, 0.7844736258649903, 0.1368783399014799, 0.22404635469404488, 0.3407844614145913, 0.2113425795553201, 0.18906139464686977, 0.2122759371068712, 0.22119819623315073, 0.21514066224966233, 0.39248397088394826, 0.21798166740936498, 0.12991926692383726, 0.2889931633315179, 0.13254666178633012, 0.13130107254961054, 0.10679903875248598, 0.2502763202210675, 0.22456639967343062, 0.23111449440647547, 0.24699996191710827, 0.24868958028438826, 0.24566248817563197, 0.11708112343520993, 0.19183390602044936, 0.2474312187681862, 0.12822302386080187, 0.23784818955780207, 0.2571919693343734, 9.999999999998899e-05, 0.12284647316870811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.045466432951636104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048415188636412365, 0.0448789580714114, 0.06923830329412972, 0.03136686869389227, 0.040272108593695344, 0.06164456169704058, 0.05677784133335495, 0.10213629221294884, 0.09143445362830138, 0.03688103803845699, 0.1684007123185295, 0.05187326608163223, 0.08125508445884422, 0.08418219243740244, 0.09721098618240287, 0.1443156437756986, 0.1557436389444813, 0.20540730355965764, 0.053218844928882736, 0.12411952749003963, 0.0992240418527055, 0.14444324241201467, 0.21265616328599202, 0.19958022626873895, 0.12455723894362725, 0.2387650283465338, 0.13777481274206693, 0.5212948281362473, 0.5672039123119279, 0.523592606735263, 0.5626683207220948, 0.5591182799318253, 0.5523151192184573, 0.5705566201542128, 0.6121859183334786, 0.5602903586574877, 0.11532182672706293, 0.06520319360496574, 0.11562512690708959, 0.10851898089650824, 0.09976479665065197, 0.10556288039832984, 0.09570550332202532, 0.09145812369196649, 0.055539101246550704, 0.13076341677868897, 0.18510647407937164, 0.16890734450945033, 0.15690820748696477, 0.17689238857567868, 0.20380710436870186, 0.1571499993800497, 0.1950427405918893, 0.19482423749851585, 0.428738767610055, 0.32234009356086, 0.261378125647878, 0.2528001745417314, 0.2061916200077365, 0.54650548201415, 0.41591961501115726, 0.3667743886645467, 0.48765903278278244, 0.25569058389803057, 0.21125763135491138, 0.3104562586308677, 0.23740171588407633, 0.20133355297871125, 0.2434293879088575, 0.19736303677914802, 0.3672791871071355, 0.22451232124912535, 0.22423620531808897, 0.21990004253970896, 0.22467662450356307, 0.1858407147656912, 0.18724908048558908, 0.20118334748102595, 0.1837478113348917, 0.28053733147509097, 0.23626139893041587, 0.20675191507194746, 0.18115002284423465, 0.2103929316389156, 0.18925183699670545, 0.19125926397974413, 0.18888923548477943, 0.20044658993066278, 0.19311632773895526, 0.1768277613942979, 0.2002452417025592, 0.9361880001750611, 0.1650403491247724, 0.8974984776439502, 0.17827056165373745, 0.18782152878683178, 0.18836490506675485, 0.16556950660775838, 0.9128245740816677, 0.1685707467823675, 0.168655805557959, 0.12699575575570432, 0.12736768525575404, 0.12861996454560432, 0.1670744606869704, 0.7514861063517112, 0.8644460220305183, 0.8382830685939427, 0.18981918117219343, 0.18949773821111737, 0.2233667182471476, 0.19331241939745536, 0.19645803846683219, 0.177318703228439, 0.23306075564825357, 0.21824916793816296, 0.21080533178255734, 0.11101382501222234, 0.0962897172503544, 0.0901645937536858, 0.08263083803202576, 0.0953075130538018, 0.09602025844699291, 0.10098959615260172, 0.10105322164257946, 0.10205380805518327]}, "mutation_prompt": null}
{"id": "d1e75f21-6f0c-446f-b9d5-f2bbffc0dba0", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99\n        self.cr_decay = 0.995\n        self.evaluations = 0\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._refined_local_search(func)  # Renamed and refined method\n            self._adapt_parameters()\n            if self.evaluations / self.budget > 0.5:\n                self._dynamic_population_adjustment()  # New method\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _refined_local_search(self, func):\n        for i in range(3):  # Try multiple local candidates\n            if self.evaluations < self.budget:\n                local_candidate = self.global_best + np.random.uniform(-0.1, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _dynamic_population_adjustment(self):\n        if self.global_best_value < np.median(self.personal_best_values):\n            self.population_size = min(self.population_size + 1, self.budget - self.evaluations)\n            new_member = np.random.uniform(-5, 5, (1, self.dim))\n            self.pop = np.vstack((self.pop, new_member))\n            self.velocity = np.vstack((self.velocity, np.zeros((1, self.dim))))\n            self.personal_best = np.vstack((self.personal_best, new_member))\n            self.personal_best_values = np.append(self.personal_best_values, np.inf)", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO optimizer with dynamic population adjustment and a refined local search for improved exploitation. ", "configspace": "", "generation": 49, "fitness": 0.3124230885764246, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.30.", "error": "", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.90840670244747, 0.9200610010700965, 0.9057413125644033, 0.9073566245151711, 0.8938682550045803, 0.9051842777298239, 0.8969865043103356, 0.9114607945527705, 0.9142050046912927, 0.07556627588326059, 0.8033012169962273, 0.8068500678858274, 0.7943479361111037, 0.8031972344578298, 0.817232923420999, 0.7625303946565553, 0.7506324195320362, 0.8214844186830796, 0.08874043476269722, 0.1560114613991287, 0.13934251160115385, 0.06614921067878354, 0.07012489930536758, 0.07269578278397437, 0.09278701882513996, 0.13318311543304628, 0.1331755741163715, 0.10223531030010125, 0.13462383403663247, 0.11248544310872277, 0.10869012113939736, 0.09486781191979266, 0.10985694545937819, 0.10852438752527616, 0.11590984253268177, 0.11146599317428008, 0.9927700045727488, 0.9936211242120411, 0.9927980533520444, 0.9934517666992643, 0.9938267859949039, 0.993843951913486, 0.9900581798488823, 0.9935038619127944, 0.9865434778670217, 0.8004307259941699, 0.8333081673132005, 0.8113239122628068, 0.7803317981260546, 0.7892638912064778, 0.8113260467674782, 0.8153779850055979, 0.8155053020235663, 0.7653965573599723, 0.059675937893977626, 0.9182017515392652, 0.21369278315515372, 0.15530146123036226, 0.06995098681478995, 0.18978638786893032, 0.15452481005458119, 0.1140709780587813, 0.13873162394057525, 0.10154049309660695, 0.3290415944063162, 0.24160356102919978, 0.13271667347113447, 0.22609084288001235, 0.2755514591935393, 0.21649969668070157, 0.23465280756817075, 0.2202136401605329, 0.13286235436382943, 0.28490240886786566, 0.22342904650562712, 0.16375275608661755, 0.2528390060974157, 0.2290629000274671, 0.19531593890388688, 0.24433883410003832, 0.13040727694277432, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016775799692510196, 9.999999999998899e-05, 0.046387374356331335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03810302187789949, 0.05595210445372445, 0.0685012118966668, 0.08460196154497956, 0.03128831746403926, 0.007150899304462999, 0.03622531751788849, 0.1202630606394447, 0.16225407735477126, 0.06434405532562681, 0.14458422403931415, 0.061786031751683956, 0.08072798401266323, 0.08350395991632864, 0.22599047662199978, 0.11362744921338586, 0.10813941666707327, 0.08146803942725434, 0.08065653409834717, 0.044855544316184215, 0.1513688161410084, 0.11614403279236507, 0.28717747783204384, 0.10343964886011459, 0.07344726724886363, 0.16570151693502067, 0.058300080291089795, 0.6580588236920155, 0.5944228204787151, 0.5601778283850765, 0.5424191134789064, 0.564563868239677, 0.6288022449212889, 0.5816767057413863, 0.5731584926326978, 0.5487999183509324, 0.08279621691551986, 0.13045541191315246, 0.06930404803582191, 0.1124626066750497, 0.09864708527061161, 0.10526125675569453, 0.05171191189803537, 0.09695714858966653, 0.13926116313816184, 0.344364876708504, 0.3593349083582692, 0.2015307570944198, 0.17318508543340416, 0.1706914545847079, 0.12039354538251723, 0.1966461692841972, 0.23128989902156638, 0.20203443032800483, 0.28200715241661845, 0.21579552810629699, 0.2590074339300781, 0.28310311685266487, 0.22638826836924886, 0.2976590332653001, 0.2561052108289704, 0.2936159720621282, 0.25465180423279754, 0.34293534574332474, 0.24881438157440028, 0.28267108527247153, 0.30157586980791506, 0.2309809156638274, 0.24063737010313213, 0.22574578680506352, 0.3944802461571608, 0.2955262766729063, 0.23869129619883112, 0.23248575552309414, 0.2259720516614756, 0.25770705673859595, 0.2205551702801074, 0.2118517228361072, 0.2047093545691696, 0.22139523104420378, 0.23056842649292741, 0.1825219679910971, 0.19739090167921114, 0.2265841394926933, 0.19964790839260727, 0.19398528317048802, 0.20999435957965185, 0.2509878084576713, 0.2108397203263156, 0.1916964484140744, 0.20067105962738618, 0.9340545805942425, 0.18698146069152188, 0.17848129340804808, 0.18903122380058757, 0.17234318589897535, 0.1878483006806766, 0.14648506221561908, 0.21312995937317614, 0.168956771493194, 0.16823450395917994, 0.891384511444212, 0.12772382630122026, 0.1287749939024576, 0.15416096547224534, 0.8389476027866262, 0.8569953198441406, 0.8830880637309182, 0.19922159687657082, 0.20367175915657676, 0.191989731177577, 0.19623543117883746, 0.2125737627561155, 0.20586018735857992, 0.20937195566502587, 0.19650883883706627, 0.2209414466574231, 0.0919338422974797, 0.09035197297411746, 0.08743682640547379, 0.058789581232694066, 0.0905645019321264, 0.1065656242904639, 0.07894792264684602, 0.09104343167012596, 0.08220447457101054]}, "mutation_prompt": null}
{"id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 50, "fitness": 0.3186597385345041, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.30.", "error": "", "parent_id": "cd15b9e2-52a8-4188-8fc3-e0f981a121b8", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "b173635f-7ab2-4d83-8b37-fbd497e1e519", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "025c0ea2-b4b7-4408-8ad5-26a498e889ba", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "280c2ae1-09fe-4068-bc8c-b6459aae2032", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "4923346f-5cac-4e9e-b82e-4113b4580708", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "2010f44d-3bf8-44fe-b02b-1fda9fc218a2", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "a8a6d7aa-9fb8-4f0c-b91f-9742f68070db", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "1d8335d2-16d7-4ca4-af69-358e2628f0fe", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "dc0ec773-02c5-41b7-94c8-8115a752a5e9", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99\n        self.cr_decay = 0.995\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._adaptive_clustering(func)  # Change 1 (New function call)\n            self._exploit_elitism(func)  # Change 2 (New function call)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _adaptive_clustering(self, func):  # Change 3 (New function)\n        if self.evaluations < self.budget:\n            centers = self.pop[np.random.choice(self.population_size, 3, replace=False)]\n            for center in centers:\n                cluster_point = center + np.random.normal(0, 0.5, self.dim)\n                cluster_point = np.clip(cluster_point, -5, 5)\n                f_cluster = func(cluster_point)\n                self.evaluations += 1\n                if f_cluster < self.global_best_value:\n                    self.global_best_value = f_cluster\n                    self.global_best = cluster_point\n\n    def _exploit_elitism(self, func):  # Change 4 (New function)\n        elite_idx = np.argmin(self.personal_best_values)\n        if self.evaluations < self.budget:\n            elite_candidate = self.personal_best[elite_idx] + np.random.normal(0, 0.1, self.dim)\n            elite_candidate = np.clip(elite_candidate, -5, 5)\n            f_elite = func(elite_candidate)\n            self.evaluations += 1\n            if f_elite < self.global_best_value:\n                self.global_best_value = f_elite\n                self.global_best = elite_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "Combines DE-PSO with adaptive clustering and exploitation through elitism to enhance exploration and exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.3152304773921361, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.8985939644773882, 0.9033714129742756, 0.8912926477011884, 0.9013711305929282, 0.8970777941202067, 0.890400258115601, 0.8882268021022041, 0.9074572864638024, 0.900374573949877, 0.7938777257177274, 0.7991659194036052, 0.8062725665949676, 0.8170706987756289, 0.8047145572977847, 0.8119163613513407, 0.7909373147384636, 0.7731454673296062, 0.8194555166544447, 0.14062794796974853, 0.10739778836254299, 0.15943228560491696, 0.14105045122083792, 0.1524691980768137, 0.1836380860398572, 0.09100479212857149, 0.11752573224498752, 0.15459170683468515, 0.155397918179907, 0.10619808067242886, 0.11216045598080104, 0.0851696853124938, 0.10840069991553825, 0.15260872952637694, 0.13892712955784503, 0.13786688003463843, 0.05026787965864499, 0.9927142340545274, 0.9931099286583371, 0.9938554959727455, 0.990374759996869, 0.9929259261330271, 0.993745526333959, 0.9905214927307002, 0.9900950811630511, 0.9777621578671508, 0.7505029362037098, 0.8148788935976972, 0.7808503577025547, 0.7860268394367912, 0.7580378527321212, 0.7627860848480797, 0.7617089477525221, 0.7952985768244281, 0.7890684038803262, 0.22340278684082937, 0.2591394387382243, 0.3510891676948217, 0.19406999875123443, 0.277214982881661, 0.19204669687272624, 0.22966752985696814, 0.14863871984670862, 0.22463771304331603, 0.23127243476362547, 0.23202891740568432, 0.13334808622059258, 0.13347317511941215, 0.23344458102089738, 0.23169045635822383, 0.12856500349190592, 0.23546350984080877, 0.23492088033714598, 0.15315912763588513, 0.2338294232071073, 0.24568017550312626, 0.3211199537882573, 0.2575558345454082, 0.25689640470362196, 0.13162003240608788, 0.1339836590692115, 0.13601816098993347, 0.016350710173672622, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01347440859880622, 0.07987893682277702, 0.07268963828580277, 0.04029689677844017, 0.028570697160296032, 0.029648408710469032, 0.029377629898411195, 0.06406808601374703, 0.11998186764648566, 0.03631491733484071, 0.037629155332092656, 0.05108632206091457, 0.07961631941098712, 0.12276815064368807, 0.09500871541540779, 0.10229912716150358, 0.10182221146315495, 0.24991900402457923, 0.040280457841103456, 0.0934632374164105, 0.19538243949651501, 0.006676865017051226, 0.15870926542012354, 0.04712089005778908, 0.06302989023408367, 0.23381116256973133, 0.08262698346084585, 0.5777623524884141, 0.575665750181541, 0.5651262130906648, 0.577512497008061, 0.5518899413051062, 0.5409225206717543, 0.5688623335241008, 0.5734511127277812, 0.5568937701146042, 0.09116287280910307, 0.05871856329639291, 0.05884030700246823, 0.11571912584863275, 0.1642691845572425, 0.1821136418683682, 0.07624889849335925, 0.10321517001319447, 0.08832429755195281, 0.3692654059370375, 0.17937564915324744, 0.2982301397957762, 0.3110006059850472, 0.15909187171178096, 0.22389928996319874, 0.18388034918628104, 0.381425034583447, 0.41306064513812757, 0.448908640435259, 0.2861234304826825, 0.22191603591846887, 0.5377630140213202, 0.22040196741137452, 0.3071416796152985, 0.4861296754303869, 0.45900104937760666, 0.5031185587891551, 0.26783815906096975, 0.2896958335476063, 0.18367859963859468, 0.24215629315971188, 0.23014497733275052, 0.20415710219004835, 0.2561618418574316, 0.18280856053778527, 0.2608498458779779, 0.1741877819397165, 0.348566101859205, 0.21047193724148017, 0.24075316945420877, 0.21830299250432061, 0.21763668971225492, 0.18559185288118574, 0.21042746234798182, 0.19884541365058828, 0.2079029260876767, 0.19374555887761558, 0.20725717197902127, 0.19572871348554977, 0.20844935400201248, 0.20921174541283416, 0.2253627987708745, 0.8506812707757605, 0.22485647000789344, 0.2005264135331214, 0.907620684079038, 0.9048030533686781, 0.18685585484401146, 0.17794561169725442, 0.1778791713275124, 0.14201601227084304, 0.13552949196732167, 0.2128183379166192, 0.16941015370304235, 0.21091110367245525, 0.1559725835547512, 0.12803047801449097, 0.11239820352836394, 0.1525281065951014, 0.21322935410082222, 0.21247436125118369, 0.8660818864330804, 0.1916932593982067, 0.19829556433633766, 0.1909070962739492, 0.19805928108219717, 0.16979966664993584, 0.2132284484176925, 0.21557262112181674, 0.19940531647351967, 0.21328997152413554, 0.08980909884852262, 0.09761986871672546, 0.09192193445724117, 0.0925250258160446, 0.08117796300738389, 0.10255382404678681, 0.07483051038865085, 0.08120831159225583, 0.09855208605658661]}, "mutation_prompt": null}
{"id": "44a2db9a-6eae-471e-afaa-82f4078cce1b", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "3b1319d8-cfb1-4c23-ad28-7738a3761d2b", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "ff51fe19-51b5-4e13-8a15-45c889870abd", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9\n        self.f = 0.8\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_decay = 0.99\n        self.cr_decay = 0.995\n        self.velocity_scaling = 0.95  # Change 1 (new attribute for adaptive velocity scaling)\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._multi_mutation_step(func)  # Change 2 (new step)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            mutant2 = np.clip(a + np.random.uniform(0.5, 1.0) * (c - b), -5, 5)  # Change 3 (additional mutation)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, mutant2)\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _multi_mutation_step(self, func):  # Change 4 (new function)\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b = self.pop[np.random.choice(idxs, 2, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - self.pop[i]), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.velocity[i] *= self.velocity_scaling  # Change 5 (apply velocity scaling)\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):\n        if self.evaluations < self.budget:\n            for _ in range(2):\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n        self.velocity_scaling *= 1.01  # Change 6 (adaptive scaling adjustment)\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "A refined DE-PSO with multi-mutation strategy and adaptive velocity scaling for enhanced diversity and convergence.", "configspace": "", "generation": 61, "fitness": 0.243212034826827, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.5788162311155083, 0.6936880198135102, 0.6423540791164273, 0.6348540201408943, 0.6230275114207036, 0.6433953480363062, 0.6396115631444561, 0.6184590111156951, 0.6263031208672611, 0.07661506466516654, 0.28201983648406226, 0.1922508293459323, 0.28825588411320335, 0.25757732077647444, 0.15124815407200842, 0.3468705569831231, 0.1681867841662419, 0.25159144353783713, 0.15934828199426265, 0.10285793013449929, 0.1845669691784131, 0.06622614298003027, 0.1347189811736571, 0.07577904139867264, 0.12343629401272849, 0.13853846382359547, 0.24330529776785892, 0.14009863581389126, 0.10618702187176732, 0.10786092050170482, 0.0993582604747677, 0.1034930613523527, 0.1090008158909288, 0.10973753008389975, 0.12643500513354977, 0.10558099066064586, 0.9891733407041772, 0.9857508911139369, 0.984390732645567, 0.9846012508626211, 0.9891532745072369, 0.9861622929399907, 0.9896125110034444, 0.9853390407301457, 0.9901746330220813, 0.39784016705603475, 0.25702309114212896, 0.2872514045016984, 0.3226560129115089, 0.2568971232786692, 0.3684668415448835, 0.2956245983455189, 0.2787126294244294, 0.2681576555778058, 0.16930786968060751, 0.30405705845767894, 0.22281577707642342, 0.19079725688465765, 0.27059041640693304, 0.27361940052639433, 0.2320963826070298, 0.17553409623457805, 0.1150038087312385, 0.16019993183785175, 0.22127931378313515, 0.14058742618886155, 0.12991655490242515, 0.16731126221279924, 0.11435143069699183, 0.1905070276445875, 0.22920009377549866, 0.20885166655781118, 0.1603587675393554, 0.12998704337897526, 0.14105912498191486, 0.15551935599336808, 0.1844372191641661, 0.14243318422049867, 0.19021737542728878, 0.17001222100392954, 0.2151893802240611, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0003012023926578511, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1252186234515058, 0.0544483710103586, 0.03402838567886335, 0.11838741664503782, 0.02269300072496394, 0.014214454991978931, 0.05657998030616984, 0.11031210770434341, 0.0657510349080509, 0.07129128673673168, 0.05391433984033234, 0.0433117232869461, 0.0744465539437027, 0.22120373496044954, 0.07342795046823736, 0.08731193864831543, 0.039966044657418376, 0.08334490515822435, 0.0924485871216515, 0.04131600705639871, 0.10646181624974327, 0.12682621886828838, 0.04765605387525518, 0.08984001909436212, 0.08889601056513163, 0.06811517523971544, 0.09723913092706649, 0.46502386796754447, 0.438004773370012, 0.48265773126216927, 0.539676736666996, 0.46696515704931874, 0.454845727665662, 0.434231055997639, 0.4545667873179967, 0.4797127122275753, 0.08196464758133026, 0.10480123447095668, 0.07077764942394005, 0.10459151160741498, 0.11276630846339719, 0.12011926381089943, 0.12231960677873777, 0.07321624048585074, 0.06079295919496741, 0.2578619003734095, 0.18523919132778532, 0.3067801893835197, 0.18730134354656192, 0.23811822893880596, 0.17790167864138007, 0.15224563208270414, 0.21726378848226124, 0.1646252577136995, 0.27116094342636443, 0.31719616355843694, 0.2609849801744998, 0.3289576850340824, 0.25861334469579533, 0.3035501599652516, 0.28975066283063955, 0.327647089604016, 0.3148727248931287, 0.14720987981962042, 0.24076359228406696, 0.24620152146544982, 0.22501192345867826, 0.24121886761540257, 0.18253346014888427, 0.2360341020032053, 0.2220510143332166, 0.1340162875859382, 0.19577380810828104, 0.17610622052077196, 0.1611923228018004, 0.1997473800338787, 0.2500384738899183, 0.1742136009789088, 0.21084747473755272, 0.22692310559546458, 0.18583659337532588, 0.18941592709797472, 0.24939241343791763, 0.18684677471216415, 0.21767684904992313, 0.22224336282627366, 0.2170508699221949, 0.22805985951351304, 0.20502408951192097, 0.20070573040564232, 0.6022389192829039, 0.16963609846574912, 0.2085960861612558, 0.7553970703722339, 0.7203820446679061, 0.8974527053815362, 0.16486003688738182, 0.15198721165124773, 0.14208326307976726, 0.20814688412207805, 0.5846227598085234, 0.16800251238727082, 0.16699665207521341, 0.2069184502500676, 0.4756740258261287, 0.20558540932489122, 0.1527812768857031, 0.2133129494303283, 0.17237741604982182, 0.18832842755898827, 0.1812396949932753, 0.18365331326765677, 0.22923362754811705, 0.2011614027028752, 0.18430761470021784, 0.19187237573800875, 0.18216986538321922, 0.07978514031995287, 0.08064520924414742, 0.07287651283473007, 0.07668351792741068, 0.12632507919098845, 0.09503111783136953, 0.07129150311973076, 0.06656378792721784, 0.0727046838231914]}, "mutation_prompt": null}
{"id": "8d58305a-fed7-4bf1-8d65-229388b7eaff", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "211f3cf8-7b2b-40b6-9e1d-0c8b7f51d1ab", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "2a556e16-2ea2-46c8-b40f-99142225ff1b", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "dbfa1455-461d-4ddc-9c85-273d92a69719", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "da8cb2e5-508a-4074-91b0-5029355caebf", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Change 1\n        self.population_size = self.initial_population_size\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9\n        self.f = 0.5  # Change 2\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_decay = 0.99\n        self.cr_decay = 0.995\n        self.evaluations = 0\n        \n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n            self._dynamic_population_resizing()  # Change 3\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)  # Change 4\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):\n        if self.evaluations < self.budget:\n            for _ in range(2):\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)\n\n    def _dynamic_population_resizing(self):  # Change 5 (New function)\n        if self.evaluations > self.budget // 2 and self.population_size > 10:\n            self.population_size = max(10, self.population_size - 1)\n            self.pop = self.pop[:self.population_size]\n            self.velocity = self.velocity[:self.population_size]\n            self.personal_best = self.personal_best[:self.population_size]\n            self.personal_best_values = self.personal_best_values[:self.population_size]", "name": "DE_PSO_Optimizer", "description": "A refined DE-PSO optimizer with adaptive mutation scaling and dynamic population resizing for improved exploration and exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.3002043154225873, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9061410407685858, 0.9185864148914684, 0.9141714865681605, 0.9107454706829483, 0.917201352946612, 0.9095726683009625, 0.8957492363066412, 0.909543589020971, 0.9070664470489674, 0.8297234747726083, 0.8100595515191533, 0.04270938173662975, 0.04347339147204876, 0.8153605009127006, 0.04675505776052813, 0.05791721084360002, 0.8160437226358371, 0.8079087325150833, 0.16091631566509057, 0.10939089290157644, 0.11069031006050123, 0.10437460784995112, 0.19049918333529225, 0.07155865731390953, 0.11140009471566825, 0.1450951604481202, 0.15859927667312368, 0.12192380776476963, 0.08528667650699207, 0.12981216694353093, 0.14286497085137595, 0.14349071815036318, 0.14204145480257302, 0.11431188241251056, 0.14551458257906724, 0.11226124974431406, 0.9926277689524402, 0.9896493147206363, 0.9901338212617813, 0.9888576655194113, 0.9923248076372395, 0.9907449616967561, 0.9896660903621344, 0.9901468698319302, 0.9937694457033078, 0.8095423695643469, 0.8009284332059542, 0.8138795557874187, 0.7959910056658214, 0.7773567735890777, 0.8037477077507885, 0.7776222054154892, 0.8138914022262286, 0.8164049870927641, 0.2256446222921601, 0.3335532709324087, 0.8614618460256718, 0.20860424696579238, 0.21296826534236502, 0.19353347142088273, 0.23119418869772257, 0.23656577643496868, 0.3899895608360767, 0.24917648508293122, 0.20188895611014235, 0.2205403385196295, 0.11106552097968747, 0.10818279795346375, 0.20501794283130426, 0.22853075119303, 0.11349178434838214, 0.252169070027232, 0.23733512554337743, 0.24668346248900141, 0.23161387320601157, 0.24084770101599173, 0.46153593419669947, 0.23915393379480954, 0.26979897077984516, 0.24477483017457935, 0.25874543491753954, 0.059535299059926716, 9.999999999998899e-05, 0.018046830774130274, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006086059961234791, 9.999999999998899e-05, 9.999999999998899e-05, 0.052446631476608, 0.1043978781426893, 0.08369399321817239, 9.999999999998899e-05, 0.009076250801182684, 0.051494567285590764, 0.05464081204157989, 0.06077039215496083, 0.04993335707553048, 0.051356388148405485, 0.03764355476288728, 0.4009992392557088, 0.09678049048759163, 0.09940512104056798, 0.08181051011722351, 0.209701660468658, 0.07437627252283874, 0.11288319390740253, 0.03831310139653965, 0.08270911718809015, 0.20850923237528451, 0.06491184632602343, 0.1796037441465933, 0.06206329533592703, 0.08426035464768067, 0.2159662793405338, 0.09219202093499757, 0.5302803575155247, 0.5565624845780611, 0.5395876333502858, 0.5574645598534125, 0.5981829060503028, 0.5577357498862239, 0.5802163146792692, 0.5615487522947322, 0.5877017520529912, 0.1583109637283041, 0.12788642078569534, 0.09339048479822665, 0.07846103488832612, 0.07209391278319055, 0.11629476806304284, 0.12257897385598937, 0.09312838485477282, 0.0962826179278018, 0.16435672434229398, 0.15985550847607932, 0.25380913378983583, 0.27095686080621484, 0.15693145690836086, 0.27831202592065285, 0.19908532691405256, 0.26400409404831127, 0.2900390266030882, 0.3110895840551047, 0.5086575113589422, 0.5052183338323603, 0.4823307096317284, 0.3742518461214368, 0.265737041763353, 0.5440574275534469, 0.24109086408664693, 0.3486864802690135, 0.17085278593430064, 0.3800752851885646, 0.1579363682629713, 0.1356878153721215, 0.14675301095484483, 0.17969373737266847, 0.28689204268363, 0.22282414443260268, 0.14996364223530523, 0.2307090752269414, 0.23415610699433742, 0.21917241191853587, 0.19690842700637545, 0.21951012727133135, 0.22047463182991556, 0.17425589927460838, 0.19375265599682912, 0.23341150738384076, 0.2108341762766186, 0.8285656607622158, 0.20720873487632108, 0.22777933657156169, 0.1976545355176913, 0.1760784428222918, 0.21235642524067644, 0.2561932377183641, 0.19875126538042043, 0.17282951555457693, 0.18785886384870032, 0.927740073976735, 0.17858270385154906, 0.09564025451684743, 0.10528436497721416, 0.1655731505616932, 0.17030810345735203, 0.1677307844310686, 0.11291108079484513, 0.16816546793466514, 0.12811911015550737, 0.16787124716916824, 0.2117451329397495, 0.21180377446859033, 0.15661576066999527, 0.2134930958618224, 0.09422186085076667, 0.18975336782285734, 0.18894446245614116, 0.20213301484460655, 0.22117222230047484, 0.21105550600974377, 0.18173067187347114, 0.20014205104899174, 0.2075887193367294, 0.19118845441899457, 0.09063523639078352, 0.11084832044904502, 0.08760947751293346, 0.09361165291419749, 0.0829870347686903, 0.0846374242056368, 0.10246730705570828, 0.0952638547417104, 0.10681790626229992]}, "mutation_prompt": null}
{"id": "fbb1c1e3-3f20-49f5-a155-40234edf1666", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.98  # Change 1: adjusted decay\n        self.cr_decay = 0.995\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._probabilistic_reinitialization()  # Change 2: new function call\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.5) * (b - c), -5, 5)  # Change 3: wider scaling factor\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):\n        if self.evaluations < self.budget:\n            for _ in range(3):  # Change 4: increased attempts\n                local_candidate = self.global_best + np.random.normal(0, 0.2, self.dim)  # Change 5: larger perturbation\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _probabilistic_reinitialization(self):  # Change 6: new function definition\n        if np.random.rand() < 0.3:  # Change 7: probabilistic check\n            self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n            self.velocity = np.zeros((self.population_size, self.dim))\n            self.personal_best = self.pop.copy()\n            self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with adaptive exploration-exploitation balance and probabilistic reinitialization to boost convergence and diversity.", "configspace": "", "generation": 67, "fitness": 0.2844422582388684, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9191793016906293, 0.9183400910372548, 0.9057023158105736, 0.911593526173621, 0.9163338522162282, 0.9189138260203453, 0.9168830274296257, 0.9181521044236552, 0.9018220296345448, 0.7929477516029009, 0.8219268580913439, 0.8395457497027177, 0.7785258474148318, 0.8295056569076409, 0.8294002915181324, 0.019073331543307148, 0.05328043044222308, 0.8278672934453971, 0.11659151658141598, 0.12219012595774781, 0.11673370918213222, 0.12105340111644036, 0.17139355012793034, 0.1391639076078216, 0.06707305418472642, 0.10552542361769612, 0.11694407834474674, 0.1565840197689642, 0.08860118930410277, 0.08315548665648698, 0.11887921407817215, 0.1083429334085575, 0.10763710652896985, 0.10876240182800412, 0.10572231161152645, 0.0951134124690729, 0.9931580586406134, 0.995314170386165, 0.9930849159687225, 0.9916931592326201, 0.9950244582558296, 0.9939080542064558, 0.9891306878579089, 0.9902632652473912, 0.9923039440534014, 0.8190571370613011, 0.7675911009334409, 0.8261601083465, 0.8087254860445745, 0.8072776547875457, 0.698854084086197, 0.8249973749747536, 0.8002702039736918, 0.8046568196419606, 0.2276133556935166, 0.1723747472786279, 0.2276683712119295, 0.21174387650250237, 0.35116359527326757, 0.1603431567220689, 0.12385160284945373, 0.1508656563960451, 0.38878582358404634, 0.2337631921991704, 0.13273345460666242, 0.19762967662401587, 0.13228219311782197, 0.13398684485153134, 0.20784388077805593, 0.20840627492649466, 0.24528819651497025, 0.22215742773620473, 0.21260754275585403, 0.23953946080956934, 0.19569650123742066, 0.21778557277040356, 0.23780900523358361, 0.13038571612093341, 0.1393614857028127, 0.13107845608682422, 0.13665820221214142, 9.999999999998899e-05, 0.006803139007959924, 0.06061880748591553, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0032340577840311857, 9.999999999998899e-05, 9.999999999998899e-05, 0.013617133746296917, 0.025262304945335767, 0.014909977006820174, 0.0006299779373454273, 9.999999999998899e-05, 0.028488572048197547, 0.014406700857468646, 0.056892759148703176, 0.08192426944948716, 0.03700425556319842, 0.036012422112112974, 0.07118606520507043, 0.09777519568862003, 0.0807651453461875, 0.11637578015090533, 0.10070448105856977, 0.11281611890561649, 0.07624595686121516, 0.0812287232275839, 0.07640822919691725, 0.16247986753625898, 0.06001755761007721, 0.10100566644961906, 0.09085566640724096, 0.06291180866263335, 0.08378419814473514, 0.05894340462191905, 0.5540766523661389, 0.5347242675444149, 0.5681792269046303, 0.5847707498104391, 0.5505428918704182, 0.6362583493902041, 0.5247629807000713, 0.597166176349178, 0.5758508128862831, 0.08476838805034148, 0.09862579195874055, 0.15883198086112882, 0.09792967844984246, 0.13019528107043077, 0.10363964141141024, 0.14144958414630615, 0.11822639250340639, 0.0937049605609287, 0.15480167039534243, 0.20470347980020187, 0.3742206637566171, 0.25277197712550437, 0.1994704292969267, 0.18266226167086164, 0.19903193709852085, 0.12531931836226817, 0.37409405589696976, 0.11361451642320275, 0.27178686834265176, 0.20045463003371222, 0.15331116191359628, 0.252099587828264, 0.4324486978266914, 0.19650166269903635, 0.2927356972798819, 0.254818684240815, 0.2334417585535411, 0.0814006086604746, 0.1917977158356745, 0.24902000372573807, 0.21808529781670527, 0.211244652952587, 0.26437048335227276, 0.13807922020891383, 0.2556648635983545, 0.15601688490833565, 0.19932601580052256, 0.20814096466852283, 0.20441869147872016, 0.2161320489738523, 0.19998212206208354, 0.19468207660979975, 0.21843034037357023, 0.18897205151660512, 0.20718307629090538, 0.19465651881318813, 0.20922737062566, 0.2256527738145303, 0.19867858814963912, 0.18510312565804754, 0.21004124453207018, 0.18022853284418483, 0.21017456255331934, 0.19952381984118905, 0.17292199036055922, 0.16355977543212952, 0.21131363617282595, 0.17883606798650087, 0.1879668762689194, 0.1882636214430099, 0.12667355508341938, 0.16713588967575466, 0.16879778123153177, 0.16829208730445466, 0.16903599880188136, 0.1277827750471482, 0.1286387868002704, 0.2074729015900778, 0.768490097996319, 0.21326590439241322, 0.12857646800830358, 0.19062531990320408, 0.1826676448363158, 0.20598345848754884, 0.21025266641704166, 0.1923771572645182, 0.19249343488296433, 0.19738258827533806, 0.20734961102907834, 0.20700960587786987, 0.09208499393157488, 0.07142587296542513, 0.08950088805245904, 0.09248784782458097, 0.08548133650603629, 0.08793327664820338, 0.0904513239809348, 0.09239651340230337, 0.09301118152973975]}, "mutation_prompt": null}
{"id": "3a5c04b8-89a1-4ed3-bf06-9aed582f62fa", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "0cc55442-b1ae-424a-9b5a-eeb1996ec5d2", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "12dc1b29-a9b9-42d5-9a1e-cab421836965", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "f4bb6616-7b3a-4987-b858-26d080e8af23", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "2931edcf-541d-4437-8a21-6e6366a0efb9", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "0e482062-3aaf-4dba-95ea-49d4a9631d47", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  \n        self.cr_decay = 0.995  \n        self.f_decay = 0.99  # New adaptive F decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)\n            self._maintain_diversity()  # New change\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), -5, 5)  # Modified mutation strategy\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):\n        if self.evaluations < self.budget:\n            for _ in range(3):  # Increased attempts for better local search\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n        self.f *= self.f_decay  # Apply F decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)\n\n    def _maintain_diversity(self):  # New function for diversity\n        diversity_threshold = 0.1\n        if np.std(self.pop) < diversity_threshold and self.evaluations < self.budget:\n            diversity_boost = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))\n            self.pop = np.clip(self.pop + diversity_boost, -5, 5)", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm with adaptive mutation strategies and diversity maintenance for improved exploration and exploitation balance.", "configspace": "", "generation": 73, "fitness": 0.30914328043366673, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9018798385811245, 0.9043225518908021, 0.9016527987478881, 0.9077299970179759, 0.9034756281610122, 0.9005093574327628, 0.9136761019244714, 0.8968557999306298, 0.9042171975951079, 0.0425016310485522, 0.7960599716223626, 0.8122208425545163, 0.7693198083010316, 0.047285373615977955, 0.7783519760234537, 0.7984505948281534, 0.018339127903679753, 0.8019951626800851, 0.14532051368132726, 0.14629483807412158, 0.14462154191127652, 0.07614580737374166, 0.10901306614969763, 0.1523377317805873, 0.11654439508045145, 0.1174614182003646, 0.13824534511191344, 0.10885478370071211, 0.12395149051225396, 0.11106330475895065, 0.11298516401712999, 0.15271265909936205, 0.11267974996451868, 0.11537685490393446, 0.1723946453855324, 0.137978178101963, 0.9904279822588024, 0.9904467797157666, 0.9926437875358675, 0.9923571068261553, 0.9907130470998946, 0.989919819711086, 0.9904955507187094, 0.9901780025352349, 0.9940146143318813, 0.7853327982664908, 0.7865166592421344, 0.8120978193842296, 0.7769703034692368, 0.6170945750835397, 0.8000885972243361, 0.7859243353203628, 0.8091752826472954, 0.8045933012825215, 0.13660397525190315, 0.16909738085859483, 0.22646161526456132, 0.21151414942705493, 0.1905208712147547, 0.9012207382138785, 0.1253182062284972, 0.12856128223228913, 0.3953224605707052, 0.14171591114535187, 0.2445563609293665, 0.24005004196137436, 0.12896460857053849, 0.13027546012572278, 0.22106671538474276, 0.11494198974911163, 0.2505666566644915, 0.23007361503269508, 0.24788148167434076, 0.4114364261775124, 0.3094941071982228, 0.2660139905750858, 0.253083716064075, 0.23725939712790534, 0.039114135773828496, 0.18809776254836874, 0.2233930790759211, 9.999999999998899e-05, 0.007017017227690436, 9.999999999998899e-05, 9.999999999998899e-05, 0.038382965349895826, 0.04961652539612693, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05497766163715534, 0.09157832183825321, 0.028308975552528093, 0.004006021650364344, 0.07225390232216145, 0.03385729291567385, 0.021074312440157672, 0.12391603166033727, 0.06012141723454967, 0.05063966668041031, 0.039462336136223186, 0.050486549653467216, 0.14772030931895097, 0.10002753947783039, 0.09801627886742059, 0.10272766423568702, 0.14208742323539936, 0.07575768932276294, 0.033542552868347175, 0.12117226154677208, 0.1706098148117713, 0.09392291192638003, 0.11974992235811188, 0.08762796811527207, 0.08379556587434112, 0.09396894485022989, 0.08264015659841184, 0.5714822081052495, 0.5661639503155413, 0.558057149279551, 0.5609624023952852, 0.5480950755628056, 0.5546372620542237, 0.5752496445771025, 0.6929779943879175, 0.5642099314472366, 0.14410968250466627, 0.14614986715293143, 0.11687609346521788, 0.1421741700918424, 0.09598463587591544, 0.11165304206476812, 0.11715721952258007, 0.0827743609790692, 0.12434101336687287, 0.23498825749813845, 0.19785018151368228, 0.1484778388768333, 0.1636362429739192, 0.28626228510742735, 0.16869190077085783, 0.19547225150983405, 0.19295656097290725, 0.2006829335715865, 0.2672484071159946, 0.4190248881754838, 0.332748600679993, 0.21530374457126122, 0.3248367305899532, 0.17855228685829572, 0.29140113688488767, 0.44483698516665604, 0.4823456713388832, 0.17468414109791752, 0.23993252904599927, 0.29237679696303676, 0.21262023678869257, 0.31087579175852464, 0.2899688214221795, 0.1651269690792171, 0.2032543575777238, 0.2749893748980674, 0.19991250393094562, 0.2256698850963631, 0.28135090758583015, 0.2333644376109758, 0.2326350842553324, 0.23455316420162964, 0.21238912579681524, 0.2097097596470071, 0.26078045689845686, 0.21061079062124055, 0.2070644117133439, 0.19763487075771002, 0.25096908536710094, 0.19554399865338135, 0.8634417093841702, 0.1812149826534596, 0.17558538543411617, 0.19192369347769633, 0.17231581992812806, 0.1865441920323987, 0.9368903442927848, 0.17860261301945846, 0.1671998482594883, 0.9310911838463868, 0.16984611827977392, 0.11644827116118595, 0.16513475545235834, 0.11307517191755267, 0.16880058797275455, 0.8767996843662152, 0.16789331563410503, 0.2082421101715073, 0.15481571161864016, 0.7881740181124733, 0.08266103536630565, 0.8175531622751826, 0.22418415681950732, 0.18736722897178548, 0.19440043700546417, 0.1843994006585954, 0.20954679339841553, 0.20595696944328756, 0.19330978603016513, 0.20501143544805878, 0.19430770216321458, 0.09400858462830453, 0.16821872622542833, 0.0921940766356345, 0.10013978295924897, 0.1389604178311945, 0.10734766737444246, 0.10159558793389589, 0.09586822142903617, 0.09540002950278215]}, "mutation_prompt": null}
{"id": "24bebe53-927f-45ea-aea4-a15c8feb1448", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        memory = []  # Change 2: Introduce memory for solutions\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._elitist_local_search(func, memory)  # Change 3: Enhanced local search\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _elitist_local_search(self, func, memory):  # Change 4: New local search method\n        if self.evaluations < self.budget and len(memory) > 0:\n            best_memory = min(memory, key=func)  # Change 5: Use best from memory\n            local_candidate = best_memory + np.random.normal(0, 0.1, self.dim)\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n            else:\n                memory.append(local_candidate)  # Change 6: Store unsuccessful candidate\n\n    def _adapt_parameters(self):  # No change\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # No change\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO with adaptive memory-based learning and elitist local search for improved convergence.", "configspace": "", "generation": 74, "fitness": 0.28355404987077176, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.28.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9066929228512117, 0.8915473031622616, 0.9031166432485541, 0.9052141194380524, 0.9025407045661437, 0.9122667393488603, 0.18097461031515982, 0.9073531353231111, 0.905164724897325, 9.999999999998899e-05, 0.7984362629898812, 0.8246463151199582, 0.7052586840752626, 0.04858217099159012, 9.999999999998899e-05, 0.8206034697547558, 0.814973790898427, 0.7996334560277459, 0.14020539192146864, 0.12239075840105251, 0.15640289102920857, 0.06317029696115728, 0.1424243907433762, 0.11173484513650744, 0.15769515860061167, 0.1321173922476364, 0.15736475231272162, 0.11247654892711012, 0.09937822100643767, 0.11420075974363986, 0.11405240549774609, 0.09425043484068318, 0.10957782135258931, 0.09734372685062387, 0.14381994211509175, 0.09815832016178161, 0.9931130578968473, 0.9910925338973549, 0.9931044259125924, 0.9909198353181068, 0.990626591055707, 0.9931153975480076, 0.9911639527777922, 0.9905626392629976, 0.9896300005414763, 0.7927295041627959, 0.821152514033107, 0.8238099261017623, 0.15352671811208274, 0.8169261931482849, 0.1537408634709473, 0.08198278108840895, 0.08919439084122038, 0.05143073724910774, 0.36627456648646406, 0.3550466016759586, 0.22728481357673813, 0.8945527309601814, 0.1607544586285663, 0.21124072435665442, 0.17849914703103276, 0.23204296260365342, 0.14991734385954036, 0.13132706064775723, 0.23110010127482994, 0.21863018445401017, 0.10379211653324694, 0.26545363120309784, 0.13239096034997588, 0.2221271797114831, 0.22744926783738528, 0.24127674772713859, 0.23674921726391818, 0.24313570706434162, 0.23055172521284384, 0.257665775653236, 0.13328231149000203, 0.15330599490297103, 0.2674411135821404, 0.279551613730066, 0.13506589892102128, 0.022830768156315018, 0.06550398465329854, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01751271487067174, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05117491644858141, 0.07630623115971136, 0.11243714236399427, 0.11251780001189093, 9.999999999998899e-05, 0.03520910082551765, 0.05179460539206371, 0.0343570889159277, 0.07302798246689235, 9.999999999998899e-05, 0.036738856872166936, 9.999999999998899e-05, 0.07988710384641307, 0.08690981939786502, 0.18445612672215017, 0.16064225584904124, 0.10075230108830258, 0.10032822434371969, 0.2713573159592998, 0.11169060717030932, 0.11336605384860687, 0.046522850686049444, 0.15473544231040381, 0.08656110195869737, 0.1729613806728879, 0.08919685892436868, 0.04942755665833176, 0.5146681106110818, 0.15334640599395954, 0.5872252427836814, 0.1824285171736788, 0.5505123159173226, 0.6040044980691319, 0.5522002227987948, 0.5569625092789665, 0.5774414710002223, 0.11786668520122934, 0.055105121999802, 0.051088733039413636, 0.18459903610281914, 0.12481067990643491, 0.15676713638853312, 0.1082844630818588, 0.1401661461760223, 0.10377141999075135, 0.25755962019475687, 0.19971314038602506, 0.19610994315479013, 0.191663742117, 0.15494859513018633, 0.2330122006223747, 0.19354394313473833, 0.15290954574969962, 0.1858196342513544, 0.3104350455997035, 0.3414273640379165, 0.3452890804439439, 0.37465561551621474, 0.21647446157146422, 0.2849539024947164, 0.21043813251875798, 0.19826162472990616, 0.268144672222984, 0.3237320408344886, 0.2654716399506415, 0.21930579717079424, 0.24600867675990257, 0.2021279982369294, 0.19695210967054666, 0.25901779667406377, 0.1393415369148544, 0.22714874921472472, 0.195241163680971, 0.20953202869222332, 0.21988691765501867, 0.1847339955092956, 0.22357096173050417, 0.22738202945214292, 0.20941540550345017, 0.1917145497918603, 0.1989484789921726, 0.2086170583570509, 0.20670342416164567, 0.1884593043175078, 0.18646933975256763, 0.20136543719295508, 0.19677583636652285, 0.18970483020403872, 0.8339642320827401, 0.200244043250413, 0.19733695612706192, 0.16569416609288323, 0.1852006175217309, 0.17751294600172385, 0.1884218521633687, 0.17732711531423995, 0.13112711094732732, 0.16903985404326927, 0.8958232295742258, 0.1683068906743822, 0.2110324798707024, 0.6378988910851997, 0.12776476755062283, 0.8481697064208562, 0.15428602472167752, 0.7784215324063934, 0.8674309643528034, 0.28942742799454335, 0.19739562996588556, 0.2072376756133113, 0.2078932532085318, 0.2241691947699893, 0.23929596212964754, 0.19319186764414087, 0.19846284489316623, 0.20810951319102367, 0.22581284938371493, 0.09127002012189656, 0.1048332492146079, 0.10723785996684077, 0.0930991528282642, 0.08737649795932978, 0.14110448363504724, 0.09482202854170685, 0.07623515800084102, 0.10465331505739572]}, "mutation_prompt": null}
{"id": "75525a9f-7103-4a93-b862-3a315ddde0ee", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "c1e45565-0ae1-4373-b1bc-8e38113365e8", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "df6a5198-3e8b-4c10-ac81-3a0eb0ca7efe", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "aad6ae39-e88e-4bdb-ab51-ca9a5434e6dd", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  \n        self.cr_decay = 0.995  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  \n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._enhanced_local_search(func)  # Change 1\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            # Change 2: Adaptive mutation factor\n            mutant = np.clip(a + np.random.uniform(0.5, 1.5) * (b - c), -5, 5)  \n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _enhanced_local_search(self, func):  # Change 3: Improved name\n        if self.evaluations < self.budget:\n            for _ in range(2):  \n                local_candidate = self.global_best + np.random.normal(0, 0.05, self.dim)  # Change 4: Reduced std dev\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  \n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n        # Change 5: Adaptive population size\n        if self.evaluations < self.budget / 2:\n            self.population_size = 30  \n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)  \n        self.cr = np.random.uniform(0.7, 1.0)  \n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  \n        self.velocity = np.zeros((self.population_size, self.dim))  \n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "Improved DE-PSO with enhanced local search, mutation strategies, and adaptive population size for accelerated convergence.", "configspace": "", "generation": 78, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {}, "mutation_prompt": null}
{"id": "948cf520-c835-4083-8882-46853a812824", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "3c62e804-c170-42bc-8c9d-e0c306b65eed", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "0092e9d4-3f9e-4b95-96c3-7790bfe6c0e4", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "e97aa728-c9cc-4d17-841c-8dd226249266", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  \n        self.cr_decay = 0.995  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._improved_local_search(func)  # Change 1 (new improved local search)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _improved_local_search(self, func):  # Change 2 (new enhanced local search)\n        if self.evaluations < self.budget:\n            for _ in range(3):  # Change 3 (increased attempts)\n                step_size = np.random.normal(0, 0.05, self.dim)  # Change 4 (smaller step size)\n                local_candidate = self.global_best + step_size\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "A refined DE-PSO with dynamic population management and enhanced local search for improved convergence speed and solution quality.", "configspace": "", "generation": 82, "fitness": 0.310035155022578, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9055898314361028, 0.9123237528888622, 0.9080330414048504, 0.9073452099055263, 0.9109284438506894, 0.9042449100722866, 0.8882559779456525, 0.9135641617554933, 0.9092167601391938, 0.07780912223007219, 0.7842772875850371, 0.7838345382574283, 0.7501882491675651, 0.8274608180879605, 0.8124565758801159, 0.8049505939470097, 0.8010722212824212, 0.8278558165507137, 0.07966937794386741, 0.10242099327510656, 0.11016071112284875, 0.06449269421665904, 0.1418964504660084, 0.14403568553797663, 0.10146812764158875, 0.7380824585598582, 0.1546225602937631, 0.11658047507525993, 0.06847356627895529, 0.1396632719791272, 0.11502280133817189, 0.13446168014013526, 0.1328974983850667, 0.09697863234493509, 0.11328718959972262, 0.11745240703771143, 0.9930312772670791, 0.9931989594689284, 0.9929862155860474, 0.9905416731187652, 0.9940049711442229, 0.9938607053600458, 0.9900581798488823, 0.9904225504435384, 0.9912711353062461, 0.7942468768686938, 0.8074956092513768, 0.8105122017258083, 0.7907283437362274, 0.7901953750422124, 0.8138685658725124, 0.7715902781512829, 0.8195353337464025, 0.7754237950464784, 0.13662080887912376, 0.22677381303490984, 0.21280070425570408, 0.2096414086506646, 0.16001886972294543, 0.27434289389417377, 0.19332534176598037, 0.11504926973945184, 0.23010106674807396, 0.24006224459890957, 0.23992898605678392, 0.23364447113015074, 0.13456486739461526, 0.13175603892323107, 0.1336415290790588, 0.22430590170115305, 0.2249274470268211, 0.23675264514361438, 0.13422518089848345, 0.2523684093721711, 0.19787123946619056, 0.25813677651696443, 0.23944597011560664, 0.11724302038725798, 0.25570236085157716, 0.14102368182833924, 0.1351868262817808, 0.09956917913490448, 9.999999999998899e-05, 9.999999999998899e-05, 0.02355137017229403, 0.0006252235793513528, 9.999999999998899e-05, 9.999999999998899e-05, 0.0030898998682239442, 9.999999999998899e-05, 0.02402564477789315, 0.062089095964842245, 0.10355998852295234, 0.061768622723971434, 0.009749508102758542, 0.013729030267837339, 0.05054433350402121, 0.10958918840687171, 0.1233152037479256, 0.03663490873637398, 0.414255907634553, 0.05121568298446055, 0.08074859949892943, 0.08579636458263828, 0.1693323999511427, 0.0777991119143222, 0.10463654407926193, 0.07722865590192618, 0.03342752082148415, 0.1520115176306781, 0.09992170135394629, 0.17247201550903812, 0.04837417166143476, 0.20608573867832558, 0.08612642535110626, 0.13736175172285092, 0.06300952373075763, 0.575008982568422, 0.5277043833004471, 0.5477660091829113, 0.5721925480416024, 0.5486427657188211, 0.5365207816638504, 0.6044634343629651, 0.6245885389167294, 0.5284039934076906, 0.14262067770532427, 0.14316510353903955, 0.07798584925673058, 0.13301438160082102, 0.16120924856544971, 0.1060116901958732, 0.09148195685861937, 0.1447095866690824, 0.11699599109056835, 0.17971834462796765, 0.19659806861091733, 0.19223589333246105, 0.20638553625377454, 0.1768282744361357, 0.21376431290010978, 0.15075982639084884, 0.20964838695524812, 0.1587374374985473, 0.23562127146448386, 0.32795361879107254, 0.21565182944785422, 0.2443441296506188, 0.23329229483560077, 0.386521717430796, 0.569437688829195, 0.4903528537154399, 0.46245109180598354, 0.19727625461836185, 0.21049405634931329, 0.24891240046621277, 0.21578358413182175, 0.19371416445485135, 0.22016199567476646, 0.17515363736307432, 0.15051142820636143, 0.34508763705939505, 0.17578928482294287, 0.21101919754379983, 0.24200869298034144, 0.2255287632295655, 0.20346355608542321, 0.2258411510158036, 0.2120978385082538, 0.189185614426562, 0.19443853124085264, 0.22107690975818828, 0.19556091208343396, 0.22617733750863267, 0.20629400728740044, 0.1924907966393875, 0.17904350749662357, 0.2532895481993267, 0.19563906541980003, 0.1914694365849181, 0.20033889235689095, 0.9418180656473522, 0.13598897206033211, 0.9220694123596124, 0.18903837532873047, 0.18846129269761547, 0.1885683996174481, 0.2113393790706003, 0.21304013254422483, 0.16914412951720592, 0.1691383884275287, 0.15442739439294728, 0.1270190773393458, 0.20850917116754264, 0.1555330174300843, 0.20818652410158534, 0.8589894512138959, 0.8874301813769274, 0.21870519502120456, 0.18970401581417795, 0.19997306860585307, 0.19395011043105792, 0.18591882993459874, 0.1969096427119904, 0.20466871901332007, 0.19924071561443168, 0.19534835920935134, 0.10822576347229329, 0.09495134806326622, 0.09985879824853039, 0.09914987706620126, 0.08431065706700469, 0.08386841951410007, 0.09285167766098079, 0.09641259407508695, 0.08855508333680084]}, "mutation_prompt": null}
{"id": "26cbd1bd-43cf-4340-a3a0-9e03b33a6311", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "9b870b03-60d0-4027-9ca1-0fabe3ab8fbc", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "90d4494d-6c97-4ecf-a50a-d823c566f5a8", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "bd88a216-1fec-4bb1-b58d-bffb09c4ca88", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "aa7d16b1-95b3-4c5d-8cab-57052fd45576", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "df34d8e7-858a-401a-aca6-23edd4de03eb", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "f0c74b01-9018-4eaa-aa31-d23b89f7a290", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "4dad6d6c-f95a-4da4-a95f-21261f4d1c67", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "411c0a9a-d5fe-4f7f-86c0-c00c0c20ed3f", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "c6d8ab0e-3c21-465e-a426-799b4b7b3ea0", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  \n        self.cr_decay = 0.995  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._dynamic_population_size()  # Change 1 (New method call)\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._elitist_stochastic_local_search(func)  # Change 2 (Improved local search)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _elitist_stochastic_local_search(self, func):  # Change 3 (Enhanced function)\n        elite_samples = np.argsort(self.personal_best_values)[:max(2, self.population_size // 5)]  # Change 4\n        for i in elite_samples:  # Change 5\n            if self.evaluations < self.budget:\n                local_candidate = self.personal_best[i] + np.random.normal(0, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)\n\n    def _dynamic_population_size(self):  # Change 6 (New method)\n        if self.evaluations % (self.budget // 10) == 0:  # Change 7\n            self.population_size = np.random.randint(15, 25)  # Change 8\n            self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 9\n            self.velocity = np.zeros((self.population_size, self.dim))  # Change 10\n            self.personal_best = self.pop.copy()  # Change 11\n            self.personal_best_values = np.full(self.population_size, np.inf)  # Change 12", "name": "DE_PSO_Optimizer", "description": "Enhanced DE-PSO with dynamic population sizing and elitist strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.31218867741487294, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9053894208002038, 0.908629609195314, 0.9190098938512049, 0.8996023942364593, 0.9122719380111712, 0.9162915142244115, 0.9060192745114428, 0.9080710791664027, 0.92328596660704, 0.7929882221682154, 0.7462729586125711, 0.8190306862088976, 0.8142814877055997, 0.7795295430864861, 0.8422976719057611, 0.05233886464257198, 0.8378132237058785, 0.8291888407153447, 0.15532604919803927, 0.1595253598952704, 0.12109415957976777, 0.15681818409705484, 0.12392238587320048, 0.11424798416187931, 0.09706729376911061, 0.1409240516604504, 0.15516577405080623, 0.11570409884349186, 0.09730351422251748, 0.12215033882835147, 0.11545345254210548, 0.1825636173808226, 0.07725520252692553, 0.1053991506772558, 0.18295662605723673, 0.15988844613018682, 0.9918488058292902, 0.987585579226745, 0.9887443316439845, 0.9912625695390425, 0.9898819766764282, 0.995159586299811, 0.9883844337624831, 0.9902213493466583, 0.9920752441610943, 0.8228227942022829, 0.8046258272340359, 0.8294793256650513, 0.8251168055140331, 0.8233948630172324, 0.8156636063415119, 0.8138535210157019, 0.8261759194880866, 0.8063446429233584, 0.21247253451065695, 0.8698843625052942, 0.2422674352506966, 0.38070754974344845, 0.27819775539491143, 0.15726439681679272, 0.12372342134736314, 0.8732521835394487, 0.23083892801600758, 0.2238338606901049, 0.13432318544759236, 0.22082362245185283, 0.13306811799337515, 0.1330899619906346, 0.13414385339601687, 0.18478115507670456, 0.22819123802112928, 0.22095450961887086, 0.2391063929243996, 0.13062383562942448, 0.17634114393181866, 0.11440946770308236, 0.2730614319741166, 0.26815955593259466, 0.13040518537587886, 0.255575949269676, 0.13413195091699015, 0.09050982684401443, 0.07609621173895242, 9.999999999998899e-05, 9.999999999998899e-05, 0.09506590690051564, 0.06806869600877274, 9.999999999998899e-05, 0.009281819052855411, 9.999999999998899e-05, 0.013033602389501686, 0.062163109950438056, 0.08770447257449432, 0.004876872248091191, 0.0038560153553822696, 0.11574522358783923, 0.07350840367806555, 0.03633881686988483, 0.026453875132262827, 0.05141671433760153, 0.0366814693684151, 0.038022750264722016, 0.09946322393309237, 0.08974168218714806, 0.11525237625284512, 0.09715160369578424, 0.3884702399966645, 0.07642353690477266, 0.045589119203845785, 0.20325701694711984, 0.08889624401500529, 0.018264036805053396, 0.09691385159346777, 0.062190622025676046, 0.0531540892977187, 0.05291149039512544, 0.05740126505621268, 0.5245188535349563, 0.5956138495932144, 0.5426984711961981, 0.6231743922703954, 0.570242220866459, 0.5671417288688125, 0.5876799408637485, 0.5743415044824337, 0.5779855235824913, 0.115926062841883, 0.11617644226614177, 0.08023894328066039, 0.12223797140742465, 0.12655342889179333, 0.14427743506767166, 0.8275481598576887, 0.09340686232992446, 0.133007209004395, 0.2832706787956144, 0.19080542208707718, 0.22135904558852537, 0.1899053783496365, 0.2728255537354023, 0.272544084179153, 0.18319802157631526, 0.21154917018142427, 0.29296931942302284, 0.5883106132295328, 0.38580328766006244, 0.3200869336391565, 0.2927418319753925, 0.21622422532984908, 0.3713120920385877, 0.2934885509703944, 0.5096936363055953, 0.19731702284729313, 0.31660380613053174, 0.28158427604870717, 0.16906475246380892, 0.21399172968659563, 0.22504902422981188, 0.2600274770955314, 0.13909104728166566, 0.2564097980615878, 0.2356804612335266, 0.22212614354388505, 0.21740459426667602, 0.22823274315031572, 0.29873350485449424, 0.24609183652802324, 0.19857343257826365, 0.16486066688678025, 0.22264945136699732, 0.19465232358680862, 0.2067412540043554, 0.24860438497646875, 0.2000018949063216, 0.20789578297186084, 0.21691463960407187, 0.8415728907981074, 0.2115893844373974, 0.20950844411902003, 0.20031128702490741, 0.11269675398417711, 0.16138198729537712, 0.15907807879393854, 0.1717676069018067, 0.15216970067518942, 0.16899355005741867, 0.17746661686243592, 0.11506893038491106, 0.1687638474368276, 0.16813903481008552, 0.16921539072691505, 0.21351554995536504, 0.5949437901107462, 0.20817692810246557, 0.16822527590814884, 0.2120499050672845, 0.15535923569543975, 0.15667112879573197, 0.18675361477433283, 0.18354792322172475, 0.18253361716761318, 0.19232614755172894, 0.2137493222373521, 0.18980352035689696, 0.18954045684884202, 0.1953917881566558, 0.21960893197943765, 0.1001810659848783, 0.09470536281715047, 0.12292485235016026, 0.09660478167851438, 0.10108526465293288, 0.0982431903812585, 0.08648972000457578, 0.08520772806166022, 0.09457619105122261]}, "mutation_prompt": null}
{"id": "b7f8f11e-adc0-43cc-a5bf-27370e3481d7", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "62fa06d1-fff5-46be-9a94-4650248595ae", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9\n        self.f = 0.8\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_decay = 0.99\n        self.cr_decay = 0.995\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n                self.f = np.random.uniform(0.5, 1.5)  # Change 1\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            neighbors = np.random.choice(self.population_size, 3, replace=False)  # Change 2\n            local_best = min(neighbors, key=lambda n: self.personal_best_values[n])  # Change 3\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.personal_best[local_best] - self.pop[i]))  # Change 4\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):\n        if self.evaluations < self.budget:\n            for _ in range(2):\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with random topology-based learning and dynamic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 94, "fitness": 0.30505144211657004, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.8630718985589935, 0.87599444650127, 0.8513818912791395, 0.8849895919957599, 0.8651520328393311, 0.8867113002221375, 0.8744418333829562, 0.8797245832204021, 0.8816532296302586, 0.7573470928687188, 0.7706620041285406, 0.7688422731555944, 0.693987762324874, 0.7740177292174517, 0.7683721035147469, 0.769856478004317, 0.7826123383024954, 0.74528534923164, 0.13574174403496908, 0.11364193449795024, 0.14974817644412453, 0.15063522997615508, 0.10482467700205145, 0.2230899451651881, 0.14900702012522304, 0.43042866915200906, 0.31929144968049283, 0.10795441583802878, 0.11150347499310742, 0.10318844676246974, 0.11959002364393267, 0.13478019899294336, 0.11893195560750303, 0.126731951645643, 0.08732346807295566, 0.12290234881400464, 0.9869238251493828, 0.9856224424421246, 0.9861688214019548, 0.9856432348677672, 0.9963129971138568, 0.9901347995534324, 0.9863587999830706, 0.9867285293735766, 0.989890203414673, 0.7446604377007172, 0.7344801250061385, 0.7442350936573408, 0.2528527119197562, 0.7287318707885612, 0.7048687400145894, 0.23537579422584531, 0.681857991855745, 0.02568994326448959, 0.7344944242645286, 0.21319852373653614, 0.6842453623950547, 0.20763941844117006, 0.3626558118502555, 0.3425020660693935, 0.7569736892762893, 0.14994686965765536, 0.11509093847741647, 0.17678492293186154, 0.18972058380267764, 0.17619204460062754, 0.19045969944471464, 0.19298412721807778, 0.18551774002027854, 0.18913950973107974, 0.18484417206164383, 0.2253184309196481, 0.19688012180186676, 0.0873550377435387, 0.1751745655043636, 0.2172815399730732, 0.19051709834974861, 0.18574057264686195, 0.20114097589597768, 0.1036904820845228, 0.20414049424642977, 9.999999999998899e-05, 0.004058707869174949, 0.008419609607837608, 0.03834232786856662, 9.999999999998899e-05, 0.0008684527769593497, 9.999999999998899e-05, 0.04050666468102082, 9.999999999998899e-05, 0.08125189368057728, 0.05123754098568001, 0.07464383144932785, 0.039390075408808345, 0.02693013653352705, 0.08800847982444682, 0.07756925097086786, 0.042142336170454264, 0.033703715479154184, 0.04813384041844493, 0.03470121463052489, 0.04819910630844393, 0.21955439047589342, 0.0863257776669194, 0.16257662706020914, 0.07342741155438381, 0.08977776585751251, 0.10906270910967086, 0.14808644121919856, 0.039974297404627546, 0.25450695447028016, 0.2759750218862661, 0.13338408610021069, 0.14090170722392903, 0.05676267237780208, 0.0805591063854969, 0.081368084832664, 0.5074089372951208, 0.5355192949339911, 0.525869483732766, 0.5494303508852794, 0.5232580270881377, 0.5310490687047206, 0.5580321200192976, 0.5586300745297136, 0.5729115123051973, 0.1082955465428116, 0.10204262518269513, 0.11187696456475171, 0.09718531905877192, 0.12310974899901106, 0.10966249603488687, 0.1225748709274661, 0.10071898438968385, 0.10289982018238675, 0.15282450130410363, 0.2100711331366325, 0.1621468044137797, 0.16217646543328623, 0.14316641028370725, 0.20813423348612015, 0.1407029936312818, 0.1719585759482759, 0.17189218807213058, 0.563435811400149, 0.49055088458487783, 0.4964906436830505, 0.591721586383124, 0.42841300076014055, 0.4691720566131209, 0.5826654142660922, 0.6731657665052171, 0.6834409151775422, 0.2963513496756235, 0.33364681744954305, 0.2419717234270301, 0.18888456865083103, 0.3071857642479514, 0.3773741469635322, 0.36475419855519875, 0.3306162233936446, 0.42758977862204384, 0.1958091150460396, 0.18316478429071847, 0.22208639145611342, 0.1720101012793086, 0.18134640642948519, 0.20544665803042483, 0.18155923309258015, 0.1900295845507457, 0.20822960919933153, 0.215965026843153, 0.2102206972018984, 0.211121857000925, 0.2919395982385302, 0.4989406858254858, 0.22821247744209738, 0.20621469928517144, 0.23753704576132395, 0.19426212652868635, 0.16599685446462809, 0.1717076744157806, 0.21111853362621724, 0.19712143795446446, 0.18528158977255293, 0.16066868455773387, 0.1839698427833668, 0.16936445815175627, 0.18735610794322988, 0.16804344749578615, 0.2081394520429729, 0.2056237016113318, 0.20537245640388468, 0.20261528270743856, 0.12461145811833918, 0.12605585517035633, 0.32714032992124187, 0.21237774818867483, 0.1815853478970575, 0.19092107647639367, 0.19430049301541397, 0.1799325607058534, 0.20152320557453118, 0.19302190069714986, 0.19439466447122755, 0.17776918638453587, 0.17625407203443955, 0.08630393115999158, 0.08992261741320673, 0.07980811790379505, 0.08714836695200301, 0.07881091575975785, 0.08930463601922833, 0.08894455799003298, 0.076623455495622, 0.08656728495782029]}, "mutation_prompt": null}
{"id": "4d4f00d0-4ef1-4981-a1e9-ce394539bb4f", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "65865717-19c7-4046-a108-4091bd02f551", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  \n        self.cr_decay = 0.995  \n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._intensify_search(func)  # Change 1 (renamed and modified)\n            self._adapt_parameters()\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                self._resize_population()  # Change 2 (new function call)\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _intensify_search(self, func):  # Change 3 (redefined method)\n        for _ in range(3):  # Change 4 (increased attempts)\n            if self.evaluations >= self.budget:\n                break\n            local_candidate = self.global_best + np.random.normal(0, 0.05, self.dim)  # Change 5\n            local_candidate = np.clip(local_candidate, -5, 5)\n            f_local = func(local_candidate)\n            self.evaluations += 1\n            if f_local < self.global_best_value:\n                self.global_best_value = f_local\n                self.global_best = local_candidate\n                break\n\n    def _adapt_parameters(self):\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):\n        self.w = np.random.uniform(0.4, 0.9)\n        self.cr = np.random.uniform(0.7, 1.0)\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)\n\n    def _resize_population(self):  # Change 6 (new method)\n        new_size = int(self.population_size * np.random.uniform(0.7, 1.3))\n        new_pop = np.random.uniform(-5, 5, (new_size, self.dim))\n        new_velocity = np.zeros((new_size, self.dim))\n        self.pop = new_pop\n        self.velocity = new_velocity\n        self.personal_best = new_pop.copy()\n        self.personal_best_values = np.full(new_size, np.inf)", "name": "DE_PSO_Optimizer", "description": "A hybrid DE-PSO algorithm with dynamic population resizing and adaptive search intensification for enhanced optimization efficiency.", "configspace": "", "generation": 96, "fitness": 0.310035155022578, "feedback": "The algorithm DE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9055898314361028, 0.9123237528888622, 0.9080330414048504, 0.9073452099055263, 0.9109284438506894, 0.9042449100722866, 0.8882559779456525, 0.9135641617554933, 0.9092167601391938, 0.07780912223007219, 0.7842772875850371, 0.7838345382574283, 0.7501882491675651, 0.8274608180879605, 0.8124565758801159, 0.8049505939470097, 0.8010722212824212, 0.8278558165507137, 0.07966937794386741, 0.10242099327510656, 0.11016071112284875, 0.06449269421665904, 0.1418964504660084, 0.14403568553797663, 0.10146812764158875, 0.7380824585598582, 0.1546225602937631, 0.11658047507525993, 0.06847356627895529, 0.1396632719791272, 0.11502280133817189, 0.13446168014013526, 0.1328974983850667, 0.09697863234493509, 0.11328718959972262, 0.11745240703771143, 0.9930312772670791, 0.9931989594689284, 0.9929862155860474, 0.9905416731187652, 0.9940049711442229, 0.9938607053600458, 0.9900581798488823, 0.9904225504435384, 0.9912711353062461, 0.7942468768686938, 0.8074956092513768, 0.8105122017258083, 0.7907283437362274, 0.7901953750422124, 0.8138685658725124, 0.7715902781512829, 0.8195353337464025, 0.7754237950464784, 0.13662080887912376, 0.22677381303490984, 0.21280070425570408, 0.2096414086506646, 0.16001886972294543, 0.27434289389417377, 0.19332534176598037, 0.11504926973945184, 0.23010106674807396, 0.24006224459890957, 0.23992898605678392, 0.23364447113015074, 0.13456486739461526, 0.13175603892323107, 0.1336415290790588, 0.22430590170115305, 0.2249274470268211, 0.23675264514361438, 0.13422518089848345, 0.2523684093721711, 0.19787123946619056, 0.25813677651696443, 0.23944597011560664, 0.11724302038725798, 0.25570236085157716, 0.14102368182833924, 0.1351868262817808, 0.09956917913490448, 9.999999999998899e-05, 9.999999999998899e-05, 0.02355137017229403, 0.0006252235793513528, 9.999999999998899e-05, 9.999999999998899e-05, 0.0030898998682239442, 9.999999999998899e-05, 0.02402564477789315, 0.062089095964842245, 0.10355998852295234, 0.061768622723971434, 0.009749508102758542, 0.013729030267837339, 0.05054433350402121, 0.10958918840687171, 0.1233152037479256, 0.03663490873637398, 0.414255907634553, 0.05121568298446055, 0.08074859949892943, 0.08579636458263828, 0.1693323999511427, 0.0777991119143222, 0.10463654407926193, 0.07722865590192618, 0.03342752082148415, 0.1520115176306781, 0.09992170135394629, 0.17247201550903812, 0.04837417166143476, 0.20608573867832558, 0.08612642535110626, 0.13736175172285092, 0.06300952373075763, 0.575008982568422, 0.5277043833004471, 0.5477660091829113, 0.5721925480416024, 0.5486427657188211, 0.5365207816638504, 0.6044634343629651, 0.6245885389167294, 0.5284039934076906, 0.14262067770532427, 0.14316510353903955, 0.07798584925673058, 0.13301438160082102, 0.16120924856544971, 0.1060116901958732, 0.09148195685861937, 0.1447095866690824, 0.11699599109056835, 0.17971834462796765, 0.19659806861091733, 0.19223589333246105, 0.20638553625377454, 0.1768282744361357, 0.21376431290010978, 0.15075982639084884, 0.20964838695524812, 0.1587374374985473, 0.23562127146448386, 0.32795361879107254, 0.21565182944785422, 0.2443441296506188, 0.23329229483560077, 0.386521717430796, 0.569437688829195, 0.4903528537154399, 0.46245109180598354, 0.19727625461836185, 0.21049405634931329, 0.24891240046621277, 0.21578358413182175, 0.19371416445485135, 0.22016199567476646, 0.17515363736307432, 0.15051142820636143, 0.34508763705939505, 0.17578928482294287, 0.21101919754379983, 0.24200869298034144, 0.2255287632295655, 0.20346355608542321, 0.2258411510158036, 0.2120978385082538, 0.189185614426562, 0.19443853124085264, 0.22107690975818828, 0.19556091208343396, 0.22617733750863267, 0.20629400728740044, 0.1924907966393875, 0.17904350749662357, 0.2532895481993267, 0.19563906541980003, 0.1914694365849181, 0.20033889235689095, 0.9418180656473522, 0.13598897206033211, 0.9220694123596124, 0.18903837532873047, 0.18846129269761547, 0.1885683996174481, 0.2113393790706003, 0.21304013254422483, 0.16914412951720592, 0.1691383884275287, 0.15442739439294728, 0.1270190773393458, 0.20850917116754264, 0.1555330174300843, 0.20818652410158534, 0.8589894512138959, 0.8874301813769274, 0.21870519502120456, 0.18970401581417795, 0.19997306860585307, 0.19395011043105792, 0.18591882993459874, 0.1969096427119904, 0.20466871901332007, 0.19924071561443168, 0.19534835920935134, 0.10822576347229329, 0.09495134806326622, 0.09985879824853039, 0.09914987706620126, 0.08431065706700469, 0.08386841951410007, 0.09285167766098079, 0.09641259407508695, 0.08855508333680084]}, "mutation_prompt": null}
{"id": "d0923b3f-6900-4a25-ad45-c945b3ef338e", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "b8589516-fa2b-46ac-8d87-afa898f8d661", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
{"id": "a2912c73-57cc-4b4b-889f-5507ba5cd13c", "solution": "import numpy as np\n\nclass DE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = self.pop.copy()\n        self.personal_best_values = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.cr = 0.9  \n        self.f = 0.8   \n        self.w = 0.5   \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w_decay = 0.99  # Adaptive inertia weight decay\n        self.cr_decay = 0.995  # Adaptive crossover rate decay\n        self.evaluations = 0\n\n    def __call__(self, func):\n        stagnation_counter = 0  # Change 1\n        while self.evaluations < self.budget:\n            self._differential_evolution_step(func)\n            self._particle_swarm_step(func)\n            self._stochastic_local_search(func)  # Change 2 (change from _local_search)\n            self._adapt_parameters()\n            # Reinitialize parameters if stagnation detected (Change 3)\n            if stagnation_counter > 10:\n                self._reinitialize_parameters()\n                stagnation_counter = 0\n        return self.global_best_value, self.global_best\n\n    def _differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), -5, 5)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.evaluations += 1\n            if f_trial < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_trial\n                self.personal_best[i] = trial\n            if f_trial < self.global_best_value:\n                self.global_best_value = f_trial\n                self.global_best = trial\n\n    def _particle_swarm_step(self, func):\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (self.personal_best[i] - self.pop[i]) +\n                                self.c2 * r2 * (self.global_best - self.pop[i]))\n            self.pop[i] = np.clip(self.pop[i] + self.velocity[i], -5, 5)\n            f_value = func(self.pop[i])\n            self.evaluations += 1\n            if f_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = f_value\n                self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_value:\n                self.global_best_value = f_value\n                self.global_best = self.pop[i]\n\n    def _stochastic_local_search(self, func):  # Change 4 (New function name)\n        if self.evaluations < self.budget:\n            for _ in range(2):  # Change 5, 6 (Multiple attempts)\n                local_candidate = self.global_best + np.random.normal(0, 0.1, self.dim)  # Change 7\n                local_candidate = np.clip(local_candidate, -5, 5)\n                f_local = func(local_candidate)\n                self.evaluations += 1\n                if f_local < self.global_best_value:\n                    self.global_best_value = f_local\n                    self.global_best = local_candidate\n                    break  # Change 8 (break if improvement)\n\n    def _adapt_parameters(self):  # Change 9 (name)\n        self.w *= self.w_decay\n        self.cr *= self.cr_decay\n\n    def _reinitialize_parameters(self):  # Change 10 (New function)\n        self.w = np.random.uniform(0.4, 0.9)  # Change 11\n        self.cr = np.random.uniform(0.7, 1.0)  # Change 12\n        self.pop = np.random.uniform(-5, 5, (self.population_size, self.dim))  # Change 13\n        self.velocity = np.zeros((self.population_size, self.dim))  # Change 14\n        # Reset personal bests\n        self.personal_best = self.pop.copy()\n        self.personal_best_values.fill(np.inf)  # Change 15", "name": "DE_PSO_Optimizer", "description": "An enhanced DE-PSO with stochastic local search and adaptive parameter reinitialization for robust convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fa726970-3d79-4dfe-a8ad-603bf1035a02", "metadata": {"aucs": [0.9013636244909856, 0.8986379642095988, 0.9083048312935433, 0.9071350518550383, 0.9087031615874661, 0.8933915840387547, 0.9058800566615768, 0.8936347509755795, 0.9057723655095326, 0.8005879575907469, 0.7845210966387031, 0.8237686108350362, 0.819304227958086, 0.047447464728427646, 0.8070697679329595, 0.058929130557191955, 0.8103654149154612, 0.8196243452021986, 0.1150428372851402, 0.1539423991671771, 0.1403459895531547, 0.13238784317196173, 0.1152147247420151, 0.15818228125908318, 0.14415717426498198, 0.18038737830930274, 0.1521772810417915, 0.15472454401629387, 0.17826505176991725, 0.12010277964248905, 0.11020661455144398, 0.12006288232448825, 0.13198841024442842, 0.09488215982216952, 0.12755474193268324, 0.0953509306997885, 0.9930352408636396, 0.9933408275042813, 0.992989009045688, 0.9905616888243716, 0.9940052073582275, 0.9939297567696307, 0.993163265009743, 0.9896700388812262, 0.9866502878374418, 0.7783697168455792, 0.8195475468245095, 0.7585488976866008, 0.7864230708527385, 0.8088527522072826, 0.7858646077865008, 0.8070688062106843, 0.8200306496429599, 0.8084940939953192, 0.2051691156761173, 0.2284223672086475, 0.8554293184908905, 0.15958692478944758, 0.16003725472022123, 0.18998475904143441, 0.1728378152177309, 0.11358359467604295, 0.38062132469872145, 0.23373276452537228, 0.12927808284872333, 0.24228751577187668, 0.13278524850655937, 0.13216577752027492, 0.1296904665934271, 0.22567635451613466, 0.22215927432716842, 0.40554450640615236, 0.23742013359637215, 0.2545041875178895, 0.12956921545923683, 0.25007295705136334, 0.2688213203744241, 0.14971927712172672, 0.13192586838152387, 0.2879091804033953, 0.2763004698916025, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06464222897499872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08077729807591516, 0.019340375180130875, 0.1107667901174203, 0.11712770068693168, 0.021048638502974115, 0.05651148488696944, 0.0755666896573366, 0.17678540818111355, 0.08692885156824182, 0.0513614489458627, 0.06853737472664712, 0.05098372649535632, 0.08421360553151913, 0.07932015207632559, 0.0972395039516949, 0.08689780453655271, 0.10953567800450914, 0.34599899997381167, 0.08872299793045679, 0.16599439334248123, 0.07880195918528166, 0.04733893089222507, 0.17374494910283178, 0.10736543406768029, 0.08275203251519891, 0.09418131598737034, 0.05391423390032268, 0.645286275336407, 0.5456913727535967, 0.6043053260507678, 0.5701838714317384, 0.5693178281464656, 0.5661203119943894, 0.625413922499141, 0.5870556054427005, 0.5763196413677383, 0.07090198910248657, 0.10844995725958184, 0.08028695645615969, 0.1269989969656059, 0.1430075570186089, 0.12287217583423082, 0.14131038881824387, 0.11788153262711565, 0.154095717656637, 0.2693938053702595, 0.18663809008927246, 0.1759682192284152, 0.17399826439692934, 0.17050319352813492, 0.2214204864036573, 0.15386112567942056, 0.30029820537129737, 0.21671970864933787, 0.317725654314277, 0.37984685811494523, 0.24817599645640442, 0.2573538878953916, 0.21842372102141305, 0.5350164731796068, 0.24144852290383834, 0.4906900655877814, 0.41193007014179517, 0.1661429547014044, 0.19172446684386735, 0.15778227935969535, 0.4327679458971887, 0.21909893200846864, 0.24023775471168385, 0.20625312497404225, 0.13946403637038352, 0.2761818441128133, 0.2028178032988167, 0.24583488035840761, 0.21921873634984834, 0.3356664325338775, 0.19128239638659894, 0.22616170682233938, 0.19862127557724452, 0.23535838602027181, 0.2254570617525078, 0.2224495727110981, 0.2242442961641533, 0.19191436356017322, 0.19658954652138516, 0.22581888970202413, 0.24546965891551897, 0.2259936713292846, 0.20249835022731266, 0.19764468976013627, 0.19819887674869052, 0.9321613834915594, 0.9208888245540162, 0.9193064726753697, 0.18891335814435684, 0.18869069507252068, 0.1884842265437655, 0.1618510295661848, 0.918105373067696, 0.16910441971212875, 0.16879389948090628, 0.1678517298447445, 0.1277805923666343, 0.12742518323429886, 0.15520587131898922, 0.212046373220796, 0.8612167293357968, 0.8253881708772104, 0.18966323694429899, 0.2044362221887175, 0.19000639161295796, 0.19415597596270096, 0.1895837093945557, 0.19969024407612312, 0.2083964396072372, 0.19440949740132596, 0.1851928746710364, 0.09866838566822356, 0.1092532739828106, 0.10651587923881967, 0.08353606460394292, 0.09285479666223417, 0.09648901009278088, 0.09642887344498008, 0.08654341728524961, 0.10326121203862726]}, "mutation_prompt": null}
