{"id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive (personal) coefficient\n        self.c2 = 1.5  # social (global) coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm Optimization with Differential Evolution for Enhanced Exploration and Exploitation.", "configspace": "", "generation": 0, "fitness": 0.2549983439097249, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7882223003563739, 0.7882223003563739, 0.7882223003563739, 0.8169154943413137, 0.8169154943413137, 0.8169154943413137, 0.7690954485281276, 0.7690954485281276, 0.7690954485281276, 0.5680197613953074, 0.5680197613953074, 0.5680197613953074, 0.5962898740523965, 0.5962898740523965, 0.5962898740523965, 0.6291853762145672, 0.6291853762145672, 0.6291853762145672, 0.10849055405339536, 0.10849055405339536, 0.10849055405339536, 0.10321959069399433, 0.10321959069399433, 0.10321959069399433, 0.22738774124028327, 0.22738774124028327, 0.22738774124028327, 0.12464419453269382, 0.12464419453269382, 0.12464419453269382, 0.14815312524317492, 0.14815312524317492, 0.14815312524317492, 0.1261171226803246, 0.1261171226803246, 0.1261171226803246, 0.9854925936412375, 0.9854925936412375, 0.9854925936412375, 0.9850584324633536, 0.9850584324633536, 0.9850584324633536, 0.9902621275085048, 0.9902621275085048, 0.9902621275085048, 0.3154053456951972, 0.3154053456951972, 0.3154053456951972, 0.15012604359786452, 0.15012604359786452, 0.15012604359786452, 0.316912557641825, 0.316912557641825, 0.316912557641825, 0.17878078668789144, 0.17878078668789144, 0.17878078668789144, 0.16148523999197129, 0.16148523999197129, 0.16148523999197129, 0.131101098679825, 0.131101098679825, 0.131101098679825, 0.1686314780943048, 0.1686314780943048, 0.1686314780943048, 0.1825208922566035, 0.1825208922566035, 0.1825208922566035, 0.18396354976501372, 0.18396354976501372, 0.18396354976501372, 0.18669892871434868, 0.18669892871434868, 0.18669892871434868, 0.2063899630263294, 0.2063899630263294, 0.2063899630263294, 0.19759715750835294, 0.19759715750835294, 0.19759715750835294, 0.00038339578821233733, 0.00038339578821233733, 0.00038339578821233733, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05690951958590118, 0.05690951958590118, 0.05690951958590118, 0.05627382708244477, 0.05627382708244477, 0.05627382708244477, 0.04733354985326044, 0.04733354985326044, 0.04733354985326044, 0.03269383584068564, 0.03269383584068564, 0.03269383584068564, 0.08402045556197213, 0.08402045556197213, 0.08402045556197213, 0.0633236603595334, 0.0633236603595334, 0.0633236603595334, 0.03968852118780908, 0.03968852118780908, 0.03968852118780908, 0.10601845290740097, 0.10601845290740097, 0.10601845290740097, 0.1216177285007971, 0.1216177285007971, 0.1216177285007971, 0.4995541034368661, 0.4995541034368661, 0.4995541034368661, 0.492310354641579, 0.492310354641579, 0.492310354641579, 0.5003491295975537, 0.5003491295975537, 0.5003491295975537, 0.05668537952738806, 0.05668537952738806, 0.05668537952738806, 0.11049434456327567, 0.11049434456327567, 0.11049434456327567, 0.11860118216965476, 0.11860118216965476, 0.11860118216965476, 0.15533634425560194, 0.15533634425560194, 0.15533634425560194, 0.18122183848109474, 0.18122183848109474, 0.18122183848109474, 0.14050011212654812, 0.14050011212654812, 0.14050011212654812, 0.41344915796781945, 0.41344915796781945, 0.41344915796781945, 0.35649604278443436, 0.35649604278443436, 0.35649604278443436, 0.1987251654574732, 0.1987251654574732, 0.1987251654574732, 0.16678798946697804, 0.16678798946697804, 0.16678798946697804, 0.17169245361638297, 0.17169245361638297, 0.17169245361638297, 0.2653531651202088, 0.2653531651202088, 0.2653531651202088, 0.19551011652520012, 0.19551011652520012, 0.19551011652520012, 0.17889426027287214, 0.17889426027287214, 0.17889426027287214, 0.19855664086176417, 0.19855664086176417, 0.19855664086176417, 0.1869236162393071, 0.1869236162393071, 0.1869236162393071, 0.1859998105179631, 0.1859998105179631, 0.1859998105179631, 0.19291202061724455, 0.19291202061724455, 0.19291202061724455, 0.8377540169390477, 0.8377540169390477, 0.8377540169390477, 0.18305148560313178, 0.18305148560313178, 0.18305148560313178, 0.16252768567090203, 0.16252768567090203, 0.16252768567090203, 0.16865006598048438, 0.16865006598048438, 0.16865006598048438, 0.21179731843543603, 0.21179731843543603, 0.21179731843543603, 0.15542124214409836, 0.15542124214409836, 0.15542124214409836, 0.17684183278463517, 0.17684183278463517, 0.17684183278463517, 0.1746524360042636, 0.1746524360042636, 0.1746524360042636, 0.17920680957455137, 0.17920680957455137, 0.17920680957455137, 0.07200599676124331, 0.07200599676124331, 0.07200599676124331, 0.06263378845221468, 0.06263378845221468, 0.06263378845221468, 0.05435512963038269, 0.05435512963038269, 0.05435512963038269]}, "mutation_prompt": null}
{"id": "60ab98cb-64e3-4385-8e2a-4dd0b2b606f5", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.initial_w = 0.9  # initial inertia weight\n        self.final_w = 0.4  # final inertia weight\n        self.c1 = 1.5  # cognitive (personal) coefficient\n        self.c2 = 1.5  # social (global) coefficient\n        self.F_base = 0.5  # base differential weight\n        self.CR = 0.9  # crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Linearly decreasing inertia weight\n            w = self.initial_w - (self.initial_w - self.final_w) * (evaluations / self.budget)\n            \n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Adaptive Mutation\n                F = self.F_base + 0.3 * np.random.rand()\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = personal_best[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO with DE using Dynamic Inertia and Adaptive Mutation for Improved Convergence.", "configspace": "", "generation": 1, "fitness": 0.21245476198712995, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.23.", "error": "", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.679091490012236, 0.679091490012236, 0.679091490012236, 0.6970006787944816, 0.6970006787944816, 0.6970006787944816, 0.69422534200186, 0.69422534200186, 0.69422534200186, 0.06966034381163022, 0.06966034381163022, 0.06966034381163022, 0.43444510422982396, 0.43444510422982396, 0.43444510422982396, 0.01597931620397175, 0.01597931620397175, 0.01597931620397175, 0.09405330346832796, 0.09405330346832796, 0.09405330346832796, 0.0996226788550092, 0.0996226788550092, 0.0996226788550092, 0.08565341250952063, 0.08565341250952063, 0.08565341250952063, 0.06935834179311473, 0.06935834179311473, 0.06935834179311473, 0.14141489296860732, 0.14141489296860732, 0.14141489296860732, 0.07185651498288248, 0.07185651498288248, 0.07185651498288248, 0.9835448329080884, 0.9835448329080884, 0.9835448329080884, 0.9903586750288825, 0.9903586750288825, 0.9903586750288825, 0.9859515458123035, 0.9859515458123035, 0.9859515458123035, 0.15772114948454563, 0.15772114948454563, 0.15772114948454563, 0.16603114932434615, 0.16603114932434615, 0.16603114932434615, 0.1735790460600749, 0.1735790460600749, 0.1735790460600749, 0.1761967684474548, 0.1761967684474548, 0.1761967684474548, 0.19248186242905108, 0.19248186242905108, 0.19248186242905108, 0.12638645548195981, 0.12638645548195981, 0.12638645548195981, 0.15513305696468982, 0.15513305696468982, 0.15513305696468982, 0.08095246896748298, 0.08095246896748298, 0.08095246896748298, 0.1455694718469902, 0.1455694718469902, 0.1455694718469902, 0.11613860372056328, 0.11613860372056328, 0.11613860372056328, 0.1338667888790036, 0.1338667888790036, 0.1338667888790036, 0.08833725958197358, 0.08833725958197358, 0.08833725958197358, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05534173775162965, 0.05534173775162965, 0.05534173775162965, 0.10827684891357281, 0.10827684891357281, 0.10827684891357281, 0.07385385035314462, 0.07385385035314462, 0.07385385035314462, 0.024353868672950973, 0.024353868672950973, 0.024353868672950973, 0.0665386059053753, 0.0665386059053753, 0.0665386059053753, 0.045455501931996656, 0.045455501931996656, 0.045455501931996656, 0.05599992429582312, 0.05599992429582312, 0.05599992429582312, 0.030500255687155198, 0.030500255687155198, 0.030500255687155198, 0.05034720548214411, 0.05034720548214411, 0.05034720548214411, 0.4497440576152618, 0.4497440576152618, 0.4497440576152618, 0.4879551285742606, 0.4879551285742606, 0.4879551285742606, 0.42773204243096297, 0.42773204243096297, 0.42773204243096297, 0.059059270817126475, 0.059059270817126475, 0.059059270817126475, 0.07481426973967631, 0.07481426973967631, 0.07481426973967631, 0.07610416337365644, 0.07610416337365644, 0.07610416337365644, 0.15981312035319428, 0.15981312035319428, 0.15981312035319428, 0.13845975374527786, 0.13845975374527786, 0.13845975374527786, 0.1485092044818651, 0.1485092044818651, 0.1485092044818651, 0.2591718285750808, 0.2591718285750808, 0.2591718285750808, 0.24899055863177344, 0.24899055863177344, 0.24899055863177344, 0.2553103980032644, 0.2553103980032644, 0.2553103980032644, 0.2092586718825299, 0.2092586718825299, 0.2092586718825299, 0.19371741976741474, 0.19371741976741474, 0.19371741976741474, 0.1897311034527721, 0.1897311034527721, 0.1897311034527721, 0.16850122813737567, 0.16850122813737567, 0.16850122813737567, 0.19667482515678292, 0.19667482515678292, 0.19667482515678292, 0.16686779932022777, 0.16686779932022777, 0.16686779932022777, 0.38625511939474366, 0.38625511939474366, 0.38625511939474366, 0.17512008073115215, 0.17512008073115215, 0.17512008073115215, 0.19245235960288687, 0.19245235960288687, 0.19245235960288687, 0.6460239768644049, 0.6460239768644049, 0.6460239768644049, 0.18567507787638637, 0.18567507787638637, 0.18567507787638637, 0.1453767082829137, 0.1453767082829137, 0.1453767082829137, 0.16256565680878043, 0.16256565680878043, 0.16256565680878043, 0.2239475955761956, 0.2239475955761956, 0.2239475955761956, 0.188815973047459, 0.188815973047459, 0.188815973047459, 0.18301123409550435, 0.18301123409550435, 0.18301123409550435, 0.18838761879216048, 0.18838761879216048, 0.18838761879216048, 0.1778688185932198, 0.1778688185932198, 0.1778688185932198, 0.07522390399559975, 0.07522390399559975, 0.07522390399559975, 0.06262819074032655, 0.06262819074032655, 0.06262819074032655, 0.05739735105045274, 0.05739735105045274, 0.05739735105045274]}, "mutation_prompt": null}
{"id": "c8ed807b-15f0-4f64-96c3-4f2aab3aa718", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive (personal) coefficient\n        self.c2 = 1.5  # social (global) coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm Optimization with Differential Evolution for Enhanced Exploration and Exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.7882223003563739, 0.7882223003563739, 0.7882223003563739, 0.8169154943413137, 0.8169154943413137, 0.8169154943413137, 0.7690954485281276, 0.7690954485281276, 0.7690954485281276, 0.5680197613953074, 0.5680197613953074, 0.5680197613953074, 0.5962898740523965, 0.5962898740523965, 0.5962898740523965, 0.6291853762145672, 0.6291853762145672, 0.6291853762145672, 0.10849055405339536, 0.10849055405339536, 0.10849055405339536, 0.10321959069399433, 0.10321959069399433, 0.10321959069399433, 0.22738774124028327, 0.22738774124028327, 0.22738774124028327, 0.12464419453269382, 0.12464419453269382, 0.12464419453269382, 0.14815312524317492, 0.14815312524317492, 0.14815312524317492, 0.1261171226803246, 0.1261171226803246, 0.1261171226803246, 0.9854925936412375, 0.9854925936412375, 0.9854925936412375, 0.9850584324633536, 0.9850584324633536, 0.9850584324633536, 0.9902621275085048, 0.9902621275085048, 0.9902621275085048, 0.3154053456951972, 0.3154053456951972, 0.3154053456951972, 0.15012604359786452, 0.15012604359786452, 0.15012604359786452, 0.316912557641825, 0.316912557641825, 0.316912557641825, 0.17878078668789144, 0.17878078668789144, 0.17878078668789144, 0.16148523999197129, 0.16148523999197129, 0.16148523999197129, 0.131101098679825, 0.131101098679825, 0.131101098679825, 0.1686314780943048, 0.1686314780943048, 0.1686314780943048, 0.1825208922566035, 0.1825208922566035, 0.1825208922566035, 0.18396354976501372, 0.18396354976501372, 0.18396354976501372, 0.18669892871434868, 0.18669892871434868, 0.18669892871434868, 0.2063899630263294, 0.2063899630263294, 0.2063899630263294, 0.19759715750835294, 0.19759715750835294, 0.19759715750835294, 0.00038339578821233733, 0.00038339578821233733, 0.00038339578821233733, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05690951958590118, 0.05690951958590118, 0.05690951958590118, 0.05627382708244477, 0.05627382708244477, 0.05627382708244477, 0.04733354985326044, 0.04733354985326044, 0.04733354985326044, 0.03269383584068564, 0.03269383584068564, 0.03269383584068564, 0.08402045556197213, 0.08402045556197213, 0.08402045556197213, 0.0633236603595334, 0.0633236603595334, 0.0633236603595334, 0.03968852118780908, 0.03968852118780908, 0.03968852118780908, 0.10601845290740097, 0.10601845290740097, 0.10601845290740097, 0.1216177285007971, 0.1216177285007971, 0.1216177285007971, 0.4995541034368661, 0.4995541034368661, 0.4995541034368661, 0.492310354641579, 0.492310354641579, 0.492310354641579, 0.5003491295975537, 0.5003491295975537, 0.5003491295975537, 0.05668537952738806, 0.05668537952738806, 0.05668537952738806, 0.11049434456327567, 0.11049434456327567, 0.11049434456327567, 0.11860118216965476, 0.11860118216965476, 0.11860118216965476, 0.15533634425560194, 0.15533634425560194, 0.15533634425560194, 0.18122183848109474, 0.18122183848109474, 0.18122183848109474, 0.14050011212654812, 0.14050011212654812, 0.14050011212654812, 0.41344915796781945, 0.41344915796781945, 0.41344915796781945, 0.35649604278443436, 0.35649604278443436, 0.35649604278443436, 0.1987251654574732, 0.1987251654574732, 0.1987251654574732, 0.16678798946697804, 0.16678798946697804, 0.16678798946697804, 0.17169245361638297, 0.17169245361638297, 0.17169245361638297, 0.2653531651202088, 0.2653531651202088, 0.2653531651202088, 0.19551011652520012, 0.19551011652520012, 0.19551011652520012, 0.17889426027287214, 0.17889426027287214, 0.17889426027287214, 0.19855664086176417, 0.19855664086176417, 0.19855664086176417, 0.1869236162393071, 0.1869236162393071, 0.1869236162393071, 0.1859998105179631, 0.1859998105179631, 0.1859998105179631, 0.19291202061724455, 0.19291202061724455, 0.19291202061724455, 0.8377540169390477, 0.8377540169390477, 0.8377540169390477, 0.18305148560313178, 0.18305148560313178, 0.18305148560313178, 0.16252768567090203, 0.16252768567090203, 0.16252768567090203, 0.16865006598048438, 0.16865006598048438, 0.16865006598048438, 0.21179731843543603, 0.21179731843543603, 0.21179731843543603, 0.15542124214409836, 0.15542124214409836, 0.15542124214409836, 0.17684183278463517, 0.17684183278463517, 0.17684183278463517, 0.1746524360042636, 0.1746524360042636, 0.1746524360042636, 0.17920680957455137, 0.17920680957455137, 0.17920680957455137, 0.07200599676124331, 0.07200599676124331, 0.07200599676124331, 0.06263378845221468, 0.06263378845221468, 0.06263378845221468, 0.05435512963038269, 0.05435512963038269, 0.05435512963038269]}, "mutation_prompt": null}
{"id": "60ee0146-0b57-410c-a933-3223a6c35238", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.initial_w = 0.9  # initial inertia weight\n        self.final_w = 0.4  # final inertia weight\n        self.c1 = 1.5  # cognitive (personal) coefficient\n        self.c2 = 1.5  # social (global) coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            w = self.initial_w - (self.initial_w - self.final_w) * evaluations / self.budget  # adaptive inertia weight\n\n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation with adaptive differential weight\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                adaptive_F = self.F + 0.2 * np.random.rand()  # slight randomization\n                mutant = np.clip(a + adaptive_F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Self-adjusting Parameters for Balanced Exploration-Exploitation.", "configspace": "", "generation": 3, "fitness": 0.21177253044136804, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.22.", "error": "", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.6769042795699627, 0.6769042795699627, 0.6769042795699627, 0.6139833355020632, 0.6139833355020632, 0.6139833355020632, 0.7354720380780985, 0.7354720380780985, 0.7354720380780985, 0.49134197430590043, 0.49134197430590043, 0.49134197430590043, 0.048605295781055435, 0.048605295781055435, 0.048605295781055435, 0.37681649938357575, 0.37681649938357575, 0.37681649938357575, 0.1024528858093996, 0.1024528858093996, 0.1024528858093996, 0.10532651186985453, 0.10532651186985453, 0.10532651186985453, 0.11071680522727034, 0.11071680522727034, 0.11071680522727034, 0.11531328688216058, 0.11531328688216058, 0.11531328688216058, 0.09466904311446322, 0.09466904311446322, 0.09466904311446322, 0.12129296260337219, 0.12129296260337219, 0.12129296260337219, 0.9846132435765084, 0.9846132435765084, 0.9846132435765084, 0.9896571600670846, 0.9896571600670846, 0.9896571600670846, 0.9903449555669201, 0.9903449555669201, 0.9903449555669201, 0.18698254769356637, 0.18698254769356637, 0.18698254769356637, 0.19177526547454182, 0.19177526547454182, 0.19177526547454182, 0.08633177467542152, 0.08633177467542152, 0.08633177467542152, 0.1783217528571207, 0.1783217528571207, 0.1783217528571207, 0.15996926684885115, 0.15996926684885115, 0.15996926684885115, 0.15746456849498192, 0.15746456849498192, 0.15746456849498192, 0.16098855787389732, 0.16098855787389732, 0.16098855787389732, 0.10422778788655307, 0.10422778788655307, 0.10422778788655307, 0.1753890139899369, 0.1753890139899369, 0.1753890139899369, 0.10616736677186855, 0.10616736677186855, 0.10616736677186855, 0.17305245380257805, 0.17305245380257805, 0.17305245380257805, 0.22489783958708187, 0.22489783958708187, 0.22489783958708187, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0017514339594905115, 0.0017514339594905115, 0.0017514339594905115, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.032951622490147936, 0.032951622490147936, 0.032951622490147936, 0.03910308227548498, 0.03910308227548498, 0.03910308227548498, 0.05920201780177137, 0.05920201780177137, 0.05920201780177137, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06578883831821969, 0.06578883831821969, 0.06578883831821969, 0.1909190026215013, 0.1909190026215013, 0.1909190026215013, 0.05628416175162587, 0.05628416175162587, 0.05628416175162587, 0.05568241920917372, 0.05568241920917372, 0.05568241920917372, 0.05314889011578583, 0.05314889011578583, 0.05314889011578583, 0.43339541663093883, 0.43339541663093883, 0.43339541663093883, 0.20637837286620775, 0.20637837286620775, 0.20637837286620775, 0.41374460682339853, 0.41374460682339853, 0.41374460682339853, 0.05996419378631801, 0.05996419378631801, 0.05996419378631801, 0.08431032456006937, 0.08431032456006937, 0.08431032456006937, 0.10540274821447015, 0.10540274821447015, 0.10540274821447015, 0.14858747787126136, 0.14858747787126136, 0.14858747787126136, 0.1329122143598661, 0.1329122143598661, 0.1329122143598661, 0.1415837226446931, 0.1415837226446931, 0.1415837226446931, 0.22633509228175086, 0.22633509228175086, 0.22633509228175086, 0.2617746121165936, 0.2617746121165936, 0.2617746121165936, 0.16256331143534497, 0.16256331143534497, 0.16256331143534497, 0.13984262710775708, 0.13984262710775708, 0.13984262710775708, 0.26414124271386197, 0.26414124271386197, 0.26414124271386197, 0.13371755146402498, 0.13371755146402498, 0.13371755146402498, 0.17226935928768783, 0.17226935928768783, 0.17226935928768783, 0.17414464306646205, 0.17414464306646205, 0.17414464306646205, 0.17911099902523397, 0.17911099902523397, 0.17911099902523397, 0.19413094914204254, 0.19413094914204254, 0.19413094914204254, 0.18071564753911007, 0.18071564753911007, 0.18071564753911007, 0.19407173642147668, 0.19407173642147668, 0.19407173642147668, 0.6311714742886674, 0.6311714742886674, 0.6311714742886674, 0.16464433627098773, 0.16464433627098773, 0.16464433627098773, 0.14633868699555186, 0.14633868699555186, 0.14633868699555186, 0.16492062508216365, 0.16492062508216365, 0.16492062508216365, 0.19967934684792488, 0.19967934684792488, 0.19967934684792488, 0.15274069973259752, 0.15274069973259752, 0.15274069973259752, 0.18501441863288404, 0.18501441863288404, 0.18501441863288404, 0.17415209729522407, 0.17415209729522407, 0.17415209729522407, 0.19328517115903043, 0.19328517115903043, 0.19328517115903043, 0.0675997854319792, 0.0675997854319792, 0.0675997854319792, 0.07685001186599316, 0.07685001186599316, 0.07685001186599316, 0.06391874697963451, 0.06391874697963451, 0.06391874697963451]}, "mutation_prompt": null}
{"id": "a97b688a-fd0e-4689-8b11-c9ba1a4fdaaf", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.c1 = 1.5  # cognitive (personal) coefficient\n        self.c2 = 1.5  # social (global) coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.evaluations = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        self.evaluations = self.pop_size\n        \n        while self.evaluations < self.budget:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n            \n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            self.evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step with adaptive mutation\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with Adaptive Inertia Weight and Differential Evolution Mutation Strategy for Improved Convergence.", "configspace": "", "generation": 4, "fitness": 0.22726075273117458, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.7026047039903933, 0.7026047039903933, 0.7026047039903933, 0.722015099834314, 0.722015099834314, 0.722015099834314, 0.665418807465793, 0.665418807465793, 0.665418807465793, 0.4649592070237353, 0.4649592070237353, 0.4649592070237353, 0.47287577566361483, 0.47287577566361483, 0.47287577566361483, 0.4394980367095088, 0.4394980367095088, 0.4394980367095088, 0.10407891775591616, 0.10407891775591616, 0.10407891775591616, 0.07806643224045762, 0.07806643224045762, 0.07806643224045762, 0.11751203485997375, 0.11751203485997375, 0.11751203485997375, 0.1016930079600683, 0.1016930079600683, 0.1016930079600683, 0.08860396680824612, 0.08860396680824612, 0.08860396680824612, 0.10411472228099372, 0.10411472228099372, 0.10411472228099372, 0.9869928575976887, 0.9869928575976887, 0.9869928575976887, 0.9869939492694564, 0.9869939492694564, 0.9869939492694564, 0.9905356586497773, 0.9905356586497773, 0.9905356586497773, 0.2741640612418451, 0.2741640612418451, 0.2741640612418451, 0.20250366814874166, 0.20250366814874166, 0.20250366814874166, 0.08790510608909519, 0.08790510608909519, 0.08790510608909519, 0.17648297123403267, 0.17648297123403267, 0.17648297123403267, 0.1574424926388177, 0.1574424926388177, 0.1574424926388177, 0.12768859894224627, 0.12768859894224627, 0.12768859894224627, 0.15158121740011377, 0.15158121740011377, 0.15158121740011377, 0.08646748821783734, 0.08646748821783734, 0.08646748821783734, 0.1625293429871466, 0.1625293429871466, 0.1625293429871466, 0.13945424065041334, 0.13945424065041334, 0.13945424065041334, 0.19105143053857354, 0.19105143053857354, 0.19105143053857354, 0.17711651922217408, 0.17711651922217408, 0.17711651922217408, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05117842574032805, 0.05117842574032805, 0.05117842574032805, 0.09250973830529585, 0.09250973830529585, 0.09250973830529585, 0.03145977933591659, 0.03145977933591659, 0.03145977933591659, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06962339533199047, 0.06962339533199047, 0.06962339533199047, 0.06645226130047321, 0.06645226130047321, 0.06645226130047321, 0.038575201296965456, 0.038575201296965456, 0.038575201296965456, 0.08596688488658422, 0.08596688488658422, 0.08596688488658422, 0.07012507458989092, 0.07012507458989092, 0.07012507458989092, 0.4049668197962535, 0.4049668197962535, 0.4049668197962535, 0.20594521327350845, 0.20594521327350845, 0.20594521327350845, 0.4657458244899726, 0.4657458244899726, 0.4657458244899726, 0.06444341865223979, 0.06444341865223979, 0.06444341865223979, 0.09754803259491418, 0.09754803259491418, 0.09754803259491418, 0.10762174019289195, 0.10762174019289195, 0.10762174019289195, 0.17936099994260024, 0.17936099994260024, 0.17936099994260024, 0.19053033030022137, 0.19053033030022137, 0.19053033030022137, 0.16451790363959573, 0.16451790363959573, 0.16451790363959573, 0.219678938738202, 0.219678938738202, 0.219678938738202, 0.3213630565095895, 0.3213630565095895, 0.3213630565095895, 0.31807332221193696, 0.31807332221193696, 0.31807332221193696, 0.17873849637110029, 0.17873849637110029, 0.17873849637110029, 0.24381722187711574, 0.24381722187711574, 0.24381722187711574, 0.22236827318306118, 0.22236827318306118, 0.22236827318306118, 0.16354107104003401, 0.16354107104003401, 0.16354107104003401, 0.1814974757345964, 0.1814974757345964, 0.1814974757345964, 0.1789755062474363, 0.1789755062474363, 0.1789755062474363, 0.18276927285518807, 0.18276927285518807, 0.18276927285518807, 0.19437437945704894, 0.19437437945704894, 0.19437437945704894, 0.19132939002592297, 0.19132939002592297, 0.19132939002592297, 0.7530773808594226, 0.7530773808594226, 0.7530773808594226, 0.15779904963201263, 0.15779904963201263, 0.15779904963201263, 0.16451700944682557, 0.16451700944682557, 0.16451700944682557, 0.1680096123410192, 0.1680096123410192, 0.1680096123410192, 0.20248731379102403, 0.20248731379102403, 0.20248731379102403, 0.24054381281901438, 0.24054381281901438, 0.24054381281901438, 0.17564402835064208, 0.17564402835064208, 0.17564402835064208, 0.18247202464210444, 0.18247202464210444, 0.18247202464210444, 0.18327255331316672, 0.18327255331316672, 0.18327255331316672, 0.06182100226832632, 0.06182100226832632, 0.06182100226832632, 0.05952469405210481, 0.05952469405210481, 0.05952469405210481, 0.06975795178705846, 0.06975795178705846, 0.06975795178705846]}, "mutation_prompt": null}
{"id": "ba74960d-7dc6-41cc-9422-34386aa01d3b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_pop_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 2.0  # increased cognitive coefficient\n        self.c2 = 2.0  # increased social coefficient\n        self.F = 0.5 + np.random.rand() * 0.3  # adaptive F in range [0.5, 0.8]\n        self.CR = 0.9  # crossover probability\n        self.dynamic_pop_size = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop_size = self.initial_pop_size\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = pop_size\n        \n        while evaluations < self.budget:\n            # Adjust inertia weight dynamically\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            # PSO step\n            r1 = np.random.rand(pop_size, self.dim)\n            r2 = np.random.rand(pop_size, self.dim)\n            vel = w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Adjust population size dynamically\n            if self.dynamic_pop_size and evaluations > self.budget // 2:\n                pop_size = max(5, int(self.initial_pop_size * (1 - evaluations / self.budget)))\n\n            # DE step\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with Adaptive Parameters and Dynamic Population Size for Improved Optimization Performance.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,5) (20,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,5) (20,5) ')", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {}, "mutation_prompt": null}
{"id": "0a0841eb-9b8f-4e62-b9f1-b23162618f74", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.0  # cognitive (personal) coefficient\n        self.c2 = 2.0  # social (global) coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        iterations = 0\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n\n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            iterations += 1\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid Particle Swarm Optimization with Differential Evolution leveraging dynamic parameters for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.17587425627228412, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.21.", "error": "", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.5106767550309091, 0.5106767550309091, 0.5106767550309091, 0.48291047601582127, 0.48291047601582127, 0.48291047601582127, 0.4800360396434685, 0.4800360396434685, 0.4800360396434685, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.2736088041916862, 0.2736088041916862, 0.2736088041916862, 0.028983540270282382, 0.028983540270282382, 0.028983540270282382, 0.07846487737829289, 0.07846487737829289, 0.07846487737829289, 0.0569154784880429, 0.0569154784880429, 0.0569154784880429, 0.092078143085366, 0.092078143085366, 0.092078143085366, 0.07312988131703935, 0.07312988131703935, 0.07312988131703935, 0.06621692776169108, 0.06621692776169108, 0.06621692776169108, 0.04420653434902255, 0.04420653434902255, 0.04420653434902255, 0.9870666567174962, 0.9870666567174962, 0.9870666567174962, 0.9907292352757834, 0.9907292352757834, 0.9907292352757834, 0.9932458111886687, 0.9932458111886687, 0.9932458111886687, 0.05983137024837182, 0.05983137024837182, 0.05983137024837182, 0.11335359731613348, 0.11335359731613348, 0.11335359731613348, 0.13456231205457703, 0.13456231205457703, 0.13456231205457703, 0.14808491083401243, 0.14808491083401243, 0.14808491083401243, 0.1472717091779574, 0.1472717091779574, 0.1472717091779574, 0.13524625103464316, 0.13524625103464316, 0.13524625103464316, 0.11593397416083184, 0.11593397416083184, 0.11593397416083184, 0.07883166228702354, 0.07883166228702354, 0.07883166228702354, 0.1058508216684062, 0.1058508216684062, 0.1058508216684062, 0.12255797906283039, 0.12255797906283039, 0.12255797906283039, 0.09640141769342281, 0.09640141769342281, 0.09640141769342281, 0.07346045606384888, 0.07346045606384888, 0.07346045606384888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03458109535171061, 0.03458109535171061, 0.03458109535171061, 0.07508742232734744, 0.07508742232734744, 0.07508742232734744, 0.028664972411832967, 0.028664972411832967, 0.028664972411832967, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04231874754794629, 0.04231874754794629, 0.04231874754794629, 0.03209669158834061, 0.03209669158834061, 0.03209669158834061, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02706417491487334, 0.02706417491487334, 0.02706417491487334, 0.0383679485131776, 0.0383679485131776, 0.0383679485131776, 0.38200146107565425, 0.38200146107565425, 0.38200146107565425, 0.35412885565613583, 0.35412885565613583, 0.35412885565613583, 0.36639840934498813, 0.36639840934498813, 0.36639840934498813, 0.0621328388624377, 0.0621328388624377, 0.0621328388624377, 0.07817160677426582, 0.07817160677426582, 0.07817160677426582, 0.06170291514495052, 0.06170291514495052, 0.06170291514495052, 0.1252471704159085, 0.1252471704159085, 0.1252471704159085, 0.15479561798775654, 0.15479561798775654, 0.15479561798775654, 0.13310118337899202, 0.13310118337899202, 0.13310118337899202, 0.21272375811148758, 0.21272375811148758, 0.21272375811148758, 0.18103895873501175, 0.18103895873501175, 0.18103895873501175, 0.25549868970306144, 0.25549868970306144, 0.25549868970306144, 0.18247769329877006, 0.18247769329877006, 0.18247769329877006, 0.16085321416776932, 0.16085321416776932, 0.16085321416776932, 0.11392612143876846, 0.11392612143876846, 0.11392612143876846, 0.1672168893640259, 0.1672168893640259, 0.1672168893640259, 0.17511967481788726, 0.17511967481788726, 0.17511967481788726, 0.15761373775176835, 0.15761373775176835, 0.15761373775176835, 0.1884760574044314, 0.1884760574044314, 0.1884760574044314, 0.17123872814017793, 0.17123872814017793, 0.17123872814017793, 0.15795169830287692, 0.15795169830287692, 0.15795169830287692, 0.4745339860961575, 0.4745339860961575, 0.4745339860961575, 0.15936827621008598, 0.15936827621008598, 0.15936827621008598, 0.14897945561812576, 0.14897945561812576, 0.14897945561812576, 0.1626059493633435, 0.1626059493633435, 0.1626059493633435, 0.1766478095459153, 0.1766478095459153, 0.1766478095459153, 0.17643879321234013, 0.17643879321234013, 0.17643879321234013, 0.1805622608620917, 0.1805622608620917, 0.1805622608620917, 0.19810492395699209, 0.19810492395699209, 0.19810492395699209, 0.19404164108309718, 0.19404164108309718, 0.19404164108309718, 0.08155175748928833, 0.08155175748928833, 0.08155175748928833, 0.04807445863280968, 0.04807445863280968, 0.04807445863280968, 0.05178518468622839, 0.05178518468622839, 0.05178518468622839]}, "mutation_prompt": null}
{"id": "4150a5aa-031b-42cc-871a-13445f63f0f4", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.9  # increased inertia weight for better exploration\n        self.c1 = 2.0  # increased cognitive coefficient for stronger personal learning\n        self.c2 = 1.0  # decreased social coefficient for reduced convergence speed\n        self.F = 0.5  # reduced differential weight for more stable evolution\n        self.CR = 0.7  # reduced crossover probability to promote diversity\n        self.max_vel = (self.upper_bound - self.lower_bound) * 0.2  # dynamic velocity clamping\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-self.max_vel, self.max_vel, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Particle Swarm Optimization step\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            vel = np.clip(vel, -self.max_vel, self.max_vel)  # apply velocity clamping\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Adaptive update of personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step with dynamic parameters\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Dynamic Parameters for Improved Convergence and Stability.", "configspace": "", "generation": 7, "fitness": 0.18571593905293102, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.40979898857712704, 0.40979898857712704, 0.40979898857712704, 0.3400933569940353, 0.3400933569940353, 0.3400933569940353, 0.3748932218841594, 0.3748932218841594, 0.3748932218841594, 0.0900955991328406, 0.0900955991328406, 0.0900955991328406, 0.06721302238730242, 0.06721302238730242, 0.06721302238730242, 0.07403569736450077, 0.07403569736450077, 0.07403569736450077, 0.08646299625467635, 0.08646299625467635, 0.08646299625467635, 0.0870397713584189, 0.0870397713584189, 0.0870397713584189, 0.10525346363147148, 0.10525346363147148, 0.10525346363147148, 0.07464842406028782, 0.07464842406028782, 0.07464842406028782, 0.08317125814007909, 0.08317125814007909, 0.08317125814007909, 0.07102922534118317, 0.07102922534118317, 0.07102922534118317, 0.9735104555882954, 0.9735104555882954, 0.9735104555882954, 0.9787204946935207, 0.9787204946935207, 0.9787204946935207, 0.9865869360589482, 0.9865869360589482, 0.9865869360589482, 0.18265430101997915, 0.18265430101997915, 0.18265430101997915, 0.1636675639172237, 0.1636675639172237, 0.1636675639172237, 0.15479020010589806, 0.15479020010589806, 0.15479020010589806, 0.25275279311631516, 0.25275279311631516, 0.25275279311631516, 0.20666498005114498, 0.20666498005114498, 0.20666498005114498, 0.22638520953116803, 0.22638520953116803, 0.22638520953116803, 0.11355444167046957, 0.11355444167046957, 0.11355444167046957, 0.0999277031904241, 0.0999277031904241, 0.0999277031904241, 0.10991425658320708, 0.10991425658320708, 0.10991425658320708, 0.09388055958768016, 0.09388055958768016, 0.09388055958768016, 0.11301199925388061, 0.11301199925388061, 0.11301199925388061, 0.0905603868963295, 0.0905603868963295, 0.0905603868963295, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12639523282595488, 0.12639523282595488, 0.12639523282595488, 0.06908234969972271, 0.06908234969972271, 0.06908234969972271, 0.06875008302179109, 0.06875008302179109, 0.06875008302179109, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02979989079223544, 0.02979989079223544, 0.02979989079223544, 0.04369148313049531, 0.04369148313049531, 0.04369148313049531, 0.08796449713533727, 0.08796449713533727, 0.08796449713533727, 0.2940406652835905, 0.2940406652835905, 0.2940406652835905, 0.35383515386719055, 0.35383515386719055, 0.35383515386719055, 0.33166579198925483, 0.33166579198925483, 0.33166579198925483, 0.08067898285428488, 0.08067898285428488, 0.08067898285428488, 0.11627809934026123, 0.11627809934026123, 0.11627809934026123, 0.09457898930696285, 0.09457898930696285, 0.09457898930696285, 0.15708142142273063, 0.15708142142273063, 0.15708142142273063, 0.13456997650603608, 0.13456997650603608, 0.13456997650603608, 0.13289151702213198, 0.13289151702213198, 0.13289151702213198, 0.22244639487798512, 0.22244639487798512, 0.22244639487798512, 0.23244301825849767, 0.23244301825849767, 0.23244301825849767, 0.22930843814387403, 0.22930843814387403, 0.22930843814387403, 0.1967269503804251, 0.1967269503804251, 0.1967269503804251, 0.1786761193875951, 0.1786761193875951, 0.1786761193875951, 0.1896712468048224, 0.1896712468048224, 0.1896712468048224, 0.18754127930752762, 0.18754127930752762, 0.18754127930752762, 0.18981973214110903, 0.18981973214110903, 0.18981973214110903, 0.20810692863141822, 0.20810692863141822, 0.20810692863141822, 0.17191076228305013, 0.17191076228305013, 0.17191076228305013, 0.17787332970954595, 0.17787332970954595, 0.17787332970954595, 0.1732019374851569, 0.1732019374851569, 0.1732019374851569, 0.4381196879212734, 0.4381196879212734, 0.4381196879212734, 0.15674425660990532, 0.15674425660990532, 0.15674425660990532, 0.2822590832588022, 0.2822590832588022, 0.2822590832588022, 0.1674977327863869, 0.1674977327863869, 0.1674977327863869, 0.20036361395077384, 0.20036361395077384, 0.20036361395077384, 0.2578530254487562, 0.2578530254487562, 0.2578530254487562, 0.17830824958705926, 0.17830824958705926, 0.17830824958705926, 0.17633250434064396, 0.17633250434064396, 0.17633250434064396, 0.1882449254434687, 0.1882449254434687, 0.1882449254434687, 0.081210662561635, 0.081210662561635, 0.081210662561635, 0.07569732663554118, 0.07569732663554118, 0.07569732663554118, 0.0789689652672334, 0.0789689652672334, 0.0789689652672334]}, "mutation_prompt": null}
{"id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 8, "fitness": 0.2738700539711725, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.24.", "error": "", "parent_id": "a8ac0398-4ab8-4fa4-966c-24754cd13be3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "0cd8c219-b8d4-43d9-a92b-94a4f362d27f", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "a6863de3-b8fb-4924-9c73-484fc61df343", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.dynamic_search_prob = 0.2  # Dynamic search probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                neighbors = np.random.choice(idxs, size=5, replace=False)  # Dynamic neighborhood selection\n                a, b, c = pos[neighbors[:3]]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation_scale = 0.1 * (1 - evaluations / self.budget)  # Adaptive perturbation\n                    perturbation = np.random.normal(0, perturbation_scale, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Dynamic Neighborhood Search and Adaptive Local Perturbation to improve exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.2620018029205657, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7538529699600938, 0.7538529699600938, 0.7538529699600938, 0.7339693893951436, 0.7339693893951436, 0.7339693893951436, 0.7545901151060663, 0.7545901151060663, 0.7545901151060663, 0.5451125649891821, 0.5451125649891821, 0.5451125649891821, 0.5372577154405658, 0.5372577154405658, 0.5372577154405658, 0.5327605789116017, 0.5327605789116017, 0.5327605789116017, 0.12070717830410727, 0.12070717830410727, 0.12070717830410727, 0.09883075818978082, 0.09883075818978082, 0.09883075818978082, 0.13209680558165493, 0.13209680558165493, 0.13209680558165493, 0.0956358952205123, 0.0956358952205123, 0.0956358952205123, 0.0951215023887122, 0.0951215023887122, 0.0951215023887122, 0.11050410641984854, 0.11050410641984854, 0.11050410641984854, 0.9404745814903048, 0.9404745814903048, 0.9404745814903048, 0.9408822598275565, 0.9408822598275565, 0.9408822598275565, 0.9539752164956165, 0.9539752164956165, 0.9539752164956165, 0.47597518642163994, 0.47597518642163994, 0.47597518642163994, 0.32529115187141266, 0.32529115187141266, 0.32529115187141266, 0.3545610750907052, 0.3545610750907052, 0.3545610750907052, 0.426467726171895, 0.426467726171895, 0.426467726171895, 0.2792384335073078, 0.2792384335073078, 0.2792384335073078, 0.5025544049474353, 0.5025544049474353, 0.5025544049474353, 0.17346235289719103, 0.17346235289719103, 0.17346235289719103, 0.22484001366274653, 0.22484001366274653, 0.22484001366274653, 0.174196555732679, 0.174196555732679, 0.174196555732679, 0.08717421095609856, 0.08717421095609856, 0.08717421095609856, 0.1512098764521046, 0.1512098764521046, 0.1512098764521046, 0.08697770164756347, 0.08697770164756347, 0.08697770164756347, 0.006484302336327352, 0.006484302336327352, 0.006484302336327352, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.042182714709634084, 0.042182714709634084, 0.042182714709634084, 0.05164656836638937, 0.05164656836638937, 0.05164656836638937, 0.042523391254856824, 0.042523391254856824, 0.042523391254856824, 0.0838649295284204, 0.0838649295284204, 0.0838649295284204, 0.025581770418092287, 0.025581770418092287, 0.025581770418092287, 0.07358589839788687, 0.07358589839788687, 0.07358589839788687, 0.07373086024511177, 0.07373086024511177, 0.07373086024511177, 0.10853701256915105, 0.10853701256915105, 0.10853701256915105, 0.04496168969026293, 0.04496168969026293, 0.04496168969026293, 0.05048598213685196, 0.05048598213685196, 0.05048598213685196, 0.482747632319279, 0.482747632319279, 0.482747632319279, 0.4678604515591691, 0.4678604515591691, 0.4678604515591691, 0.5018116155432579, 0.5018116155432579, 0.5018116155432579, 0.10892774452809206, 0.10892774452809206, 0.10892774452809206, 0.09010158238487087, 0.09010158238487087, 0.09010158238487087, 0.10757522859348534, 0.10757522859348534, 0.10757522859348534, 0.17386703380226443, 0.17386703380226443, 0.17386703380226443, 0.19702640094919865, 0.19702640094919865, 0.19702640094919865, 0.16961808042057036, 0.16961808042057036, 0.16961808042057036, 0.2176124036962599, 0.2176124036962599, 0.2176124036962599, 0.2313170868508735, 0.2313170868508735, 0.2313170868508735, 0.26229464972131167, 0.26229464972131167, 0.26229464972131167, 0.16709941578649778, 0.16709941578649778, 0.16709941578649778, 0.15928084343296467, 0.15928084343296467, 0.15928084343296467, 0.12930518424009207, 0.12930518424009207, 0.12930518424009207, 0.19805487777755504, 0.19805487777755504, 0.19805487777755504, 0.1801601415404701, 0.1801601415404701, 0.1801601415404701, 0.19532277631327855, 0.19532277631327855, 0.19532277631327855, 0.1903827634698826, 0.1903827634698826, 0.1903827634698826, 0.19648045946878778, 0.19648045946878778, 0.19648045946878778, 0.21414982563369078, 0.21414982563369078, 0.21414982563369078, 0.6066726515636895, 0.6066726515636895, 0.6066726515636895, 0.17843003349996345, 0.17843003349996345, 0.17843003349996345, 0.6086925021084162, 0.6086925021084162, 0.6086925021084162, 0.16121170155310305, 0.16121170155310305, 0.16121170155310305, 0.19767966208915566, 0.19767966208915566, 0.19767966208915566, 0.47140037088430087, 0.47140037088430087, 0.47140037088430087, 0.18076033326608665, 0.18076033326608665, 0.18076033326608665, 0.17108378708643757, 0.17108378708643757, 0.17108378708643757, 0.2228347748514754, 0.2228347748514754, 0.2228347748514754, 0.07222687940121142, 0.07222687940121142, 0.07222687940121142, 0.0685177288644303, 0.0685177288644303, 0.0685177288644303, 0.07221774034809314, 0.07221774034809314, 0.07221774034809314]}, "mutation_prompt": null}
{"id": "a222ecdf-5877-4f76-99cb-6d774b803a52", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 25\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.0  # initial cognitive coefficient\n        self.c2 = 1.5  # initial social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.15  # increased probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Adaptive learning rates\n            self.w = 0.4 + 0.5 * np.random.rand()\n            self.c1 = 1.5 + 0.5 * np.random.rand()\n            self.c2 = 1.5 + 0.5 * np.random.rand()\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Gradient-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    grad = np.gradient(fitness)\n                    local_candidate = pos[i] - 0.01 * grad[i]\n                    local_candidate = np.clip(local_candidate, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with Adaptive Learning and Gradient-based Local Search to boost convergence speed and solution quality by incorporating adaptive learning rates and gradient information.", "configspace": "", "generation": 11, "fitness": 0.22516387585212688, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7190163862503195, 0.7190163862503195, 0.7190163862503195, 0.6859745961429506, 0.6859745961429506, 0.6859745961429506, 0.683458150989394, 0.683458150989394, 0.683458150989394, 0.03560560319608863, 0.03560560319608863, 0.03560560319608863, 0.21925709897205958, 0.21925709897205958, 0.21925709897205958, 0.4241035033018844, 0.4241035033018844, 0.4241035033018844, 0.14082056469740079, 0.14082056469740079, 0.14082056469740079, 0.10205132733939115, 0.10205132733939115, 0.10205132733939115, 0.10165130343185758, 0.10165130343185758, 0.10165130343185758, 0.06550620372856486, 0.06550620372856486, 0.06550620372856486, 0.08725349503598878, 0.08725349503598878, 0.08725349503598878, 0.10603809732694769, 0.10603809732694769, 0.10603809732694769, 0.9911720619273903, 0.9911720619273903, 0.9911720619273903, 0.9840984537065445, 0.9840984537065445, 0.9840984537065445, 0.9887386681952459, 0.9887386681952459, 0.9887386681952459, 0.16363000140118145, 0.16363000140118145, 0.16363000140118145, 0.19728234611766016, 0.19728234611766016, 0.19728234611766016, 0.18478805099544982, 0.18478805099544982, 0.18478805099544982, 0.21041486424515465, 0.21041486424515465, 0.21041486424515465, 0.1982222402727114, 0.1982222402727114, 0.1982222402727114, 0.20952430618216278, 0.20952430618216278, 0.20952430618216278, 0.19366692745743364, 0.19366692745743364, 0.19366692745743364, 0.14629787205316458, 0.14629787205316458, 0.14629787205316458, 0.16753682910722778, 0.16753682910722778, 0.16753682910722778, 0.08616595549569006, 0.08616595549569006, 0.08616595549569006, 0.13149566012587166, 0.13149566012587166, 0.13149566012587166, 0.17453272376771545, 0.17453272376771545, 0.17453272376771545, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05947306889139914, 0.05947306889139914, 0.05947306889139914, 0.017624089452759062, 0.017624089452759062, 0.017624089452759062, 0.06310487478934079, 0.06310487478934079, 0.06310487478934079, 0.018201146280177993, 0.018201146280177993, 0.018201146280177993, 0.0844273185706177, 0.0844273185706177, 0.0844273185706177, 0.07494330679482342, 0.07494330679482342, 0.07494330679482342, 0.04058489490302253, 0.04058489490302253, 0.04058489490302253, 0.17100205330167317, 0.17100205330167317, 0.17100205330167317, 0.22009359150335983, 0.22009359150335983, 0.22009359150335983, 0.41128242345592436, 0.41128242345592436, 0.41128242345592436, 0.4468347851204255, 0.4468347851204255, 0.4468347851204255, 0.4538775780014769, 0.4538775780014769, 0.4538775780014769, 0.09189758026313155, 0.09189758026313155, 0.09189758026313155, 0.07846884780382735, 0.07846884780382735, 0.07846884780382735, 0.08505056164571634, 0.08505056164571634, 0.08505056164571634, 0.14055610154115095, 0.14055610154115095, 0.14055610154115095, 0.1940619095183359, 0.1940619095183359, 0.1940619095183359, 0.15089437089361513, 0.15089437089361513, 0.15089437089361513, 0.3405152856815, 0.3405152856815, 0.3405152856815, 0.2461050763947603, 0.2461050763947603, 0.2461050763947603, 0.30503985547091594, 0.30503985547091594, 0.30503985547091594, 0.2123602921174309, 0.2123602921174309, 0.2123602921174309, 0.17938436720742845, 0.17938436720742845, 0.17938436720742845, 0.11797209360680483, 0.11797209360680483, 0.11797209360680483, 0.17054279256020377, 0.17054279256020377, 0.17054279256020377, 0.17885455189375554, 0.17885455189375554, 0.17885455189375554, 0.20787958347808144, 0.20787958347808144, 0.20787958347808144, 0.23140638640817301, 0.23140638640817301, 0.23140638640817301, 0.18778843881234242, 0.18778843881234242, 0.18778843881234242, 0.19915387410925178, 0.19915387410925178, 0.19915387410925178, 0.7970231079955092, 0.7970231079955092, 0.7970231079955092, 0.1683344739747239, 0.1683344739747239, 0.1683344739747239, 0.15829556760822017, 0.15829556760822017, 0.15829556760822017, 0.16656238887905472, 0.16656238887905472, 0.16656238887905472, 0.20866598536464276, 0.20866598536464276, 0.20866598536464276, 0.19189006805117514, 0.19189006805117514, 0.19189006805117514, 0.176465073340201, 0.176465073340201, 0.176465073340201, 0.17285471491953408, 0.17285471491953408, 0.17285471491953408, 0.19428992518213917, 0.19428992518213917, 0.19428992518213917, 0.07532237369045292, 0.07532237369045292, 0.07532237369045292, 0.06474400904538957, 0.06474400904538957, 0.06474400904538957, 0.05936698136721574, 0.05936698136721574, 0.05936698136721574]}, "mutation_prompt": null}
{"id": "9e56c854-6a80-43d0-afa1-b02fae1592c2", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "96f670f2-6ad6-456d-92b2-12d678f5569d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n        self.learning_rate = 0.1  # adaptive learning rate for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.learning_rate * (global_best - a), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * self.learning_rate, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with Adaptive Learning Rates and Differential Mutations to Improve Convergence and Robustness.", "configspace": "", "generation": 13, "fitness": 0.26500947778285716, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.23.", "error": "", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7482034092962915, 0.7482034092962915, 0.7482034092962915, 0.7004973283735778, 0.7004973283735778, 0.7004973283735778, 0.7655152365788604, 0.7655152365788604, 0.7655152365788604, 0.5248283111877875, 0.5248283111877875, 0.5248283111877875, 0.5382828731607296, 0.5382828731607296, 0.5382828731607296, 0.5584274813482607, 0.5584274813482607, 0.5584274813482607, 0.10486220261724177, 0.10486220261724177, 0.10486220261724177, 0.12419675604245062, 0.12419675604245062, 0.12419675604245062, 0.10712130084070215, 0.10712130084070215, 0.10712130084070215, 0.1193235402486773, 0.1193235402486773, 0.1193235402486773, 0.11232050207295963, 0.11232050207295963, 0.11232050207295963, 0.1190973274895688, 0.1190973274895688, 0.1190973274895688, 0.9392043314165358, 0.9392043314165358, 0.9392043314165358, 0.9441778302497458, 0.9441778302497458, 0.9441778302497458, 0.9517861476986771, 0.9517861476986771, 0.9517861476986771, 0.3607233313733763, 0.3607233313733763, 0.3607233313733763, 0.3628048366635882, 0.3628048366635882, 0.3628048366635882, 0.3399994577970856, 0.3399994577970856, 0.3399994577970856, 0.6576176100952845, 0.6576176100952845, 0.6576176100952845, 0.1520552516628968, 0.1520552516628968, 0.1520552516628968, 0.2970373504647793, 0.2970373504647793, 0.2970373504647793, 0.1962128559458104, 0.1962128559458104, 0.1962128559458104, 0.1763647286905975, 0.1763647286905975, 0.1763647286905975, 0.24133123449806249, 0.24133123449806249, 0.24133123449806249, 0.08497391817979183, 0.08497391817979183, 0.08497391817979183, 0.1572203289853722, 0.1572203289853722, 0.1572203289853722, 0.10230421870076911, 0.10230421870076911, 0.10230421870076911, 0.00221210703018182, 0.00221210703018182, 0.00221210703018182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07133013141387434, 0.07133013141387434, 0.07133013141387434, 0.056218463052472134, 0.056218463052472134, 0.056218463052472134, 0.05207921781450964, 0.05207921781450964, 0.05207921781450964, 0.14904925088670629, 0.14904925088670629, 0.14904925088670629, 0.36417959659364874, 0.36417959659364874, 0.36417959659364874, 0.07452121502714015, 0.07452121502714015, 0.07452121502714015, 0.09112286867340569, 0.09112286867340569, 0.09112286867340569, 0.1320335839936151, 0.1320335839936151, 0.1320335839936151, 0.05190507966266833, 0.05190507966266833, 0.05190507966266833, 0.48725471119811614, 0.48725471119811614, 0.48725471119811614, 0.5011405126541686, 0.5011405126541686, 0.5011405126541686, 0.5419118429599583, 0.5419118429599583, 0.5419118429599583, 0.0914693329450974, 0.0914693329450974, 0.0914693329450974, 0.08144970924513961, 0.08144970924513961, 0.08144970924513961, 0.08532842280258757, 0.08532842280258757, 0.08532842280258757, 0.15031716193705347, 0.15031716193705347, 0.15031716193705347, 0.16519065540111932, 0.16519065540111932, 0.16519065540111932, 0.20668549216810084, 0.20668549216810084, 0.20668549216810084, 0.23682188884295707, 0.23682188884295707, 0.23682188884295707, 0.19140581186051608, 0.19140581186051608, 0.19140581186051608, 0.18088107691656252, 0.18088107691656252, 0.18088107691656252, 0.24349057952148645, 0.24349057952148645, 0.24349057952148645, 0.17697757621208987, 0.17697757621208987, 0.17697757621208987, 0.2120639408548297, 0.2120639408548297, 0.2120639408548297, 0.18401104268245427, 0.18401104268245427, 0.18401104268245427, 0.18877116817822737, 0.18877116817822737, 0.18877116817822737, 0.17797962882113338, 0.17797962882113338, 0.17797962882113338, 0.20651568211342086, 0.20651568211342086, 0.20651568211342086, 0.19914372985244422, 0.19914372985244422, 0.19914372985244422, 0.19507109225019326, 0.19507109225019326, 0.19507109225019326, 0.5897893941882464, 0.5897893941882464, 0.5897893941882464, 0.1729516880702444, 0.1729516880702444, 0.1729516880702444, 0.49683448613548364, 0.49683448613548364, 0.49683448613548364, 0.3070069931640733, 0.3070069931640733, 0.3070069931640733, 0.12240334459668756, 0.12240334459668756, 0.12240334459668756, 0.34483562844819193, 0.34483562844819193, 0.34483562844819193, 0.18658662772084944, 0.18658662772084944, 0.18658662772084944, 0.18940864868701335, 0.18940864868701335, 0.18940864868701335, 0.20470925102784854, 0.20470925102784854, 0.20470925102784854, 0.07278440038765399, 0.07278440038765399, 0.07278440038765399, 0.07188894816659919, 0.07188894816659919, 0.07188894816659919, 0.08626071452746331, 0.08626071452746331, 0.08626071452746331]}, "mutation_prompt": null}
{"id": "9c107156-0ec9-40e8-8293-fcc3896abda0", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "52b86ed9-4092-4ae0-a03e-204703ffcf14", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "183881a0-a2b9-4ec2-92eb-b4d2a5db662f", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "47ff87d3-032a-4442-9bc9-dcc4527c9fce", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "1d5f97ca-0386-473a-bc99-a76855166462", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.local_search_prob = 0.1  # probability for local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Adaptively adjust PSO parameters based on evaluations\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Probability-based local search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Probability-based Local Search for Improved Convergence by dynamically adjusting PSO and DE parameters and adding a local search mechanism.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7544066416948527, 0.7544066416948527, 0.7544066416948527, 0.7382611581280087, 0.7382611581280087, 0.7382611581280087, 0.7445630385587598, 0.7445630385587598, 0.7445630385587598, 0.48069068246304636, 0.48069068246304636, 0.48069068246304636, 0.5404951137394745, 0.5404951137394745, 0.5404951137394745, 0.5723429918146227, 0.5723429918146227, 0.5723429918146227, 0.3268257753122208, 0.3268257753122208, 0.3268257753122208, 0.1372982333251106, 0.1372982333251106, 0.1372982333251106, 0.346401078030126, 0.346401078030126, 0.346401078030126, 0.08624816967699611, 0.08624816967699611, 0.08624816967699611, 0.07788189115180122, 0.07788189115180122, 0.07788189115180122, 0.1245720520509136, 0.1245720520509136, 0.1245720520509136, 0.9404783566618913, 0.9404783566618913, 0.9404783566618913, 0.9408637719001092, 0.9408637719001092, 0.9408637719001092, 0.9539753588104027, 0.9539753588104027, 0.9539753588104027, 0.4073450362112866, 0.4073450362112866, 0.4073450362112866, 0.33624851225290087, 0.33624851225290087, 0.33624851225290087, 0.3580386450186741, 0.3580386450186741, 0.3580386450186741, 0.5967781825207157, 0.5967781825207157, 0.5967781825207157, 0.18723798703040773, 0.18723798703040773, 0.18723798703040773, 0.18359320631078113, 0.18359320631078113, 0.18359320631078113, 0.1752756433792967, 0.1752756433792967, 0.1752756433792967, 0.17342475460590645, 0.17342475460590645, 0.17342475460590645, 0.20433477925933619, 0.20433477925933619, 0.20433477925933619, 0.09128015280062007, 0.09128015280062007, 0.09128015280062007, 0.1545717036862887, 0.1545717036862887, 0.1545717036862887, 0.3010958170166136, 0.3010958170166136, 0.3010958170166136, 0.0024842546706534963, 0.0024842546706534963, 0.0024842546706534963, 0.0034203868292174144, 0.0034203868292174144, 0.0034203868292174144, 0.005507858543464916, 0.005507858543464916, 0.005507858543464916, 0.07323399613596526, 0.07323399613596526, 0.07323399613596526, 0.03525538865636557, 0.03525538865636557, 0.03525538865636557, 0.03446133102545934, 0.03446133102545934, 0.03446133102545934, 0.029335626803663195, 0.029335626803663195, 0.029335626803663195, 0.06477415129402508, 0.06477415129402508, 0.06477415129402508, 0.07167452638550853, 0.07167452638550853, 0.07167452638550853, 0.17439323511375482, 0.17439323511375482, 0.17439323511375482, 0.05684598422165632, 0.05684598422165632, 0.05684598422165632, 0.06196591461646206, 0.06196591461646206, 0.06196591461646206, 0.4999047737496426, 0.4999047737496426, 0.4999047737496426, 0.4868044103057235, 0.4868044103057235, 0.4868044103057235, 0.5069586830625862, 0.5069586830625862, 0.5069586830625862, 0.08610478651708653, 0.08610478651708653, 0.08610478651708653, 0.08960535435147554, 0.08960535435147554, 0.08960535435147554, 0.12871538061050436, 0.12871538061050436, 0.12871538061050436, 0.16177148134811103, 0.16177148134811103, 0.16177148134811103, 0.16837349644323307, 0.16837349644323307, 0.16837349644323307, 0.162423418922082, 0.162423418922082, 0.162423418922082, 0.3006863814490718, 0.3006863814490718, 0.3006863814490718, 0.2331468373527884, 0.2331468373527884, 0.2331468373527884, 0.319937529861123, 0.319937529861123, 0.319937529861123, 0.15825396115000367, 0.15825396115000367, 0.15825396115000367, 0.13046456574058962, 0.13046456574058962, 0.13046456574058962, 0.22751044801344444, 0.22751044801344444, 0.22751044801344444, 0.1657416570774085, 0.1657416570774085, 0.1657416570774085, 0.18110005723151212, 0.18110005723151212, 0.18110005723151212, 0.18280511947277167, 0.18280511947277167, 0.18280511947277167, 0.1844766887879985, 0.1844766887879985, 0.1844766887879985, 0.19827613134523947, 0.19827613134523947, 0.19827613134523947, 0.5794877702583092, 0.5794877702583092, 0.5794877702583092, 0.6469078402080084, 0.6469078402080084, 0.6469078402080084, 0.17688872783403842, 0.17688872783403842, 0.17688872783403842, 0.5878199395313182, 0.5878199395313182, 0.5878199395313182, 0.1615519069408059, 0.1615519069408059, 0.1615519069408059, 0.19796312542983985, 0.19796312542983985, 0.19796312542983985, 0.47272530592659623, 0.47272530592659623, 0.47272530592659623, 0.19906297838922815, 0.19906297838922815, 0.19906297838922815, 0.17007341758660965, 0.17007341758660965, 0.17007341758660965, 0.1831077387151141, 0.1831077387151141, 0.1831077387151141, 0.0633590933873498, 0.0633590933873498, 0.0633590933873498, 0.07637809474857582, 0.07637809474857582, 0.07637809474857582, 0.0823753964688716, 0.0823753964688716, 0.0823753964688716]}, "mutation_prompt": null}
{"id": "bfb47066-95b0-4924-b45e-47313f250745", "solution": "import numpy as np\n\nclass EnhancedPSO_DE_MetaLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.7  # social coefficient\n        self.F = 0.7  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.meta_learn_rate = 0.05  # rate to adjust hyperparameters\n        self.diversity_factor = 0.1  # factor for diversity-based exploration\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        \n        while evaluations < self.budget:\n            # Meta-learning adjustment\n            improvement_rate = np.mean(personal_best_value - np.min(personal_best_value))\n            if improvement_rate < 0.01:\n                self.w += self.meta_learn_rate\n                self.c1 -= self.meta_learn_rate\n                self.c2 -= self.meta_learn_rate\n            else:\n                self.w -= self.meta_learn_rate\n                self.c1 += self.meta_learn_rate\n                self.c2 += self.meta_learn_rate\n\n            # Particle Swarm Optimization step with adaptive parameters\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            # Evaluate the candidate solutions\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            # Update personal and global bests\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Differential Evolution step with diversity enhancement\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + self.diversity_factor * np.random.standard_normal(self.dim), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "EnhancedPSO_DE_MetaLearning", "description": "Enhanced Particle Swarm-DE with Adaptive Meta-Learning to dynamically update strategies and parameters based on performance and landscape.", "configspace": "", "generation": 19, "fitness": 0.16635264474500705, "feedback": "The algorithm EnhancedPSO_DE_MetaLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.20.", "error": "", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.37786500249647315, 0.37786500249647315, 0.37786500249647315, 0.36611487032643153, 0.36611487032643153, 0.36611487032643153, 0.3660535404752904, 0.3660535404752904, 0.3660535404752904, 0.020805215158428703, 0.020805215158428703, 0.020805215158428703, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004907061751868835, 0.004907061751868835, 0.004907061751868835, 0.09637270285648336, 0.09637270285648336, 0.09637270285648336, 0.0843570798948855, 0.0843570798948855, 0.0843570798948855, 0.07201264389570061, 0.07201264389570061, 0.07201264389570061, 0.09064455137706318, 0.09064455137706318, 0.09064455137706318, 0.05957766241158957, 0.05957766241158957, 0.05957766241158957, 0.04641047927448161, 0.04641047927448161, 0.04641047927448161, 0.9844804801564158, 0.9844804801564158, 0.9844804801564158, 0.9748380123352203, 0.9748380123352203, 0.9748380123352203, 0.9823241364665164, 0.9823241364665164, 0.9823241364665164, 0.1357825676474257, 0.1357825676474257, 0.1357825676474257, 0.11134934525622286, 0.11134934525622286, 0.11134934525622286, 0.17912763859102432, 0.17912763859102432, 0.17912763859102432, 0.18271820880255762, 0.18271820880255762, 0.18271820880255762, 0.17649130973002536, 0.17649130973002536, 0.17649130973002536, 0.10667170331466747, 0.10667170331466747, 0.10667170331466747, 0.12782363959402043, 0.12782363959402043, 0.12782363959402043, 0.10140468433786887, 0.10140468433786887, 0.10140468433786887, 0.12667086680295891, 0.12667086680295891, 0.12667086680295891, 0.08687076551512851, 0.08687076551512851, 0.08687076551512851, 0.13088193896856937, 0.13088193896856937, 0.13088193896856937, 0.12852239034480062, 0.12852239034480062, 0.12852239034480062, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04908648519071013, 0.04908648519071013, 0.04908648519071013, 0.031536046343887625, 0.031536046343887625, 0.031536046343887625, 0.05144348119440478, 0.05144348119440478, 0.05144348119440478, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014721716766307846, 0.014721716766307846, 0.014721716766307846, 0.03934041942177624, 0.03934041942177624, 0.03934041942177624, 0.06279418781860135, 0.06279418781860135, 0.06279418781860135, 0.3701934635292323, 0.3701934635292323, 0.3701934635292323, 0.3146715418628663, 0.3146715418628663, 0.3146715418628663, 0.37879443939311375, 0.37879443939311375, 0.37879443939311375, 0.08634305193125202, 0.08634305193125202, 0.08634305193125202, 0.05018468822026967, 0.05018468822026967, 0.05018468822026967, 0.07094176590961765, 0.07094176590961765, 0.07094176590961765, 0.16053142650459684, 0.16053142650459684, 0.16053142650459684, 0.12617670589621433, 0.12617670589621433, 0.12617670589621433, 0.16890531549849253, 0.16890531549849253, 0.16890531549849253, 0.21281657535132148, 0.21281657535132148, 0.21281657535132148, 0.14793105781002303, 0.14793105781002303, 0.14793105781002303, 0.1583438127746778, 0.1583438127746778, 0.1583438127746778, 0.13352530149702801, 0.13352530149702801, 0.13352530149702801, 0.13404399379075038, 0.13404399379075038, 0.13404399379075038, 0.12268807974513707, 0.12268807974513707, 0.12268807974513707, 0.15858440700500598, 0.15858440700500598, 0.15858440700500598, 0.21846778972565017, 0.21846778972565017, 0.21846778972565017, 0.17725701432813235, 0.17725701432813235, 0.17725701432813235, 0.18099037936888507, 0.18099037936888507, 0.18099037936888507, 0.1792143379612533, 0.1792143379612533, 0.1792143379612533, 0.16176473393690827, 0.16176473393690827, 0.16176473393690827, 0.307379365330666, 0.307379365330666, 0.307379365330666, 0.15809128840984832, 0.15809128840984832, 0.15809128840984832, 0.18549911182884482, 0.18549911182884482, 0.18549911182884482, 0.16916782637413674, 0.16916782637413674, 0.16916782637413674, 0.20811281743534393, 0.20811281743534393, 0.20811281743534393, 0.15615805499302993, 0.15615805499302993, 0.15615805499302993, 0.17876301467943867, 0.17876301467943867, 0.17876301467943867, 0.20612694111725383, 0.20612694111725383, 0.20612694111725383, 0.1749128760707097, 0.1749128760707097, 0.1749128760707097, 0.04778044723257535, 0.04778044723257535, 0.04778044723257535, 0.05099909918005219, 0.05099909918005219, 0.05099909918005219, 0.0513288624303716, 0.0513288624303716, 0.0513288624303716]}, "mutation_prompt": null}
{"id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.28232469592350823, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "018af272-ee68-400a-bdb1-8dce8049c2e3", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "b713f62b-ebba-42d5-89e2-4cbda127fcc9", "solution": "import numpy as np\n\nclass AdaptiveParticleDynamicsOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.7\n        self.CR = 0.8\n        self.diversity_threshold = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            vel = w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[current_global_best_index] < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = personal_best_value[current_global_best_index]\n\n            diversity = np.std(fitness)\n            if diversity < self.diversity_threshold:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant = np.clip(personal_best[idxs[0]] + self.F * (personal_best[idxs[1]] - personal_best[idxs[2]]), self.lower_bound, self.upper_bound)\n\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pos[i])\n\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < fitness[i]:\n                        pos[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < global_best_value:\n                            global_best = trial\n                            global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveParticleDynamicsOptimization", "description": "Adaptive Particle Dynamics Optimization (APDO) integrates variable inertia, population diversity, and a dual-phase mutation to enhance balance and adaptability in exploration and exploitation.", "configspace": "", "generation": 21, "fitness": 0.23804043161959226, "feedback": "The algorithm AdaptiveParticleDynamicsOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.24.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.744778851957494, 0.744778851957494, 0.744778851957494, 0.16084169747339672, 0.16084169747339672, 0.16084169747339672, 0.7503268323316653, 0.7503268323316653, 0.7503268323316653, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5075208235322883, 0.5075208235322883, 0.5075208235322883, 0.004226726527577385, 0.004226726527577385, 0.004226726527577385, 0.12152385826321466, 0.12152385826321466, 0.12152385826321466, 0.07138124436606341, 0.07138124436606341, 0.07138124436606341, 0.14582527903290388, 0.14582527903290388, 0.14582527903290388, 0.11905923533790375, 0.11905923533790375, 0.11905923533790375, 0.10408207052386698, 0.10408207052386698, 0.10408207052386698, 0.1417894653105739, 0.1417894653105739, 0.1417894653105739, 0.9890652508831715, 0.9890652508831715, 0.9890652508831715, 0.98885790878139, 0.98885790878139, 0.98885790878139, 0.9917103568968462, 0.9917103568968462, 0.9917103568968462, 0.5312948563952334, 0.5312948563952334, 0.5312948563952334, 0.6003719284580602, 0.6003719284580602, 0.6003719284580602, 0.5058911386609112, 0.5058911386609112, 0.5058911386609112, 0.20675099074418601, 0.20675099074418601, 0.20675099074418601, 0.15953454756500907, 0.15953454756500907, 0.15953454756500907, 0.11684836524877884, 0.11684836524877884, 0.11684836524877884, 0.1776965702365162, 0.1776965702365162, 0.1776965702365162, 0.2176494759785209, 0.2176494759785209, 0.2176494759785209, 0.18620622969151757, 0.18620622969151757, 0.18620622969151757, 0.17681588914946988, 0.17681588914946988, 0.17681588914946988, 0.18307322986999397, 0.18307322986999397, 0.18307322986999397, 0.227853975488294, 0.227853975488294, 0.227853975488294, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.015645481324487287, 0.015645481324487287, 0.015645481324487287, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06648498344276665, 0.06648498344276665, 0.06648498344276665, 0.09061628706210956, 0.09061628706210956, 0.09061628706210956, 0.029556492061354023, 0.029556492061354023, 0.029556492061354023, 0.04185649788720891, 0.04185649788720891, 0.04185649788720891, 0.07424267483598324, 0.07424267483598324, 0.07424267483598324, 0.07917610881588821, 0.07917610881588821, 0.07917610881588821, 0.009299357500219596, 0.009299357500219596, 0.009299357500219596, 0.03435790977979469, 0.03435790977979469, 0.03435790977979469, 0.07564400148383355, 0.07564400148383355, 0.07564400148383355, 0.4791190102577513, 0.4791190102577513, 0.4791190102577513, 0.20930125494824803, 0.20930125494824803, 0.20930125494824803, 0.5147514666518346, 0.5147514666518346, 0.5147514666518346, 0.05171735334543859, 0.05171735334543859, 0.05171735334543859, 0.13371918587306486, 0.13371918587306486, 0.13371918587306486, 0.1520309309729735, 0.1520309309729735, 0.1520309309729735, 0.1824235912809199, 0.1824235912809199, 0.1824235912809199, 0.19104858770186894, 0.19104858770186894, 0.19104858770186894, 0.1883004373756093, 0.1883004373756093, 0.1883004373756093, 0.32768975570637227, 0.32768975570637227, 0.32768975570637227, 0.39961090308995983, 0.39961090308995983, 0.39961090308995983, 0.34582966733585185, 0.34582966733585185, 0.34582966733585185, 0.17108509439527675, 0.17108509439527675, 0.17108509439527675, 0.24969423578237382, 0.24969423578237382, 0.24969423578237382, 0.11972790752940343, 0.11972790752940343, 0.11972790752940343, 0.18535671137897858, 0.18535671137897858, 0.18535671137897858, 0.2105868849432816, 0.2105868849432816, 0.2105868849432816, 0.18489389290903113, 0.18489389290903113, 0.18489389290903113, 0.22308904675504104, 0.22308904675504104, 0.22308904675504104, 0.21837445609123673, 0.21837445609123673, 0.21837445609123673, 0.22573657781161027, 0.22573657781161027, 0.22573657781161027, 0.8096564043401963, 0.8096564043401963, 0.8096564043401963, 0.16599278418141772, 0.16599278418141772, 0.16599278418141772, 0.19651131640241315, 0.19651131640241315, 0.19651131640241315, 0.1662714500203456, 0.1662714500203456, 0.1662714500203456, 0.20933724713449575, 0.20933724713449575, 0.20933724713449575, 0.1490234549077446, 0.1490234549077446, 0.1490234549077446, 0.18186973631369951, 0.18186973631369951, 0.18186973631369951, 0.18611618754499037, 0.18611618754499037, 0.18611618754499037, 0.2170675236116062, 0.2170675236116062, 0.2170675236116062, 0.07924805216915576, 0.07924805216915576, 0.07924805216915576, 0.08026484303148285, 0.08026484303148285, 0.08026484303148285, 0.08530853191847598, 0.08530853191847598, 0.08530853191847598]}, "mutation_prompt": null}
{"id": "75e2f05f-32f2-4dd6-adc5-dfcc583569e2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            temperature = 1 - (evaluations / self.budget)\n            self.w = 0.9 - 0.4 * temperature\n            self.c1 = 2.0 * (1 - temperature)\n            self.c2 = 2.0 * temperature\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n\n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * temperature, self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE_SA", "description": "Enhanced Adaptive Hybrid PSO-DE with Simulated Annealing-like Cooling Schedule and Randomized DE Mutation for improved global search capability.", "configspace": "", "generation": 22, "fitness": 0.2554599021776036, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.28.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.9099151430208472, 0.9099151430208472, 0.9099151430208472, 0.9122917921284183, 0.9122917921284183, 0.9122917921284183, 0.8613880377582825, 0.8613880377582825, 0.8613880377582825, 0.03590449480440239, 0.03590449480440239, 0.03590449480440239, 0.056704589258045446, 0.056704589258045446, 0.056704589258045446, 0.005079975312767937, 0.005079975312767937, 0.005079975312767937, 0.08451040915513641, 0.08451040915513641, 0.08451040915513641, 0.05894802944414057, 0.05894802944414057, 0.05894802944414057, 0.171868459100741, 0.171868459100741, 0.171868459100741, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.033896136352869366, 0.033896136352869366, 0.033896136352869366, 0.12397401172250067, 0.12397401172250067, 0.12397401172250067, 0.9899906677781567, 0.9899906677781567, 0.9899906677781567, 0.9933591583477548, 0.9933591583477548, 0.9933591583477548, 0.9910652350531204, 0.9910652350531204, 0.9910652350531204, 0.7843239467177077, 0.7843239467177077, 0.7843239467177077, 0.4744551676383997, 0.4744551676383997, 0.4744551676383997, 0.7621273503850428, 0.7621273503850428, 0.7621273503850428, 0.4388804862453404, 0.4388804862453404, 0.4388804862453404, 0.16174744411163244, 0.16174744411163244, 0.16174744411163244, 0.12935949208133402, 0.12935949208133402, 0.12935949208133402, 0.21158433620324035, 0.21158433620324035, 0.21158433620324035, 0.00012352550881000735, 0.00012352550881000735, 0.00012352550881000735, 0.16345591859525777, 0.16345591859525777, 0.16345591859525777, 0.25790482715459506, 0.25790482715459506, 0.25790482715459506, 0.24574429564745814, 0.24574429564745814, 0.24574429564745814, 0.25079043212916474, 0.25079043212916474, 0.25079043212916474, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05756129293323098, 0.05756129293323098, 0.05756129293323098, 0.046415437795016445, 0.046415437795016445, 0.046415437795016445, 0.053151455182257834, 0.053151455182257834, 0.053151455182257834, 0.036351950162038515, 0.036351950162038515, 0.036351950162038515, 0.10112095805632759, 0.10112095805632759, 0.10112095805632759, 0.07828687428777215, 0.07828687428777215, 0.07828687428777215, 0.11752042526742612, 0.11752042526742612, 0.11752042526742612, 0.039229623449198, 0.039229623449198, 0.039229623449198, 0.054934293217064445, 0.054934293217064445, 0.054934293217064445, 0.5965651520376614, 0.5965651520376614, 0.5965651520376614, 0.5373104587303854, 0.5373104587303854, 0.5373104587303854, 0.6138212775397923, 0.6138212775397923, 0.6138212775397923, 0.0779308935379267, 0.0779308935379267, 0.0779308935379267, 0.09165544271705606, 0.09165544271705606, 0.09165544271705606, 0.10007432108069259, 0.10007432108069259, 0.10007432108069259, 0.17132592987619277, 0.17132592987619277, 0.17132592987619277, 0.3173361047247625, 0.3173361047247625, 0.3173361047247625, 0.24368661446960294, 0.24368661446960294, 0.24368661446960294, 0.20471729208020584, 0.20471729208020584, 0.20471729208020584, 0.31287622823674044, 0.31287622823674044, 0.31287622823674044, 0.1785484772252126, 0.1785484772252126, 0.1785484772252126, 0.17669939522200384, 0.17669939522200384, 0.17669939522200384, 0.1462422687301851, 0.1462422687301851, 0.1462422687301851, 0.15460235565445857, 0.15460235565445857, 0.15460235565445857, 0.19894420712818384, 0.19894420712818384, 0.19894420712818384, 0.14609504931376838, 0.14609504931376838, 0.14609504931376838, 0.18518924439012097, 0.18518924439012097, 0.18518924439012097, 0.196655469969785, 0.196655469969785, 0.196655469969785, 0.22676151258679733, 0.22676151258679733, 0.22676151258679733, 0.25295003200465815, 0.25295003200465815, 0.25295003200465815, 0.932918488290067, 0.932918488290067, 0.932918488290067, 0.15723972922126306, 0.15723972922126306, 0.15723972922126306, 0.16553941119930682, 0.16553941119930682, 0.16553941119930682, 0.16884028730803602, 0.16884028730803602, 0.16884028730803602, 0.21222476199648022, 0.21222476199648022, 0.21222476199648022, 0.15706210753308492, 0.15706210753308492, 0.15706210753308492, 0.19845588589382368, 0.19845588589382368, 0.19845588589382368, 0.18489997640900713, 0.18489997640900713, 0.18489997640900713, 0.19527872812892066, 0.19527872812892066, 0.19527872812892066, 0.06269021252639018, 0.06269021252639018, 0.06269021252639018, 0.0815266328630947, 0.0815266328630947, 0.0815266328630947, 0.05208333615629568, 0.05208333615629568, 0.05208333615629568]}, "mutation_prompt": null}
{"id": "6e004b50-45f9-4c87-a9fb-2660699732d7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "a1a52e01-b539-46bf-8bfb-8c28c12f800a", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.levy_alpha = 1.5\n        self.local_search_prob = 0.15\n        self.adaptive_pop_size = self.pop_size\n\n    def levy_flight(self, dim):\n        u = np.random.normal(0, 1, dim) * np.sqrt(np.gamma(1 + self.levy_alpha) * np.sin(np.pi * self.levy_alpha / 2) / \n                                                   (np.gamma((1 + self.levy_alpha) / 2) * self.levy_alpha * 2**((self.levy_alpha - 1) / 2)))\n        v = np.random.normal(0, 1, dim)\n        step = u / abs(v)**(1 / self.levy_alpha)\n        return step\n\n    def chaotic_local_search(self, pos, dim):\n        beta = 0.7 + 0.3 * np.sin(2 * np.pi * np.random.rand())\n        perturbation = np.random.normal(0, 0.1, dim)\n        return pos + beta * perturbation * np.linalg.norm(pos)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    local_candidate = np.clip(\n                        self.chaotic_local_search(pos[i], self.dim) + self.levy_flight(self.dim), \n                        self.lower_bound, self.upper_bound\n                    )\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "RefinedHybridPSO_DE_Levy", "description": "A refined version of Adaptive Hybrid PSO-DE incorporating a Lvy flight-based exploration and chaotic local search for enhanced diversity and intensification.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {}, "mutation_prompt": null}
{"id": "f5430e8d-8bdd-440b-b962-19a12065ddc4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "69020ce8-2e92-41c4-9909-059055dcd833", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "f0606a7f-45de-4c3a-be8a-22d3016dab67", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "876b2204-6966-4524-8daa-81c06055dc5b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "cead82a1-2fc1-450a-b116-272853ca575d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.multiswarm_prob = 0.2\n        self.subswarm_count = 3\n        self.local_search_prob = 0.15\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.4 * (evaluations / self.budget)\n            self.c1 = 2.5 * (1 - evaluations / self.budget)\n            self.c2 = 2.5 * (evaluations / self.budget)\n\n            # Multi-swarm strategy with bidirectional learning\n            if np.random.rand() < self.multiswarm_prob:\n                pos_split = np.array_split(pos, self.subswarm_count)\n                for subswarm in pos_split:\n                    subswarm_best_idx = np.argmin([func(ind) for ind in subswarm])\n                    subswarm_best = subswarm[subswarm_best_idx]\n                    for p in subswarm:\n                        if evaluations >= self.budget:\n                            break\n                        vel = self.w * vel + self.c1 * np.random.rand(self.dim) * (personal_best - p) + self.c2 * np.random.rand(self.dim) * (subswarm_best - p)\n                        p += vel\n                        p = np.clip(p, self.lower_bound, self.upper_bound)\n                        new_fitness = func(p)\n                        evaluations += 1\n                        if new_fitness < func(personal_best):\n                            personal_best = p\n                            if new_fitness < global_best_value:\n                                global_best = p\n                                global_best_value = new_fitness\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Multi-swarm strategy and Bidirectional Learning to improve diversity and convergence speed.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"non-broadcastable output operand with shape (5,) doesn't match the broadcast shape (20,5)\").", "error": "ValueError(\"non-broadcastable output operand with shape (5,) doesn't match the broadcast shape (20,5)\")", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {}, "mutation_prompt": null}
{"id": "f6fe72e5-b77d-40a2-a9ae-41157fb68e5f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "821ac3f9-4c56-4282-bec5-56720de4ae45", "solution": "import numpy as np\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 30\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.2\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 60)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 15)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n                    # Gradient-based local search\n                    gradient = np.sign(np.random.normal(0, 1, self.dim))\n                    local_candidate_gradient = np.clip(global_best + 0.01 * gradient, self.lower_bound, self.upper_bound)\n                    local_fitness_gradient = func(local_candidate_gradient)\n                    evaluations += 1\n                    if local_fitness_gradient < global_best_value:\n                        global_best = local_candidate_gradient\n                        global_best_value = local_fitness_gradient\n\n        return global_best, global_best_value", "name": "EnhancedDynamicHybridPSO_DE", "description": "Enhanced Dynamic Hybrid PSO-DE with Gradient-Based Local Search for improved adaptation and exploitation-exploration balance.", "configspace": "", "generation": 31, "fitness": 0.2702045835596297, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.23.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7679470613764536, 0.7679470613764536, 0.7679470613764536, 0.7909410456178713, 0.7909410456178713, 0.7909410456178713, 0.7558266471022796, 0.7558266471022796, 0.7558266471022796, 0.6082411607791894, 0.6082411607791894, 0.6082411607791894, 0.5655229254232006, 0.5655229254232006, 0.5655229254232006, 0.6058355614127803, 0.6058355614127803, 0.6058355614127803, 0.15185069721568578, 0.15185069721568578, 0.15185069721568578, 0.14533369167533183, 0.14533369167533183, 0.14533369167533183, 0.1574388158731448, 0.1574388158731448, 0.1574388158731448, 0.11208919667023653, 0.11208919667023653, 0.11208919667023653, 0.1350244042702874, 0.1350244042702874, 0.1350244042702874, 0.08103798997019718, 0.08103798997019718, 0.08103798997019718, 0.9557644611968263, 0.9557644611968263, 0.9557644611968263, 0.9284460328027154, 0.9284460328027154, 0.9284460328027154, 0.9168608880462855, 0.9168608880462855, 0.9168608880462855, 0.4614353211543001, 0.4614353211543001, 0.4614353211543001, 0.3723663926160239, 0.3723663926160239, 0.3723663926160239, 0.5115262894468391, 0.5115262894468391, 0.5115262894468391, 0.2943298596332461, 0.2943298596332461, 0.2943298596332461, 0.17978263444469123, 0.17978263444469123, 0.17978263444469123, 0.3176296427261619, 0.3176296427261619, 0.3176296427261619, 0.26913680799188167, 0.26913680799188167, 0.26913680799188167, 0.24614501785786758, 0.24614501785786758, 0.24614501785786758, 0.20011616090127615, 0.20011616090127615, 0.20011616090127615, 0.16083400067721576, 0.16083400067721576, 0.16083400067721576, 0.12486640340202249, 0.12486640340202249, 0.12486640340202249, 0.21717951262704338, 0.21717951262704338, 0.21717951262704338, 0.0010886089368430385, 0.0010886089368430385, 0.0010886089368430385, 0.00011272658968142224, 0.00011272658968142224, 0.00011272658968142224, 0.006125418054848564, 0.006125418054848564, 0.006125418054848564, 0.07365825837393625, 0.07365825837393625, 0.07365825837393625, 0.07398240733797157, 0.07398240733797157, 0.07398240733797157, 0.10396637470857273, 0.10396637470857273, 0.10396637470857273, 0.056235138690887476, 0.056235138690887476, 0.056235138690887476, 0.25652518404392677, 0.25652518404392677, 0.25652518404392677, 0.06366786106090205, 0.06366786106090205, 0.06366786106090205, 0.0412523370022001, 0.0412523370022001, 0.0412523370022001, 0.22228200332412063, 0.22228200332412063, 0.22228200332412063, 0.058368495033478185, 0.058368495033478185, 0.058368495033478185, 0.49722327761908613, 0.49722327761908613, 0.49722327761908613, 0.4818563478823761, 0.4818563478823761, 0.4818563478823761, 0.4742631814328927, 0.4742631814328927, 0.4742631814328927, 0.08826398614270747, 0.08826398614270747, 0.08826398614270747, 0.0783574278924778, 0.0783574278924778, 0.0783574278924778, 0.132999009806977, 0.132999009806977, 0.132999009806977, 0.1637843122366739, 0.1637843122366739, 0.1637843122366739, 0.1627175658551061, 0.1627175658551061, 0.1627175658551061, 0.15822883115649744, 0.15822883115649744, 0.15822883115649744, 0.2483209674650686, 0.2483209674650686, 0.2483209674650686, 0.3264194345429695, 0.3264194345429695, 0.3264194345429695, 0.2300859121569273, 0.2300859121569273, 0.2300859121569273, 0.25340888668812944, 0.25340888668812944, 0.25340888668812944, 0.20345793453916028, 0.20345793453916028, 0.20345793453916028, 0.11833081993318373, 0.11833081993318373, 0.11833081993318373, 0.19397300867261658, 0.19397300867261658, 0.19397300867261658, 0.2010532124031268, 0.2010532124031268, 0.2010532124031268, 0.19987081663761785, 0.19987081663761785, 0.19987081663761785, 0.1879142457000612, 0.1879142457000612, 0.1879142457000612, 0.2185279621664863, 0.2185279621664863, 0.2185279621664863, 0.18894922626907407, 0.18894922626907407, 0.18894922626907407, 0.16971311088900765, 0.16971311088900765, 0.16971311088900765, 0.741990377174399, 0.741990377174399, 0.741990377174399, 0.15798805618307832, 0.15798805618307832, 0.15798805618307832, 0.15235696319742897, 0.15235696319742897, 0.15235696319742897, 0.19183831519981953, 0.19183831519981953, 0.19183831519981953, 0.416454347592761, 0.416454347592761, 0.416454347592761, 0.18063907385475908, 0.18063907385475908, 0.18063907385475908, 0.1978330194476995, 0.1978330194476995, 0.1978330194476995, 0.1799787765780846, 0.1799787765780846, 0.1799787765780846, 0.08202224952647652, 0.08202224952647652, 0.08202224952647652, 0.10080640535231156, 0.10080640535231156, 0.10080640535231156, 0.08432951802987187, 0.08432951802987187, 0.08432951802987187]}, "mutation_prompt": null}
{"id": "6227afb9-9a70-4c51-a358-e752baa50e37", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "7c44a1de-9926-41f6-bb2e-5f33e87dee40", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.15  # Increased local search probability\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        # Function to dynamically adjust learning rates\n        def adjust_learning_rates():\n            self.w = 0.5 + 0.4 * np.random.rand()  # Random inertia weight for enhanced exploration\n            self.c1 = 1.5 + np.random.rand()  # Adaptive cognitive coefficient\n            self.c2 = 1.5 + np.random.rand()  # Adaptive social coefficient\n\n        while evaluations < self.budget:\n            adjust_learning_rates()\n\n            # Self-organizing population adjustment strategy\n            if evaluations % (self.pop_size * 3) == 0:  # More frequent adjustments\n                diversity = np.std(personal_best_value)\n                if diversity < 0.05:  # Adjust threshold for faster adaptation\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 3, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 3, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)  # More randomization for r1\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)  # More randomization for r2\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Novel Self-Organizing Population Dynamics and Adaptive Learning Rates for Improved Convergence.", "configspace": "", "generation": 33, "fitness": 0.1931534108489402, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.21.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.4979274985548371, 0.4979274985548371, 0.4979274985548371, 0.4305426488171834, 0.4305426488171834, 0.4305426488171834, 0.5437239750575125, 0.5437239750575125, 0.5437239750575125, 0.0355257402900917, 0.0355257402900917, 0.0355257402900917, 0.13802990889423727, 0.13802990889423727, 0.13802990889423727, 0.14856468686272584, 0.14856468686272584, 0.14856468686272584, 0.07492117581554014, 0.07492117581554014, 0.07492117581554014, 0.09641396529137414, 0.09641396529137414, 0.09641396529137414, 0.053675251245276945, 0.053675251245276945, 0.053675251245276945, 0.08121257603088938, 0.08121257603088938, 0.08121257603088938, 0.10384664493036666, 0.10384664493036666, 0.10384664493036666, 0.084962222884302, 0.084962222884302, 0.084962222884302, 0.9901011050691462, 0.9901011050691462, 0.9901011050691462, 0.9919793088406107, 0.9919793088406107, 0.9919793088406107, 0.9900984729850584, 0.9900984729850584, 0.9900984729850584, 0.11806762467192566, 0.11806762467192566, 0.11806762467192566, 0.1325344454562355, 0.1325344454562355, 0.1325344454562355, 0.13928834072168594, 0.13928834072168594, 0.13928834072168594, 0.14408165544114526, 0.14408165544114526, 0.14408165544114526, 0.15772951328966922, 0.15772951328966922, 0.15772951328966922, 0.26929223855514617, 0.26929223855514617, 0.26929223855514617, 0.12212999369479549, 0.12212999369479549, 0.12212999369479549, 0.10687209051893265, 0.10687209051893265, 0.10687209051893265, 0.13181930745767545, 0.13181930745767545, 0.13181930745767545, 0.08421509940732663, 0.08421509940732663, 0.08421509940732663, 0.16597670156610078, 0.16597670156610078, 0.16597670156610078, 0.10887826613176876, 0.10887826613176876, 0.10887826613176876, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07420632934003457, 0.07420632934003457, 0.07420632934003457, 0.056942761145970744, 0.056942761145970744, 0.056942761145970744, 0.07003477672822722, 0.07003477672822722, 0.07003477672822722, 0.019360963537575104, 0.019360963537575104, 0.019360963537575104, 0.06263836073452445, 0.06263836073452445, 0.06263836073452445, 0.051556787428655104, 0.051556787428655104, 0.051556787428655104, 0.10188075553168441, 0.10188075553168441, 0.10188075553168441, 0.06549994468583387, 0.06549994468583387, 0.06549994468583387, 0.06294567785518757, 0.06294567785518757, 0.06294567785518757, 0.3566407047262943, 0.3566407047262943, 0.3566407047262943, 0.39072671110027657, 0.39072671110027657, 0.39072671110027657, 0.40042732197662567, 0.40042732197662567, 0.40042732197662567, 0.08007515487272232, 0.08007515487272232, 0.08007515487272232, 0.0843453819610791, 0.0843453819610791, 0.0843453819610791, 0.06391453762847465, 0.06391453762847465, 0.06391453762847465, 0.14513159273812237, 0.14513159273812237, 0.14513159273812237, 0.13919143840022152, 0.13919143840022152, 0.13919143840022152, 0.22828041186726922, 0.22828041186726922, 0.22828041186726922, 0.2434707264625251, 0.2434707264625251, 0.2434707264625251, 0.2552807942043067, 0.2552807942043067, 0.2552807942043067, 0.16901954443480427, 0.16901954443480427, 0.16901954443480427, 0.15628202724572948, 0.15628202724572948, 0.15628202724572948, 0.14752888385073926, 0.14752888385073926, 0.14752888385073926, 0.1506094286293057, 0.1506094286293057, 0.1506094286293057, 0.18987104401099464, 0.18987104401099464, 0.18987104401099464, 0.15477379095743415, 0.15477379095743415, 0.15477379095743415, 0.15243828402165405, 0.15243828402165405, 0.15243828402165405, 0.17819664459737194, 0.17819664459737194, 0.17819664459737194, 0.18745982538871941, 0.18745982538871941, 0.18745982538871941, 0.17688587055181326, 0.17688587055181326, 0.17688587055181326, 0.6466413349133295, 0.6466413349133295, 0.6466413349133295, 0.17462323697697213, 0.17462323697697213, 0.17462323697697213, 0.184403455737444, 0.184403455737444, 0.184403455737444, 0.1646950195163399, 0.1646950195163399, 0.1646950195163399, 0.20046678001706952, 0.20046678001706952, 0.20046678001706952, 0.24703884961593126, 0.24703884961593126, 0.24703884961593126, 0.18066675488513084, 0.18066675488513084, 0.18066675488513084, 0.1797216708612006, 0.1797216708612006, 0.1797216708612006, 0.1941371703768957, 0.1941371703768957, 0.1941371703768957, 0.0611349606733429, 0.0611349606733429, 0.0611349606733429, 0.05382168306475521, 0.05382168306475521, 0.05382168306475521, 0.06136772938954693, 0.06136772938954693, 0.06136772938954693]}, "mutation_prompt": null}
{"id": "51951415-9d82-4fdf-9e64-eb470117de65", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "d47d5bf7-3e73-40fe-9291-dc6bac6b9dda", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "ad342796-550d-47cf-ae8b-5737193f9134", "solution": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 30\n        self.w = 0.7\n        self.c1 = 1.0\n        self.c2 = 2.0\n        self.F = 0.5\n        self.CR = 0.9\n        self.local_search_prob = 0.15\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 1.5 * np.random.rand()\n            self.c2 = 1.5 + 0.5 * (evaluations / self.budget)\n\n            # Global learning factor for better convergence\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Energy-based mutation for diversity and escape from local optima\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                energy_factor = np.random.rand()\n                mutant = np.clip(a + self.F * (b - c) * energy_factor, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "ImprovedAdaptiveHybridPSO_DE", "description": "Improved Adaptive Hybrid PSO-DE with Global Learning and Energy-based Mutation for enhanced search efficiency and better convergence.", "configspace": "", "generation": 36, "fitness": 0.23495189566368582, "feedback": "The algorithm ImprovedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.23.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.6396378606147499, 0.6396378606147499, 0.6396378606147499, 0.6299729793401896, 0.6299729793401896, 0.6299729793401896, 0.6838905995181301, 0.6838905995181301, 0.6838905995181301, 0.390971739465253, 0.390971739465253, 0.390971739465253, 0.36078314312246385, 0.36078314312246385, 0.36078314312246385, 0.369780359582507, 0.369780359582507, 0.369780359582507, 0.11352694659104423, 0.11352694659104423, 0.11352694659104423, 0.06725841670560362, 0.06725841670560362, 0.06725841670560362, 0.10390542775699707, 0.10390542775699707, 0.10390542775699707, 0.10649769574832657, 0.10649769574832657, 0.10649769574832657, 0.08657486577414819, 0.08657486577414819, 0.08657486577414819, 0.09772525166336932, 0.09772525166336932, 0.09772525166336932, 0.9813320908646167, 0.9813320908646167, 0.9813320908646167, 0.9858292579532145, 0.9858292579532145, 0.9858292579532145, 0.9860021911078439, 0.9860021911078439, 0.9860021911078439, 0.2776227092055561, 0.2776227092055561, 0.2776227092055561, 0.2533617021822643, 0.2533617021822643, 0.2533617021822643, 0.30741472604897224, 0.30741472604897224, 0.30741472604897224, 0.19265474061044807, 0.19265474061044807, 0.19265474061044807, 0.1931858603922726, 0.1931858603922726, 0.1931858603922726, 0.43453522326496874, 0.43453522326496874, 0.43453522326496874, 0.17463974766874513, 0.17463974766874513, 0.17463974766874513, 0.1624348370399119, 0.1624348370399119, 0.1624348370399119, 0.16928015272261998, 0.16928015272261998, 0.16928015272261998, 0.14292130719259244, 0.14292130719259244, 0.14292130719259244, 0.19775352050679762, 0.19775352050679762, 0.19775352050679762, 0.10356868568484356, 0.10356868568484356, 0.10356868568484356, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06814659904132858, 0.06814659904132858, 0.06814659904132858, 0.07501254685151415, 0.07501254685151415, 0.07501254685151415, 0.03679477012328347, 0.03679477012328347, 0.03679477012328347, 0.047353823228431624, 0.047353823228431624, 0.047353823228431624, 0.056721206470586205, 0.056721206470586205, 0.056721206470586205, 0.07086159973355644, 0.07086159973355644, 0.07086159973355644, 0.009497128291280799, 0.009497128291280799, 0.009497128291280799, 0.03235809275587087, 0.03235809275587087, 0.03235809275587087, 0.07115265729478759, 0.07115265729478759, 0.07115265729478759, 0.47161495694206435, 0.47161495694206435, 0.47161495694206435, 0.47471617809164146, 0.47471617809164146, 0.47471617809164146, 0.47394306783618567, 0.47394306783618567, 0.47394306783618567, 0.08526423214384526, 0.08526423214384526, 0.08526423214384526, 0.10918903644170241, 0.10918903644170241, 0.10918903644170241, 0.07968867161747317, 0.07968867161747317, 0.07968867161747317, 0.20111996177646074, 0.20111996177646074, 0.20111996177646074, 0.21705376472734028, 0.21705376472734028, 0.21705376472734028, 0.15731204911292385, 0.15731204911292385, 0.15731204911292385, 0.23569711364845103, 0.23569711364845103, 0.23569711364845103, 0.36664019344207877, 0.36664019344207877, 0.36664019344207877, 0.3366619087387881, 0.3366619087387881, 0.3366619087387881, 0.16116069631421048, 0.16116069631421048, 0.16116069631421048, 0.17549394051797795, 0.17549394051797795, 0.17549394051797795, 0.12541162052075783, 0.12541162052075783, 0.12541162052075783, 0.18833680703174493, 0.18833680703174493, 0.18833680703174493, 0.19546430113916324, 0.19546430113916324, 0.19546430113916324, 0.20110529684562417, 0.20110529684562417, 0.20110529684562417, 0.20824964041279737, 0.20824964041279737, 0.20824964041279737, 0.19239878595953952, 0.19239878595953952, 0.19239878595953952, 0.2071881577532989, 0.2071881577532989, 0.2071881577532989, 0.7783567466181059, 0.7783567466181059, 0.7783567466181059, 0.1642189009212438, 0.1642189009212438, 0.1642189009212438, 0.14524514377467734, 0.14524514377467734, 0.14524514377467734, 0.16671783310825627, 0.16671783310825627, 0.16671783310825627, 0.19873455644679883, 0.19873455644679883, 0.19873455644679883, 0.1509395693991613, 0.1509395693991613, 0.1509395693991613, 0.18529164846180646, 0.18529164846180646, 0.18529164846180646, 0.17692627304512165, 0.17692627304512165, 0.17692627304512165, 0.17839498037178347, 0.17839498037178347, 0.17839498037178347, 0.0787510027501841, 0.0787510027501841, 0.0787510027501841, 0.07219488961941789, 0.07219488961941789, 0.07219488961941789, 0.07579410013566235, 0.07579410013566235, 0.07579410013566235]}, "mutation_prompt": null}
{"id": "2dd1ee8a-6ece-43cc-91e2-eb1cd7cbeac5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.memory_size = 5\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        memory = []\n        adaptive_CR = np.full(self.pop_size, self.CR)\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on memory\n            if len(memory) >= self.memory_size:\n                diversity = np.std(memory, axis=0).mean()\n                if diversity < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n                memory.pop(0)\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n            memory.append(fitness)\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                adaptive_CR[i] = 0.9 - 0.5 * (evaluations / self.budget)\n                cross_points = np.random.rand(self.dim) < adaptive_CR[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Introduce Adaptive Differential Evolution with Dynamic Memory and Adaptive Crossover for improved diversity and convergence.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.')", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {}, "mutation_prompt": null}
{"id": "c78e617b-1cf1-4097-b2e6-2d8c7672422c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "ec7a90e9-9bd9-4ed4-95b7-87a57717bd18", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            adaptive_factor = evaluations / self.budget\n            self.w = 0.5 + 0.4 * (1 - adaptive_factor)\n            self.c1 = 2.0 * (0.5 + adaptive_factor)\n            self.c2 = 2.0 * (1 - 0.5 * adaptive_factor)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.3 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "EnhancedAdaptiveHybridPSO_DE with adaptive learning rates and strategic individual level mutation for improved convergence efficiency.", "configspace": "", "generation": 39, "fitness": 0.20404879022668457, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.22.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.6837217643426512, 0.6837217643426512, 0.6837217643426512, 0.6385730125692969, 0.6385730125692969, 0.6385730125692969, 0.5676968216949649, 0.5676968216949649, 0.5676968216949649, 0.5152274306243403, 0.5152274306243403, 0.5152274306243403, 0.3693459536703295, 0.3693459536703295, 0.3693459536703295, 0.1250590742910772, 0.1250590742910772, 0.1250590742910772, 0.09876036118218867, 0.09876036118218867, 0.09876036118218867, 0.058871765074950955, 0.058871765074950955, 0.058871765074950955, 0.09181482421796094, 0.09181482421796094, 0.09181482421796094, 0.046405875745473724, 0.046405875745473724, 0.046405875745473724, 0.06938735544088193, 0.06938735544088193, 0.06938735544088193, 0.09426506254723355, 0.09426506254723355, 0.09426506254723355, 0.9883314872628289, 0.9883314872628289, 0.9883314872628289, 0.9909302893429283, 0.9909302893429283, 0.9909302893429283, 0.9882451712632309, 0.9882451712632309, 0.9882451712632309, 0.10909414603057466, 0.10909414603057466, 0.10909414603057466, 0.12859286317592233, 0.12859286317592233, 0.12859286317592233, 0.15211090978941466, 0.15211090978941466, 0.15211090978941466, 0.17461263693821694, 0.17461263693821694, 0.17461263693821694, 0.17664779203479397, 0.17664779203479397, 0.17664779203479397, 0.29986048988691405, 0.29986048988691405, 0.29986048988691405, 0.1442986796542547, 0.1442986796542547, 0.1442986796542547, 0.09253052940516338, 0.09253052940516338, 0.09253052940516338, 0.09322604182967043, 0.09322604182967043, 0.09322604182967043, 0.09688070349642908, 0.09688070349642908, 0.09688070349642908, 0.12284807734486947, 0.12284807734486947, 0.12284807734486947, 0.08930071511756488, 0.08930071511756488, 0.08930071511756488, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.029637818096622914, 0.029637818096622914, 0.029637818096622914, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.052656785357589775, 0.052656785357589775, 0.052656785357589775, 0.007940057430742664, 0.007940057430742664, 0.007940057430742664, 0.02455899123082783, 0.02455899123082783, 0.02455899123082783, 0.024018726161865733, 0.024018726161865733, 0.024018726161865733, 0.059445826585352135, 0.059445826585352135, 0.059445826585352135, 0.09289866290151039, 0.09289866290151039, 0.09289866290151039, 0.03168666234988671, 0.03168666234988671, 0.03168666234988671, 0.11670203161937864, 0.11670203161937864, 0.11670203161937864, 0.04482703154192769, 0.04482703154192769, 0.04482703154192769, 0.3999400393782716, 0.3999400393782716, 0.3999400393782716, 0.4464545126960825, 0.4464545126960825, 0.4464545126960825, 0.39193214741227245, 0.39193214741227245, 0.39193214741227245, 0.06610510381047274, 0.06610510381047274, 0.06610510381047274, 0.08312013450971845, 0.08312013450971845, 0.08312013450971845, 0.0840622904730779, 0.0840622904730779, 0.0840622904730779, 0.18296056466728572, 0.18296056466728572, 0.18296056466728572, 0.183140073214612, 0.183140073214612, 0.183140073214612, 0.16397934699472239, 0.16397934699472239, 0.16397934699472239, 0.20318989103644158, 0.20318989103644158, 0.20318989103644158, 0.23606888445951957, 0.23606888445951957, 0.23606888445951957, 0.1508624958698499, 0.1508624958698499, 0.1508624958698499, 0.15723030989023723, 0.15723030989023723, 0.15723030989023723, 0.1866624593762214, 0.1866624593762214, 0.1866624593762214, 0.15001213887929643, 0.15001213887929643, 0.15001213887929643, 0.17058351554295115, 0.17058351554295115, 0.17058351554295115, 0.1524056472614298, 0.1524056472614298, 0.1524056472614298, 0.17486922322976295, 0.17486922322976295, 0.17486922322976295, 0.1893963553852276, 0.1893963553852276, 0.1893963553852276, 0.16506752578370454, 0.16506752578370454, 0.16506752578370454, 0.18238297028641715, 0.18238297028641715, 0.18238297028641715, 0.531757248271848, 0.531757248271848, 0.531757248271848, 0.1647384239137868, 0.1647384239137868, 0.1647384239137868, 0.1366684955291284, 0.1366684955291284, 0.1366684955291284, 0.18690784633169444, 0.18690784633169444, 0.18690784633169444, 0.18709193703463878, 0.18709193703463878, 0.18709193703463878, 0.14349069437882023, 0.14349069437882023, 0.14349069437882023, 0.17856984068127402, 0.17856984068127402, 0.17856984068127402, 0.1799038178936917, 0.1799038178936917, 0.1799038178936917, 0.197328585550271, 0.197328585550271, 0.197328585550271, 0.07312096706870819, 0.07312096706870819, 0.07312096706870819, 0.04745392251182545, 0.04745392251182545, 0.04745392251182545, 0.052843059748195476, 0.052843059748195476, 0.052843059748195476]}, "mutation_prompt": null}
{"id": "5f59d0e5-ddef-48d1-b15a-e87188eddf63", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.9  # Start with higher inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.2  # Increase local search probability\n        self.adaptive_pop_size = self.pop_size\n        self.convergence_threshold = 1e-5  # Threshold for convergence-driven local search\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight based on convergence\n            self.w = 0.9 if np.std(personal_best_value) > self.convergence_threshold else 0.4\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Convergence-driven local search\n            if np.std(fitness) < self.convergence_threshold:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Adaptive Inertia and Convergence-driven Local Search for improved exploration-exploitation trade-off and convergence speed.", "configspace": "", "generation": 40, "fitness": 0.1839530687488308, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.20.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.5330211299513423, 0.5330211299513423, 0.5330211299513423, 0.26548895565803643, 0.26548895565803643, 0.26548895565803643, 0.6166734597557, 0.6166734597557, 0.6166734597557, 0.3326436410450143, 0.3326436410450143, 0.3326436410450143, 0.28077607985366015, 0.28077607985366015, 0.28077607985366015, 0.015149343550568628, 0.015149343550568628, 0.015149343550568628, 0.09869533059774693, 0.09869533059774693, 0.09869533059774693, 0.08032915404992158, 0.08032915404992158, 0.08032915404992158, 0.06851624395322653, 0.06851624395322653, 0.06851624395322653, 0.057295159230782655, 0.057295159230782655, 0.057295159230782655, 0.05730234593451644, 0.05730234593451644, 0.05730234593451644, 0.08131236556928745, 0.08131236556928745, 0.08131236556928745, 0.9533675093940239, 0.9533675093940239, 0.9533675093940239, 0.9792107684435363, 0.9792107684435363, 0.9792107684435363, 0.9515470000970847, 0.9515470000970847, 0.9515470000970847, 0.10746640974789456, 0.10746640974789456, 0.10746640974789456, 0.11894861762002529, 0.11894861762002529, 0.11894861762002529, 0.1425235705205159, 0.1425235705205159, 0.1425235705205159, 0.17419847165578284, 0.17419847165578284, 0.17419847165578284, 0.15240838015775315, 0.15240838015775315, 0.15240838015775315, 0.18471800052564924, 0.18471800052564924, 0.18471800052564924, 0.1398145289408318, 0.1398145289408318, 0.1398145289408318, 0.12373550565792013, 0.12373550565792013, 0.12373550565792013, 0.1402008677687271, 0.1402008677687271, 0.1402008677687271, 0.033704198235826155, 0.033704198235826155, 0.033704198235826155, 0.12969127802218405, 0.12969127802218405, 0.12969127802218405, 0.08410544739998527, 0.08410544739998527, 0.08410544739998527, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.046792926388170564, 0.046792926388170564, 0.046792926388170564, 0.0069938008830015, 0.0069938008830015, 0.0069938008830015, 0.0258767742258742, 0.0258767742258742, 0.0258767742258742, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02084370723703577, 0.02084370723703577, 0.02084370723703577, 0.029338562308054317, 0.029338562308054317, 0.029338562308054317, 0.026094881738459863, 0.026094881738459863, 0.026094881738459863, 0.015504903198283904, 0.015504903198283904, 0.015504903198283904, 0.10173262160341456, 0.10173262160341456, 0.10173262160341456, 0.36734741760710243, 0.36734741760710243, 0.36734741760710243, 0.4467720350445876, 0.4467720350445876, 0.4467720350445876, 0.4328044992486415, 0.4328044992486415, 0.4328044992486415, 0.06629475651566297, 0.06629475651566297, 0.06629475651566297, 0.093477731014736, 0.093477731014736, 0.093477731014736, 0.0604220483739315, 0.0604220483739315, 0.0604220483739315, 0.14072963155542406, 0.14072963155542406, 0.14072963155542406, 0.13649376695183202, 0.13649376695183202, 0.13649376695183202, 0.1361024251214501, 0.1361024251214501, 0.1361024251214501, 0.1969388561896721, 0.1969388561896721, 0.1969388561896721, 0.20194490372445784, 0.20194490372445784, 0.20194490372445784, 0.265351037870624, 0.265351037870624, 0.265351037870624, 0.14091736864868543, 0.14091736864868543, 0.14091736864868543, 0.1396340727219123, 0.1396340727219123, 0.1396340727219123, 0.12367218667181856, 0.12367218667181856, 0.12367218667181856, 0.16179534039732857, 0.16179534039732857, 0.16179534039732857, 0.16250257556576542, 0.16250257556576542, 0.16250257556576542, 0.17756661855391653, 0.17756661855391653, 0.17756661855391653, 0.18333211899374413, 0.18333211899374413, 0.18333211899374413, 0.20692035444903456, 0.20692035444903456, 0.20692035444903456, 0.19674323179701925, 0.19674323179701925, 0.19674323179701925, 0.27562303317032133, 0.27562303317032133, 0.27562303317032133, 0.21237382485099165, 0.21237382485099165, 0.21237382485099165, 0.2277289970278905, 0.2277289970278905, 0.2277289970278905, 0.1779319292879873, 0.1779319292879873, 0.1779319292879873, 0.21955056539582352, 0.21955056539582352, 0.21955056539582352, 0.19859409921723636, 0.19859409921723636, 0.19859409921723636, 0.17108910302384628, 0.17108910302384628, 0.17108910302384628, 0.17536772156125702, 0.17536772156125702, 0.17536772156125702, 0.17964793920567357, 0.17964793920567357, 0.17964793920567357, 0.06041477001643958, 0.06041477001643958, 0.06041477001643958, 0.07602108405366148, 0.07602108405366148, 0.07602108405366148, 0.05609296516750417, 0.05609296516750417, 0.05609296516750417]}, "mutation_prompt": null}
{"id": "4759e06c-0fa6-4dd8-a5d0-c4b9fa5db721", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "b724662c-258d-42b3-bf14-a905cdfdbeda", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "1738e010-06e0-4518-8c98-ed0f55b2ad3f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "6054e957-34f8-42e9-972e-570d827bd2a9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "4a682b39-847f-4465-98da-2a20bb513e55", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "ac31f70c-f69b-4583-b3a1-2dc0c3effa42", "solution": "import numpy as np\n\nclass AdaptiveDynamicPSO_DE_CMA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n        self.sigma = 0.3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n        covariance = np.eye(self.dim)\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.c2 = 1.5 + 0.5 * (evaluations / self.budget)\n\n            fitness_std_dev = np.std(personal_best_value)\n            if evaluations % (self.pop_size * 5) == 0 and fitness_std_dev < 0.1:\n                self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 60)\n            else:\n                self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n\n            pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n            vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # Stochastic Covariance Matrix Adaptation\n            if np.random.rand() < 0.3:\n                step = np.random.multivariate_normal(np.zeros(self.dim), covariance, self.adaptive_pop_size)\n                pos += step\n                pos = np.clip(pos, self.lower_bound, self.upper_bound)\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveDynamicPSO_DE_CMA", "description": "Adaptive Dynamic PSO-DE with Fitness Diversity Monitoring and Stochastic Covariance Matrix Adaptation for enhanced convergence and diversity management.", "configspace": "", "generation": 46, "fitness": 0.15113611394648108, "feedback": "The algorithm AdaptiveDynamicPSO_DE_CMA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.19.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.267400761446662, 0.267400761446662, 0.267400761446662, 0.3093801172215276, 0.3093801172215276, 0.3093801172215276, 0.3069644633058527, 0.3069644633058527, 0.3069644633058527, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000999332655246099, 0.000999332655246099, 0.000999332655246099, 0.06405538558784463, 0.06405538558784463, 0.06405538558784463, 0.0764195169887083, 0.0764195169887083, 0.0764195169887083, 0.0686490023751789, 0.0686490023751789, 0.0686490023751789, 0.04879605417701838, 0.04879605417701838, 0.04879605417701838, 0.05506389612274054, 0.05506389612274054, 0.05506389612274054, 0.06126273148997474, 0.06126273148997474, 0.06126273148997474, 0.9870244980439667, 0.9870244980439667, 0.9870244980439667, 0.9914434036166274, 0.9914434036166274, 0.9914434036166274, 0.9828437141004993, 0.9828437141004993, 0.9828437141004993, 0.10200406971555254, 0.10200406971555254, 0.10200406971555254, 0.11841401789502615, 0.11841401789502615, 0.11841401789502615, 0.14313294545143251, 0.14313294545143251, 0.14313294545143251, 0.16349055584861383, 0.16349055584861383, 0.16349055584861383, 0.14867503601771825, 0.14867503601771825, 0.14867503601771825, 0.15422990144821436, 0.15422990144821436, 0.15422990144821436, 0.07916108704165803, 0.07916108704165803, 0.07916108704165803, 0.046996779984420756, 0.046996779984420756, 0.046996779984420756, 0.031382075634519446, 0.031382075634519446, 0.031382075634519446, 0.014626716525503958, 0.014626716525503958, 0.014626716525503958, 0.06463697054632067, 0.06463697054632067, 0.06463697054632067, 0.047037720198616295, 0.047037720198616295, 0.047037720198616295, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005690949280641178, 0.0005690949280641178, 0.0005690949280641178, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03990206756641568, 0.03990206756641568, 0.03990206756641568, 0.06013130116789289, 0.06013130116789289, 0.06013130116789289, 0.03512250881375312, 0.03512250881375312, 0.03512250881375312, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022966534564502927, 0.022966534564502927, 0.022966534564502927, 0.014715419851865974, 0.014715419851865974, 0.014715419851865974, 0.037532631832759344, 0.037532631832759344, 0.037532631832759344, 0.2616069981421577, 0.2616069981421577, 0.2616069981421577, 0.26768760962548854, 0.26768760962548854, 0.26768760962548854, 0.26864757813916684, 0.26864757813916684, 0.26864757813916684, 0.06968624037248505, 0.06968624037248505, 0.06968624037248505, 0.06310836985461554, 0.06310836985461554, 0.06310836985461554, 0.06001705339316454, 0.06001705339316454, 0.06001705339316454, 0.14938380545988206, 0.14938380545988206, 0.14938380545988206, 0.14139717267412522, 0.14139717267412522, 0.14139717267412522, 0.16015426963705848, 0.16015426963705848, 0.16015426963705848, 0.19459680669113344, 0.19459680669113344, 0.19459680669113344, 0.18095625205956212, 0.18095625205956212, 0.18095625205956212, 0.21454801897829245, 0.21454801897829245, 0.21454801897829245, 0.1261133414070449, 0.1261133414070449, 0.1261133414070449, 0.12704862484783808, 0.12704862484783808, 0.12704862484783808, 0.10905499935653185, 0.10905499935653185, 0.10905499935653185, 0.19130830584305236, 0.19130830584305236, 0.19130830584305236, 0.15315148868189354, 0.15315148868189354, 0.15315148868189354, 0.16223736495210672, 0.16223736495210672, 0.16223736495210672, 0.1579360662177136, 0.1579360662177136, 0.1579360662177136, 0.16373504442867193, 0.16373504442867193, 0.16373504442867193, 0.17074066379321007, 0.17074066379321007, 0.17074066379321007, 0.3256207123236251, 0.3256207123236251, 0.3256207123236251, 0.14823889327783968, 0.14823889327783968, 0.14823889327783968, 0.15861493486883205, 0.15861493486883205, 0.15861493486883205, 0.1802788819888097, 0.1802788819888097, 0.1802788819888097, 0.1974409149406371, 0.1974409149406371, 0.1974409149406371, 0.17969371951456992, 0.17969371951456992, 0.17969371951456992, 0.19732355148024294, 0.19732355148024294, 0.19732355148024294, 0.19032138212468286, 0.19032138212468286, 0.19032138212468286, 0.18037734723229681, 0.18037734723229681, 0.18037734723229681, 0.07368293126705261, 0.07368293126705261, 0.07368293126705261, 0.052484908973768896, 0.052484908973768896, 0.052484908973768896, 0.05887563943438867, 0.05887563943438867, 0.05887563943438867]}, "mutation_prompt": null}
{"id": "89c7b435-d672-4f9b-9d19-eb800963cb3e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "da5c554b-38b5-43c1-b8a5-9252ed080001", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "10061217-efb7-4219-a43d-cee3d1772603", "solution": "import numpy as np\n\nclass EnhancedDynamicPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight for velocity control\n            self.w = 0.9 - 0.7 * (evaluations / self.budget)\n            self.c1 = 1.5 - 1.0 * (evaluations / self.budget)\n            self.c2 = 1.5 + 1.5 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant_1 = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                mutant_2 = np.clip(pos[i] + np.random.normal(0, 0.1, self.dim), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial_1 = np.where(cross_points, mutant_1, pos[i])\n                trial_2 = np.where(cross_points, mutant_2, pos[i])\n\n                trial_1_fitness = func(trial_1)\n                trial_2_fitness = func(trial_2)\n                evaluations += 2\n                if trial_1_fitness < fitness[i]:\n                    pos[i] = trial_1\n                    fitness[i] = trial_1_fitness\n                    if trial_1_fitness < global_best_value:\n                        global_best = trial_1\n                        global_best_value = trial_1_fitness\n                elif trial_2_fitness < fitness[i]:\n                    pos[i] = trial_2\n                    fitness[i] = trial_2_fitness\n                    if trial_2_fitness < global_best_value:\n                        global_best = trial_2\n                        global_best_value = trial_2_fitness\n\n        return global_best, global_best_value", "name": "EnhancedDynamicPSO_DE", "description": "Enhanced Dynamic PSO-DE with Adaptive Velocity Control and Dual Mutation Strategy to improve convergence speed and solution accuracy.", "configspace": "", "generation": 49, "fitness": 0.24684501628533354, "feedback": "The algorithm EnhancedDynamicPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7070591604509175, 0.7070591604509175, 0.7070591604509175, 0.7251056633001242, 0.7251056633001242, 0.7251056633001242, 0.7353022256817558, 0.7353022256817558, 0.7353022256817558, 0.5498972789848049, 0.5498972789848049, 0.5498972789848049, 0.572842051776121, 0.572842051776121, 0.572842051776121, 0.3728726499671987, 0.3728726499671987, 0.3728726499671987, 0.10729214086402028, 0.10729214086402028, 0.10729214086402028, 0.10596553589676261, 0.10596553589676261, 0.10596553589676261, 0.08750449720501385, 0.08750449720501385, 0.08750449720501385, 0.09784548186472275, 0.09784548186472275, 0.09784548186472275, 0.08215278321461339, 0.08215278321461339, 0.08215278321461339, 0.1171947361891118, 0.1171947361891118, 0.1171947361891118, 0.9821356543211782, 0.9821356543211782, 0.9821356543211782, 0.9810591147166148, 0.9810591147166148, 0.9810591147166148, 0.980750627565231, 0.980750627565231, 0.980750627565231, 0.2866020155897049, 0.2866020155897049, 0.2866020155897049, 0.25770118577692336, 0.25770118577692336, 0.25770118577692336, 0.2501950112310024, 0.2501950112310024, 0.2501950112310024, 0.1871067217649227, 0.1871067217649227, 0.1871067217649227, 0.1575506739575938, 0.1575506739575938, 0.1575506739575938, 0.16633485812809923, 0.16633485812809923, 0.16633485812809923, 0.1724952643092914, 0.1724952643092914, 0.1724952643092914, 0.10964786990147113, 0.10964786990147113, 0.10964786990147113, 0.2409440007826582, 0.2409440007826582, 0.2409440007826582, 0.17909319748423203, 0.17909319748423203, 0.17909319748423203, 0.15792551828950996, 0.15792551828950996, 0.15792551828950996, 0.1798171658985761, 0.1798171658985761, 0.1798171658985761, 0.03659395577205704, 0.03659395577205704, 0.03659395577205704, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09183212891357617, 0.09183212891357617, 0.09183212891357617, 0.004192611581321781, 0.004192611581321781, 0.004192611581321781, 0.04108097907033337, 0.04108097907033337, 0.04108097907033337, 0.03054865625165437, 0.03054865625165437, 0.03054865625165437, 0.09585191678828686, 0.09585191678828686, 0.09585191678828686, 0.17013611917447446, 0.17013611917447446, 0.17013611917447446, 0.072347324502532, 0.072347324502532, 0.072347324502532, 0.05545889958302719, 0.05545889958302719, 0.05545889958302719, 0.054004897305146904, 0.054004897305146904, 0.054004897305146904, 0.46141880016503356, 0.46141880016503356, 0.46141880016503356, 0.4308346859317722, 0.4308346859317722, 0.4308346859317722, 0.47204337508517813, 0.47204337508517813, 0.47204337508517813, 0.06657488295348557, 0.06657488295348557, 0.06657488295348557, 0.09143412107042781, 0.09143412107042781, 0.09143412107042781, 0.08829562558518578, 0.08829562558518578, 0.08829562558518578, 0.14621983392791427, 0.14621983392791427, 0.14621983392791427, 0.16845742296003552, 0.16845742296003552, 0.16845742296003552, 0.3123954547755262, 0.3123954547755262, 0.3123954547755262, 0.21708739480186512, 0.21708739480186512, 0.21708739480186512, 0.3522954047910536, 0.3522954047910536, 0.3522954047910536, 0.33481553721020396, 0.33481553721020396, 0.33481553721020396, 0.18014926317775648, 0.18014926317775648, 0.18014926317775648, 0.17812400720319566, 0.17812400720319566, 0.17812400720319566, 0.23622138010153226, 0.23622138010153226, 0.23622138010153226, 0.16631055336257938, 0.16631055336257938, 0.16631055336257938, 0.19445988486877452, 0.19445988486877452, 0.19445988486877452, 0.15133593686689728, 0.15133593686689728, 0.15133593686689728, 0.19428046253251308, 0.19428046253251308, 0.19428046253251308, 0.1942611782081204, 0.1942611782081204, 0.1942611782081204, 0.18392119444851496, 0.18392119444851496, 0.18392119444851496, 0.7797161238392156, 0.7797161238392156, 0.7797161238392156, 0.1925713748427318, 0.1925713748427318, 0.1925713748427318, 0.15458870165425764, 0.15458870165425764, 0.15458870165425764, 0.16835029853403116, 0.16835029853403116, 0.16835029853403116, 0.20481299684998822, 0.20481299684998822, 0.20481299684998822, 0.49517800031529746, 0.49517800031529746, 0.49517800031529746, 0.1865313654798103, 0.1865313654798103, 0.1865313654798103, 0.17203385534663307, 0.17203385534663307, 0.17203385534663307, 0.18567703780336486, 0.18567703780336486, 0.18567703780336486, 0.06987722021536702, 0.06987722021536702, 0.06987722021536702, 0.06667408538727726, 0.06667408538727726, 0.06667408538727726, 0.07325313819388835, 0.07325313819388835, 0.07325313819388835]}, "mutation_prompt": null}
{"id": "ec94381b-7b0d-4ae5-9cef-96a1a3016042", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "3991094c-479a-42ac-b103-68ce71e2e6e4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F = 0.8\n        self.CR = 0.9\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = self.initial_w - (self.initial_w - self.final_w) * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n\n            current_global_best_value = np.min(personal_best_value[:self.adaptive_pop_size])\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[np.argmin(personal_best_value[:self.adaptive_pop_size])]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if evaluations % (self.pop_size * 5) == 0:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Adaptive Learning Rate and Refinement Stage to balance exploration-exploitation dynamically and improve convergence speed.", "configspace": "", "generation": 51, "fitness": 0.16891148967876443, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.20.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.4183331868681447, 0.4183331868681447, 0.4183331868681447, 0.5094508786810086, 0.5094508786810086, 0.5094508786810086, 0.4913386587547558, 0.4913386587547558, 0.4913386587547558, 0.013948196067920304, 0.013948196067920304, 0.013948196067920304, 0.027033498742637274, 0.027033498742637274, 0.027033498742637274, 0.06277788817024044, 0.06277788817024044, 0.06277788817024044, 0.08571436502919183, 0.08571436502919183, 0.08571436502919183, 0.07588824891494372, 0.07588824891494372, 0.07588824891494372, 0.08034420201796588, 0.08034420201796588, 0.08034420201796588, 0.05989227627989635, 0.05989227627989635, 0.05989227627989635, 0.06305643019894691, 0.06305643019894691, 0.06305643019894691, 0.011804865595514635, 0.011804865595514635, 0.011804865595514635, 0.9880235700336636, 0.9880235700336636, 0.9880235700336636, 0.9920900695045263, 0.9920900695045263, 0.9920900695045263, 0.9762704238865354, 0.9762704238865354, 0.9762704238865354, 0.07784252138035352, 0.07784252138035352, 0.07784252138035352, 0.10299054718795941, 0.10299054718795941, 0.10299054718795941, 0.1186655399475931, 0.1186655399475931, 0.1186655399475931, 0.14781313078841107, 0.14781313078841107, 0.14781313078841107, 0.157138205805625, 0.157138205805625, 0.157138205805625, 0.14382159863759314, 0.14382159863759314, 0.14382159863759314, 0.08899830047918089, 0.08899830047918089, 0.08899830047918089, 0.07378852516141376, 0.07378852516141376, 0.07378852516141376, 0.12836100931406202, 0.12836100931406202, 0.12836100931406202, 0.10212532467865221, 0.10212532467865221, 0.10212532467865221, 0.10198160682275814, 0.10198160682275814, 0.10198160682275814, 0.08900080059708126, 0.08900080059708126, 0.08900080059708126, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004926778242314911, 0.004926778242314911, 0.004926778242314911, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03091940781381053, 0.03091940781381053, 0.03091940781381053, 0.021699704037527745, 0.021699704037527745, 0.021699704037527745, 0.02794278394970784, 0.02794278394970784, 0.02794278394970784, 0.009388460074311156, 0.009388460074311156, 0.009388460074311156, 0.02909062360334358, 0.02909062360334358, 0.02909062360334358, 0.03961987435342673, 0.03961987435342673, 0.03961987435342673, 0.0545316712462347, 0.0545316712462347, 0.0545316712462347, 0.028807017843669014, 0.028807017843669014, 0.028807017843669014, 0.04965560325345886, 0.04965560325345886, 0.04965560325345886, 0.31617702663789127, 0.31617702663789127, 0.31617702663789127, 0.3510100785811312, 0.3510100785811312, 0.3510100785811312, 0.2901028719714225, 0.2901028719714225, 0.2901028719714225, 0.07432104720634836, 0.07432104720634836, 0.07432104720634836, 0.06838482296539328, 0.06838482296539328, 0.06838482296539328, 0.07525706774411733, 0.07525706774411733, 0.07525706774411733, 0.16148464648792238, 0.16148464648792238, 0.16148464648792238, 0.19925656432119554, 0.19925656432119554, 0.19925656432119554, 0.13163137884106435, 0.13163137884106435, 0.13163137884106435, 0.20030547619775263, 0.20030547619775263, 0.20030547619775263, 0.20723189579543422, 0.20723189579543422, 0.20723189579543422, 0.22249821223879673, 0.22249821223879673, 0.22249821223879673, 0.14751205044407723, 0.14751205044407723, 0.14751205044407723, 0.1275387583258163, 0.1275387583258163, 0.1275387583258163, 0.11219983862804894, 0.11219983862804894, 0.11219983862804894, 0.1746649121583922, 0.1746649121583922, 0.1746649121583922, 0.16161857388359746, 0.16161857388359746, 0.16161857388359746, 0.15168185588096783, 0.15168185588096783, 0.15168185588096783, 0.18188239925663852, 0.18188239925663852, 0.18188239925663852, 0.19387190940951948, 0.19387190940951948, 0.19387190940951948, 0.1729036275033563, 0.1729036275033563, 0.1729036275033563, 0.3889981064268436, 0.3889981064268436, 0.3889981064268436, 0.14674575458643324, 0.14674575458643324, 0.14674575458643324, 0.1577321569460488, 0.1577321569460488, 0.1577321569460488, 0.15510393066282158, 0.15510393066282158, 0.15510393066282158, 0.1520174626373657, 0.1520174626373657, 0.1520174626373657, 0.19113477259201084, 0.19113477259201084, 0.19113477259201084, 0.2012394623491628, 0.2012394623491628, 0.2012394623491628, 0.17820399393116626, 0.17820399393116626, 0.17820399393116626, 0.20218146485884414, 0.20218146485884414, 0.20218146485884414, 0.0619071938876683, 0.0619071938876683, 0.0619071938876683, 0.06410539881650712, 0.06410539881650712, 0.06410539881650712, 0.05544675073290395, 0.05544675073290395, 0.05544675073290395]}, "mutation_prompt": null}
{"id": "77aacb81-db15-4108-a979-32f00340f7fb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "168005ad-3720-4481-b32e-272503ae31b8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "e237221e-3811-432a-8be4-e277b21a64cd", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "13611864-063a-4de6-b125-b49d70a5b0b1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "3adf201c-c179-46c4-819d-15cb32e98d0f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "39c96668-c067-409b-be76-b161d3e7b51f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "77f0b92d-4632-417a-9941-5720641d7c31", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "262c30b2-1207-49d2-88a1-9e53fee8e1d7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "fe642b56-80ea-4f54-9e56-779228aa6c0a", "solution": "import numpy as np\n\nclass AdaptiveMultiSwarmHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        swarms = [np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.pop_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_bests = [swarm.copy() for swarm in swarms]\n        personal_best_values = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        global_best_indices = [np.argmin(p_values) for p_values in personal_best_values]\n        global_bests = [personal_bests[i][global_best_indices[i]] for i in range(self.num_swarms)]\n        global_best_values = [personal_best_values[i][global_best_indices[i]] for i in range(self.num_swarms)]\n        \n        evaluations = self.pop_size * self.num_swarms\n\n        while evaluations < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)\n                self.c1 = 2.0 * (1 - evaluations / self.budget)\n                self.c2 = 2.0 * (evaluations / self.budget)\n\n                r1 = np.random.rand(self.pop_size, self.dim)\n                r2 = np.random.rand(self.pop_size, self.dim)\n                velocities[swarm_idx] = self.w * velocities[swarm_idx] + self.c1 * r1 * (personal_bests[swarm_idx] - swarms[swarm_idx]) + self.c2 * r2 * (global_bests[swarm_idx] - swarms[swarm_idx])\n                swarms[swarm_idx] = np.clip(swarms[swarm_idx] + velocities[swarm_idx], self.lower_bound, self.upper_bound)\n\n                fitness = np.array([func(ind) for ind in swarms[swarm_idx]])\n                evaluations += self.pop_size\n\n                better_mask = fitness < personal_best_values[swarm_idx]\n                personal_bests[swarm_idx][better_mask] = swarms[swarm_idx][better_mask]\n                personal_best_values[swarm_idx][better_mask] = fitness[better_mask]\n\n                current_global_best_index = np.argmin(personal_best_values[swarm_idx])\n                current_global_best_value = personal_best_values[swarm_idx][current_global_best_index]\n                if current_global_best_value < global_best_values[swarm_idx]:\n                    global_bests[swarm_idx] = personal_bests[swarm_idx][current_global_best_index]\n                    global_best_values[swarm_idx] = current_global_best_value\n                \n                # Fitness sharing and DE operations\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    idxs = np.random.choice([idx for idx in range(self.pop_size) if idx != i], 3, replace=False)\n                    a, b, c = swarms[swarm_idx][idxs]\n                    mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, swarms[swarm_idx][i])\n\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < fitness[i]:\n                        swarms[swarm_idx][i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < global_best_values[swarm_idx]:\n                            global_bests[swarm_idx] = trial\n                            global_best_values[swarm_idx] = trial_fitness\n\n                # Diversity preservation through random restart\n                if evaluations % (self.pop_size * 10) == 0:\n                    diversity = np.std(swarms[swarm_idx])\n                    if diversity < 0.1:\n                        swarms[swarm_idx] = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n                        velocities[swarm_idx] = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n\n        overall_best_value = min(global_best_values)\n        best_index = global_best_values.index(overall_best_value)\n        return global_bests[best_index], overall_best_value", "name": "AdaptiveMultiSwarmHybridPSO_DE", "description": "Adaptive Multi-Swarm Hybrid PSO-DE with Fitness Sharing and Dynamic Diversity Preservation to enhance exploration and exploitative capabilities.", "configspace": "", "generation": 60, "fitness": 0.22257314892646232, "feedback": "The algorithm AdaptiveMultiSwarmHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.19.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.6060821257367808, 0.6060821257367808, 0.6060821257367808, 0.5484794391261907, 0.5484794391261907, 0.5484794391261907, 0.5609063629892587, 0.5609063629892587, 0.5609063629892587, 0.20093395315829532, 0.20093395315829532, 0.20093395315829532, 0.20093052228791275, 0.20093052228791275, 0.20093052228791275, 0.13978152794809107, 0.13978152794809107, 0.13978152794809107, 0.11182545895242457, 0.11182545895242457, 0.11182545895242457, 0.1049265452010788, 0.1049265452010788, 0.1049265452010788, 0.09838792640989302, 0.09838792640989302, 0.09838792640989302, 0.0975679095102403, 0.0975679095102403, 0.0975679095102403, 0.10247058457804492, 0.10247058457804492, 0.10247058457804492, 0.08535892978639348, 0.08535892978639348, 0.08535892978639348, 0.9022856027136056, 0.9022856027136056, 0.9022856027136056, 0.9099610289383148, 0.9099610289383148, 0.9099610289383148, 0.9358796798365924, 0.9358796798365924, 0.9358796798365924, 0.20236006490067848, 0.20236006490067848, 0.20236006490067848, 0.21963349523957232, 0.21963349523957232, 0.21963349523957232, 0.2016047199708837, 0.2016047199708837, 0.2016047199708837, 0.26085428153631296, 0.26085428153631296, 0.26085428153631296, 0.3119672079554803, 0.3119672079554803, 0.3119672079554803, 0.20727559710143406, 0.20727559710143406, 0.20727559710143406, 0.20488340997189158, 0.20488340997189158, 0.20488340997189158, 0.23668078028217177, 0.23668078028217177, 0.23668078028217177, 0.13075406238402432, 0.13075406238402432, 0.13075406238402432, 0.1934814825343285, 0.1934814825343285, 0.1934814825343285, 0.1478661295377326, 0.1478661295377326, 0.1478661295377326, 0.15191582492277522, 0.15191582492277522, 0.15191582492277522, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02256007440843988, 0.02256007440843988, 0.02256007440843988, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09185999353313834, 0.09185999353313834, 0.09185999353313834, 0.07281640854945692, 0.07281640854945692, 0.07281640854945692, 0.05717382070526489, 0.05717382070526489, 0.05717382070526489, 0.06276186866328504, 0.06276186866328504, 0.06276186866328504, 0.1304215039783192, 0.1304215039783192, 0.1304215039783192, 0.06248909665348579, 0.06248909665348579, 0.06248909665348579, 0.08114466928564157, 0.08114466928564157, 0.08114466928564157, 0.09746378048293225, 0.09746378048293225, 0.09746378048293225, 0.07776961557358952, 0.07776961557358952, 0.07776961557358952, 0.40844747587515173, 0.40844747587515173, 0.40844747587515173, 0.42428765441707605, 0.42428765441707605, 0.42428765441707605, 0.40664685314536797, 0.40664685314536797, 0.40664685314536797, 0.11430624537266487, 0.11430624537266487, 0.11430624537266487, 0.10256822575139979, 0.10256822575139979, 0.10256822575139979, 0.12415205187835476, 0.12415205187835476, 0.12415205187835476, 0.13586866746557857, 0.13586866746557857, 0.13586866746557857, 0.19849715037316218, 0.19849715037316218, 0.19849715037316218, 0.13944593768905944, 0.13944593768905944, 0.13944593768905944, 0.3289383669206212, 0.3289383669206212, 0.3289383669206212, 0.2641282927239088, 0.2641282927239088, 0.2641282927239088, 0.2556691295301664, 0.2556691295301664, 0.2556691295301664, 0.17776572203364338, 0.17776572203364338, 0.17776572203364338, 0.16956308078229998, 0.16956308078229998, 0.16956308078229998, 0.19702058583566773, 0.19702058583566773, 0.19702058583566773, 0.18851449016605293, 0.18851449016605293, 0.18851449016605293, 0.184336879590686, 0.184336879590686, 0.184336879590686, 0.17972522439212568, 0.17972522439212568, 0.17972522439212568, 0.1958161031027753, 0.1958161031027753, 0.1958161031027753, 0.1755054503429725, 0.1755054503429725, 0.1755054503429725, 0.2267176100857401, 0.2267176100857401, 0.2267176100857401, 0.49256268189486996, 0.49256268189486996, 0.49256268189486996, 0.4398435457036697, 0.4398435457036697, 0.4398435457036697, 0.17630599446489736, 0.17630599446489736, 0.17630599446489736, 0.23989593483194294, 0.23989593483194294, 0.23989593483194294, 0.24951759961924025, 0.24951759961924025, 0.24951759961924025, 0.22461953508525667, 0.22461953508525667, 0.22461953508525667, 0.1762321741602063, 0.1762321741602063, 0.1762321741602063, 0.19785621651217966, 0.19785621651217966, 0.19785621651217966, 0.17663979675082608, 0.17663979675082608, 0.17663979675082608, 0.07713339575340528, 0.07713339575340528, 0.07713339575340528, 0.07581091498207293, 0.07581091498207293, 0.07581091498207293, 0.06921225012829013, 0.06921225012829013, 0.06921225012829013]}, "mutation_prompt": null}
{"id": "9e62230c-f617-44e3-91f0-37700062dbf8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "a205df8f-a724-4101-bfaa-3978ccb3bd75", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "cbdc7c43-310b-4227-9b9b-38e13b6b0c9b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "1424d39d-ff07-4c31-a1ef-c7313c02df85", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "f7171c4f-a8df-4353-9b72-3b9a01151009", "solution": "import numpy as np\n\nclass EnhancedEvolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n        self.strategy_prob = [0.5, 0.5]\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                self.adaptive_pop_size = min(max(int(self.adaptive_pop_size * 1.1), 10), 50)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            strategy_choice = np.random.choice([0, 1], p=self.strategy_prob)\n\n            if strategy_choice == 0:\n                r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n                r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n                vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n                pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n            else:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                    a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pos[i])\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < personal_best_value[i]:\n                        pos[i] = trial\n                        personal_best[i] = trial\n                        personal_best_value[i] = trial_fitness\n                        if trial_fitness < global_best_value:\n                            global_best = trial\n                            global_best_value = trial_fitness\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n            # Update strategy probabilities based on performance\n            if np.std(personal_best_value) < 0.1:\n                self.strategy_prob = [0.7, 0.3]\n            else:\n                self.strategy_prob = [0.5, 0.5]\n\n        return global_best, global_best_value", "name": "EnhancedEvolutionaryStrategy", "description": "Enhanced Evolutionary Strategy with Adaptive Search Operators and Dynamic Strategy Selection for improved convergence and robustness.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,5) (22,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,5) (22,5) ')", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {}, "mutation_prompt": null}
{"id": "474630c5-0fae-4879-baf0-fe247cd6a2f5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "7e974d37-12ad-4319-962d-6b7965c9d0ac", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "5c2d97c3-e954-4bce-9eb2-ba1c5894c1d4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "f60cfbb9-52d6-46dc-9621-b7fc04793afc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "6f414d40-8ca0-430b-b507-fd3c5e758c30", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "a99f7187-10dd-40f3-8bb4-2e0d2440d3f1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "82c7c4f8-b67b-4109-a8f7-36f15d552f26", "solution": "import numpy as np\n\nclass MultiOperatorAPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.15\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                convergence_indicator = np.std(personal_best_value) / np.abs(global_best_value)\n                if convergence_indicator < 0.05:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n\n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "MultiOperatorAPSO_DE", "description": "Multi-Operator Adaptive PSO-DE with stability-driven dynamic population and hybrid mutation-crossover strategy for enhanced convergence.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,5) (25,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,5) (25,5) ')", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {}, "mutation_prompt": null}
{"id": "e51c6a44-6890-40c6-b51e-8cb3965b7000", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "dcd50137-6ea4-4822-b9ad-fdd0680f8eff", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "78e7e346-55b3-404b-be8f-b882b72f0bc1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "b45dec11-1d28-4aaf-9583-63066e979506", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "4a5e978a-7b18-450f-869b-f83b2764f5d2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "03799823-95ab-42fe-ab4b-e8ba55897ea2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "1fe60bae-5d3f-46f8-a287-6133e430e16e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "bbb15ce7-7a5b-486a-9213-4e315263b4de", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "c9b8ea1d-f9fd-4e64-bcf2-b40122cc0392", "solution": "import numpy as np\n\nclass EnhancedDynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.2\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                F_dynamic = 0.5 + 0.3 * np.random.rand()\n                mutant = np.clip(a + F_dynamic * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    gradient = np.random.uniform(-0.5, 0.5, self.dim)\n                    local_candidate = np.clip(pos[i] + gradient * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedDynamicHybridPSO_DE", "description": "Enhanced Dynamic Hybrid PSO-DE with Adaptive Differential Strategy and Stochastic Gradient-based Local Search for improved convergence and exploration-exploitation balance.", "configspace": "", "generation": 81, "fitness": 0.26293836336809595, "feedback": "The algorithm EnhancedDynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7689784301716502, 0.7689784301716502, 0.7689784301716502, 0.7408590214939821, 0.7408590214939821, 0.7408590214939821, 0.7169934279626659, 0.7169934279626659, 0.7169934279626659, 0.5502180020996299, 0.5502180020996299, 0.5502180020996299, 0.6058226796404407, 0.6058226796404407, 0.6058226796404407, 0.6217193755650704, 0.6217193755650704, 0.6217193755650704, 0.14227263626986808, 0.14227263626986808, 0.14227263626986808, 0.13374287739131685, 0.13374287739131685, 0.13374287739131685, 0.09553337234172887, 0.09553337234172887, 0.09553337234172887, 0.06958988185011328, 0.06958988185011328, 0.06958988185011328, 0.09607774195242347, 0.09607774195242347, 0.09607774195242347, 0.0953788637486106, 0.0953788637486106, 0.0953788637486106, 0.9490543686494839, 0.9490543686494839, 0.9490543686494839, 0.9783019566435239, 0.9783019566435239, 0.9783019566435239, 0.970614189873818, 0.970614189873818, 0.970614189873818, 0.4937647964380264, 0.4937647964380264, 0.4937647964380264, 0.4687458882118726, 0.4687458882118726, 0.4687458882118726, 0.543096818635636, 0.543096818635636, 0.543096818635636, 0.2814155548457463, 0.2814155548457463, 0.2814155548457463, 0.18158321932371435, 0.18158321932371435, 0.18158321932371435, 0.17557811066353646, 0.17557811066353646, 0.17557811066353646, 0.15472163858139754, 0.15472163858139754, 0.15472163858139754, 0.14446702978760617, 0.14446702978760617, 0.14446702978760617, 0.15980365062119695, 0.15980365062119695, 0.15980365062119695, 0.10516988309980357, 0.10516988309980357, 0.10516988309980357, 0.13043269368262367, 0.13043269368262367, 0.13043269368262367, 0.17853098129807599, 0.17853098129807599, 0.17853098129807599, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00040906869186496664, 0.00040906869186496664, 0.00040906869186496664, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07343410806206374, 0.07343410806206374, 0.07343410806206374, 0.03979305708098091, 0.03979305708098091, 0.03979305708098091, 0.026342745401606416, 0.026342745401606416, 0.026342745401606416, 0.02888545212834248, 0.02888545212834248, 0.02888545212834248, 0.09736418202091557, 0.09736418202091557, 0.09736418202091557, 0.1020974791171737, 0.1020974791171737, 0.1020974791171737, 0.1122731125955887, 0.1122731125955887, 0.1122731125955887, 0.059225302987082395, 0.059225302987082395, 0.059225302987082395, 0.1583843837880493, 0.1583843837880493, 0.1583843837880493, 0.47675485435249043, 0.47675485435249043, 0.47675485435249043, 0.4481189444954361, 0.4481189444954361, 0.4481189444954361, 0.4838311840853007, 0.4838311840853007, 0.4838311840853007, 0.08501205264433298, 0.08501205264433298, 0.08501205264433298, 0.1130440317293413, 0.1130440317293413, 0.1130440317293413, 0.08212758896803352, 0.08212758896803352, 0.08212758896803352, 0.17368532613911158, 0.17368532613911158, 0.17368532613911158, 0.15321786876718668, 0.15321786876718668, 0.15321786876718668, 0.16561746134202548, 0.16561746134202548, 0.16561746134202548, 0.22615909630446063, 0.22615909630446063, 0.22615909630446063, 0.17347363750996958, 0.17347363750996958, 0.17347363750996958, 0.251768657555953, 0.251768657555953, 0.251768657555953, 0.21054737897155462, 0.21054737897155462, 0.21054737897155462, 0.18635296162876025, 0.18635296162876025, 0.18635296162876025, 0.17487133387916343, 0.17487133387916343, 0.17487133387916343, 0.20063929248776236, 0.20063929248776236, 0.20063929248776236, 0.18171700158358128, 0.18171700158358128, 0.18171700158358128, 0.2018464983836945, 0.2018464983836945, 0.2018464983836945, 0.18914120899909292, 0.18914120899909292, 0.18914120899909292, 0.20685229549195372, 0.20685229549195372, 0.20685229549195372, 0.18617044458515386, 0.18617044458515386, 0.18617044458515386, 0.7366414662530489, 0.7366414662530489, 0.7366414662530489, 0.4269622466137467, 0.4269622466137467, 0.4269622466137467, 0.575612907341469, 0.575612907341469, 0.575612907341469, 0.15770683827628817, 0.15770683827628817, 0.15770683827628817, 0.23601868011631055, 0.23601868011631055, 0.23601868011631055, 0.19920725476710666, 0.19920725476710666, 0.19920725476710666, 0.17849314263794025, 0.17849314263794025, 0.17849314263794025, 0.19535165985611158, 0.19535165985611158, 0.19535165985611158, 0.19452213386056205, 0.19452213386056205, 0.19452213386056205, 0.06323582338552713, 0.06323582338552713, 0.06323582338552713, 0.06371460420638253, 0.06371460420638253, 0.06371460420638253, 0.08227030256682533, 0.08227030256682533, 0.08227030256682533]}, "mutation_prompt": null}
{"id": "ee60c8d7-a585-404d-a169-8ccc321a431f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_ES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.step_size = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.step_size * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_ES", "description": "Adaptive Particle Swarm Optimization with Evolutionary Strategies and Local Search for Enhanced Global Optimization.", "configspace": "", "generation": 82, "fitness": 0.2517532863504486, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_ES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7025900770007383, 0.7025900770007383, 0.7025900770007383, 0.7157845571436705, 0.7157845571436705, 0.7157845571436705, 0.6938480587877023, 0.6938480587877023, 0.6938480587877023, 0.5285839834898051, 0.5285839834898051, 0.5285839834898051, 0.48125927197190377, 0.48125927197190377, 0.48125927197190377, 0.5630948298690703, 0.5630948298690703, 0.5630948298690703, 0.09641225387331709, 0.09641225387331709, 0.09641225387331709, 0.11433794530455943, 0.11433794530455943, 0.11433794530455943, 0.11693425225026, 0.11693425225026, 0.11693425225026, 0.06926507875584265, 0.06926507875584265, 0.06926507875584265, 0.09532177495647887, 0.09532177495647887, 0.09532177495647887, 0.07722430310583261, 0.07722430310583261, 0.07722430310583261, 0.9155309749693019, 0.9155309749693019, 0.9155309749693019, 0.9315292015056735, 0.9315292015056735, 0.9315292015056735, 0.9478666788743022, 0.9478666788743022, 0.9478666788743022, 0.41008063495963565, 0.41008063495963565, 0.41008063495963565, 0.44003644599250014, 0.44003644599250014, 0.44003644599250014, 0.4692352614380668, 0.4692352614380668, 0.4692352614380668, 0.28210047587485265, 0.28210047587485265, 0.28210047587485265, 0.21736562809822602, 0.21736562809822602, 0.21736562809822602, 0.25160521435218464, 0.25160521435218464, 0.25160521435218464, 0.1541300546676464, 0.1541300546676464, 0.1541300546676464, 0.13352405241909016, 0.13352405241909016, 0.13352405241909016, 0.15488595842127884, 0.15488595842127884, 0.15488595842127884, 0.09272562708115362, 0.09272562708115362, 0.09272562708115362, 0.12292317090540872, 0.12292317090540872, 0.12292317090540872, 0.17165318530623153, 0.17165318530623153, 0.17165318530623153, 0.04198158901872362, 0.04198158901872362, 0.04198158901872362, 0.004890926804284601, 0.004890926804284601, 0.004890926804284601, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06230887090739601, 0.06230887090739601, 0.06230887090739601, 0.06438327862861037, 0.06438327862861037, 0.06438327862861037, 0.055718708129611105, 0.055718708129611105, 0.055718708129611105, 0.032893667209631494, 0.032893667209631494, 0.032893667209631494, 0.07895627950610173, 0.07895627950610173, 0.07895627950610173, 0.09031208987222472, 0.09031208987222472, 0.09031208987222472, 0.15034614968821547, 0.15034614968821547, 0.15034614968821547, 0.046135159435158, 0.046135159435158, 0.046135159435158, 0.12395225032589774, 0.12395225032589774, 0.12395225032589774, 0.45161404439887687, 0.45161404439887687, 0.45161404439887687, 0.45711297664605677, 0.45711297664605677, 0.45711297664605677, 0.4562597643879035, 0.4562597643879035, 0.4562597643879035, 0.09773587871312261, 0.09773587871312261, 0.09773587871312261, 0.09238440566965855, 0.09238440566965855, 0.09238440566965855, 0.10082590840202887, 0.10082590840202887, 0.10082590840202887, 0.15107707396871406, 0.15107707396871406, 0.15107707396871406, 0.14001018467725845, 0.14001018467725845, 0.14001018467725845, 0.15896179821376677, 0.15896179821376677, 0.15896179821376677, 0.28597613403777955, 0.28597613403777955, 0.28597613403777955, 0.22845135798689908, 0.22845135798689908, 0.22845135798689908, 0.2838000519411292, 0.2838000519411292, 0.2838000519411292, 0.2214937433755313, 0.2214937433755313, 0.2214937433755313, 0.17762251933089923, 0.17762251933089923, 0.17762251933089923, 0.1391346472032856, 0.1391346472032856, 0.1391346472032856, 0.18362612395492328, 0.18362612395492328, 0.18362612395492328, 0.1629281534103757, 0.1629281534103757, 0.1629281534103757, 0.18563704074010134, 0.18563704074010134, 0.18563704074010134, 0.19193328843124946, 0.19193328843124946, 0.19193328843124946, 0.181449393156493, 0.181449393156493, 0.181449393156493, 0.20929374203039186, 0.20929374203039186, 0.20929374203039186, 0.62965321592175, 0.62965321592175, 0.62965321592175, 0.17423367596252992, 0.17423367596252992, 0.17423367596252992, 0.5523384777465514, 0.5523384777465514, 0.5523384777465514, 0.1765754796715706, 0.1765754796715706, 0.1765754796715706, 0.20003481795139355, 0.20003481795139355, 0.20003481795139355, 0.349647174043614, 0.349647174043614, 0.349647174043614, 0.18781105647179552, 0.18781105647179552, 0.18781105647179552, 0.18642489463380696, 0.18642489463380696, 0.18642489463380696, 0.18272273411350104, 0.18272273411350104, 0.18272273411350104, 0.07911354675419768, 0.07911354675419768, 0.07911354675419768, 0.07354035538594739, 0.07354035538594739, 0.07354035538594739, 0.07498503699861048, 0.07498503699861048, 0.07498503699861048]}, "mutation_prompt": null}
{"id": "c08c1b64-c569-4d17-848d-beed37004190", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "ced89f30-d7c6-4481-b36f-50fc8dfd2360", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.8\n        self.local_search_prob = 0.2\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n        restart_threshold = 0.1  # Threshold for restarting the population\n\n        while evaluations < self.budget:\n            self.w = 0.5 + 0.4 * (1 - evaluations / self.budget)\n            self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.c2 = 1.5 + 0.5 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < restart_threshold:\n                    pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.adaptive_pop_size, self.dim))\n                    vel = np.random.uniform(-1, 1, (self.adaptive_pop_size, self.dim))\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            # DE Mutation and Crossover\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            # Enhanced Local Search\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "RefinedAdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with Strategic Restart Mechanism and Enhanced Local Search for improved exploration and convergence.", "configspace": "", "generation": 84, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,5) (20,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,5) (20,5) ')", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {}, "mutation_prompt": null}
{"id": "9741951d-210d-40e2-81ca-d877f4cf080e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "b263017f-62a8-4469-a35f-b800deeac248", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "25d34217-7f9f-460f-a99c-0e7d59f35454", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "85f28db2-5e44-4364-b9bc-ec7471f432c5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "4e4f3ee3-998f-4360-8b7f-26184fc05dcb", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_AdaptiveVelocity:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.2\n        self.adaptive_pop_size = self.pop_size\n        self.memory = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        self.memory_fitness = np.full(self.pop_size, float('inf'))\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n        self.memory = personal_best.copy()\n        self.memory_fitness = personal_best_value.copy()\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n                    # Memory-based enhancement\n                    if local_fitness < self.memory_fitness[i]:\n                        self.memory[i] = local_candidate\n                        self.memory_fitness[i] = local_fitness\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                if fitness[i] > self.memory_fitness[i]:\n                    pos[i] = self.memory[i]\n                    fitness[i] = self.memory_fitness[i]\n                    if self.memory_fitness[i] < global_best_value:\n                        global_best = self.memory[i]\n                        global_best_value = self.memory_fitness[i]\n\n        return global_best, global_best_value", "name": "EnhancedHybridPSO_DE_AdaptiveVelocity", "description": "Enhanced Hybrid PSO-DE with Adaptive Velocity Control and Memory-based Local Search for improved convergence speed and solution quality.", "configspace": "", "generation": 89, "fitness": 0.1662796570110327, "feedback": "The algorithm EnhancedHybridPSO_DE_AdaptiveVelocity got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.19.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.48329129172029883, 0.48329129172029883, 0.48329129172029883, 0.3535990236793165, 0.3535990236793165, 0.3535990236793165, 0.3378140636303487, 0.3378140636303487, 0.3378140636303487, 0.2220040956499021, 0.2220040956499021, 0.2220040956499021, 0.10055704534096277, 0.10055704534096277, 0.10055704534096277, 0.14140905510274626, 0.14140905510274626, 0.14140905510274626, 0.07219437695252018, 0.07219437695252018, 0.07219437695252018, 0.0808354316673987, 0.0808354316673987, 0.0808354316673987, 0.0639999893533677, 0.0639999893533677, 0.0639999893533677, 0.058622253470901664, 0.058622253470901664, 0.058622253470901664, 0.04604861581145048, 0.04604861581145048, 0.04604861581145048, 0.037995788055981805, 0.037995788055981805, 0.037995788055981805, 0.9170700189749665, 0.9170700189749665, 0.9170700189749665, 0.9639395847303405, 0.9639395847303405, 0.9639395847303405, 0.9364277482553005, 0.9364277482553005, 0.9364277482553005, 0.0775920572570652, 0.0775920572570652, 0.0775920572570652, 0.06420772301817834, 0.06420772301817834, 0.06420772301817834, 0.12071909622712396, 0.12071909622712396, 0.12071909622712396, 0.15669542297958794, 0.15669542297958794, 0.15669542297958794, 0.13668231180519141, 0.13668231180519141, 0.13668231180519141, 0.12204060629945268, 0.12204060629945268, 0.12204060629945268, 0.13292950556185823, 0.13292950556185823, 0.13292950556185823, 0.17618968687701186, 0.17618968687701186, 0.17618968687701186, 0.038180464004259784, 0.038180464004259784, 0.038180464004259784, 0.0416804533253482, 0.0416804533253482, 0.0416804533253482, 0.1362464483376813, 0.1362464483376813, 0.1362464483376813, 0.019464181535224112, 0.019464181535224112, 0.019464181535224112, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.034900710809323776, 0.034900710809323776, 0.034900710809323776, 0.05489712700936611, 0.05489712700936611, 0.05489712700936611, 0.042002314324397605, 0.042002314324397605, 0.042002314324397605, 0.01785636709143179, 0.01785636709143179, 0.01785636709143179, 0.015612624878628578, 0.015612624878628578, 0.015612624878628578, 0.06036903120720494, 0.06036903120720494, 0.06036903120720494, 0.014291689841466004, 0.014291689841466004, 0.014291689841466004, 0.04890928602280942, 0.04890928602280942, 0.04890928602280942, 0.0297026042612224, 0.0297026042612224, 0.0297026042612224, 0.39065307981260733, 0.39065307981260733, 0.39065307981260733, 0.3610654653574241, 0.3610654653574241, 0.3610654653574241, 0.3517521844826901, 0.3517521844826901, 0.3517521844826901, 0.06703124046158027, 0.06703124046158027, 0.06703124046158027, 0.08053698624712924, 0.08053698624712924, 0.08053698624712924, 0.08033418755329136, 0.08033418755329136, 0.08033418755329136, 0.14611289053636833, 0.14611289053636833, 0.14611289053636833, 0.13411389741764068, 0.13411389741764068, 0.13411389741764068, 0.12898317457164343, 0.12898317457164343, 0.12898317457164343, 0.17240214918554397, 0.17240214918554397, 0.17240214918554397, 0.23251590252252907, 0.23251590252252907, 0.23251590252252907, 0.16224890889559507, 0.16224890889559507, 0.16224890889559507, 0.12733321481216664, 0.12733321481216664, 0.12733321481216664, 0.1323051691246122, 0.1323051691246122, 0.1323051691246122, 0.11090505574200282, 0.11090505574200282, 0.11090505574200282, 0.1618499238941995, 0.1618499238941995, 0.1618499238941995, 0.15339979465492692, 0.15339979465492692, 0.15339979465492692, 0.14815656067726068, 0.14815656067726068, 0.14815656067726068, 0.17185845872246974, 0.17185845872246974, 0.17185845872246974, 0.15430671769222004, 0.15430671769222004, 0.15430671769222004, 0.16858206384183594, 0.16858206384183594, 0.16858206384183594, 0.3330359377901543, 0.3330359377901543, 0.3330359377901543, 0.14884719533371715, 0.14884719533371715, 0.14884719533371715, 0.19605715788675748, 0.19605715788675748, 0.19605715788675748, 0.14560968278268827, 0.14560968278268827, 0.14560968278268827, 0.1146822992000962, 0.1146822992000962, 0.1146822992000962, 0.2746369473704513, 0.2746369473704513, 0.2746369473704513, 0.2028553632647786, 0.2028553632647786, 0.2028553632647786, 0.20067766781602348, 0.20067766781602348, 0.20067766781602348, 0.18415571997983948, 0.18415571997983948, 0.18415571997983948, 0.05716017524587347, 0.05716017524587347, 0.05716017524587347, 0.05645635863990062, 0.05645635863990062, 0.05645635863990062, 0.06423567820869991, 0.06423567820869991, 0.06423567820869991]}, "mutation_prompt": null}
{"id": "b30625c0-a437-4971-922c-bc2cdb656edc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "5dcfb35d-dfea-4cdd-86a3-61a6587b35bd", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "1b1762ad-c2fe-4efe-8830-83d1db5cb40f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "61222487-7daa-4a19-81c0-57acfd5c598e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "f3fbb0a2-fa13-4f35-a76e-4c889479cdab", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "1c1c59d7-58a2-45ae-87b5-c2e9499712c6", "solution": "import numpy as np\n\nclass AdaptiveMemoryHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.memory_size = 5\n        self.memory = []\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            if evaluations % (self.pop_size * 5) == 0 and evaluations > self.pop_size * 5:\n                self.memory.append(global_best)\n                if len(self.memory) > self.memory_size:\n                    self.memory.pop(0)\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            if self.memory:\n                memory_best = min(self.memory, key=lambda m: func(m))\n                if func(memory_best) < global_best_value:\n                    global_best = memory_best\n                    global_best_value = func(memory_best)\n\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveMemoryHybridPSO_DE", "description": "Adaptive Memory-Based Hybrid PSO-DE incorporates a memory of promising solutions to enhance exploration and exploitation balance while dynamically adjusting its strategy.", "configspace": "", "generation": 95, "fitness": 0.2511703910315887, "feedback": "The algorithm AdaptiveMemoryHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7335841783682051, 0.7335841783682051, 0.7335841783682051, 0.7459675158584775, 0.7459675158584775, 0.7459675158584775, 0.6931993428916315, 0.6931993428916315, 0.6931993428916315, 0.47884743420135545, 0.47884743420135545, 0.47884743420135545, 0.513678212465354, 0.513678212465354, 0.513678212465354, 0.417383456675511, 0.417383456675511, 0.417383456675511, 0.14171870503322193, 0.14171870503322193, 0.14171870503322193, 0.13361308892651835, 0.13361308892651835, 0.13361308892651835, 0.0906228569734372, 0.0906228569734372, 0.0906228569734372, 0.10182890183099425, 0.10182890183099425, 0.10182890183099425, 0.10361554106543513, 0.10361554106543513, 0.10361554106543513, 0.11342896858098228, 0.11342896858098228, 0.11342896858098228, 0.9683705344435608, 0.9683705344435608, 0.9683705344435608, 0.9734649014356788, 0.9734649014356788, 0.9734649014356788, 0.958333389586107, 0.958333389586107, 0.958333389586107, 0.3241091277597409, 0.3241091277597409, 0.3241091277597409, 0.23504685653992485, 0.23504685653992485, 0.23504685653992485, 0.30846651859879415, 0.30846651859879415, 0.30846651859879415, 0.2608899310292867, 0.2608899310292867, 0.2608899310292867, 0.23550287661562153, 0.23550287661562153, 0.23550287661562153, 0.28741121733324304, 0.28741121733324304, 0.28741121733324304, 0.16395681061454015, 0.16395681061454015, 0.16395681061454015, 0.16733004165419263, 0.16733004165419263, 0.16733004165419263, 0.1608739271389159, 0.1608739271389159, 0.1608739271389159, 0.08137253648121023, 0.08137253648121023, 0.08137253648121023, 0.1887581551095845, 0.1887581551095845, 0.1887581551095845, 0.1923679949726801, 0.1923679949726801, 0.1923679949726801, 0.004138624821156012, 0.004138624821156012, 0.004138624821156012, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0022523076011636833, 0.0022523076011636833, 0.0022523076011636833, 0.058484677639050076, 0.058484677639050076, 0.058484677639050076, 0.02935615162167038, 0.02935615162167038, 0.02935615162167038, 0.07094788389885631, 0.07094788389885631, 0.07094788389885631, 0.11473099454999869, 0.11473099454999869, 0.11473099454999869, 0.06790105270188218, 0.06790105270188218, 0.06790105270188218, 0.08444164706506618, 0.08444164706506618, 0.08444164706506618, 0.05456533897509375, 0.05456533897509375, 0.05456533897509375, 0.052006223519290296, 0.052006223519290296, 0.052006223519290296, 0.11747381229537535, 0.11747381229537535, 0.11747381229537535, 0.4903526723606576, 0.4903526723606576, 0.4903526723606576, 0.47545895192529974, 0.47545895192529974, 0.47545895192529974, 0.5126931956952467, 0.5126931956952467, 0.5126931956952467, 0.10024883692692288, 0.10024883692692288, 0.10024883692692288, 0.09830427195519953, 0.09830427195519953, 0.09830427195519953, 0.0771234444042328, 0.0771234444042328, 0.0771234444042328, 0.13207682080087257, 0.13207682080087257, 0.13207682080087257, 0.14633362072440903, 0.14633362072440903, 0.14633362072440903, 0.1573302751254283, 0.1573302751254283, 0.1573302751254283, 0.28200740531252133, 0.28200740531252133, 0.28200740531252133, 0.2659101972335449, 0.2659101972335449, 0.2659101972335449, 0.22363989918190252, 0.22363989918190252, 0.22363989918190252, 0.17550798717347293, 0.17550798717347293, 0.17550798717347293, 0.20441198606348232, 0.20441198606348232, 0.20441198606348232, 0.17507135324635126, 0.17507135324635126, 0.17507135324635126, 0.20654923101745348, 0.20654923101745348, 0.20654923101745348, 0.15331398748374436, 0.15331398748374436, 0.15331398748374436, 0.17871480279772645, 0.17871480279772645, 0.17871480279772645, 0.19798495102315672, 0.19798495102315672, 0.19798495102315672, 0.17579469690757632, 0.17579469690757632, 0.17579469690757632, 0.22451583921442986, 0.22451583921442986, 0.22451583921442986, 0.6388530393482089, 0.6388530393482089, 0.6388530393482089, 0.4751030778791263, 0.4751030778791263, 0.4751030778791263, 0.5549195936846227, 0.5549195936846227, 0.5549195936846227, 0.1503060035649696, 0.1503060035649696, 0.1503060035649696, 0.16929773742379184, 0.16929773742379184, 0.16929773742379184, 0.2587297442865212, 0.2587297442865212, 0.2587297442865212, 0.17324970831634978, 0.17324970831634978, 0.17324970831634978, 0.19072701425755212, 0.19072701425755212, 0.19072701425755212, 0.18154631638728147, 0.18154631638728147, 0.18154631638728147, 0.06428747291122394, 0.06428747291122394, 0.06428747291122394, 0.06774380061586183, 0.06774380061586183, 0.06774380061586183, 0.076018482152439, 0.076018482152439, 0.076018482152439]}, "mutation_prompt": null}
{"id": "acc5347b-b5e8-433b-ae7e-b8e84a01ea3b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "da907b65-b95e-451b-bf70-e053f3bfccda", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
{"id": "2414fb69-5023-4982-b938-f7e03472a8de", "solution": "import numpy as np\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.swarm_count = 3  # Multiple swarms\n        self.w = 0.9\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.F = 0.6\n        self.CR = 0.8\n        self.exploration_prob = 0.2\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.4 * (evaluations / self.budget)\n\n            # Strategic exploration\n            if np.random.rand() < self.exploration_prob:\n                for i in range(self.swarm_count):\n                    if evaluations >= self.budget:\n                        break\n                    idxs = np.random.choice(self.pop_size, self.pop_size // self.swarm_count, replace=False)\n                    swarm_best_idx = idxs[np.argmin(personal_best_value[idxs])]\n                    local_best = personal_best[swarm_best_idx]\n                    r1 = np.random.rand(len(idxs), self.dim)\n                    r2 = np.random.rand(len(idxs), self.dim)\n                    vel[idxs] = self.w * vel[idxs] + self.c1 * r1 * (personal_best[idxs] - pos[idxs]) + self.c2 * r2 * (local_best - pos[idxs])\n                    pos[idxs] = np.clip(pos[idxs] + vel[idxs], self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.pop_size\n\n            better_mask = fitness < personal_best_value\n            personal_best[better_mask] = pos[better_mask]\n            personal_best_value[better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value)\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n        return global_best, global_best_value", "name": "AdaptiveMultiSwarmPSODE", "description": "Adaptive Multi-Swarm PSO-DE with Dynamic Learning and Strategic Exploration for Enhanced Convergence.", "configspace": "", "generation": 98, "fitness": 0.16877377222682527, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.19.", "error": "", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.3540655838648721, 0.3540655838648721, 0.3540655838648721, 0.40054960974377674, 0.40054960974377674, 0.40054960974377674, 0.39743267919944913, 0.39743267919944913, 0.39743267919944913, 0.0846134048767524, 0.0846134048767524, 0.0846134048767524, 0.08796106866164888, 0.08796106866164888, 0.08796106866164888, 0.083315887285898, 0.083315887285898, 0.083315887285898, 0.0944913671427332, 0.0944913671427332, 0.0944913671427332, 0.07749446123139658, 0.07749446123139658, 0.07749446123139658, 0.07790920414205116, 0.07790920414205116, 0.07790920414205116, 0.07472899154828505, 0.07472899154828505, 0.07472899154828505, 0.07945460419894113, 0.07945460419894113, 0.07945460419894113, 0.06630957644856739, 0.06630957644856739, 0.06630957644856739, 0.9600043362849567, 0.9600043362849567, 0.9600043362849567, 0.9242112009201395, 0.9242112009201395, 0.9242112009201395, 0.9433298018476256, 0.9433298018476256, 0.9433298018476256, 0.13801357432318162, 0.13801357432318162, 0.13801357432318162, 0.11755114393174904, 0.11755114393174904, 0.11755114393174904, 0.12938248076151304, 0.12938248076151304, 0.12938248076151304, 0.14521473486443082, 0.14521473486443082, 0.14521473486443082, 0.22964486027571274, 0.22964486027571274, 0.22964486027571274, 0.1839307441438366, 0.1839307441438366, 0.1839307441438366, 0.1107203422774804, 0.1107203422774804, 0.1107203422774804, 0.08814914936247309, 0.08814914936247309, 0.08814914936247309, 0.11519288411396378, 0.11519288411396378, 0.11519288411396378, 0.07380734992734161, 0.07380734992734161, 0.07380734992734161, 0.11774742357296086, 0.11774742357296086, 0.11774742357296086, 0.08777827709955743, 0.08777827709955743, 0.08777827709955743, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06565060174202264, 0.06565060174202264, 0.06565060174202264, 0.04239915449232101, 0.04239915449232101, 0.04239915449232101, 0.07382342342726156, 0.07382342342726156, 0.07382342342726156, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.032691134154301804, 0.032691134154301804, 0.032691134154301804, 0.04506480328812068, 0.04506480328812068, 0.04506480328812068, 0.052895473594230524, 0.052895473594230524, 0.052895473594230524, 0.3076782874823818, 0.3076782874823818, 0.3076782874823818, 0.33656879766045267, 0.33656879766045267, 0.33656879766045267, 0.3570960323929653, 0.3570960323929653, 0.3570960323929653, 0.08396057313349592, 0.08396057313349592, 0.08396057313349592, 0.07375231133025861, 0.07375231133025861, 0.07375231133025861, 0.07719636731516621, 0.07719636731516621, 0.07719636731516621, 0.135262641332886, 0.135262641332886, 0.135262641332886, 0.1371147843486773, 0.1371147843486773, 0.1371147843486773, 0.1355031378806587, 0.1355031378806587, 0.1355031378806587, 0.21293652534745733, 0.21293652534745733, 0.21293652534745733, 0.17167786349744696, 0.17167786349744696, 0.17167786349744696, 0.21499625732569716, 0.21499625732569716, 0.21499625732569716, 0.14389353726954612, 0.14389353726954612, 0.14389353726954612, 0.12585606503775526, 0.12585606503775526, 0.12585606503775526, 0.17178075461031206, 0.17178075461031206, 0.17178075461031206, 0.16987184859308802, 0.16987184859308802, 0.16987184859308802, 0.1582837692525374, 0.1582837692525374, 0.1582837692525374, 0.20267551777043058, 0.20267551777043058, 0.20267551777043058, 0.16310218330233006, 0.16310218330233006, 0.16310218330233006, 0.17772783115057023, 0.17772783115057023, 0.17772783115057023, 0.17355216543144636, 0.17355216543144636, 0.17355216543144636, 0.35084844677920524, 0.35084844677920524, 0.35084844677920524, 0.18081691560793822, 0.18081691560793822, 0.18081691560793822, 0.16155534426391127, 0.16155534426391127, 0.16155534426391127, 0.16276146522980128, 0.16276146522980128, 0.16276146522980128, 0.13567006505734225, 0.13567006505734225, 0.13567006505734225, 0.14942401913714765, 0.14942401913714765, 0.14942401913714765, 0.17334437356983323, 0.17334437356983323, 0.17334437356983323, 0.17203163597033655, 0.17203163597033655, 0.17203163597033655, 0.1921944671537985, 0.1921944671537985, 0.1921944671537985, 0.061004322187011906, 0.061004322187011906, 0.061004322187011906, 0.0690539164964612, 0.0690539164964612, 0.0690539164964612, 0.056390044663521044, 0.056390044663521044, 0.056390044663521044]}, "mutation_prompt": null}
{"id": "f9c0d535-7574-4e13-aab2-f23f686c06d3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_prob = 0.1\n        self.adaptive_pop_size = self.pop_size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pos = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = pos.copy()\n        personal_best_value = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_value)\n        global_best = personal_best[global_best_index]\n        global_best_value = personal_best_value[global_best_index]\n\n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            self.c1 = 2.0 * (1 - evaluations / self.budget)\n            self.c2 = 2.0 * (evaluations / self.budget)\n\n            # Dynamic population adjustment based on convergence rate\n            if evaluations % (self.pop_size * 5) == 0:\n                if np.std(personal_best_value) < 0.1:\n                    self.adaptive_pop_size = min(self.adaptive_pop_size + 5, 50)\n                else:\n                    self.adaptive_pop_size = max(self.adaptive_pop_size - 5, 10)\n                pos = np.resize(pos, (self.adaptive_pop_size, self.dim))\n                vel = np.resize(vel, (self.adaptive_pop_size, self.dim))\n\n            r1 = np.random.rand(self.adaptive_pop_size, self.dim)\n            r2 = np.random.rand(self.adaptive_pop_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best[:self.adaptive_pop_size] - pos) + self.c2 * r2 * (global_best - pos)\n            pos = np.clip(pos + vel, self.lower_bound, self.upper_bound)\n\n            fitness = np.array([func(ind) for ind in pos])\n            evaluations += self.adaptive_pop_size\n\n            better_mask = fitness < personal_best_value[:self.adaptive_pop_size]\n            personal_best[:self.adaptive_pop_size][better_mask] = pos[better_mask]\n            personal_best_value[:self.adaptive_pop_size][better_mask] = fitness[better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_value[:self.adaptive_pop_size])\n            current_global_best_value = personal_best_value[current_global_best_index]\n            if current_global_best_value < global_best_value:\n                global_best = personal_best[current_global_best_index]\n                global_best_value = current_global_best_value\n\n            for i in range(self.adaptive_pop_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.adaptive_pop_size) if idx != i]\n                a, b, c = pos[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pos[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pos[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_fitness\n\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.adaptive_pop_size):\n                    if evaluations >= self.budget:\n                        break\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_candidate = np.clip(pos[i] + perturbation * np.linalg.norm(global_best - pos[i]), self.lower_bound, self.upper_bound)\n                    local_fitness = func(local_candidate)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        pos[i] = local_candidate\n                        fitness[i] = local_fitness\n                        if local_fitness < global_best_value:\n                            global_best = local_candidate\n                            global_best_value = local_fitness\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with Local Environment Learning and Dynamic Population for improved adaptability and exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0a9b008d-834a-4871-bdc2-a4bd3f5dfec7", "metadata": {"aucs": [0.7829526978647318, 0.7829526978647318, 0.7829526978647318, 0.823557052225424, 0.823557052225424, 0.823557052225424, 0.7924706834767755, 0.7924706834767755, 0.7924706834767755, 0.6187229353944521, 0.6187229353944521, 0.6187229353944521, 0.6349479520470738, 0.6349479520470738, 0.6349479520470738, 0.66860155123759, 0.66860155123759, 0.66860155123759, 0.10119708474682554, 0.10119708474682554, 0.10119708474682554, 0.09613929536714172, 0.09613929536714172, 0.09613929536714172, 0.4892390811558839, 0.4892390811558839, 0.4892390811558839, 0.10494958003169963, 0.10494958003169963, 0.10494958003169963, 0.11573118126713122, 0.11573118126713122, 0.11573118126713122, 0.11651063598420575, 0.11651063598420575, 0.11651063598420575, 0.9576065364316726, 0.9576065364316726, 0.9576065364316726, 0.9618739681787662, 0.9618739681787662, 0.9618739681787662, 0.9379860089661392, 0.9379860089661392, 0.9379860089661392, 0.45348485139022054, 0.45348485139022054, 0.45348485139022054, 0.43553010586400664, 0.43553010586400664, 0.43553010586400664, 0.5030595914964939, 0.5030595914964939, 0.5030595914964939, 0.2819290162673267, 0.2819290162673267, 0.2819290162673267, 0.15695256809005964, 0.15695256809005964, 0.15695256809005964, 0.4524095190899561, 0.4524095190899561, 0.4524095190899561, 0.16472145238138125, 0.16472145238138125, 0.16472145238138125, 0.16343853461036106, 0.16343853461036106, 0.16343853461036106, 0.14702509902959116, 0.14702509902959116, 0.14702509902959116, 0.1232642242829477, 0.1232642242829477, 0.1232642242829477, 0.18097566714754998, 0.18097566714754998, 0.18097566714754998, 0.16612980425395485, 0.16612980425395485, 0.16612980425395485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036715622569203465, 0.036715622569203465, 0.036715622569203465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.062232516134517746, 0.062232516134517746, 0.062232516134517746, 0.048789144514628235, 0.048789144514628235, 0.048789144514628235, 0.046691192906857526, 0.046691192906857526, 0.046691192906857526, 0.0395784264995207, 0.0395784264995207, 0.0395784264995207, 0.10233186356484036, 0.10233186356484036, 0.10233186356484036, 0.08004344900464022, 0.08004344900464022, 0.08004344900464022, 0.06142749077529497, 0.06142749077529497, 0.06142749077529497, 0.0950541682392555, 0.0950541682392555, 0.0950541682392555, 0.07546538080576282, 0.07546538080576282, 0.07546538080576282, 0.48803005680688116, 0.48803005680688116, 0.48803005680688116, 0.5133262244356, 0.5133262244356, 0.5133262244356, 0.45950457839016656, 0.45950457839016656, 0.45950457839016656, 0.10012745194437778, 0.10012745194437778, 0.10012745194437778, 0.08038191941461048, 0.08038191941461048, 0.08038191941461048, 0.11613704527286772, 0.11613704527286772, 0.11613704527286772, 0.133603788467756, 0.133603788467756, 0.133603788467756, 0.13388182311132424, 0.13388182311132424, 0.13388182311132424, 0.1519728997241797, 0.1519728997241797, 0.1519728997241797, 0.28070604760439244, 0.28070604760439244, 0.28070604760439244, 0.3041279757281504, 0.3041279757281504, 0.3041279757281504, 0.1799244216966277, 0.1799244216966277, 0.1799244216966277, 0.1201019819966479, 0.1201019819966479, 0.1201019819966479, 0.11492244945346686, 0.11492244945346686, 0.11492244945346686, 0.15368328432910916, 0.15368328432910916, 0.15368328432910916, 0.18852352503574332, 0.18852352503574332, 0.18852352503574332, 0.18361910748647126, 0.18361910748647126, 0.18361910748647126, 0.1971137821271255, 0.1971137821271255, 0.1971137821271255, 0.2002064067907825, 0.2002064067907825, 0.2002064067907825, 0.1888093985162923, 0.1888093985162923, 0.1888093985162923, 0.2110323649851028, 0.2110323649851028, 0.2110323649851028, 0.6315515306924995, 0.6315515306924995, 0.6315515306924995, 0.6710377880205106, 0.6710377880205106, 0.6710377880205106, 0.5849255675360936, 0.5849255675360936, 0.5849255675360936, 0.14332040578296656, 0.14332040578296656, 0.14332040578296656, 0.3167025301851133, 0.3167025301851133, 0.3167025301851133, 0.6253762441370949, 0.6253762441370949, 0.6253762441370949, 0.17930074760601966, 0.17930074760601966, 0.17930074760601966, 0.18673626432310553, 0.18673626432310553, 0.18673626432310553, 0.1772423952297586, 0.1772423952297586, 0.1772423952297586, 0.07959579038871056, 0.07959579038871056, 0.07959579038871056, 0.0761262975883672, 0.0761262975883672, 0.0761262975883672, 0.07579007839079055, 0.07579007839079055, 0.07579007839079055]}, "mutation_prompt": null}
