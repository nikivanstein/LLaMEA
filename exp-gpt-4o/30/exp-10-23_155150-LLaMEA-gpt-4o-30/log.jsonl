{"id": "c6b1667a-b55b-4cfc-a9a8-50a0a3ebc2b2", "solution": "import numpy as np\n\nclass HybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < 0.9\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead each generation\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "HybridDE_ANM", "description": "A hybrid metaheuristic integrating Differential Evolution (DE) and Adaptive Nelder-Mead (ANM) for efficient global and local search balance.", "configspace": "", "generation": 0, "fitness": 0.41906731592834057, "feedback": "The algorithm HybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": null, "metadata": {"aucs": [0.25078872615843706, 0.9798121430837056, 0.9780343549329474, 0.9794000742629726, 0.979018584263392, 0.9346134790175069, 0.9778504916511426, 0.9593628910007441, 0.9667489061888408, 0.892574161517673, 0.8943820921083993, 0.044945729092369935, 0.9235395020387843, 0.05109392692196579, 0.9067035826143109, 0.1470305325173884, 0.898119993585962, 0.9571364549620138, 0.09077544034345142, 0.08765435844947078, 0.09116764242166608, 0.04791383588761999, 0.08463073392427867, 0.0761286344844413, 0.06333559629958185, 0.09437240888228249, 0.12087353081480201, 0.05040767925389722, 0.05320362836871917, 0.018025617595362364, 0.09497295287015606, 0.05433374037801364, 0.01316634830169916, 0.0504329505665142, 0.03242237963326822, 0.01741521474480523, 0.9428065092850046, 0.9859557821560518, 0.9759251708314808, 0.09967421566401513, 0.09964461638114497, 0.9110213520767327, 0.9800068209850181, 0.9899941575312897, 0.9004210113005967, 0.13110171538705984, 0.15962529766610956, 0.6860718414089864, 0.7846089981689729, 0.7488556859078694, 0.36685522743586474, 0.8235736677535932, 0.08921588643048994, 9.999999999998899e-05, 0.18196902125841186, 0.17915308869848012, 0.08160503531207941, 0.33051829929288035, 0.22570349234387554, 0.08282083487557335, 0.22788381714570005, 0.23101273710435488, 0.13087310046700218, 0.9571136683215934, 0.1360165262885974, 0.9355070298077803, 0.9557525063505362, 0.13563010651135687, 0.9237624895143248, 0.948994559328155, 0.1382306787866333, 0.9503934312810864, 0.9543080898726941, 0.13659080407690527, 0.13814105882214112, 0.9384447690115051, 0.9297571170821856, 0.13835563776518522, 0.9558480810353653, 0.9117299589473014, 0.9247895333016068, 0.7921564453631795, 0.935664431766464, 0.8614711445871608, 0.8539164860210964, 0.9205557865559201, 0.9327921548271243, 0.8255056537675287, 0.9380081647028575, 0.8493516734312497, 0.24624267984544745, 0.9363939376841184, 0.1402818840803517, 0.08188250894580251, 0.9042964318275324, 0.9145470759138236, 0.8851247210856013, 0.898657029471871, 0.8943452172634272, 0.8493253863190022, 0.8897361080048007, 0.8058294092404693, 0.9285843449130898, 0.9314151625153817, 0.9050505839349751, 0.9069391293032334, 0.7971429042203569, 0.8040063513789958, 0.09241296295070056, 0.8576454018967135, 0.3181095366778288, 0.423310763342458, 0.07638745266326719, 0.7272085326993984, 0.08722326759770715, 0.3089775200649041, 0.09777744173318292, 0.24088582168240924, 0.9671474007490638, 0.9652726950626322, 0.9670545806624274, 0.9689067977162358, 0.9556287616387356, 0.9563586766779295, 0.9685846191377374, 0.9697284923523091, 0.050554594155832966, 0.07122741602205063, 0.06698303650026194, 0.08786723282653497, 0.06051415354641454, 0.10847427165360735, 0.13804119173371088, 0.07368457641139525, 0.07821182239548985, 0.11059374653256693, 0.14561883061126302, 0.16890893655542494, 0.25680123466736615, 0.2674775276976459, 0.1447369292371239, 0.12669718771732297, 0.1680769071999756, 0.20772404922332965, 0.13810211234996372, 0.1999267146317658, 0.1801428604894738, 0.2530236869801916, 0.14872289732949706, 0.19262710817527362, 0.15496017904271064, 0.19791531111683958, 0.1985080761854604, 0.16024090204940566, 0.17687509141448332, 0.13654774572737516, 0.12625268438786041, 0.07854152832338024, 0.09885932705851319, 0.1490507178893038, 0.17136093095953397, 0.14563862666285365, 0.23726121932372257, 0.15107344350135077, 0.23384541137699066, 0.2691422483194753, 0.28771670527174054, 0.16547310280351435, 0.229968064496748, 0.14633163661763815, 0.26941879250077705, 0.2055127602617638, 0.17801876529565108, 0.17811147320478649, 0.16438246657883215, 0.16133464659198182, 0.18445386467293, 0.17619935850490132, 0.21204997880557586, 0.18587808611683043, 0.127342155269771, 0.9833070626523912, 0.1534454672832407, 0.2013365505152368, 0.20197867652326518, 0.11697877295476888, 0.14305114281625153, 0.16330134662597195, 0.972141180451772, 0.9744262361023948, 0.21442694242982552, 0.07361338066594636, 0.1052684686369515, 0.16868877573271934, 0.940607156604442, 0.113192060729985, 0.9551395956770807, 0.15701129920145318, 0.21454004657622128, 0.24667772306568836, 0.1949423996833738, 0.2940649127784347, 0.233921939641058, 0.19670861703194675, 0.25631146056410925, 0.32646133043721626, 0.22008491766126204, 0.08952248331359347, 0.08924313973130105, 0.07299949713068743, 0.08409985957317456, 0.11157785686100652, 0.0999921591508457, 0.052262059681305595, 0.10040148897416079, 0.09721462769760769]}, "mutation_prompt": null}
{"id": "23273867-b731-47eb-b904-ab3a2a6ecb77", "solution": "import numpy as np\n\nclass HybridDE_ANM_SPR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.delta = 0.2  # Probability to regenerate individuals\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < 0.9\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                # Stochastic Population Regeneration\n                if np.random.rand() < self.delta:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.func_evals += 1\n\n            # Adaptive Nelder-Mead each generation\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "HybridDE_ANM_SPR", "description": "An enhanced hybrid algorithm combining Differential Evolution (DE), Adaptive Nelder-Mead (ANM), and Stochastic Population Regeneration (SPR) for improved global exploration and local exploitation.", "configspace": "", "generation": 1, "fitness": 0.40495330174612076, "feedback": "The algorithm HybridDE_ANM_SPR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.37.", "error": "", "parent_id": "c6b1667a-b55b-4cfc-a9a8-50a0a3ebc2b2", "metadata": {"aucs": [0.9791512182001947, 0.9655701465732841, 0.25494996711279927, 0.9727219604412481, 0.9720936000140106, 0.9761976928382143, 0.9761683337937469, 0.9671697624779734, 0.9708545882334245, 9.999999999998899e-05, 0.9232966697045066, 9.999999999998899e-05, 0.0503255225926067, 0.9082511613722217, 0.8543750741001837, 0.0052528970934719865, 0.9077232435600864, 0.9312504265002571, 0.12789831090352455, 0.07857277843898991, 0.07625557124137938, 0.10755040735189436, 0.06137024775346911, 0.08118090956382096, 0.09896561080776078, 0.09466400587557022, 0.09772217162857555, 0.07137749299107576, 0.06860931967039918, 0.057786321874284785, 0.11364109895023722, 0.019963776728715077, 0.05306577295311854, 0.07362379959252796, 0.022846238625259363, 0.06683043537261579, 0.924524453021303, 0.9186079026350175, 0.987592557989519, 0.9881713888709822, 0.9353083216065357, 0.9542580737203153, 0.9872212453792246, 0.9261428066844434, 0.9208872812508158, 0.418108172265244, 0.6841090969514174, 0.35101376566810505, 0.5974755258378703, 0.44257536323849545, 0.5610196038358477, 0.0888927649868747, 0.4024317802080789, 0.6892187021488543, 0.10027683525177622, 0.21171583807889427, 0.1391885860646731, 0.28492744683138194, 0.11207341841494345, 0.1344036587009012, 0.17955154327010403, 0.14142360598456594, 0.15490906576268026, 0.9465172972739523, 0.011433800522527071, 0.13390837391220733, 0.1370038379067966, 0.9327166444575526, 0.9260378604657952, 0.9423488031635798, 0.9358536947752851, 0.13779565862709042, 0.901662273054616, 0.13762260320600417, 0.9403952491805968, 0.1376777375399888, 0.13823055029018505, 0.13104697763734363, 0.9434012108622185, 0.9251641049114917, 0.13771466128927368, 0.8521133650923336, 0.9124773768972525, 0.9225791384341203, 0.9327060109125834, 0.9224872247850697, 9.999999999998899e-05, 0.8383645304378488, 0.8896692675958041, 0.8894476365922742, 0.90496190626869, 0.8866744627236681, 0.19492497761785066, 0.022247730974177093, 0.8257305332696945, 0.049793011998455206, 0.9069363613205927, 0.8380103482848024, 0.8965612898651347, 0.8400962561313127, 0.8833537534390897, 0.8435264927601396, 0.9324928501691135, 0.9321519249803188, 0.8290034541919824, 0.9320823703896259, 0.9103865849625402, 0.8045345904556467, 0.24467625542656812, 0.5538838709598406, 0.4672051185590299, 0.47104780090427234, 0.9308057483305688, 0.33908418719242495, 0.3055347423310403, 0.09834228289119251, 0.059678522045334303, 0.9534985702563945, 0.9584708174462058, 0.9593044215676385, 0.9621010477354214, 0.9495259858335304, 0.9562751510194081, 0.9541807427373007, 0.9327321923746793, 0.9584064189651158, 0.04826264977080519, 0.07858152738706448, 0.0597761854675638, 0.07387837347138959, 0.08992205079344107, 0.16690067290664734, 0.061815735083446954, 0.07131035178961465, 0.08773745246216225, 0.12341925527229647, 0.1050497130532807, 0.18657223695695146, 0.1991229420484918, 0.14371866286276547, 0.12234681701319772, 0.2066446948603019, 0.19827773451757003, 0.1697393263116439, 0.17460746013655515, 0.1550317655490573, 0.2005772745249561, 0.18969602767649507, 0.1444322068644276, 0.16538941290159126, 0.15574477883476734, 0.22408949932019562, 0.1381463977213807, 0.09751454068126864, 0.11605721277284775, 0.15569515112594456, 0.13444227339262982, 0.20169640895237073, 0.25558702201310946, 0.18442151134524865, 0.11940825856185233, 0.20469176775674225, 0.14163526276950722, 0.22250627079394203, 0.16026226838668756, 0.17859426305721027, 0.18682469613919206, 0.2970285776156094, 0.21927543780225078, 0.17383086451527452, 0.1750840638596023, 0.1771390856329379, 0.16487777009380422, 0.16576377911661888, 0.1551875846909354, 0.18125338021230808, 0.17871185993906147, 0.17878842281586171, 0.1597915612641131, 0.19151547940836466, 0.9802347351168114, 0.17775210645318928, 0.178883334736625, 0.1728922041676788, 0.2017845130969197, 0.15461095473529074, 0.14317649199169213, 0.16609527804712887, 0.1683550295445173, 0.9776629300637746, 0.15782815164415365, 0.21207250977277403, 0.9713669768132543, 0.09426008619680759, 0.1113629545968754, 0.11312322463174007, 0.9689555864608683, 0.16934263939168648, 0.18075818178357417, 0.16978158960939105, 0.1783400078163766, 0.19849362386413405, 0.17011629340216372, 0.21507684516735814, 0.2191445262021301, 0.21372321752768242, 0.21063451835183655, 0.07888420866989887, 0.08192620820530083, 0.05598149222099402, 0.054278308786168794, 0.1176075639168257, 0.12078366479352864, 0.06713267927463862, 0.08080228892518992, 0.050108265116851514]}, "mutation_prompt": null}
{"id": "867d29bb-ceaa-4152-b43d-c63e64a96208", "solution": "import numpy as np\n\nclass RefinedHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.delta = 1.2  # New parameter for adaptive differential evolution\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Adaptive Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                F = 0.5 + np.random.rand() * 0.5  # Adaptive scaling factor\n                mutant = np.clip(a + F * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < 0.9\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Enhanced Nelder-Mead with dynamic simplex size\n            if self.func_evals < self.budget:\n                for _ in range(int(self.pop_size / self.dim)):\n                    best_idx = np.argmin(self.fitness)\n                    simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                    simplex_fitness = np.array([func(p) for p in simplex])\n                    self.func_evals += len(simplex)\n\n                    while self.func_evals < self.budget:\n                        order = np.argsort(simplex_fitness)\n                        simplex = simplex[order]\n                        simplex_fitness = simplex_fitness[order]\n\n                        centroid = np.mean(simplex[:-1], axis=0)\n                        reflected = centroid + self.alpha * (centroid - simplex[-1])\n                        reflected = np.clip(reflected, self.lb, self.ub)\n                        f_reflected = func(reflected)\n                        self.func_evals += 1\n\n                        if f_reflected < simplex_fitness[0]:\n                            expanded = centroid + self.gamma * (reflected - centroid)\n                            expanded = np.clip(expanded, self.lb, self.ub)\n                            f_expanded = func(expanded)\n                            self.func_evals += 1\n\n                            if f_expanded < f_reflected:\n                                simplex[-1] = expanded\n                                simplex_fitness[-1] = f_expanded\n                            else:\n                                simplex[-1] = reflected\n                                simplex_fitness[-1] = f_reflected\n                        elif f_reflected < simplex_fitness[-2]:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                        else:\n                            contracted = centroid + self.beta * (simplex[-1] - centroid)\n                            contracted = np.clip(contracted, self.lb, self.ub)\n                            f_contracted = func(contracted)\n                            self.func_evals += 1\n\n                            if f_contracted < simplex_fitness[-1]:\n                                simplex[-1] = contracted\n                                simplex_fitness[-1] = f_contracted\n                            else:\n                                for j in range(1, len(simplex)):\n                                    simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                    simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                    simplex_fitness[j] = func(simplex[j])\n                                self.func_evals += len(simplex) - 1\n\n                    # Update population with the best simplex solution\n                    best_simplex_idx = np.argmin(simplex_fitness)\n                    if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                        self.pop[best_idx] = simplex[best_simplex_idx]\n                        self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "RefinedHybridDE_ANM", "description": "A refined hybrid approach incorporating Adaptive Differential Evolution and enhanced Nelder-Mead for balanced exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.4085285886502165, "feedback": "The algorithm RefinedHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.37.", "error": "", "parent_id": "c6b1667a-b55b-4cfc-a9a8-50a0a3ebc2b2", "metadata": {"aucs": [0.9794796614858267, 0.9804523392517277, 0.9752552084561156, 0.9720539477396631, 0.977242255344086, 0.9748339398667972, 0.9727366647530604, 0.9748960970000327, 0.3556578235278941, 0.9173484786904994, 0.6862980993432308, 0.916152996628431, 0.9014275927101594, 0.9479282497796416, 0.9393144004342581, 0.9416722227264998, 0.9504795405411258, 0.9174867484108358, 0.03085237388874651, 0.1377430101486138, 0.09479225752918086, 0.05059175710102648, 0.06531464835660972, 0.16670856311162752, 0.05655483268440198, 0.16302308098772444, 0.08458910586283164, 0.05633327887206996, 0.08431953060011488, 0.050327295454598575, 0.10772457597434038, 0.032535671464901106, 0.015527215995149724, 0.03461016153926377, 0.02359112149699505, 0.06509876338312337, 0.09948251897762161, 0.9253974349467795, 0.9220652819122582, 0.9390045142566604, 0.9174500950590968, 0.9424140305633067, 0.9772453220338557, 0.9094827855301885, 0.9898223458215852, 0.15747562193190257, 0.6249575628800887, 0.8285678159088161, 0.4682523449356256, 0.8534134555488833, 0.8684304752974475, 0.5822997783044217, 0.46310151853308135, 0.11443700520447986, 0.18826971121199187, 0.17234772051996283, 0.1343335220762799, 0.18090406203653853, 0.1310223558614414, 0.18604982744899556, 0.10846531457689412, 0.10109497413241497, 0.09108611396956823, 0.9575459550757897, 0.9608231788578331, 0.9517399250745484, 0.2611464764285282, 0.13843798192595536, 0.9355961751620665, 0.12189768804773393, 0.9526730644218007, 0.9244534284707953, 0.13772145105924827, 0.1376550511439204, 0.9105810875148604, 0.12622962633557744, 0.93859324271947, 0.9140006194159778, 0.949253424410535, 0.03545775019017605, 0.9391543111932253, 0.07438811382018773, 0.9192654506832368, 0.9255143451782718, 0.04796569801928341, 0.8044972700767219, 0.9511590988182483, 0.8790608690971966, 0.9477454933814323, 0.8714774761178515, 0.10734100810518721, 0.9138747272754096, 0.9102682589559545, 0.8877294003778813, 0.11996117046740018, 0.8990616583391967, 0.8889620523987438, 0.22706676665978298, 0.901292811674127, 0.8458576084599487, 0.8825992536737336, 0.8576184605845802, 0.9405850813650858, 0.8759098856136801, 0.9155375135569402, 0.8432672258381819, 0.8575647838023823, 0.8571897014402843, 0.24548933574847698, 0.12546887046420596, 0.05138059326527489, 0.8053711750901025, 9.999999999998899e-05, 0.04502547457251327, 0.10957195190682856, 0.5366751790646415, 0.10831786702346435, 0.27072425308586645, 0.9647720998957925, 0.9619800521497734, 0.9632634475820331, 0.9594316932063118, 0.9648943865233923, 0.9629118330227087, 0.9611172661412334, 0.9455612379013452, 0.0876700650766068, 0.07113975733975852, 0.10332528623303427, 0.06537124371610536, 0.14964131296785654, 0.0615878109657797, 0.05161273555596668, 0.07620037393547696, 0.14985389881552236, 0.12581496218477806, 0.13622759048811317, 0.1810808325236174, 0.21231031684736823, 0.1952733497065905, 0.15564754976646766, 0.1342551481287919, 0.09550636664963186, 0.12120116488729582, 0.1362314651245622, 0.2185411179479334, 0.2117054620173393, 0.20782125674514929, 0.16570055546333784, 0.22824525682689523, 0.13366828520859875, 0.2671692510500908, 0.1861081837794124, 0.07983881011072658, 0.13078675382608185, 0.11344400764606777, 0.14088539440928494, 0.1979031425322031, 0.1061885879144493, 0.16136123307609374, 0.10749381045402695, 0.16057100084249232, 0.23134264758993672, 0.2754159341937762, 0.15002223387583158, 0.2272561867621633, 0.2804578130256715, 0.24068834585661436, 0.24627487033443285, 0.20403554481911246, 0.21902047648878542, 0.16570890085827272, 0.1767660253117116, 0.15786734762288013, 0.1683904488443988, 0.1863096891161521, 0.1667552246208014, 0.1692573803596169, 0.2120305694971285, 0.1656954051956373, 0.13661046278743327, 0.12692012023598087, 0.1542445812211758, 0.17292051067866598, 0.20163344179266562, 0.17882891401087797, 0.1433178223821273, 0.16550365473606088, 0.14536963883696497, 0.31492701052017213, 0.2140125352427299, 0.21378322153516804, 0.2127553363200947, 0.11291706148526204, 0.971350541273971, 0.2139117327009662, 0.09451663506534624, 0.15757106387397912, 0.2051196398279478, 0.2806669420907253, 0.19453232875773818, 0.18246216305491803, 0.19169799506166008, 0.19818307623588594, 0.2563864806910444, 0.20536697981014973, 0.2112806248453316, 0.039797210523391136, 0.10979868085963684, 0.07107359184186757, 0.07590449848887004, 0.07120277188702562, 0.11400530003685816, 0.09230997211246994, 0.0700416905334661, 0.06496717345736036]}, "mutation_prompt": null}
{"id": "732b5c59-6671-44c1-8067-0be3632e64b2", "solution": "import numpy as np\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Adaptive Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead each generation\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveDE_NM", "description": "AdaptiveDE_NM: An enhanced Differential Evolution with adaptive control parameters and Nelder-Mead for fine-tuning local exploitation.", "configspace": "", "generation": 3, "fitness": 0.41906731592834057, "feedback": "The algorithm AdaptiveDE_NM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": "c6b1667a-b55b-4cfc-a9a8-50a0a3ebc2b2", "metadata": {"aucs": [0.25078872615843706, 0.9798121430837056, 0.9780343549329474, 0.9794000742629726, 0.979018584263392, 0.9346134790175069, 0.9778504916511426, 0.9593628910007441, 0.9667489061888408, 0.892574161517673, 0.8943820921083993, 0.044945729092369935, 0.9235395020387843, 0.05109392692196579, 0.9067035826143109, 0.1470305325173884, 0.898119993585962, 0.9571364549620138, 0.09077544034345142, 0.08765435844947078, 0.09116764242166608, 0.04791383588761999, 0.08463073392427867, 0.0761286344844413, 0.06333559629958185, 0.09437240888228249, 0.12087353081480201, 0.05040767925389722, 0.05320362836871917, 0.018025617595362364, 0.09497295287015606, 0.05433374037801364, 0.01316634830169916, 0.0504329505665142, 0.03242237963326822, 0.01741521474480523, 0.9428065092850046, 0.9859557821560518, 0.9759251708314808, 0.09967421566401513, 0.09964461638114497, 0.9110213520767327, 0.9800068209850181, 0.9899941575312897, 0.9004210113005967, 0.13110171538705984, 0.15962529766610956, 0.6860718414089864, 0.7846089981689729, 0.7488556859078694, 0.36685522743586474, 0.8235736677535932, 0.08921588643048994, 9.999999999998899e-05, 0.18196902125841186, 0.17915308869848012, 0.08160503531207941, 0.33051829929288035, 0.22570349234387554, 0.08282083487557335, 0.22788381714570005, 0.23101273710435488, 0.13087310046700218, 0.9571136683215934, 0.1360165262885974, 0.9355070298077803, 0.9557525063505362, 0.13563010651135687, 0.9237624895143248, 0.948994559328155, 0.1382306787866333, 0.9503934312810864, 0.9543080898726941, 0.13659080407690527, 0.13814105882214112, 0.9384447690115051, 0.9297571170821856, 0.13835563776518522, 0.9558480810353653, 0.9117299589473014, 0.9247895333016068, 0.7921564453631795, 0.935664431766464, 0.8614711445871608, 0.8539164860210964, 0.9205557865559201, 0.9327921548271243, 0.8255056537675287, 0.9380081647028575, 0.8493516734312497, 0.24624267984544745, 0.9363939376841184, 0.1402818840803517, 0.08188250894580251, 0.9042964318275324, 0.9145470759138236, 0.8851247210856013, 0.898657029471871, 0.8943452172634272, 0.8493253863190022, 0.8897361080048007, 0.8058294092404693, 0.9285843449130898, 0.9314151625153817, 0.9050505839349751, 0.9069391293032334, 0.7971429042203569, 0.8040063513789958, 0.09241296295070056, 0.8576454018967135, 0.3181095366778288, 0.423310763342458, 0.07638745266326719, 0.7272085326993984, 0.08722326759770715, 0.3089775200649041, 0.09777744173318292, 0.24088582168240924, 0.9671474007490638, 0.9652726950626322, 0.9670545806624274, 0.9689067977162358, 0.9556287616387356, 0.9563586766779295, 0.9685846191377374, 0.9697284923523091, 0.050554594155832966, 0.07122741602205063, 0.06698303650026194, 0.08786723282653497, 0.06051415354641454, 0.10847427165360735, 0.13804119173371088, 0.07368457641139525, 0.07821182239548985, 0.11059374653256693, 0.14561883061126302, 0.16890893655542494, 0.25680123466736615, 0.2674775276976459, 0.1447369292371239, 0.12669718771732297, 0.1680769071999756, 0.20772404922332965, 0.13810211234996372, 0.1999267146317658, 0.1801428604894738, 0.2530236869801916, 0.14872289732949706, 0.19262710817527362, 0.15496017904271064, 0.19791531111683958, 0.1985080761854604, 0.16024090204940566, 0.17687509141448332, 0.13654774572737516, 0.12625268438786041, 0.07854152832338024, 0.09885932705851319, 0.1490507178893038, 0.17136093095953397, 0.14563862666285365, 0.23726121932372257, 0.15107344350135077, 0.23384541137699066, 0.2691422483194753, 0.28771670527174054, 0.16547310280351435, 0.229968064496748, 0.14633163661763815, 0.26941879250077705, 0.2055127602617638, 0.17801876529565108, 0.17811147320478649, 0.16438246657883215, 0.16133464659198182, 0.18445386467293, 0.17619935850490132, 0.21204997880557586, 0.18587808611683043, 0.127342155269771, 0.9833070626523912, 0.1534454672832407, 0.2013365505152368, 0.20197867652326518, 0.11697877295476888, 0.14305114281625153, 0.16330134662597195, 0.972141180451772, 0.9744262361023948, 0.21442694242982552, 0.07361338066594636, 0.1052684686369515, 0.16868877573271934, 0.940607156604442, 0.113192060729985, 0.9551395956770807, 0.15701129920145318, 0.21454004657622128, 0.24667772306568836, 0.1949423996833738, 0.2940649127784347, 0.233921939641058, 0.19670861703194675, 0.25631146056410925, 0.32646133043721626, 0.22008491766126204, 0.08952248331359347, 0.08924313973130105, 0.07299949713068743, 0.08409985957317456, 0.11157785686100652, 0.0999921591508457, 0.052262059681305595, 0.10040148897416079, 0.09721462769760769]}, "mutation_prompt": null}
{"id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Slightly reduced population size for faster convergence\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.6  # Modified contraction factor\n        self.gamma = 2.0\n        self.mutation_factor = 0.7  # Dynamic mutation factor for DE\n        self.crossover_rate = 0.85  # Slightly increased crossover probability\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM", "description": "An enhanced hybrid integrating Differential Evolution (DE) with Adaptive Nelder-Mead (ANM) and dynamic mutation scaling for improved convergence efficiency.", "configspace": "", "generation": 4, "fitness": 0.42716105601068, "feedback": "The algorithm EnhancedHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "c6b1667a-b55b-4cfc-a9a8-50a0a3ebc2b2", "metadata": {"aucs": [0.9762959104566021, 0.9736231030382079, 0.963728009499896, 0.9735113123534176, 0.09212167430081952, 0.9755952970479215, 0.9786825623980184, 0.9760219429503243, 0.974401326428342, 0.044795797272862536, 0.9091560286871013, 0.9252756397886515, 0.922605251087177, 0.9202832427472554, 0.9360400999069859, 0.9416002120276216, 0.9201416535396789, 0.9376497964886594, 0.07538925232839333, 0.12060055493419475, 0.09899731951395407, 0.09423674502580648, 0.05973115717524957, 0.14877559125152473, 0.10876195792726862, 0.11432416497653064, 0.052059765923437196, 0.03843809415476096, 0.1674859867517685, 0.08769400813814099, 0.09516400545029502, 0.07151054358179432, 0.045343724397145735, 0.04274174770045125, 0.0572105396208783, 0.07871499641861845, 0.9891385544918037, 0.991792593823684, 0.9177240936144407, 0.09946804391573316, 0.9101665179266323, 0.8839473056600369, 0.9227638085139478, 0.9112822032103762, 0.9244131896104459, 0.9465858727395895, 0.5016672883644151, 0.957314934706626, 0.11460729245320722, 0.7535305527882278, 0.9293471560102375, 0.9123634014909717, 0.4730283010240205, 0.8826982037392958, 0.23866165554596497, 0.11713676704900844, 0.17226122517502918, 0.24347447747165052, 0.2920556060238163, 0.27299477442967957, 0.07685285345388582, 0.11995334164127203, 0.14708101569915566, 0.9435111831980644, 0.11529857367330076, 0.13367083961426163, 0.9392205526966392, 0.9522692061522365, 0.9504700728348152, 0.1380991768582428, 0.943468850084708, 0.9475236158426162, 0.13343662942569356, 0.1381089777991683, 0.9566156036755462, 0.14920068655359342, 0.9296308117938022, 0.9439518586867703, 0.13203330240406463, 0.893286592168107, 0.1358965852759202, 0.07397342650967675, 0.8993855461295501, 0.9214966452447291, 0.7812634362093187, 0.8929785841337243, 0.8426990195700048, 0.9394329293634864, 0.22524552976766044, 0.9303900995277804, 0.9255365117527893, 0.13494180751794704, 0.8993979525209563, 0.9107946599394429, 0.8287713996809036, 0.8945663587416245, 0.8639623187699583, 0.880256757469406, 0.9009998158240413, 0.8995629718150558, 0.8705487097594604, 0.8479946673756733, 0.9235371086502047, 0.9259926521334619, 0.7945354534853138, 0.8387423656963409, 0.8385542884266451, 0.8625852302194777, 0.49936646620688174, 0.41668274047024567, 0.06362848747995198, 0.5584291019730514, 0.328879989380954, 0.12391868076306312, 0.905234111628435, 0.11474940027336, 0.1042748689309343, 0.9597099472097946, 0.962379418730426, 0.9517276570733404, 0.9604034400673335, 0.9654942131399306, 0.9680873287221002, 0.3573529275849644, 0.9582212591984027, 0.9623282095367196, 0.08011295596374368, 0.034412113619127216, 0.12083089420559157, 0.10844435959590659, 0.05047042918759159, 0.07172351359750773, 0.11424410461784373, 0.05054043487763826, 0.12106433967493668, 0.1813977721409067, 0.10248844670644064, 0.16073276796985825, 0.14004315189370575, 0.23862363443807166, 0.20390486878370917, 0.15503092919230854, 0.10948101271525101, 0.16171251892443672, 0.1278180029405236, 0.19079276192213424, 0.1755619557214373, 0.19147931873023138, 0.16553215871553018, 0.1534635146297434, 0.20690228130090016, 0.19856596644671742, 0.1558970361719243, 0.1595600642960715, 0.08701371917233058, 0.10762733029051519, 0.1188793357136585, 0.15658759201364414, 0.2075522999186845, 0.13356170828219804, 0.10847418599693825, 0.11289398672585793, 0.2557120180473901, 0.18019601746340264, 0.238586681518152, 0.23212591588665044, 0.20232473455944378, 0.2412938007398252, 0.21554784172335817, 0.1773276213545365, 0.20697466670656617, 0.18373786938492298, 0.21986484867699585, 0.17595348266130528, 0.1668795197829508, 0.17381667144632662, 0.19189529503844527, 0.15619285373627645, 0.2118928315008055, 0.18018001395958128, 0.1666756638825707, 0.1270598501901926, 0.1547511511489511, 0.9837021658504509, 0.19735219035600737, 0.1148386453648651, 0.1433051409436943, 0.166710924977713, 0.9831452317608017, 0.3231962509322902, 0.21451291869151634, 0.06591827353843605, 0.9736951936891274, 0.169702835615673, 0.1564145451473853, 0.10524797290064436, 0.16887715020102456, 0.11282346833491319, 0.20698084511077508, 0.1428271486596181, 0.21963243725782056, 0.17911898931386294, 0.22557932766386024, 0.17029705641264847, 0.24896013219252489, 0.2665753432163642, 0.18266304685885748, 0.0866063013948718, 0.03085439634042908, 0.07691039752460516, 0.09981018260026397, 0.10099210747413634, 0.09686619110410011, 0.05696828422441724, 0.08215301063448333, 0.10541151631143708]}, "mutation_prompt": null}
{"id": "f81b0d95-9da3-46a0-bcf9-c4847c525565", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Slightly reduced population size for faster convergence\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.6  # Modified contraction factor\n        self.gamma = 2.0\n        self.mutation_factor = 0.7  # Dynamic mutation factor for DE\n        self.crossover_rate = 0.85  # Slightly increased crossover probability\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM", "description": "An enhanced hybrid integrating Differential Evolution (DE) with Adaptive Nelder-Mead (ANM) and dynamic mutation scaling for improved convergence efficiency.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.9762959104566021, 0.9736231030382079, 0.963728009499896, 0.9735113123534176, 0.09212167430081952, 0.9755952970479215, 0.9786825623980184, 0.9760219429503243, 0.974401326428342, 0.044795797272862536, 0.9091560286871013, 0.9252756397886515, 0.922605251087177, 0.9202832427472554, 0.9360400999069859, 0.9416002120276216, 0.9201416535396789, 0.9376497964886594, 0.07538925232839333, 0.12060055493419475, 0.09899731951395407, 0.09423674502580648, 0.05973115717524957, 0.14877559125152473, 0.10876195792726862, 0.11432416497653064, 0.052059765923437196, 0.03843809415476096, 0.1674859867517685, 0.08769400813814099, 0.09516400545029502, 0.07151054358179432, 0.045343724397145735, 0.04274174770045125, 0.0572105396208783, 0.07871499641861845, 0.9891385544918037, 0.991792593823684, 0.9177240936144407, 0.09946804391573316, 0.9101665179266323, 0.8839473056600369, 0.9227638085139478, 0.9112822032103762, 0.9244131896104459, 0.9465858727395895, 0.5016672883644151, 0.957314934706626, 0.11460729245320722, 0.7535305527882278, 0.9293471560102375, 0.9123634014909717, 0.4730283010240205, 0.8826982037392958, 0.23866165554596497, 0.11713676704900844, 0.17226122517502918, 0.24347447747165052, 0.2920556060238163, 0.27299477442967957, 0.07685285345388582, 0.11995334164127203, 0.14708101569915566, 0.9435111831980644, 0.11529857367330076, 0.13367083961426163, 0.9392205526966392, 0.9522692061522365, 0.9504700728348152, 0.1380991768582428, 0.943468850084708, 0.9475236158426162, 0.13343662942569356, 0.1381089777991683, 0.9566156036755462, 0.14920068655359342, 0.9296308117938022, 0.9439518586867703, 0.13203330240406463, 0.893286592168107, 0.1358965852759202, 0.07397342650967675, 0.8993855461295501, 0.9214966452447291, 0.7812634362093187, 0.8929785841337243, 0.8426990195700048, 0.9394329293634864, 0.22524552976766044, 0.9303900995277804, 0.9255365117527893, 0.13494180751794704, 0.8993979525209563, 0.9107946599394429, 0.8287713996809036, 0.8945663587416245, 0.8639623187699583, 0.880256757469406, 0.9009998158240413, 0.8995629718150558, 0.8705487097594604, 0.8479946673756733, 0.9235371086502047, 0.9259926521334619, 0.7945354534853138, 0.8387423656963409, 0.8385542884266451, 0.8625852302194777, 0.49936646620688174, 0.41668274047024567, 0.06362848747995198, 0.5584291019730514, 0.328879989380954, 0.12391868076306312, 0.905234111628435, 0.11474940027336, 0.1042748689309343, 0.9597099472097946, 0.962379418730426, 0.9517276570733404, 0.9604034400673335, 0.9654942131399306, 0.9680873287221002, 0.3573529275849644, 0.9582212591984027, 0.9623282095367196, 0.08011295596374368, 0.034412113619127216, 0.12083089420559157, 0.10844435959590659, 0.05047042918759159, 0.07172351359750773, 0.11424410461784373, 0.05054043487763826, 0.12106433967493668, 0.1813977721409067, 0.10248844670644064, 0.16073276796985825, 0.14004315189370575, 0.23862363443807166, 0.20390486878370917, 0.15503092919230854, 0.10948101271525101, 0.16171251892443672, 0.1278180029405236, 0.19079276192213424, 0.1755619557214373, 0.19147931873023138, 0.16553215871553018, 0.1534635146297434, 0.20690228130090016, 0.19856596644671742, 0.1558970361719243, 0.1595600642960715, 0.08701371917233058, 0.10762733029051519, 0.1188793357136585, 0.15658759201364414, 0.2075522999186845, 0.13356170828219804, 0.10847418599693825, 0.11289398672585793, 0.2557120180473901, 0.18019601746340264, 0.238586681518152, 0.23212591588665044, 0.20232473455944378, 0.2412938007398252, 0.21554784172335817, 0.1773276213545365, 0.20697466670656617, 0.18373786938492298, 0.21986484867699585, 0.17595348266130528, 0.1668795197829508, 0.17381667144632662, 0.19189529503844527, 0.15619285373627645, 0.2118928315008055, 0.18018001395958128, 0.1666756638825707, 0.1270598501901926, 0.1547511511489511, 0.9837021658504509, 0.19735219035600737, 0.1148386453648651, 0.1433051409436943, 0.166710924977713, 0.9831452317608017, 0.3231962509322902, 0.21451291869151634, 0.06591827353843605, 0.9736951936891274, 0.169702835615673, 0.1564145451473853, 0.10524797290064436, 0.16887715020102456, 0.11282346833491319, 0.20698084511077508, 0.1428271486596181, 0.21963243725782056, 0.17911898931386294, 0.22557932766386024, 0.17029705641264847, 0.24896013219252489, 0.2665753432163642, 0.18266304685885748, 0.0866063013948718, 0.03085439634042908, 0.07691039752460516, 0.09981018260026397, 0.10099210747413634, 0.09686619110410011, 0.05696828422441724, 0.08215301063448333, 0.10541151631143708]}, "mutation_prompt": null}
{"id": "343d4014-4e7f-414a-a552-92d9fa4fc3c8", "solution": "import numpy as np\n\nclass NovelHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2  # Slightly increased reflection factor\n        self.beta = 0.5  # Further reduction in contraction factor\n        self.gamma = 2.1  # Increased expansion factor\n        self.mutation_factor = 0.8  # Slightly increased mutation factor for DE\n        self.crossover_rate = 0.9  # Increased crossover rate\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead with stochastic simplification\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                if np.random.rand() < 0.5:  # Stochastic simplification\n                                    simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                else:\n                                    simplex[j] = centroid\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "NovelHybridDE_ANM", "description": "A novel variant of Differential Evolution with Adaptive Nelder-Mead incorporating stochastic simplification for robust global search.", "configspace": "", "generation": 6, "fitness": 0.33985194018246384, "feedback": "The algorithm NovelHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.34.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.2476180863852131, 0.9729461683222318, 0.9689506462664785, 0.9768344333019421, 0.9756004153159002, 0.32118824928445444, 0.9766992950002843, 0.9760758997332487, 0.2438129521277318, 0.18146213781205722, 0.16946752388604036, 0.04495765420429465, 0.8871691409904828, 0.9375059975113667, 0.910563502016333, 0.42101065556641404, 0.9283404695400113, 0.938024337935985, 0.05815564492019243, 0.07944732085501072, 0.05135672214293063, 0.11839674181887005, 0.07662273405430808, 0.04375461554111704, 0.04842387172962248, 0.06409971629133193, 0.10637440858001823, 0.04297754639358242, 0.07313930136188096, 0.01884681728644011, 0.04645725785386656, 0.053586571685172224, 0.007212031284678622, 0.03666067829730346, 0.036377365168780984, 0.01338622193998562, 0.923334442341956, 0.9869853192941644, 0.9504112909408687, 0.09964367310011712, 0.09964461638114497, 0.9490877979663204, 0.980047609825606, 0.9899941575312897, 0.8739405431303853, 0.1561073254520925, 0.5296016951030472, 0.19584734335874754, 0.37301947350601417, 0.1580021169271606, 0.3435060263109976, 0.15623118335134112, 0.08918702684320234, 9.999999999998899e-05, 0.1368440765184643, 0.19721924002593627, 0.0816068896472214, 0.1681980335549761, 0.14691816989339623, 0.12134302052034307, 0.23054776277062294, 0.12468112242849472, 0.13121541361023814, 0.1079012767567823, 0.10722058171249449, 0.9028864609586152, 0.9246764063258921, 0.1364932047938595, 0.908321574473579, 0.9355297464301927, 0.9299543584083354, 0.9313199944351434, 0.941750623304599, 0.05541244474530704, 0.929750669580871, 0.1369492005116515, 0.13494763566449142, 0.13765617925607476, 0.9466141784230421, 0.12475451174602292, 0.9182106531876837, 0.10746628175991957, 0.8702131316816487, 0.40020225225609674, 0.5604247594249501, 0.045592215218034804, 0.1048094711009897, 0.0094447411389732, 0.40099173847734326, 0.06947388399039678, 0.8246474245080617, 0.20676512226243604, 0.12900558642605997, 0.08469255621790617, 0.3699754793960395, 0.8742452547571444, 0.3253043760173142, 0.13608279533375367, 0.19475734528357347, 0.8304928053800649, 0.8363604832073455, 0.8332772232988281, 0.6252823718777001, 0.8751991914736895, 0.8816550187063906, 0.8490817368485538, 0.7946172275062519, 0.7718269167936733, 0.5987194762743754, 0.39402766070120954, 0.7383845537953275, 0.5986040605816503, 0.09972739860895785, 0.1345448981212476, 0.8455920341327815, 0.11692305897498734, 0.10114291820327614, 0.26257139248340533, 0.9629440906098743, 0.9640567024680005, 0.955624713181367, 0.941625625086343, 0.9277111789055761, 0.9648640707451352, 0.9502110417597768, 0.9531489900983239, 0.054234839853596006, 0.06620972060179775, 0.0562778788918471, 0.08185283672638766, 0.048848979201927656, 0.07764289390039048, 0.060005079264836, 0.09081723285015564, 0.06737726921061926, 0.10089559966779704, 0.10076239739915072, 0.13878284078421455, 0.2182581417807954, 0.1854142380536179, 0.12771621814012446, 0.14396256425022147, 0.11208981725445888, 0.1387161966088597, 0.12131666365710136, 0.22137886002278973, 0.18864703445706898, 0.24087405231301817, 0.18053518982868555, 0.16810262481800853, 0.15155804174052534, 0.2450695040806513, 0.16055201318961432, 0.13904127653589837, 0.16375978759042487, 0.14257128892932347, 0.08622469243696562, 0.09901746239662368, 0.10538285607038722, 0.1485612778262625, 0.14847895042671244, 0.13961177597102725, 0.2793974188203703, 0.21377868030496006, 0.14725014517487234, 0.17742867555459996, 0.22403602099660602, 0.20982263936553225, 0.1994761284470843, 0.20108833744827692, 0.21908208666630558, 0.16131609644444111, 0.16870176439163875, 0.1611388082555728, 0.17257789870273466, 0.16898563501915864, 0.1647830482254834, 0.1498344183462743, 0.16738675587302898, 0.150673424713764, 0.12292642959586231, 0.9791194150730068, 0.15335130602643188, 0.15134535913428993, 0.15815737884667125, 0.14120793221873496, 0.13750989300460736, 0.10769148627934277, 0.11088368191088704, 0.28318547977885666, 0.19284858293550355, 0.07360418667501167, 0.9504671170742317, 0.1687257228678758, 0.09470209099028526, 0.11286151310221137, 0.9630391849026058, 0.15696125603182953, 0.14854910175386304, 0.15625149535020022, 0.19348657533244518, 0.2142764210720831, 0.18565885450002073, 0.1411826664238004, 0.1736849778802727, 0.14612808435484625, 0.18130837396692467, 0.08186583688583637, 0.0775216576394625, 0.11692907165973887, 0.06329384380065606, 0.10468828046418677, 0.09719134879301505, 0.0627880438182159, 0.1012133867722117, 0.06667750448445675]}, "mutation_prompt": null}
{"id": "a5d3b3d8-2dbe-4ffa-8045-efb4d19a2a52", "solution": "import numpy as np\n\nclass AdaptiveDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for diverse exploration\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.1  # Slightly adjusted reflection coefficient\n        self.beta = 0.5  # Reduced contraction coefficient for better exploration\n        self.gamma = 2.5  # Increased expansion coefficient\n        self.mutation_factor = 0.8  # Enhanced dynamic mutation factor for DE\n        self.crossover_rate = 0.9  # Increased crossover probability\n        self.learning_rate = 0.01  # Adaptive learning rate for improving local search\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveDE_ANM", "description": "A novel hybrid of Differential Evolution and Adaptive Nelder-Mead with enhanced dynamic mutation and adaptive learning rates for improved global and local exploration.", "configspace": "", "generation": 7, "fitness": 0.42648592025685156, "feedback": "The algorithm AdaptiveDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.2526992297666889, 0.9769596401285641, 0.9719201716075109, 0.9760919043799211, 0.9785880794910113, 0.19179935662597558, 0.979676119277215, 0.9634817572108259, 0.9628906496453465, 0.8296407194657657, 0.8737736105513217, 0.8756253498037367, 0.9046923006525827, 0.9495202033484148, 0.9459641096712856, 0.14989771243333738, 0.8776417844043808, 0.9465764882394586, 0.09784129481721215, 0.1084203533886754, 0.09477564671877059, 0.08769182896998973, 0.09116839122333409, 0.06700626793072428, 0.0911317876274792, 0.13785397827017964, 0.16746793084946243, 0.06913472571244206, 0.07359859631796539, 0.025810295564853147, 0.09468914750376245, 0.09850237244532312, 0.006261385378596218, 0.03846271596654838, 0.04061856238319561, 0.0384061647493954, 0.9155038334362233, 0.9843108206589378, 0.986587680656864, 0.9497408767047115, 0.09964461638114497, 0.09891323287836717, 0.9846306021992415, 0.9899941575312897, 0.9529537155760323, 0.15162899731793844, 0.8763545933643617, 0.18007620402955493, 0.48793465158949867, 0.15537351665945864, 0.6493816420088228, 0.41322483633501306, 0.08920168445659238, 9.999999999998899e-05, 0.13879719281546876, 0.1879098390915559, 0.08160465094885372, 0.24573592411275436, 0.1731701543859021, 0.0642034206290587, 0.1675044340270444, 0.144996183557217, 0.1012634663133607, 0.9448276929297063, 0.870304215751535, 0.9431225937495862, 0.9267441801165772, 0.8921300468257841, 0.9385466609924684, 0.9357758504398133, 0.9499496612454309, 0.9223358566193781, 0.9391591187949699, 0.9194875637901385, 0.9368312677235483, 0.9189415338908092, 0.13466923333726077, 0.1382047532854498, 0.9519958898126322, 0.12894432441081094, 0.9123759237563474, 0.6886347339247824, 0.9393952906442693, 0.8917841505166678, 0.7463135968654581, 0.8221874445031445, 0.8279585248923919, 0.15922911204531343, 0.803271712746088, 0.755611757149165, 0.17911961805427146, 0.8308344247487649, 0.8447419909128004, 0.08277662874341041, 0.8664567096461495, 0.8803392517124417, 0.8010542334825846, 0.856897845752388, 0.887538037169078, 0.8379870744562157, 0.8633231027256678, 0.9040441201911218, 0.8478482495910904, 0.9421972040210663, 0.8838358883981622, 0.8662199469681552, 0.8568550053722146, 0.7480822800011016, 0.5668754111414794, 0.4284924827100308, 0.5240463541824316, 0.7786555070502057, 0.08333009282442949, 0.6178174706360053, 0.35201907749185, 0.06686283521917735, 0.10110727291680999, 0.2502768856823896, 0.9459917188703377, 0.9584812550329521, 0.9658835402755663, 0.9651897436779189, 0.9423263929447593, 0.9619197523367606, 0.9601931644226279, 0.9656178486245177, 0.06912260605987397, 0.08449163716134522, 0.08164100676750408, 0.09846056160931238, 0.057675179855246506, 0.07147383213297032, 0.1033214706234814, 0.07869462362799573, 0.1130391579441763, 0.12835192121277994, 0.10127952683600816, 0.1830406248194627, 0.4231728560578014, 0.18134605695793227, 0.1175164197077242, 0.1942086246229413, 0.18271474965755874, 0.2719153171007499, 0.14718159416267684, 0.22857188771643389, 0.18687547107833313, 0.1647592857855228, 0.1485884373590779, 0.19498448097494903, 0.15696836866756747, 0.2458652914182814, 0.1517461795270758, 0.1356706869677473, 0.13136133182232823, 0.17461090041518068, 0.2177230641213047, 0.14253740894127587, 0.1124817243173396, 0.15153931740996085, 0.16275873189352008, 0.13809024949595805, 0.19099091501362842, 0.1905607370890191, 0.14835984656925616, 0.30741784117678117, 0.24343381306402467, 0.16039024793463308, 0.20178038960789746, 0.18263998179217056, 0.22625792809494105, 0.15594617073907524, 0.16926649915651015, 0.15990372136930087, 0.16929614155767392, 0.15920393703516478, 0.17902841837911088, 0.17611460550754476, 0.1558501802150677, 0.14935346441468267, 0.1273452375019266, 0.9788906926929342, 0.14855365424141087, 0.20131692921069666, 0.20188860273836318, 0.2010152949944073, 0.14302812624410965, 0.16359145156565702, 0.9775886876826787, 0.9688955090005967, 0.2144729804078206, 0.07360087003338889, 0.10523928071954813, 0.16877324940699978, 0.9585944387749084, 0.11304750096854077, 0.9640920507476697, 0.15713580069268884, 0.19509564809711888, 0.2013990925184863, 0.20131163046393596, 0.26842308067239284, 0.2203938751551371, 0.1614443472061814, 0.20864405862416346, 0.21061582325217054, 0.25228294097201287, 0.10734923069219982, 0.08534219149208333, 0.06842611449776048, 0.09234663737554671, 0.09644629058282406, 0.08551651633306467, 0.06177956532470141, 0.11109435665575185, 0.1054089254611934]}, "mutation_prompt": null}
{"id": "75fdb0ee-b6b0-4224-9b96-7ff622f914e5", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM_Reinit:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5  # Further modified contraction factor\n        self.gamma = 2.5  # Enhanced expansion factor\n        self.mutation_factor = 0.9  # Increased mutation factor for exploration\n        self.crossover_rate = 0.8\n        self.reinit_interval = self.budget // 5  # Reinitialize periodically\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n            # Periodic reinitialization\n            if self.func_evals % self.reinit_interval == 0:\n                self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                for i in range(self.pop_size):\n                    self.fitness[i] = func(self.pop[i])\n                    self.func_evals += 1\n                    if self.func_evals >= self.budget:\n                        return self.pop[np.argmin(self.fitness)]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM_Reinit", "description": "A novel hybrid optimizer combining Differential Evolution with Adaptive Nelder-Mead and periodic reinitialization to balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.4219825771139481, "feedback": "The algorithm EnhancedHybridDE_ANM_Reinit got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.2654907977864005, 0.9763935579512527, 0.9745984209603733, 0.9796095835552006, 0.9786867900406494, 0.19046190090042925, 0.9681985749169691, 0.9683018942144832, 0.9639984524221343, 0.803807965766808, 0.8678111652414208, 0.8539147001783803, 0.8672683019724697, 0.9498698375199544, 0.8906069163385381, 0.943942692553572, 0.8391907030699931, 0.9495028350482932, 0.08141936502933877, 0.09496144325896272, 0.16742617079789612, 0.08454666521080012, 0.07885277977158534, 0.07367168601532137, 0.08167370309148936, 0.06496424633645748, 0.11365715911520635, 0.053263975769820004, 0.035446299611416876, 0.04639461296738323, 0.10843426047684102, 0.015563663395871896, 0.04525747537070579, 0.02924398676417317, 0.02511986413620415, 0.07855603016226409, 0.9899068293538956, 0.9841372831419446, 0.9579414202062755, 0.9892616711541067, 0.09960658980485582, 0.9215186073551574, 0.9899605532837368, 0.9898387099331727, 0.9666067755873958, 0.13962194799596328, 0.5454497487974055, 0.059976002602566414, 0.18113775240789254, 0.04512741222651917, 0.610529337086549, 0.361110729058698, 0.0892096390978877, 0.4683025678376823, 0.1305224915143044, 0.17816911613739395, 0.10881569324918805, 0.18399754265300494, 0.14659608555561987, 0.06408774174540555, 0.14541949605198423, 0.17975711506887204, 0.15177881845385766, 0.8042216800468924, 9.999999999998899e-05, 0.9445407669343153, 0.9494658152453131, 0.13815326213098778, 0.9378914546065882, 0.9474846876646172, 0.129803137308116, 0.9436353686146338, 0.9403849834035947, 0.934885765197915, 0.9246221498214905, 0.9085661882272144, 0.9141534403217153, 0.13833122275497678, 0.9421010657492205, 0.9366498736650611, 0.8795456637698011, 0.8498030718119912, 0.8742468036640366, 0.9133615989933181, 0.8375445717650976, 0.8446290346229721, 0.8395431914551671, 0.821555103686416, 0.810163017779109, 0.2645113032139219, 0.8505731451072283, 0.14331908078503053, 0.8957465374256158, 0.23202635192021848, 0.8605581292386074, 0.9273875620824632, 0.877736460146946, 0.8601041653639911, 0.8599250270444029, 0.901576069952553, 0.8256665146163993, 0.9077076617390925, 0.9300715807779418, 0.9306958782771003, 0.9175071866168025, 0.8562911420478663, 0.8113829445784415, 0.11285967341796799, 0.7442081238264806, 0.18064199179327045, 0.8897687714666006, 0.18096985284138878, 0.34406812657301467, 0.9176711501143741, 0.11073651180677846, 0.0617880294962726, 0.10934999205152707, 0.97255044337757, 0.9600286436005929, 0.966074457411056, 0.9590904414734955, 0.9687870055090889, 0.9626449379192752, 0.9581547908105008, 0.9691562344904632, 0.9691670477225773, 0.06505798202370383, 0.05055066478699499, 0.07127509999936865, 0.06347070593875359, 0.04634901961821292, 0.12773257117311532, 0.0522360558522349, 0.05038040792489251, 0.07789804386269228, 0.13211188608637348, 0.14437317195632893, 0.16979776791871448, 0.17759825628915682, 0.27952437324656443, 0.1517923625459332, 0.19277616351968285, 0.20080794666739765, 0.13688268214833021, 0.1155433506639949, 0.21062323326284726, 0.2263879764807959, 0.18999663294421554, 0.14976753445023827, 0.17016251794851045, 0.16623462622627305, 0.24188515877612426, 0.20038654820483648, 0.18180383842647985, 0.13537206917953082, 0.12463925163525513, 0.15340360888993743, 0.07291135310922514, 0.1436841303743136, 0.14119588265626482, 0.12158163433995273, 0.16770146003315334, 0.22569794363579376, 0.22219504509583532, 0.176381964861978, 0.20171038129812324, 0.23665378884184562, 0.22474129725218306, 0.21737164137942255, 0.18607727227342086, 0.22508138355501073, 0.1528070159434166, 0.1780189088821511, 0.14925840016568614, 0.1962413378750163, 0.21678496890772425, 0.1845210271951745, 0.16495366091641228, 0.17486310760869905, 0.18349636804858493, 0.16862156646109894, 0.9823338398539276, 0.1638146357229181, 0.20143672382345756, 0.2013818213799916, 0.11697831406772752, 0.14322990377049516, 0.16347351633625928, 0.16211024461808188, 0.9665365637100665, 0.2145180072677606, 0.9545553712509345, 0.21400805175546433, 0.16929821629049602, 0.15696603735397074, 0.1107739846606488, 0.10484056237847439, 0.1571513448949714, 0.187811318083967, 0.20639856053211303, 0.22350356556959128, 0.2754885319881347, 0.18822456616389527, 0.23655234611483433, 0.16877419008053496, 0.2341693939580799, 0.23083210049195568, 0.03252158069073541, 0.10367640352969554, 0.07748732587411944, 0.1122981352341691, 0.0823573787468862, 0.09742222550074053, 0.06730883650077701, 0.07327448530515523, 0.092973482795905]}, "mutation_prompt": null}
{"id": "01c51577-4301-484f-bc67-0077b2945467", "solution": "import numpy as np\n\nclass AdaptiveHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for better diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2  # Increased reflection parameter for faster exploration\n        self.beta = 0.5  # Further modified contraction factor for flexibility\n        self.gamma = 2.5  # Increased expansion coefficient to enhance global search\n        self.mutation_factor = 0.8  # Adaptive mutation factor based on success history\n        self.crossover_rate = 0.9  # Enhanced crossover rate for more aggressive mixing\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        success_history = []\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    success_history.append(1)\n                else:\n                    success_history.append(0)\n\n            # Update mutation factor adaptively\n            if len(success_history) > 50:\n                success_rate = np.mean(success_history[-50:])\n                self.mutation_factor = 0.5 + success_rate * 0.5\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveHybridDE_ANM", "description": "A hybrid approach combining Differential Evolution (DE) with an enhanced Adaptive Nelder-Mead (ANM) and adaptive learning rates for robust high-dimensional optimization.", "configspace": "", "generation": 9, "fitness": 0.38774482047216086, "feedback": "The algorithm AdaptiveHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.35.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.24761776080441034, 0.9728916071619707, 0.9648757993312519, 0.9761509246145146, 0.9756726450975215, 0.3211882579684606, 0.9764213047568459, 0.9746163090128156, 0.2438129521277318, 0.866303717826873, 0.16626314742203918, 0.330774900369458, 0.867624810491966, 0.9238078963571796, 0.07121829091798859, 0.9140285622381445, 0.5711755803236427, 0.843783917512658, 0.12840113618291504, 0.07372068017316047, 0.10596922891378857, 0.16673283408482442, 0.07885163106527238, 0.06321942704051053, 0.08313158107899887, 0.058934393779899286, 0.13798911044707707, 0.06688223850926334, 0.07989783919966664, 0.0340685329243573, 0.08464259588775991, 0.056215423571810974, 0.0052689004197959965, 0.028200871591875565, 0.04062523497391213, 0.025077827075101977, 0.9807684678456663, 0.9002384117284316, 0.9220918708335591, 0.09961312429147107, 0.09964461638114497, 0.09890737637398905, 0.9843483854887116, 0.9899941575312897, 0.8574359327553384, 0.15623533466915107, 0.11626965763679542, 0.37028655945101807, 0.633828452357916, 0.15760729327884893, 0.20600228795498698, 0.37591841984130536, 0.08917433319512835, 9.999999999998899e-05, 0.13880931211622116, 0.19768628581658843, 0.0816068896472214, 0.1744655591197226, 0.23542519678746288, 0.13963069626730462, 0.23168437944816045, 0.129711666041746, 0.13121541361023814, 0.9271778986298862, 0.10834450380919303, 0.923130039507756, 0.9241495788547742, 0.8745033344608135, 0.920381707160638, 0.931541099703935, 0.9286855776955207, 0.9085728218900886, 0.9322966475822976, 0.12688056208933085, 0.9314663634155558, 0.13690450260816156, 0.917770688782463, 0.13767530238198722, 0.9409674603497783, 0.8466527076960904, 0.9389779445386979, 0.6081930791269123, 0.8735141115655378, 0.8086910593334293, 0.41220459390362596, 0.6573684732608329, 0.7267686844025805, 0.8056394659276394, 0.7875019296663326, 0.707153497405379, 0.7718964625283272, 0.7360808524836429, 0.1287002817151901, 0.637790627320254, 0.8371589144973313, 0.83860704248567, 0.8425451035666391, 0.8171782181064262, 0.799620009394818, 0.8039569602196981, 0.8471092398697806, 0.7976733994718487, 0.9113182027967016, 0.8418093287288262, 0.8806468462185456, 0.8275399538576932, 0.08252873875331079, 0.7716453241793085, 0.5869877891104827, 0.20326331001347908, 0.012288766756615277, 0.6327315136766944, 0.09972739860895763, 0.13235843626493604, 0.06035099393274379, 0.13096238136967053, 0.1015016333638219, 0.2625716819205137, 0.952918988793881, 0.9482068340691641, 0.9546789072817602, 0.9520105293679304, 0.8987333922124087, 0.9525794581706767, 0.9432514433428983, 0.9510161942040701, 0.07612771277713293, 0.08432990160570064, 0.07383435018377804, 0.07883670414300847, 0.0465312679250397, 0.1378188128520642, 0.08392996252463547, 0.09471629745376353, 0.07184301115488945, 0.1157977850241434, 0.15597563807214954, 0.1644284029105193, 0.21701341071249292, 0.22948031293206395, 0.14925480316397477, 0.17028509001771475, 0.17185863754219444, 0.27838336128560714, 0.13420619521895039, 0.26323637858272797, 0.18887020652551523, 0.27401195815175794, 0.18481270750046763, 0.1887633500393704, 0.1671484759642775, 0.24188923164676657, 0.18946504178130474, 0.13664534159898234, 0.2105637114218335, 0.157955063014376, 0.212802605287277, 0.08864262237297205, 0.11791867359437691, 0.158859210303396, 0.15475066517283864, 0.15042339952309924, 0.22399215779058412, 0.3442834381838673, 0.1485038163132525, 0.19889929896611114, 0.2587705047146309, 0.1836690423577042, 0.23998272570504664, 0.20588783744880956, 0.2664348088236379, 0.16209780575512434, 0.17389597067286866, 0.18001351636711793, 0.1738584732088153, 0.18127840050312294, 0.16479270717639516, 0.18874524685875638, 0.16834860251992545, 0.15908736534177004, 0.1273407536508514, 0.9769908356111934, 0.14923992201715808, 0.20115179148899476, 0.201859943943986, 0.11695756216905517, 0.14302763635041282, 0.16609710867414285, 0.11962619829194099, 0.9625798847913618, 0.21431675725382981, 0.0736124790318552, 0.10521745997389176, 0.16908837121749454, 0.9389386861981162, 0.11303771278801955, 0.962133489511026, 0.1571231015210075, 0.2634499459469688, 0.20040136771896033, 0.21087149571776254, 0.20895726909698897, 0.21992427005893123, 0.19017222544914014, 0.26617285019811154, 0.24238246356825588, 0.2068714233678154, 0.11551462463145745, 0.0807468395462021, 0.12982093156528096, 0.0953652753308748, 0.10449784515027205, 0.11013174970965245, 0.06186937729250841, 0.10621826862078321, 0.07940453971488892]}, "mutation_prompt": null}
{"id": "8453ae7c-6c60-43d6-acab-9ff3e2cf66ac", "solution": "import numpy as np\n\nclass NovelHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 7 * dim  # Adjusted population size for balance\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2  # Slight tweak to reflection factor\n        self.beta = 0.5  # Altered contraction factor\n        self.gamma = 2.5  # Increased expansion factor\n        self.mutation_factor = 0.6  # Adjusted for exploration\n        self.crossover_rate = 0.9  # Enhanced crossover probability\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice([idx for idx in range(self.pop_size) if idx != i], 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.7 * (simplex[j] - simplex[0])  # Increased contraction\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "NovelHybridDE_ANM", "description": "This novel hybrid algorithm combines Differential Evolution (DE) with an Adaptive Nelder-Mead (ANM) approach, employing dynamic crossover and mutation strategies for robust convergence.", "configspace": "", "generation": 10, "fitness": 0.3912019659887019, "feedback": "The algorithm NovelHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.36.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.1772446973244176, 0.9808190233577952, 0.9797304694821436, 0.9743813582109699, 0.9779029078295642, 0.9796465260283862, 0.959851820620333, 0.9696792689152494, 0.9678188683825292, 0.044559467835198485, 0.803238975535788, 0.8776092171731589, 0.8617173223848151, 0.8612894631434337, 9.999999999998899e-05, 0.8388063621363638, 0.8205141567934098, 0.9364114428502905, 0.12778854552824215, 0.12108076330699913, 0.07207824319328815, 0.10854779230632461, 0.1286384917815081, 0.09500201067647318, 0.08371665682007445, 0.09782921468958417, 0.1079927341563438, 0.047552103205766416, 0.03631008503286681, 0.10732205423195607, 0.1377300430730013, 0.012064643595489755, 0.07137325031835029, 0.05469753752990014, 0.1263214685135845, 0.06326123447312659, 0.8876362169885134, 0.9924526735961787, 0.9915548571866416, 0.9030183887133392, 0.972212219337809, 0.9829372994517125, 0.8955931855799256, 0.9397739165055881, 0.9910762717920658, 0.5113680586308504, 0.5887013403058019, 0.39014608279188556, 0.19059007148293672, 0.19746637882808582, 0.36351329830159274, 0.05919854651713263, 0.3437027423227914, 0.2054488034131433, 0.19849343161158928, 0.11751144312689465, 0.11020755243703739, 0.1838356280201323, 0.2070324592807148, 0.11845239488942683, 0.05775837683712526, 0.23937921054336753, 0.11180563807227062, 0.9306493688665316, 0.15606345151818968, 0.1382956850644137, 0.13266196626868498, 0.8874715893158689, 0.12829345101971668, 0.9545757155192292, 0.9291693674505288, 0.9175029479158996, 0.01752883586345111, 0.9401982362969178, 0.9166914905349535, 0.1299295504555723, 0.9475494806926277, 0.1345525647283885, 0.9392968586736262, 0.9528747258562978, 0.1384822052206689, 0.863003414003541, 0.10058043097479152, 0.7927205860693728, 0.785429270615136, 0.8090681805057158, 9.999999999998899e-05, 0.4479189664509037, 0.8415629269353809, 0.7767180874715084, 0.2495765509307093, 0.842419553811024, 0.11110899582339295, 0.8599972920620417, 0.8942806986417066, 0.8585087007883596, 0.491624519787784, 0.7922187415470285, 0.8819826811523857, 0.7593112869816708, 0.7191464326596456, 0.7927329856627447, 0.9128159363591413, 0.8926451808395065, 0.935877807536133, 0.7216201944834111, 0.8953992597644691, 0.8047674997576211, 0.1369817200772222, 0.19758247488213343, 0.05618719589780574, 0.007066649555867444, 0.040620635078928324, 0.07922355057356711, 0.5586183597859549, 0.06978545387678892, 0.10987543279707335, 0.9591212215113861, 0.9649083896585091, 0.9433682167407128, 0.9528828172247001, 0.9351437333489343, 0.94853041218618, 0.9631873117979259, 0.9481367054958169, 0.9541676525900868, 0.09600180040721462, 0.12788408270859797, 9.999999999998899e-05, 0.07054558068995598, 0.12064340677367347, 0.0799155565151326, 0.09831013793887322, 0.075392834171643, 0.0875406666137164, 0.09888964037702974, 0.14673723483655432, 0.13001900632170293, 0.12578462229999854, 0.20604611238388815, 0.08637366957899395, 0.16958089497129458, 0.11428735658700917, 0.1844669984406, 0.14372876452150207, 0.2003085140161487, 0.24138739581785595, 0.18340398358048937, 0.16652850716264878, 0.20437858468210846, 0.1950777963096434, 0.21251151678021574, 0.23873531941358384, 0.1548389605038738, 0.0779346733956785, 0.16380386885891507, 0.12770758707348628, 0.11832717061438269, 0.23065130871141004, 0.17481629840789414, 0.20643058739527564, 0.13370909119952756, 0.19025588902112456, 0.2867025824744982, 0.21271856144906942, 0.20220265307139984, 0.3113875987099455, 0.26578142641261016, 0.25877946702628374, 0.178058928738155, 0.2725108630996599, 0.1820940570679539, 0.16887205518005866, 0.15494246119116817, 0.1582881099539165, 0.23304864888378019, 0.18664203040602267, 0.16180656165039164, 0.18010591014055932, 0.1589574400364019, 0.16854370174550037, 0.16877682738507083, 0.15458216148911963, 0.16679662621493285, 0.17324299986323044, 0.17951783510925157, 0.14328809874544446, 0.1106220265993374, 0.9697181905976432, 0.2657141535057662, 0.214055594293309, 0.2136429308216924, 0.105288520265582, 0.1552982344097843, 0.20838063205944868, 0.9685507860523721, 0.15736645019525253, 0.9711831484680111, 0.24316794394191688, 0.2351959890647377, 0.19198479148360237, 0.17830234717649618, 0.23863979591756257, 0.20534650322568448, 0.19899189244499094, 0.2079088837163533, 0.2310151134357047, 0.11510698521964446, 0.10151443276893857, 0.07672895205421759, 0.07945090097832053, 0.10951467040871543, 0.07375081117292726, 0.08286939773240609, 0.0958029603410907, 0.07200227712446994]}, "mutation_prompt": null}
{"id": "21561801-ff28-4fa8-a343-c52cf9f23424", "solution": "import numpy as np\n\nclass EnhancedHybridDE_EANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for better diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2  # Slightly increased reflection coefficient\n        self.beta = 0.5  # Reduced contraction factor for more aggressive searches\n        self.gamma = 2.5  # Increased expansion coefficient\n        self.mutation_factor = 0.8  # Slightly increased mutation factor for DE\n        self.crossover_rate = 0.9  # Further increased crossover probability\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Enhanced Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_EANM", "description": "A novel hybrid algorithm combining Differential Evolution (DE) with an Enhanced Adaptive Nelder-Mead (EANM) method featuring dynamic parameter adaptation and accelerated simplex updates for efficient exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.38774482047216086, "feedback": "The algorithm EnhancedHybridDE_EANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.35.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.24761776080441034, 0.9728916071619707, 0.9648757993312519, 0.9761509246145146, 0.9756726450975215, 0.3211882579684606, 0.9764213047568459, 0.9746163090128156, 0.2438129521277318, 0.866303717826873, 0.16626314742203918, 0.330774900369458, 0.867624810491966, 0.9238078963571796, 0.07121829091798859, 0.9140285622381445, 0.5711755803236427, 0.843783917512658, 0.12840113618291504, 0.07372068017316047, 0.10596922891378857, 0.16673283408482442, 0.07885163106527238, 0.06321942704051053, 0.08313158107899887, 0.058934393779899286, 0.13798911044707707, 0.06688223850926334, 0.07989783919966664, 0.0340685329243573, 0.08464259588775991, 0.056215423571810974, 0.0052689004197959965, 0.028200871591875565, 0.04062523497391213, 0.025077827075101977, 0.9807684678456663, 0.9002384117284316, 0.9220918708335591, 0.09961312429147107, 0.09964461638114497, 0.09890737637398905, 0.9843483854887116, 0.9899941575312897, 0.8574359327553384, 0.15623533466915107, 0.11626965763679542, 0.37028655945101807, 0.633828452357916, 0.15760729327884893, 0.20600228795498698, 0.37591841984130536, 0.08917433319512835, 9.999999999998899e-05, 0.13880931211622116, 0.19768628581658843, 0.0816068896472214, 0.1744655591197226, 0.23542519678746288, 0.13963069626730462, 0.23168437944816045, 0.129711666041746, 0.13121541361023814, 0.9271778986298862, 0.10834450380919303, 0.923130039507756, 0.9241495788547742, 0.8745033344608135, 0.920381707160638, 0.931541099703935, 0.9286855776955207, 0.9085728218900886, 0.9322966475822976, 0.12688056208933085, 0.9314663634155558, 0.13690450260816156, 0.917770688782463, 0.13767530238198722, 0.9409674603497783, 0.8466527076960904, 0.9389779445386979, 0.6081930791269123, 0.8735141115655378, 0.8086910593334293, 0.41220459390362596, 0.6573684732608329, 0.7267686844025805, 0.8056394659276394, 0.7875019296663326, 0.707153497405379, 0.7718964625283272, 0.7360808524836429, 0.1287002817151901, 0.637790627320254, 0.8371589144973313, 0.83860704248567, 0.8425451035666391, 0.8171782181064262, 0.799620009394818, 0.8039569602196981, 0.8471092398697806, 0.7976733994718487, 0.9113182027967016, 0.8418093287288262, 0.8806468462185456, 0.8275399538576932, 0.08252873875331079, 0.7716453241793085, 0.5869877891104827, 0.20326331001347908, 0.012288766756615277, 0.6327315136766944, 0.09972739860895763, 0.13235843626493604, 0.06035099393274379, 0.13096238136967053, 0.1015016333638219, 0.2625716819205137, 0.952918988793881, 0.9482068340691641, 0.9546789072817602, 0.9520105293679304, 0.8987333922124087, 0.9525794581706767, 0.9432514433428983, 0.9510161942040701, 0.07612771277713293, 0.08432990160570064, 0.07383435018377804, 0.07883670414300847, 0.0465312679250397, 0.1378188128520642, 0.08392996252463547, 0.09471629745376353, 0.07184301115488945, 0.1157977850241434, 0.15597563807214954, 0.1644284029105193, 0.21701341071249292, 0.22948031293206395, 0.14925480316397477, 0.17028509001771475, 0.17185863754219444, 0.27838336128560714, 0.13420619521895039, 0.26323637858272797, 0.18887020652551523, 0.27401195815175794, 0.18481270750046763, 0.1887633500393704, 0.1671484759642775, 0.24188923164676657, 0.18946504178130474, 0.13664534159898234, 0.2105637114218335, 0.157955063014376, 0.212802605287277, 0.08864262237297205, 0.11791867359437691, 0.158859210303396, 0.15475066517283864, 0.15042339952309924, 0.22399215779058412, 0.3442834381838673, 0.1485038163132525, 0.19889929896611114, 0.2587705047146309, 0.1836690423577042, 0.23998272570504664, 0.20588783744880956, 0.2664348088236379, 0.16209780575512434, 0.17389597067286866, 0.18001351636711793, 0.1738584732088153, 0.18127840050312294, 0.16479270717639516, 0.18874524685875638, 0.16834860251992545, 0.15908736534177004, 0.1273407536508514, 0.9769908356111934, 0.14923992201715808, 0.20115179148899476, 0.201859943943986, 0.11695756216905517, 0.14302763635041282, 0.16609710867414285, 0.11962619829194099, 0.9625798847913618, 0.21431675725382981, 0.0736124790318552, 0.10521745997389176, 0.16908837121749454, 0.9389386861981162, 0.11303771278801955, 0.962133489511026, 0.1571231015210075, 0.2634499459469688, 0.20040136771896033, 0.21087149571776254, 0.20895726909698897, 0.21992427005893123, 0.19017222544914014, 0.26617285019811154, 0.24238246356825588, 0.2068714233678154, 0.11551462463145745, 0.0807468395462021, 0.12982093156528096, 0.0953652753308748, 0.10449784515027205, 0.11013174970965245, 0.06186937729250841, 0.10621826862078321, 0.07940453971488892]}, "mutation_prompt": null}
{"id": "fc006192-f38e-434f-abd2-fafcf15deaaa", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for better exploration\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.1  # Adjusted reflection coefficient for ANM\n        self.beta = 0.5  # Lower contraction factor for more conservative approach\n        self.gamma = 2.1  # Increased exploration potential during expansion\n        self.mutation_factor = 0.6  # Slightly reduced mutation factor for DE\n        self.crossover_rate = 0.9  # Increased crossover probability for better diversity\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Update population with the best simplex solution\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM_v2", "description": "A refined hybrid combining Differential Evolution with Adaptive Nelder-Mead and adaptive mutation control to enhance global convergence in diverse optimization landscapes.", "configspace": "", "generation": 12, "fitness": 0.42558704857259844, "feedback": "The algorithm EnhancedHybridDE_ANM_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.23010832433242678, 0.963186461657216, 0.9723615147684839, 0.9740927475393975, 0.9762686532976849, 0.2643841636177724, 0.9740935548708664, 0.9805454802204566, 0.9550767709082595, 0.9018696406076762, 0.9352670064327091, 0.8718923592399164, 0.9360146575232113, 0.9587435103282835, 0.22598706643120214, 0.913409472612837, 0.8726780260057286, 0.9032914657649862, 0.09882384417794965, 0.07883430530631463, 0.0987803145788243, 0.13720495431336588, 0.059723365737474166, 0.06513975187855758, 0.07138622335314171, 0.0562683047180923, 0.06326846394302388, 0.08165035033752688, 0.06502881955638262, 0.020748430532397055, 0.04562744977281741, 0.059494240804568665, 0.0263197683274351, 0.039594482173125445, 0.05783847322852287, 0.059464863007541835, 0.987180399422658, 0.8880541482684595, 0.9262065394575603, 0.899261886680339, 0.09967225546985614, 0.09924487057347287, 0.9342326126006053, 0.9893579166506801, 0.8899184341071881, 0.7373622809110565, 0.5303574596634861, 0.2589099273615467, 0.2279877382757579, 0.16372888278107056, 0.5225250867334799, 0.7794602790695133, 0.08919660940163099, 0.22950560398543662, 0.13093526599686278, 0.2522508259746865, 0.1130925662098714, 0.2777616300341218, 0.14485510652804312, 0.06955817777512185, 0.1797617021602459, 0.16602820828667608, 0.14557653936473303, 0.69025900617823, 0.9135521182893582, 0.9367626839286634, 0.9587063065303211, 0.927950099137989, 0.023884519017180694, 0.10065620290248134, 0.9546632368344176, 0.8973960413526124, 0.9436290670891742, 0.9226616058555108, 0.9320064923403121, 0.9202915431713137, 0.9192313456088144, 0.9513817011483945, 0.9546699122864845, 0.9117104260288844, 0.9255964360610686, 0.8584989374149736, 0.9226655505304298, 0.8678195865317595, 0.7695440848383399, 0.9290168866278882, 0.020634769674227615, 0.7845584791878871, 0.9276630088626395, 0.8687657136947831, 0.8333934426376487, 0.8612040046917913, 0.8876465564308301, 0.07795587931654702, 0.8932864265809118, 0.9299476700230087, 0.8591007855941954, 0.8884823335382286, 0.8764436797929088, 0.915080906879284, 0.865362995740248, 0.8452141985405139, 0.9222267039994323, 0.921970713146419, 0.8711010084221108, 0.8162995092661602, 0.8634472877640741, 0.9106204167055294, 0.2814173486742001, 0.18618903959101807, 0.7219283865032009, 0.46564076520225495, 0.040543365580681945, 0.2820791573239205, 0.059444401579579975, 0.06440907645032767, 0.10926317805503172, 0.46671022109672644, 0.9611456486622886, 0.9608977090438793, 0.9555276616781899, 0.9481725609437295, 0.9604820022835439, 0.9693731503321271, 0.3074703532383829, 0.9597407220886922, 0.017275319718515814, 0.12050595279484844, 0.08723660800170241, 0.09911108362318333, 0.06324389448441237, 0.19635917244491197, 0.07614692988836924, 0.07135202316769995, 0.05388012544394771, 0.2042234488522544, 0.13420862104152298, 0.17996398669880231, 0.14659095588265314, 0.23057506546210138, 0.14050676937101214, 0.13797598243437192, 0.08573249945738881, 0.1642089129173162, 0.16126135484514093, 0.22866220118995395, 0.18041451876956238, 0.1441028384894576, 0.1657662226178711, 0.2110528491355962, 0.15754295723747092, 0.19368780952269316, 0.15825218914244765, 0.11582865439567613, 0.16733196393674554, 0.1564300540389293, 0.14340846749918112, 0.1124924531416811, 0.20653099500723704, 0.1235020525093099, 0.12488781899464652, 0.1617156525235054, 0.2317870327738093, 0.22027617998765536, 0.24657325926070806, 0.2434669556715553, 0.1990653391690782, 0.24441542049365228, 0.24276642879004928, 0.14697906450264941, 0.21424685960698764, 0.16626354669583743, 0.18477054529902015, 0.21448499344500738, 0.16757177830246328, 0.1710255639416569, 0.18730722000219702, 0.205076069410693, 0.18620566229017355, 0.16698699546532025, 0.1887720086314445, 0.11975414142421759, 0.1315818324417949, 0.43762570600168504, 0.20190823829365023, 0.11711357028787028, 0.14326555553322073, 0.16587464518260153, 0.21368080398109546, 0.9688239948894095, 0.214224380252222, 0.9659973034072218, 0.16940168377719167, 0.16933727777227048, 0.09004076483432544, 0.972035677758937, 0.16862411603584548, 0.9662889660146772, 0.1805389084968192, 0.20663902309160254, 0.1821892532510847, 0.15588675223523063, 0.21132982930179556, 0.21530045825319355, 0.21178864749553838, 0.21784794641152072, 0.2115711542850558, 0.11573031618298302, 0.08355385121653003, 0.0537045844698647, 0.1058435307982698, 0.09584567967254476, 0.08332988449519962, 0.06363538394498969, 0.08810127807026524, 0.07853275952636429]}, "mutation_prompt": null}
{"id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "solution": "import numpy as np\n\nclass HybridDE_ANM_DynamicCrossover:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "HybridDE_ANM_DynamicCrossover", "description": "Hybrid Differential Evolution (DE) with Adaptive Nelder-Mead (ANM) and dynamic crossover for enhanced global search and local exploitation.", "configspace": "", "generation": 13, "fitness": 0.43736170339578573, "feedback": "The algorithm HybridDE_ANM_DynamicCrossover got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.37.", "error": "", "parent_id": "22988613-bac4-4f7c-a8a7-d7b7e677a789", "metadata": {"aucs": [0.16821127023514804, 0.9769910265683307, 0.9730108413850964, 0.9736454846724548, 0.10065394057059662, 0.9690385053093918, 0.9741041409973515, 0.9797655292733127, 0.9760148215663796, 0.9201932928101417, 0.8842559334734769, 0.9516228033646202, 0.8885202408759502, 0.8895487446601108, 0.9386446511268367, 0.9308262359869932, 0.8691264340181278, 0.9116918169745524, 0.07387575744046682, 0.1078530110165501, 0.09477169391503992, 0.1290359168474262, 0.058198548623600965, 0.1099051024438833, 0.05661009017406382, 0.11446487635620561, 0.054488262760699735, 0.08455959315373673, 0.02672892218380607, 0.022135245051802643, 0.099026898319314, 0.020590770550617865, 0.08434687543442487, 0.02364883911961957, 0.03848203948343121, 0.07662497518187683, 0.8979972294996789, 0.9283413512923252, 0.9167662963524111, 0.8988972716738238, 0.9595536514067257, 0.8903869663488905, 0.9919391656808871, 0.9517638622077519, 0.9385400938768647, 0.7225128590507093, 0.8207514192590117, 0.8643970083693586, 0.5557965494103785, 0.7386558115945216, 0.8329730006284708, 0.0890358743629922, 0.6499121653894939, 0.6033099554942281, 0.22202549618020928, 0.06504316638902763, 0.23182294421526684, 0.23923798672240915, 0.21499296991798966, 0.16022413598251117, 0.10083896316851237, 0.10880538463000011, 0.16910880586000965, 0.13190478380810744, 0.1253304860380955, 0.8774522771405976, 0.9396977341317005, 0.13821981764727187, 0.9378232957871945, 0.9272280236177991, 0.1380174292533458, 0.9234997658258096, 0.13818771617154213, 0.13665879562881122, 0.9638025223338509, 0.14535344248713955, 0.9561284443800144, 0.9476839740222132, 0.9583291030579335, 0.9163547830839129, 0.13523953830062652, 0.8329011574878664, 0.8022478184872337, 0.8732459146073379, 0.8202856806116026, 0.9188395787994708, 0.9068581065491695, 0.9412960199674443, 0.8625105229871636, 0.9211449972585397, 0.9205482257218801, 0.867692005145045, 0.8843165757954716, 0.9004268208246577, 0.9119715795732793, 0.8994092330240844, 0.8877954650750451, 0.8720632147697653, 0.8997286760004336, 0.8316104579733454, 0.9033448651433807, 0.8456718696723065, 0.9080939389586206, 0.9172811081350094, 0.8908699468441189, 0.9135291303912064, 0.08257190301847317, 0.9070450415284388, 0.925726981241636, 0.8142850176061375, 0.05994784888349691, 0.7347044352098744, 0.23906192583782815, 0.9017762424822446, 0.14658405455375756, 0.16144989474604987, 0.08933937679002502, 0.9709989727009466, 0.9683193752285263, 0.9665005646307356, 0.9697021118676227, 0.9617534957382574, 0.2647278970555811, 0.5481793933898436, 0.9429072616125678, 0.9637825615412794, 0.06797016015300994, 0.032644866218977, 0.09902545268212892, 0.09919219314938887, 0.04072337823162597, 0.11449388155562534, 0.08468739363326061, 0.03556063419590283, 0.09526526953793257, 0.20661686277427493, 0.12383929732556243, 0.19428357782411199, 0.14181246370872846, 0.28676635976183995, 0.13700869772829283, 0.13854816869160225, 0.11222032131670989, 0.21554358428046372, 0.18294343947022662, 0.2603431182331831, 0.1580979229795232, 0.2292165937331161, 0.1698145780495015, 0.14496513160263835, 0.19750850358090788, 0.23449742937813345, 0.16230557813859592, 0.10023694664256033, 0.12763259511203395, 0.11373003124507508, 0.10679690266561592, 0.11384393831773265, 0.1748665583570641, 0.22092441661876905, 0.25680212847091044, 0.16931595560246804, 0.2627551277646113, 0.18090767666957697, 0.14711360421016217, 0.2806251996978546, 0.17861071215441138, 0.27012972777318023, 0.24832485621395817, 0.19149299325198288, 0.2301366324494436, 0.19507548226927318, 0.2286229026369937, 0.16380072398641676, 0.18766608671801677, 0.174086836558627, 0.19206229304273836, 0.180462792701776, 0.17589010808319527, 0.17426764974677023, 0.13716633771313358, 0.11702205338346305, 0.18932203985940832, 0.9801442739687107, 0.16900047131751728, 0.11487277189102785, 0.14326657679672772, 0.12923044843472198, 0.9844082277054117, 0.35510945081886824, 0.2138690450439814, 0.15641008442401239, 0.21216280292565026, 0.1691575181496231, 0.15673984946057995, 0.10521382674546398, 0.9669389108711777, 0.11312550961589163, 0.18108961419686587, 0.1702773075400984, 0.18009597687789114, 0.18868036582917724, 0.19750925403504793, 0.17529072772849774, 0.18975944263592226, 0.21540513879293344, 0.206023729852987, 0.07358900011501479, 0.06974282639736651, 0.10926121878332129, 0.1115865880076592, 0.08733070255178266, 0.10141849495519073, 0.08332698907721747, 0.10505687384699613, 0.09464503117123346]}, "mutation_prompt": null}
{"id": "5f09851d-b2f2-4bd2-a318-504595dc18fe", "solution": "import numpy as np\n\nclass StochasticSwarm_HybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.7  # Adjusted\n        self.adaptive_crossover = True\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with Adaptive Crossover\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n\n                if self.adaptive_crossover:\n                    self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "StochasticSwarm_HybridDE_ANM", "description": "Stochastic Swarming Hybrid DE with Adaptive ANM and Adaptive Crossover for enhanced exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.41022360677214376, "feedback": "The algorithm StochasticSwarm_HybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.37.", "error": "", "parent_id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "metadata": {"aucs": [0.980586645459177, 0.23844433781102126, 0.9618201858741391, 0.9725971430459969, 0.9787776662345018, 0.1834758326944812, 0.9737647543632623, 0.9782527654012396, 0.9747061257954851, 0.2280115966306051, 0.04555944647914989, 0.8112724582391924, 0.9029445222801246, 0.9335967890523515, 0.8350792564524534, 0.9189049467295568, 0.056309228921882615, 0.9341585692741466, 0.06946356506146711, 0.08734199969398726, 0.0648062787830499, 0.06281302296889257, 0.04535505585884003, 0.0670590672870216, 0.11365120871895362, 0.07859369001270822, 0.10362907809713451, 0.053422748936110875, 0.02833780197162883, 0.034638294234431655, 0.0988860738644316, 0.029859963859681593, 0.023625544113635044, 0.0465008173364142, 0.13706431974096833, 0.012078231227917957, 0.9907346785061664, 0.8885055866975082, 0.07480994910362371, 0.9190291483337176, 0.91550548202346, 0.9334491772041317, 0.9340128679185905, 0.959068730723815, 0.9760147192452631, 0.6889428729363881, 0.8255349973869915, 0.06200053520369675, 0.27029228594862975, 0.473220253530383, 0.7537800120951772, 0.20731636217789062, 0.8859065132399486, 0.11965893190407406, 0.18277841032314113, 0.13174299969312508, 0.15838734005537614, 0.16046639609079283, 0.03690651789911481, 0.24612226675527837, 0.09475835014654554, 0.12911490976687234, 0.13740387271800936, 0.9524032006070932, 0.9244271148270967, 0.9520946671819147, 0.9678803402336702, 0.1356953082816097, 0.8960400687996273, 0.13810203306366453, 0.9514416983497007, 0.13570953007371156, 0.8488865184566134, 0.9392996302455181, 0.13209803596640468, 0.13769602442342876, 0.9059441594735997, 0.16676074738596558, 0.9520565676105813, 0.9459754209708107, 0.9215186903796235, 0.7951741464064772, 0.8657405584093747, 0.8043090798861702, 0.9057606852900837, 0.8958014499989263, 0.9155855193048059, 0.9052401785464899, 0.863776581025757, 0.9353337730265955, 0.8927321942418284, 0.9308305413504948, 0.9298935699429336, 0.9084592397796422, 0.9110161639426372, 0.8122387048026414, 0.8593381366154929, 0.8248963181541491, 0.15546044714871166, 0.05583234731602427, 0.9165553557053865, 0.8916037156536984, 0.9056705386361387, 0.9367576882603925, 0.9034540162507592, 0.8189515004051258, 0.8924432351763719, 0.8529053829759818, 0.863913173699926, 0.8027610668212289, 0.04563390699599823, 0.429139270368855, 0.2703971108940654, 0.38449774048190466, 0.9036597439982202, 0.05958872563453188, 0.445592286303126, 0.9502821026991135, 0.9668529984595848, 0.9684181603797867, 0.9411500405507363, 0.9627305494969819, 0.10296045157954192, 0.9643682564118672, 0.9492170201495398, 0.3143737757813554, 0.10871012138578229, 0.04062369414571354, 0.047709841350851656, 0.09470071931224577, 0.11419305883895359, 0.09128961595049989, 0.1678052844271657, 0.1287033119434403, 0.09842751190268972, 0.17074298357483098, 0.14099195386574825, 0.16463044749596556, 0.14757594380993544, 0.1961829520732239, 0.11945377308413319, 0.10705193240119038, 0.13645334018387023, 0.20405099994693732, 0.15384129514843992, 0.1426815344618011, 0.16981082676268944, 0.18312805951815625, 0.18113361296319364, 0.15418967542397144, 0.1860664575245775, 0.28425260389419926, 0.19243706742835331, 0.08239614451270294, 0.06791862392658854, 0.09348871913364454, 0.10927861128089411, 0.08179780337882747, 0.1336181165603535, 0.14330830074969925, 0.16943647525132144, 0.15209359889130725, 0.22502683745234264, 0.20387512053265777, 0.20840528281912207, 0.18056416948296994, 0.22233452561349032, 0.2238660415487349, 0.2639109808396861, 0.23751191692856388, 0.25215839590019484, 0.15679506669435272, 0.20048142776418687, 0.16513845824415618, 0.1713688026072634, 0.16770169215528785, 0.17190360860179044, 0.16040647887217652, 0.17745978208367108, 0.156182811094008, 0.18873523644337398, 0.1272287886161958, 0.148575980825429, 0.9809489673619151, 0.20225950065639875, 0.20072646251478987, 0.14342378540379175, 0.14603915072963625, 0.1538421453161264, 0.4641992536015438, 0.21443066862337468, 0.07343518549861161, 0.2134525725445129, 0.1693145826005692, 0.15566586672117322, 0.09478598125870463, 0.1591818240493148, 0.9723752843260766, 0.22209312678320625, 0.15220556171911925, 0.20614642992233911, 0.1753202468652837, 0.1835447216961843, 0.19240371233315623, 0.24139162013322502, 0.19033031514327337, 0.18771154102435872, 0.04110016154030438, 0.07401724256928266, 0.08233669497219942, 0.12406238425597016, 0.10540147225867635, 0.07825884063828814, 0.0647078482899347, 0.06814911470471174, 0.06904997367959864]}, "mutation_prompt": null}
{"id": "e0a4de93-7cc1-4c3a-b0e8-61edafb384c4", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM_DynamicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.9\n        self.dynamic_factor = 0.5\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with dynamic mutation\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutation_factor_dynamic = self.mutation_factor + self.dynamic_factor * np.random.rand()\n                mutant = np.clip(a + mutation_factor_dynamic * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM_DynamicMutation", "description": "Enhanced Hybrid Differential Evolution with Adaptive Nelder-Mead and dynamic mutation for robust exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.41737760368470733, "feedback": "The algorithm EnhancedHybridDE_ANM_DynamicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "metadata": {"aucs": [0.9778451044357545, 0.9781593813680252, 0.9715773553403234, 0.9688849650914007, 0.18328457926880004, 0.9755763951972726, 0.9744591845212922, 0.9577045768609859, 0.2002316928938409, 0.8835298485055603, 0.044737429993882194, 0.04445968554657975, 0.9105560467874113, 0.8869970213931586, 0.8908025505151866, 0.9176771638435227, 0.9243797276559746, 0.932702973727237, 0.05015762850946426, 0.0505741609614333, 0.09466445551373204, 0.03963246067093973, 0.12079186256436769, 0.0632230416517583, 0.05797933022163593, 0.12063172362781771, 0.05190596828789562, 0.09880775213621529, 0.08117173615205941, 0.03255564563333557, 0.10772457597434038, 0.026369499871999547, 0.027459749412149126, 0.033699448101266904, 0.059612105925432646, 0.08740574811211077, 0.9369464061115309, 0.9499754503951225, 0.9290810367507868, 0.9423984629802742, 0.8930446114456501, 0.9274630262550383, 0.8811410451931024, 0.8860205954140457, 0.9109348636236206, 0.15747562193190257, 0.849824228417981, 0.9460704274247255, 0.39807412301564393, 0.15534987434169656, 0.40401669328674583, 0.8414250052701538, 0.08910348430311732, 0.04594888882951309, 0.1260779008013282, 0.17514660980288732, 0.1578643271766743, 0.22488482530835663, 0.12743638170160643, 0.394314779108621, 0.23929928013089052, 0.1523865580804934, 0.12121957506156744, 0.9592236878450761, 0.9467616128452856, 0.9367923029069403, 0.9527100885861634, 0.138089057504582, 0.9098178445349098, 0.13810642987338628, 0.961932738290638, 0.1376918094928007, 0.13704587346147434, 0.13746106115190793, 0.13805939236088538, 0.13217069158072758, 0.9362238018835046, 0.9524220140020027, 0.9489352622044558, 0.9531680631092213, 0.9311307649878917, 0.884453911216122, 0.8617433522502131, 0.9415962797856049, 0.9166642458276558, 0.9432113965280906, 0.9459822246095239, 0.9121965312748394, 0.8955639037872898, 0.867035682946696, 0.8608759976395499, 0.9266087613184673, 0.8740053125474456, 0.8786872870838819, 0.0700706614918023, 0.4288269340485411, 0.9074082358722622, 0.9011561415897705, 0.9383393599225265, 0.9167598976688, 0.8505171567825924, 0.8824987617069733, 0.9234883046038925, 0.9221506962954689, 0.8303648488519985, 0.8958836033906596, 0.8264351138887769, 0.8462949079805502, 0.13077960785368137, 0.2709775478892017, 0.12572482086339842, 0.007027810414368285, 0.8071055120874102, 0.04434679775856909, 0.17352943269740173, 0.17495052982680315, 0.11205271591831956, 0.9651022154544167, 0.9596485387132203, 0.9550969693138219, 0.9602903435271074, 0.9660017218591844, 0.9673444285693705, 0.962230860281974, 0.9597672701550056, 0.9657637377843243, 0.07341535806597099, 0.09856479300156373, 0.08170175731524465, 0.06726202235792988, 0.08448019883937719, 0.11386336671654951, 0.06146910773455039, 0.09039699728941253, 0.09459705984300237, 0.099964708571331, 0.1824698265419189, 0.18194540376525936, 0.1888528525356088, 0.19809551130378833, 0.12089325573356413, 0.14814469652418227, 0.1667218604367916, 0.14925906134665434, 0.13336826172358873, 0.15646288330481273, 0.21358157428020874, 0.21458522013963688, 0.13599452238896304, 0.2817609856846294, 0.2566847795059929, 0.31340084559594705, 0.17444360230071543, 0.14336650889837277, 0.15839329337917896, 0.17092571271027102, 0.16394946120410425, 0.13694658722368114, 0.16724035393382508, 0.11826249894417051, 0.10850469286567455, 0.22105241221488547, 0.20641526186830728, 0.1757715220942544, 0.16670340616497958, 0.2173734770043083, 0.2733864332676935, 0.20827515199903368, 0.21647669816166948, 0.28700780414855753, 0.23823535579133204, 0.1738521670218912, 0.17149797961649582, 0.14992407928385876, 0.1683904488443988, 0.1835520931416873, 0.17681007150323225, 0.15268716563948492, 0.17884374264043434, 0.17493913935577166, 0.9692235721361864, 0.12709121950958446, 0.15455059999861898, 0.17269327008118218, 0.2016945330272435, 0.21267842915026758, 0.14322876748214508, 0.16567890891296866, 0.09277387605441667, 0.31596575627859325, 0.9798700839506105, 0.2139284610140335, 0.21390831325951742, 0.0830188677501783, 0.9661407028671651, 0.10484208780745574, 0.10456311650721495, 0.15703266577793673, 0.20180587085888135, 0.18039188851366328, 0.18801043150626306, 0.16500172103720556, 0.18230776835373474, 0.20705723830824962, 0.21723754380139626, 0.1980222125484835, 0.20974705326722454, 0.06957462466971376, 0.05343299396390244, 0.07020863105650732, 0.08378605707259723, 0.09221142781261804, 0.06624359784002609, 0.05106859526909302, 0.07457579201312259, 0.0776721577333701]}, "mutation_prompt": null}
{"id": "1ba1fbc1-a1eb-4536-9d01-c7a01010fb81", "solution": "import numpy as np\n\nclass EnhancedDE_ANM_StochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.ranking_prob = 0.45  # Probability for stochastic ranking\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with Stochastic Ranking\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i] or np.random.rand() < self.ranking_prob:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedDE_ANM_StochasticRanking", "description": "Enhanced Differential Evolution with Adaptive Nelder-Mead and dynamic crossover, incorporating stochastic ranking for better balance between exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.41487845544991203, "feedback": "The algorithm EnhancedDE_ANM_StochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.37.", "error": "", "parent_id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "metadata": {"aucs": [0.9787370536370665, 0.9770883715166695, 0.9792476231213562, 0.9745570522119641, 0.9715698958945868, 0.24654138661136182, 0.9689217518355848, 0.9764572112144139, 0.9706767273001574, 0.8960883188000744, 0.9274362917012733, 0.9002370483904711, 0.0503254514573529, 0.9383505334299133, 0.9334409666325785, 0.06269006316989978, 0.9085226814870495, 0.06333341986565866, 0.09897448661915154, 0.196181487501756, 0.12874794012534807, 0.14792424223766643, 0.08163767532228194, 0.09310375535428517, 0.09139672157797252, 0.06187635323219487, 0.06713132226228191, 0.018669253446970235, 0.04292500986327363, 0.07304110043637502, 0.0397094975794009, 0.010395602113895674, 0.019782793782983754, 0.040648018120122864, 0.08409282266640872, 0.009341375774113314, 0.9826020403937012, 0.9486102847181446, 0.9915624628511623, 0.9810785713864498, 0.9543145226613612, 0.8676831309097983, 0.9569565094391824, 0.9638142954555364, 0.9535511460157408, 0.7149523789673125, 0.6180756561149157, 0.8340642222935971, 0.5589418337906054, 0.15324286926333264, 0.4020662595834096, 0.5225948367855374, 0.4437871700266388, 0.12588760924688214, 0.22496102414064523, 0.19761185918120816, 0.1522909412116087, 0.0667108215001172, 0.10756045307799811, 0.13972466951771367, 0.13052223531477047, 0.10882673281503308, 0.17996588759229304, 0.9523883800599073, 0.13799137297855835, 0.13800837114308961, 0.9550158042649479, 0.9367985866948654, 0.9319244861270297, 0.13474661031158863, 0.9617127327649908, 0.13823264202944463, 0.9386055409270304, 0.9449643472486262, 0.13612514615698856, 0.13797313881318474, 0.9557004639786396, 0.25901507473103746, 0.9260850452866894, 0.9190107244977184, 0.9154501616467113, 0.07712980966967731, 0.8693481262948607, 0.8022477067332674, 0.8332667073869886, 0.9191518316866873, 0.9109456312913713, 0.09252212866424303, 0.09323641266131688, 0.13035630983889823, 0.9168522582454168, 0.8511620063242125, 0.9071094522966348, 0.8927433489770038, 0.8512831027185325, 0.8887390092750295, 0.9184270870767508, 0.8653483620476443, 0.8784483572693127, 0.814335871514891, 0.8900325222636046, 0.8050583052765596, 0.836277470575553, 0.9159362224577875, 0.9175380526961854, 0.8606053776763389, 0.822920000306141, 0.7934933926273282, 0.0487560320081053, 0.8330019294782234, 0.06798622786564679, 0.48455744284399926, 0.9203759014378052, 0.028941346665269374, 0.6617186613679662, 0.12612803425299934, 0.08651159795223051, 0.9614135870211389, 0.9620426096242246, 0.9682930703105372, 0.9655851751334683, 0.9660438906659136, 0.964174923059439, 0.9711280017728027, 0.9427132623040414, 0.965933666238302, 0.08938639234531653, 0.05892224110210631, 0.07169887586757706, 0.09516977894489753, 0.12838483353244734, 0.0787238281169026, 0.059713862584794386, 0.09900776193908312, 0.06543465677456328, 0.12612401983412513, 0.12864318300267297, 0.1444188037537668, 0.10320620979992856, 0.17511350867462094, 0.13192498617639625, 0.30325990077869724, 0.13878776982389174, 0.10358798737981156, 0.12878011345658613, 0.2453328763467315, 0.16782696406403885, 0.19133937531811673, 0.12769903229630986, 0.18267370393907412, 0.16125789744001084, 0.23215700237694936, 0.16641265697574437, 0.05985389541960007, 0.15132860276479865, 0.13717653023308263, 0.17729093096887405, 0.11241619086658161, 0.10347786904811074, 0.09104707656291011, 0.23473764816111908, 0.09677908911316713, 0.17281468555038193, 0.1924386987672465, 0.2647277063308646, 0.14784358305204537, 0.19055794031163953, 0.15525082581331318, 0.24296935345959714, 0.2216328875492397, 0.19648788658834238, 0.17907151117622944, 0.15540664740556398, 0.16954587656710796, 0.1678125066870152, 0.18027121138174573, 0.16015814173922027, 0.19211021348823776, 0.2121816377235607, 0.1562013221207198, 0.18885929984318472, 0.3739726104437444, 0.11160199692183981, 0.96950133107913, 0.20063454038795248, 0.20089493186940555, 0.1276595622059633, 0.2131326272830022, 0.9719691576502442, 0.9734743430751511, 0.2119763002890721, 0.21412496487526933, 0.21333371715227845, 0.16941350264954358, 0.15689808148095485, 0.21412128796970842, 0.20285799286419992, 0.09278333201285882, 0.20320488285537774, 0.16549095235127165, 0.2558427531776454, 0.197446968784446, 0.17055256889424675, 0.16725122388181646, 0.2980801978641453, 0.23801828447352158, 0.19101710472987532, 0.08086382964067074, 0.10204872493305062, 0.06577238775718941, 0.05906258183110935, 0.10691006776444245, 0.09354852386622059, 0.05292997810072342, 0.06729285542185681, 0.05329363524039599]}, "mutation_prompt": null}
{"id": "25a1f4f9-fa39-425e-a3dc-fc6dd1e1942d", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM_StochasticCrossover:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Adjusted population size\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.05  # Slightly adjusted reflection coefficient\n        self.beta = 0.45  # Slightly adjusted contraction coefficient\n        self.gamma = 2.05  # Slightly adjusted expansion coefficient\n        self.mutation_factor = 0.85  # Adjusted mutation factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.hierarchy_factor = 0.3  # New parameter for stochastic hierarchy\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM_StochasticCrossover", "description": "Enhanced Hybrid Differential Evolution with Adaptive Nelder-Mead and stochastic hierarchy crossover for improved exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.41851187040811594, "feedback": "The algorithm EnhancedHybridDE_ANM_StochasticCrossover got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "metadata": {"aucs": [0.2591199030906096, 0.9782803328516884, 0.9637961254276245, 0.9740899753771469, 0.9815013187502113, 0.33079466315962025, 0.9773739278317066, 0.9609592584838956, 0.9728155231252703, 9.999999999998899e-05, 0.8904810653765906, 0.8763551431257587, 0.879664061638196, 0.9275903800019074, 0.9205135552972404, 0.9198862926178936, 0.05591470972157819, 0.9467834946762396, 0.07355622153692476, 0.10853270622178335, 0.1281445920918617, 0.08469303987066856, 0.04936717439094229, 0.09108291005970603, 0.09511946750769407, 0.09450884463913334, 0.08450343485792033, 0.05788025282828968, 0.04724489428547762, 0.03251566022897934, 0.10288934334150923, 0.030803472477537452, 0.004804658364663372, 0.03356817305971238, 0.03954503733935433, 0.03609697396366596, 0.989790583877979, 0.9870597132315205, 0.9579393042841399, 0.9779657495547075, 0.09962730528918584, 0.913924330670218, 0.9899525495602169, 0.9898776867353309, 0.9721555274062759, 0.6369135930834502, 0.08352640138141121, 0.16606001184057495, 0.5710449063931864, 0.7533943165084754, 0.04553951268546552, 0.5590453026999196, 0.08924732660600787, 9.999999999998899e-05, 0.1812188871862016, 0.2027270804975031, 0.11313229990329365, 0.39466602504817017, 0.15826088728879262, 0.11081151258845168, 0.15090796375718896, 0.13941977100598468, 0.11438921673036007, 0.8578409679305499, 0.1095052173791351, 0.9115820708836213, 0.9508064368287997, 0.9073459344011124, 0.9434047812327838, 0.13850177321702506, 0.9234508106010784, 0.9619464357967228, 0.9522432290872441, 0.9307080087560061, 0.9252365235395787, 0.9097857918016439, 0.9279086141844304, 0.1382779589415215, 0.9435369117924958, 0.9507442622742258, 0.9368585903940408, 0.7327613473109593, 0.779236146774522, 0.9272370057640351, 0.8378409364482297, 0.8782782475973483, 0.057875139296543976, 0.7979068844678363, 0.9123181705906523, 9.999999999998899e-05, 0.8081426626173394, 0.851072644492968, 0.9012578386087313, 0.36668575108990775, 0.883065720055792, 0.04097403658182974, 0.8706301360390734, 0.8378620877529893, 0.8627223274444085, 0.8577964661665017, 0.8637144920092014, 0.8035398801950274, 0.9263414074242747, 0.9212647141086335, 0.924064025382354, 0.9181551741097397, 0.7871508764553644, 0.8093279538789873, 0.07784459587952985, 0.7225764365705402, 0.7711143446240669, 0.4265683838342418, 0.09763475985278469, 0.860568528289047, 0.22983945963984465, 0.19169784213847862, 0.09299195536127858, 0.9611761551897898, 0.9645084797691363, 0.9640491939290152, 0.3420764840130939, 0.9735638825755939, 0.9673986370638893, 0.9509464455353199, 0.9597871661031917, 0.9179998009639849, 0.05043885658983305, 0.07874059319346238, 0.11988126305473001, 0.06722477706247698, 0.0685209810997327, 0.09898579471285318, 0.1377808392539951, 0.08147437359463128, 0.10774179708413123, 0.11718491093664474, 0.10441566612507791, 0.1641241424708011, 0.14055168337469293, 0.2160209772945677, 0.13236955002943362, 0.19640748748357106, 0.20023140654314198, 0.14084764808796013, 0.15443259693300537, 0.1636765157666321, 0.20021012182943065, 0.16905678562847026, 0.1443289120629555, 0.2028952921828152, 0.17480214434460117, 0.1979170445839017, 0.14450286883264107, 0.12859687341953596, 0.11669235055638805, 0.14372261537904996, 0.13382737438950787, 0.12975544184083354, 0.2247077218556498, 0.17988989264932065, 0.1411061828368243, 0.1310310074857527, 0.2704125728873735, 0.2759220706608053, 0.14826900621514016, 0.22082731698273106, 0.21050292962968375, 0.2532786188148747, 0.20553004644098372, 0.17219086071121215, 0.22691069306268463, 0.15859231670144125, 0.16795748806769606, 0.16207435626819666, 0.16664527768735227, 0.21440166877116662, 0.15400565161479718, 0.16273371297635497, 0.18010247876269836, 0.16761059565819092, 0.9668783998697159, 0.9823746578788837, 0.11495384208162829, 0.1545661726976021, 0.2018205479564853, 0.11708926991107582, 0.14303186425022463, 0.16625113949022396, 0.1675705923879044, 0.9741174397654508, 0.21440381954156096, 0.07361336451012068, 0.21340981263444758, 0.16923327753678152, 0.9553543691279255, 0.113166173907016, 0.10461417913504278, 0.12853901587298022, 0.16440560467276277, 0.21011132699215573, 0.19573959128146257, 0.16218249896658732, 0.19342522028214215, 0.20650462169979045, 0.24400311035344913, 0.20726241653449484, 0.19283280086674515, 0.074337323289139, 0.09833679308240029, 0.10743074307515477, 0.0562253231510611, 0.11235598782230505, 0.09025057586448326, 0.05590662212230202, 0.06702123856691511, 0.06825882202106737]}, "mutation_prompt": null}
{"id": "3037be72-9810-4c67-bdb4-4ead456983e0", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.45\n        self.gamma = 2.5\n        self.mutation_factor = 0.85\n        self.crossover_rate = 0.85\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM", "description": "Enhanced Hybrid Differential Evolution with Adaptive Nelder-Mead and dynamically adjusted parameters for robust search and convergence.", "configspace": "", "generation": 18, "fitness": 0.353172903593568, "feedback": "The algorithm EnhancedHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.33.", "error": "", "parent_id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "metadata": {"aucs": [0.2591562574625609, 0.9803197942508957, 0.9222912157726111, 0.9730074656097736, 0.9765518173202675, 0.23910046455312317, 0.9698669339593438, 0.9689594839532258, 0.9771684470329776, 0.19041933509573006, 0.610069002163449, 0.6339211325232492, 0.6716508469609812, 0.8117457018935739, 0.07149011486477741, 0.8343680913872994, 0.7924757847921028, 0.8265412996293202, 0.09388077801609651, 0.11335706100686715, 0.07114994735824254, 0.07896290234850278, 0.04940305737798467, 0.06924095515715123, 0.09474930306939655, 0.06484297172324827, 0.07617754230918761, 0.06470687667291364, 0.057670680740634306, 0.05781681762006119, 0.10849437810778073, 0.027371447920954584, 0.009785620282485086, 0.03970901964701823, 0.04403052096490323, 0.03329827595791213, 0.989793708042899, 0.9848903617305268, 0.9641283195969335, 0.989108429028908, 0.09962772092714711, 0.9800648183058028, 0.9899545969894882, 0.9899577055205614, 0.8924608554106701, 0.18393880831456544, 0.20252887690336752, 0.22900397920422255, 0.2571883012641365, 0.1556450799664577, 0.04544759712312296, 0.32476171421189215, 0.08920200981406601, 9.999999999998899e-05, 0.13827054201741573, 0.211896059704624, 0.11854746866958266, 0.1815163198697004, 0.13631719024738287, 0.16694398061487992, 0.16750483064746113, 0.15082184637188345, 0.10315649956095607, 0.9049669895710986, 9.999999999998899e-05, 0.13721445397799492, 0.9052053999247744, 0.8948757724930023, 0.8210074304286648, 0.9110361575472367, 0.9035264394732604, 0.9552485018998493, 0.9441904126468793, 0.8835434633821697, 0.9181193807319656, 0.8393274595329956, 0.1299297458707961, 0.13801865997567364, 0.9289799185442493, 0.2549898214690336, 0.8556542818047191, 0.4233793360781436, 0.09950123940846989, 0.19480352030420023, 0.5685840616758224, 0.5745849081362235, 0.021360838077483457, 0.009644933456432359, 0.5836827147324284, 0.20617184874564487, 0.1201328739840134, 0.5873905770500778, 0.2354131241600147, 0.3359341083354177, 0.6395742346184217, 0.03852626439189466, 0.777559084904597, 0.5235229053302336, 0.06931261397672828, 0.8237963725515834, 0.8088714104958901, 0.6386828446173034, 0.5673658922952913, 0.8207233593865514, 0.4601246850024314, 0.8350133954246121, 0.6597873951485642, 0.6945395245365855, 0.73359544266441, 0.15737211805785412, 0.3416983954566496, 0.21959920909273856, 0.19314090822801877, 0.06844379838537384, 0.15855890364288006, 0.12519922722248888, 0.0927643406989147, 0.90164950375055, 0.9504049817940845, 0.9403134769689316, 0.33374408711461834, 0.9627613225068555, 0.9484893457710701, 0.9187281141677706, 0.9632513856468858, 0.9307526709439682, 0.03833255154563542, 0.06280391408071828, 0.11404668146318908, 0.07134321324100024, 0.06957412832769883, 0.12088718189759207, 0.10301269547421266, 0.09812097813186682, 0.10955615949877406, 0.18004579604264004, 0.1406905698041765, 0.16187613420245894, 0.26496291065356425, 0.20131862820595658, 0.13779794454491345, 0.2034011651478771, 0.19769256316496953, 0.1294076626982349, 0.15733465330114793, 0.18849936044387527, 0.17737279081233615, 0.16395232433914064, 0.14102810005788635, 0.174804432062862, 0.20821839806844789, 0.20971188362951165, 0.20267575111408642, 0.1489342290593979, 0.25775279579691324, 0.17193551069172663, 0.17895167582098204, 0.10673992002397259, 0.2574796531290612, 0.1449829911274645, 0.1354075633524099, 0.1386062261766252, 0.2509511409006724, 0.21593144628143723, 0.23368201725903426, 0.24357816470515326, 0.2837673537150286, 0.2755652794480261, 0.2864171509095562, 0.22814671715743495, 0.19302131237344045, 0.15851932580132067, 0.16513166563887915, 0.15649506782559242, 0.1607733104376784, 0.1813651163192922, 0.15407174004037372, 0.17552070467554026, 0.19285493277036025, 0.15908082971789994, 0.9656734121280508, 0.9792496208131065, 0.11487191941556862, 0.15448660177079654, 0.20177269295803557, 0.11696433751423141, 0.1431844469421445, 0.16462611760390877, 0.09446963161822075, 0.9707870818145771, 0.21365833201322815, 0.07361505447444883, 0.21289931263855588, 0.16924441776147048, 0.2124287621950529, 0.11311453529590487, 0.10461766788401416, 0.12851624418686292, 0.18204192980300604, 0.18640628092694667, 0.2237064134368696, 0.1614767557882042, 0.17533366492254931, 0.22493335870662268, 0.23540166882725566, 0.2174253663590734, 0.2504534821764901, 0.09557157821847928, 0.10350205974352322, 0.08726410759281111, 0.09741099932576158, 0.07719840157861091, 0.1026449320914753, 0.0485540733541564, 0.1067517146689152, 0.10004323277296934]}, "mutation_prompt": null}
{"id": "cdd635fc-e288-49a2-a43b-df0592018284", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for better diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.9\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM", "description": "Enhanced Hybrid Differential Evolution with Adaptive Nelder-Mead leveraging dynamic fitness-based mutation and crossover rates for better exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.4377694057231935, "feedback": "The algorithm EnhancedHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "81ba0964-a41e-4882-ac87-38e6aabdbc2c", "metadata": {"aucs": [0.9765567015779058, 0.9772801989641262, 0.9794774045664253, 0.9765108022336558, 0.962854360533921, 0.976547195448076, 0.9725028292267196, 0.9670229113168569, 0.9654504307024038, 0.8807235795242215, 0.9353058450380384, 0.08186868848925988, 0.07056007685695131, 0.9290557031781972, 0.9366027755310461, 0.05646861280318349, 0.05695070023066495, 0.9571364549620138, 0.10131169928512807, 0.0989885624754957, 0.08144854341090468, 0.07151021899052434, 0.0492654572659762, 0.08445139317000672, 0.04194490422610486, 0.12059758612769933, 0.11357519218512702, 0.0734960730496288, 0.0650947068257528, 0.0496058499663814, 0.07115237490175441, 0.03443343544096422, 0.02585081913061238, 0.05177885809023952, 0.03638757404170134, 0.04059188273999881, 0.9105373152138039, 0.9479712352494916, 0.9895017940124192, 0.9609761843010647, 0.9308454481575252, 0.9632610413405357, 0.882709115564886, 0.8622244075056464, 0.9377927954602706, 0.8245152914531721, 0.872215168299906, 0.24373816913219326, 0.17897995386585697, 0.11791749382614247, 0.6677792453558576, 0.7219466698462114, 0.08856439324080079, 0.6541465956811322, 0.2121608551832267, 0.17723866029855584, 0.1721250406475736, 0.1581574610852584, 0.1090923695976811, 0.3958728181463401, 0.1089789554727264, 0.1332766420251399, 0.15229072899080387, 0.9543095765821421, 0.9440699831311077, 0.9430298420677843, 0.005710813623775679, 0.939241998888033, 0.9207823405147549, 0.14864921685935895, 0.9040540690557691, 0.9516836772662207, 0.9525752056278088, 0.9149898419161111, 0.9399770692786822, 0.9128249195944914, 0.9245777009833632, 0.1380144514194258, 0.9565711199176387, 0.13795274588137107, 0.9140653369894481, 0.9059015843355336, 0.9266052106006395, 0.8500598007596096, 0.9342002912107048, 0.9303807266222786, 0.862274693113896, 0.9381552538130826, 0.8773142333468109, 0.17427988197871525, 0.8776428618296719, 0.9115944753787458, 0.8901946973937515, 0.10776002561476439, 0.8717481666884888, 0.9325237221843483, 0.8697154864014508, 0.8415524207097611, 0.8698696777688071, 0.8563141136850272, 0.8738807435414204, 0.8498290645531753, 0.9322312344313936, 0.89024786904503, 0.9170798737392355, 0.8861852077644017, 0.872491301934532, 0.8860244956147956, 0.7691357691803382, 0.3128671925597234, 0.7677821457687987, 0.16550385270123336, 0.08081071100313453, 0.05771433139275883, 0.4363673180743617, 0.7075400905399486, 0.11030144892673821, 0.9705660413882441, 0.9598555934189046, 0.9694156226965978, 0.9584172572130558, 0.9601366929020003, 0.9631745053325135, 0.9600873519922978, 0.9694269137333558, 0.9646969106001534, 0.0714071781188037, 0.08410354369387973, 0.073820001527925, 0.07066778381029615, 0.049008177473640724, 0.10503726846591965, 0.0650845532674541, 0.057889379040619526, 0.0717456349663731, 0.18067924304806382, 0.10928228071622648, 0.16497104158233944, 0.1362657793189792, 0.20417494395765157, 0.16231917424929054, 0.1702200300318265, 0.1196145227058445, 0.18115503883764772, 0.18316157424019552, 0.17555545367714553, 0.1900639948995665, 0.17048076190710548, 0.17048032008401237, 0.20727519725330135, 0.19503486987193208, 0.2108247278292832, 0.2711907410027353, 0.12365644171329315, 0.11097273901970384, 0.11447586131358767, 0.15093092470581682, 0.08444537566784638, 0.11170812759642579, 0.14518984273541813, 0.15644018304626206, 0.17882273735671061, 0.2962981613865361, 0.21344167017358795, 0.18408107047515965, 0.23829051336359885, 0.18559868275959446, 0.19074647896034536, 0.19916343376020007, 0.23027825628050613, 0.2716805976846798, 0.1620891110952425, 0.17801876529565108, 0.17913044866640682, 0.15387155687910814, 0.1636066735999, 0.18445386467293, 0.18000918138486544, 0.165163631767812, 0.17285740803217142, 0.18859232294515105, 0.12195853274002366, 0.154316933385098, 0.9804140264587708, 0.20206774737867494, 0.20113205658705713, 0.14291454863066533, 0.165398768823813, 0.9790455129532607, 0.9737391016860366, 0.21393850221155597, 0.07360533375333811, 0.21306982504341765, 0.10978251361043423, 0.15703020327987616, 0.10509506209240083, 0.11007932132112475, 0.9606046170062305, 0.20845644238386052, 0.1827485843515827, 0.17452478939826, 0.2401519115096371, 0.22999936763682027, 0.22647792203886763, 0.21425714927958106, 0.19103122652367188, 0.2104966344364806, 0.06470576764233915, 0.06698371970111838, 0.06958655461544183, 0.09761680712914189, 0.12259869297742587, 0.07186652425828122, 0.05060216077738611, 0.07686865641292784, 0.061385815715216285]}, "mutation_prompt": null}
{"id": "f98e015f-05d3-48a8-b3ca-15fdf68908fa", "solution": "import numpy as np\n\nclass SynergisticDE_ASNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Adjusted population size for computational efficiency\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.5\n        self.gamma = 2.5\n        self.base_mutation_factor = 0.7\n        self.base_crossover_rate = 0.85\n        self.inertia_weight = 0.9  # Introduced inertia weight for enhanced diversity\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit) + self.inertia_weight * norm_fit\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit) + 0.1 * norm_fit\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters and inertia\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead with elitist learning\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "SynergisticDE_ASNM", "description": "Synergistic Differential Evolution with Adaptive Strategy and Nelder-Mead, incorporating dynamic inertia weights and elitist learning for enhanced convergence.", "configspace": "", "generation": 20, "fitness": 0.36977445670386155, "feedback": "The algorithm SynergisticDE_ASNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.35.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.9769650378580236, 0.9770350103552744, 0.9285679661322739, 0.9799187587927031, 0.09277732647521386, 0.9664120919237223, 0.9794993696621401, 0.9646489106471046, 0.9805319379500962, 0.6632201159389652, 0.8126451680418303, 9.999999999998899e-05, 0.865559747134615, 0.9084710181339678, 0.9425940025405748, 0.7957486867096368, 0.05683134301538795, 0.913185032342517, 0.12085097414029933, 0.11383535733588523, 0.09120228593215174, 0.11117867895325251, 0.05809248217243823, 0.080817806599494, 0.06526392613758292, 0.10342587464690967, 0.0739713939861042, 0.08751828134213446, 0.08629543381456262, 0.04177452105616253, 0.08405006833830775, 0.07148112195622092, 0.10342101178252272, 0.04060747391689279, 0.034116035413429335, 0.023044191088765542, 0.9719499994097727, 0.9356764494329031, 0.9768181682355151, 0.982927790213469, 0.9345361192199487, 0.9903561412682169, 0.9149496681998729, 0.8868422997420018, 0.9187921073106442, 0.2259325310026591, 0.15674343267782753, 0.1882406885896979, 0.29851885325512817, 0.16355717158363348, 0.6178466520206938, 0.1343550537309518, 0.541325982104234, 0.20713181106159206, 0.18091419238246054, 0.133752721532025, 0.14358066239342404, 0.14860993135073763, 0.24401663058551282, 0.16325205022501554, 0.0655838608774657, 0.11931228496185764, 0.1277460604645716, 0.9570386650517211, 0.301101206265747, 0.1773298462285735, 0.9252381973334061, 0.1377092659250322, 0.1346695003592795, 0.872442389982758, 0.1381960075881209, 0.9439065160920334, 0.16356577873839873, 0.1356467957032217, 0.1383380315672852, 0.9232006832516146, 0.9293025832137091, 0.9290916647030627, 0.18640230374890288, 0.9405855718547704, 0.918150397175103, 0.07552526225680467, 0.1260355060843782, 0.8622716855977134, 0.7209462461992706, 0.9354481561189206, 0.7570531296990304, 0.01195640045332147, 0.045637984929417286, 0.9066540809178522, 0.8526764851813223, 0.06357730838288156, 0.8805950224786191, 0.7752221589096306, 0.184982695319851, 0.884337251765515, 0.8510188953249292, 0.8658250179691411, 0.7780205395853108, 0.9131004694372556, 0.7823434370044219, 0.8432515282299828, 0.8893478273968183, 0.6386866243762805, 0.9138226360562064, 0.7921719686915183, 0.7573624041325021, 0.7898237666666456, 0.23195968952125445, 0.05045549020248985, 0.040671759775376626, 0.00737061448994103, 0.059524399730019883, 0.4173724328307832, 0.41761365414189644, 0.05813074242521599, 0.1481037370567052, 0.9552418149046255, 0.9477086376849264, 0.9590202713598815, 0.9491976479144734, 0.9649774799686575, 0.9728435800139349, 0.31317395738275067, 0.4867441848026922, 0.9628813738087207, 0.09498135132390906, 0.1084469050647473, 0.09899282460575798, 0.09497514598602042, 0.05648957579242886, 0.10349610444866408, 0.09912957346288565, 0.08469415906832733, 0.09932238866135068, 0.21444571500686982, 0.11062404704133444, 0.1313756942544294, 0.13463899562919446, 0.15479258222963177, 0.1191590377301065, 0.17800488691012595, 0.18132141905367116, 0.15317178893271544, 0.12739162944078197, 0.2620402816680363, 0.15798680887321648, 0.18732619689184116, 0.14939445572552523, 0.16392774795991605, 0.15914850501144917, 0.2588183332932299, 0.17107691751497767, 0.11452520949477352, 0.1548317101127692, 0.12742787168524372, 0.18169873368288836, 0.1272018833189673, 0.1922019995840082, 0.2672948455270079, 0.10750991060763171, 0.07444289046978325, 0.21311546096500789, 0.19831725380098897, 0.14832755103464224, 0.2901224041522783, 0.20355286864682243, 0.20892963602944514, 0.24021282886986606, 0.10800232738687665, 0.16347245599142135, 0.1680660423949717, 0.1640321433385823, 0.15953810978061667, 0.18264988865931941, 0.1865029066576902, 0.1572615107929558, 0.1723107686591513, 0.15885273556475565, 0.1585546639756592, 0.1685389915464215, 0.1270927886177433, 0.11334201733882343, 0.9708455084659692, 0.20205694614431546, 0.20048030768045866, 0.142387254076196, 0.1185844369614859, 0.16786984814287131, 0.37973479765544493, 0.1611336617539102, 0.10289105981029678, 0.10851985372508677, 0.1695340169917674, 0.1562264651830727, 0.16927118158876586, 0.16925765867549436, 0.9672668194293816, 0.1978597367724918, 0.15560892090059786, 0.21523429511842995, 0.1971818455817761, 0.1878541719504938, 0.17571787391782767, 0.17540034065654142, 0.23009918843318167, 0.213196659618055, 0.09401364707737925, 0.10842702674401039, 0.08262578873555737, 0.0780608139162321, 0.08447831470167388, 0.08954020779337368, 0.0745113416356844, 0.05920659660520955, 0.11157346326117845]}, "mutation_prompt": null}
{"id": "1c55c586-5527-4c60-b049-e7d863954141", "solution": "import numpy as np\n\nclass QuantumInspiredQE_HDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Adjusted population size for quantum effects\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.3  # Modified alpha for better reflection\n        self.beta = 0.4   # Adjusted contraction parameter\n        self.gamma = 2.1  # Enhanced expansion parameter\n        self.base_mutation_factor = 0.7  # Slight mutation factor reduction\n        self.base_crossover_rate = 0.85  # Adjusted crossover rate\n        self.quantum_factor = 0.1  # New quantum factor for state influence\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def quantum_superposition(self):\n        # Generate new states based on quantum superposition principles\n        return np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim)) * self.quantum_factor\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Quantum-inspired update\n            if self.func_evals < self.budget:\n                new_quantum_states = self.quantum_superposition()\n                for q_state in new_quantum_states:\n                    if self.func_evals >= self.budget:\n                        break\n                    f_q_state = func(q_state)\n                    self.func_evals += 1\n                    max_fit_idx = np.argmax(self.fitness)\n                    if f_q_state < self.fitness[max_fit_idx]:\n                        self.fitness[max_fit_idx] = f_q_state\n                        self.pop[max_fit_idx] = q_state\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "QuantumInspiredQE_HDE_ANM", "description": "Quantum-Inspired Evolutionary Algorithm (QE_HDE_ANM) combines quantum superposition principles with adaptive Nelder-Mead and Differential Evolution for enhanced global and local search.", "configspace": "", "generation": 21, "fitness": 0.2546233584206164, "feedback": "The algorithm QuantumInspiredQE_HDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.26.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.7725747531104896, 0.2249856989498885, 0.842308537930931, 0.9444624758086233, 0.8807123966631958, 0.9634644125387207, 0.8991030990190184, 0.9405149628872609, 0.9643332352154653, 0.39407150459677953, 0.26576266193515885, 0.10081449654478258, 0.09407644269120408, 0.12427072051479304, 0.08098222080942141, 0.1265948361669358, 0.06875377396611693, 0.08534442605659276, 0.056307118046406535, 0.05027350840622857, 0.07252477136154245, 0.15065311261407455, 0.056010781333682313, 0.06496595797717652, 0.0782867880238991, 0.12230783980615578, 0.16648479912089165, 0.04114484727447376, 0.06731256021388998, 0.04640565097467586, 0.04362151527650626, 0.01403045215719978, 0.026373479425373936, 0.048898756460023285, 0.012864865867032282, 0.025701730402141743, 0.986268904298808, 0.9871751328636893, 0.9873711225299403, 0.967951115787909, 0.9132715536875654, 0.9879234339966568, 0.9593059294167241, 0.9399368032109557, 0.9876548558529168, 0.089407940558629, 0.08802123918877969, 0.05156584543910281, 0.12724582665273187, 0.14636760766253065, 0.08928750965466747, 0.08921347018428571, 0.14488967002287279, 0.12277659503054872, 0.1329595321739997, 0.13238056710253965, 0.1319538227750907, 0.15730527368319802, 0.10760727410063886, 0.19067700285976474, 0.06145673550171016, 0.12736765653477145, 0.13053075922790935, 0.7971348460534332, 0.21496494114741627, 9.999999999998899e-05, 0.5984113616128157, 0.28156559582914065, 0.13470182732718639, 0.6527168828637366, 0.12464511821531121, 0.6622287503129554, 0.23040985892045907, 0.22507742816382648, 0.7533231767113001, 0.8066739964742851, 0.18592726313519092, 0.7927163727179284, 0.7928789956682409, 0.6932609835550776, 0.8368000327307812, 0.07336639389246935, 0.11271540929675716, 0.40119760520857795, 0.011393835223580617, 0.05549822405613991, 0.19230548100192457, 0.09612047222728393, 0.2171423165083013, 0.24296694091588944, 0.19354092737088613, 0.26024168990860386, 0.14801099322127742, 0.11047889409921896, 0.2547889100304864, 0.07499385927657454, 0.23542692430307333, 0.17692058230717833, 0.23808232779612049, 0.26719536530241406, 0.3556896791316311, 0.06835672589028075, 0.6740813581478652, 0.2921955651806255, 0.36572932136608316, 0.36027158436420637, 0.1278956980851379, 0.14792987536548585, 0.1061475146356754, 0.3095739397015833, 0.11143593233702509, 0.034259858027066215, 0.25026533705493426, 0.37001040978672073, 0.11055271963954016, 0.24267025195564107, 0.07583285522750027, 0.869992171858953, 0.612920888788966, 0.22431758392999845, 0.6818143571124379, 0.1380744237319952, 0.1751172310553416, 0.25897577121116166, 0.16879725037270732, 0.2586551180365362, 0.08127328761214592, 0.13742818009873914, 0.1201410937741515, 0.09359188325881151, 0.06161310407882847, 0.10707364030183675, 0.08566522446349933, 0.04765694788240815, 0.06262659227278544, 0.11219843139382557, 0.15602071914508686, 0.15539938072508153, 0.15800380339341924, 0.1289171745044474, 0.12300886664068678, 0.23381468108835546, 0.11246668308262886, 0.13960459910087608, 0.13294936682966785, 0.1540176663692837, 0.17206981474236982, 0.18425601285020643, 0.1717699419045461, 0.16684240424270846, 0.177919001094214, 0.2136852223753254, 0.1766975224464994, 0.07819074098254242, 0.0898216095846317, 0.1256997784534971, 0.10912494241423554, 0.13601819978443486, 0.13443576079853847, 0.14008187838214836, 0.11447351519450544, 0.15603941116664988, 0.3367268551186807, 0.25977779401347, 0.33646588652955756, 0.2656917406857616, 0.30406248037017736, 0.39645883650311253, 0.3283294419032057, 0.282575997980257, 0.21942852686066294, 0.17381853212383447, 0.15533695935632863, 0.1725698256295678, 0.16500741815857578, 0.15482326843622263, 0.16465686144619884, 0.20302882101701758, 0.16581238201867676, 0.18067392313923503, 0.18792826935536688, 0.17870503127460102, 0.15011725533018871, 0.18926530125709795, 0.20142266455329239, 0.19321153143764835, 0.14254500308485563, 0.1700090708378822, 0.12982570162863816, 0.300637842817322, 0.21335173930960805, 0.07314803960792693, 0.6319305443542749, 0.16665406704329777, 0.15117818560365615, 0.10234733700932608, 0.10445254333242882, 0.10983460522427246, 0.22685691709493871, 0.1662750677750109, 0.18909573950244496, 0.21814326428704112, 0.21628120499687897, 0.18523398343119424, 0.23382952810943425, 0.16623441853703047, 0.18095460495740523, 0.036817756456955064, 0.04837124465999387, 0.052516978967619976, 0.04987871731436244, 0.09838725665762482, 0.047596546060571066, 0.06494550362372231, 0.05383198928733668, 0.05832695482110162]}, "mutation_prompt": null}
{"id": "272136b6-44b9-41d4-a89c-6ee349c9d5db", "solution": "import numpy as np\n\nclass StochasticHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim  # Increased population size for better diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0 + np.random.rand()  # Stochastic adjustment of alpha\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = np.random.uniform(0.6, 0.9)  # Randomized within a range\n        self.base_crossover_rate = 0.9\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit) + np.random.normal(0, 0.1)  # Added noise\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "StochasticHybridDE_ANM", "description": "Stochastic Hybrid Differential Evolution with Adaptive Nelder-Mead employing probabilistic parameter tuning and diversity promotion for enhanced exploration and exploitation.", "configspace": "", "generation": 22, "fitness": 0.37624566897473677, "feedback": "The algorithm StochasticHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.35.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.21047668401401531, 0.9588780665137551, 0.9663192730792994, 0.9650547185773195, 0.9692785709641423, 0.9644101934128746, 0.9621371733134413, 0.9775830777710373, 0.9739140566415642, 0.8183878496360949, 0.04332317634393856, 0.8865097097271253, 0.7489813326278172, 0.10021899447089855, 0.9495207095125423, 0.5470543195813337, 0.8860250565777393, 0.06322863962617409, 0.03636074190360128, 0.08441363238067645, 0.04295724678450119, 0.1205003018721238, 0.08766764295980889, 0.09105446187277577, 0.06498741832967025, 0.12042759729979002, 0.07884581184617512, 0.02282242493551634, 0.13687597381986782, 0.037449533006377766, 0.06902355806329996, 0.07356061607391862, 0.03174040642742826, 0.0782344832966323, 0.04211203608464131, 0.05184299136120629, 0.9375692679509218, 0.9850500700665138, 0.9307698140057263, 0.9889468061327296, 0.9878661196204556, 0.9041622179631456, 0.8951760740501932, 0.9851149461342706, 0.9632500629785629, 0.3467647976018178, 0.5647291884818098, 0.1916041336305272, 0.20937781231709096, 0.41309449903302775, 0.7955105488271841, 0.12722471049821527, 0.08884178575836177, 0.20930785162277254, 0.18743931307811212, 0.2284700478207039, 0.21822081801621473, 0.1329879367525364, 0.21558308794080727, 0.1744691525441544, 0.06891578071378368, 0.1508809806083875, 0.1521471431380692, 0.900256673723767, 0.9246342594565725, 0.13833232903573534, 0.8995664715653898, 0.11056333737123736, 0.9197702101203604, 0.9193027646611056, 0.9317972567238741, 0.8991816195991555, 0.13791033885949744, 0.10473461767996506, 0.9507564240252229, 0.8947213623071957, 0.8983368358863123, 0.9296564165158576, 0.9123322611722526, 0.08127495234813065, 0.9211324867312933, 0.14592949407965372, 0.743811976268267, 0.09912245014680265, 9.999999999998899e-05, 0.8443123348693634, 0.7873789257174497, 0.14353475168425267, 0.93482865076134, 0.08886524061304868, 0.09147822432630914, 0.9261713748071482, 0.2381013179265158, 0.2135293317431881, 0.803767408126384, 0.919614866144473, 0.7629084171126023, 0.898039696072608, 0.8633850158061394, 0.7235719195436319, 0.8407193544253365, 0.828162728032526, 0.9068428190291966, 0.9328529986493235, 0.9499138460055552, 0.6818257540195574, 0.8938115375251036, 0.8863075203347863, 0.11825947629596101, 9.999999999998899e-05, 0.8956371646261744, 0.04066752307190258, 0.6681982188730189, 0.45250910288021073, 0.0767407840543769, 0.17698208252821845, 0.09851352428234628, 0.916545393587784, 0.22966427164630532, 0.9668366632311011, 0.9166889299371329, 0.9630378968919744, 0.962737085257218, 0.9339198263199834, 0.9556857129440671, 0.9607072525577132, 0.09838643353251753, 0.09865927147381282, 0.12727589531194883, 0.0736868833678147, 0.08778709955128527, 0.07385928963715505, 0.03262148930526787, 0.09449657070928497, 0.06947100701082587, 0.10068579669786182, 0.210665142149138, 0.18427424515704516, 0.28489031681642574, 0.1343002675239977, 0.1419453064247438, 0.14930864518021114, 0.13695555370693835, 0.187810609817592, 0.16615474512780015, 0.160228319452415, 0.1672401379159072, 0.19433170706984848, 0.16031039954955906, 0.1568314667040066, 0.2505005422396622, 0.19138550471506355, 0.17474543044969937, 0.08629815751537384, 0.0585199650662962, 0.1263737218048704, 0.16430377654798145, 0.0931300386013596, 0.15730456017431027, 0.10734093941582956, 0.11966303196589378, 0.12359274906579654, 0.2405190849927391, 0.2543935999318989, 0.2154183707417805, 0.25282181780229207, 0.17750021271438277, 0.16454091452961106, 0.21158083432078412, 0.21805209580003082, 0.21247225857868934, 0.17891257061512622, 0.17326911374593434, 0.16945536883576862, 0.17010373253741495, 0.1736443092150004, 0.17680531236239327, 0.16571518881098513, 0.169043252865117, 0.17387399707669215, 0.17755707039544033, 0.12668693267459907, 0.154341635453778, 0.1661151783782432, 0.20163936351979161, 0.15219246433526679, 0.1432733601564884, 0.1662610434160322, 0.120634783702678, 0.19019827838501602, 0.21435071266230088, 0.07360613281799888, 0.1544035127134975, 0.16835115977433524, 0.12828366281687353, 0.10494876548273313, 0.10492624224249758, 0.21354199021120357, 0.2075976929615585, 0.15735859296910804, 0.21472735809000798, 0.257599622729636, 0.2814699098099621, 0.19334428005979376, 0.27687062780551974, 0.21282024020890866, 0.26305559224907316, 0.041261886752156585, 0.09656605326576428, 0.08801279440255572, 0.07472693046701717, 0.1135833207315724, 0.07763708356156929, 0.07318023568864207, 0.07094428217302085, 0.09130572471212639]}, "mutation_prompt": null}
{"id": "d9c8bd88-5b17-48a7-90db-96023abb5b7d", "solution": "import numpy as np\n\nclass HybridDE_AdaptiveNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Slightly reduced population size for faster convergence\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.6  # Adjusted contraction coefficient for more aggressive contraction\n        self.gamma = 2.5  # Slightly increased expansion factor for better exploration\n        self.base_mutation_factor = 0.85  # Adjusted default mutation factor\n        self.base_crossover_rate = 0.85  # Adjusted default crossover rate\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit * np.random.rand())  # Added stochasticity\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit * np.random.rand())  # Added stochasticity\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "HybridDE_AdaptiveNM", "description": "Hybrid DE with Adaptive Parameters and Nelder-Mead using fitness-based adjustments and stochastic exploration for enhanced convergence.", "configspace": "", "generation": 23, "fitness": 0.42118887290105095, "feedback": "The algorithm HybridDE_AdaptiveNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.9787065318144197, 0.977784562929778, 0.9626750398036092, 0.9738651821092011, 0.9766392643823459, 0.9786632766746411, 0.9734368816876735, 0.9773008136760636, 0.9713364445978272, 0.9091399274361823, 0.9015508497924847, 9.999999999998899e-05, 0.8813817088921192, 0.9139770894659659, 0.9106785450157581, 0.8623082192193016, 0.944028199968517, 0.939009924103577, 0.08463805488459275, 0.11419261317234908, 0.12818065941738022, 0.054685230370199345, 0.08747281752459224, 0.030910765036825216, 0.056584193922768256, 0.07165091587293682, 0.07387438341294306, 0.1473264821643594, 0.014318855931010899, 0.03002869805540398, 0.08469130902971234, 0.07876484406328677, 0.036435738596337086, 0.09807501361374893, 0.023397883464105873, 0.08144199918511008, 0.9635956694493372, 0.9778102642706527, 0.9753981358824265, 0.9887384723813103, 0.9076010457005869, 0.8991397026174074, 0.9894876126602058, 0.9414941511374135, 0.8658619843085211, 0.9243430508234076, 0.9033142486388255, 0.9132162433148061, 0.2962416674965942, 0.8898697379450504, 0.9483427631598332, 0.26893084516639587, 0.776401588176426, 0.7802355134176938, 0.14166440565040417, 0.11740883029762061, 0.2524261580262379, 0.2156116991860666, 0.06896936139759968, 0.12681325627564477, 0.14218710422931913, 0.10610582035341776, 0.23966541311601297, 0.9337579288381083, 0.1385018275076716, 0.9211478549530724, 0.8943455622866968, 0.9305583215420745, 0.13770910895720812, 0.13852725484813544, 0.9510303032676263, 0.9416451529705226, 0.13163030202331394, 0.1384729530563511, 0.946693081585177, 0.2409689123089196, 0.12383898604277366, 0.13773116259462537, 0.9337115621013826, 0.08624638595826495, 0.9042893966259915, 0.8760042181272313, 0.9400576289013767, 0.8168957189690564, 0.8884853313581392, 0.900927534343666, 0.8202697102752168, 0.3553337770283115, 0.9416417013786227, 0.853163497341928, 0.8761638918132207, 0.7912566096909939, 0.880821745674032, 0.9240655667863795, 0.8593458404967839, 0.20900507793133916, 0.8438455638883221, 0.8780846238999871, 0.8225574671291128, 0.20444207248894164, 0.8647351496317526, 0.05611582688612127, 0.9128029887277833, 0.9263761738488068, 0.8466130920634823, 0.846757567180879, 0.8813023359336071, 0.8411836121381332, 0.6987325585058091, 0.13895209513238282, 0.6696667578921128, 0.07596790750630933, 0.2281112590470723, 0.4054403916224376, 0.18743365648735566, 0.6110515279261887, 0.1279245070782299, 0.953564703975129, 0.9652266877966299, 0.9570159007053777, 0.12761979418157465, 0.9646672975591705, 0.9594898265591466, 0.9681085852191208, 0.9506738235538236, 0.9621381726439574, 0.07074191144209141, 0.05779355244240103, 0.06536294392612596, 0.07906146348838883, 0.05498567710894253, 0.07875204110639022, 0.1085120232242518, 0.09899985902369102, 0.13858797657688482, 0.18248869304452442, 0.12380865420020182, 0.17865095660864116, 0.15904341927769816, 0.17810297397856922, 0.20501894437980528, 0.1599222336156335, 0.14153160608016502, 0.14875979284420426, 0.15654790704289012, 0.18344908459527842, 0.1669935705631036, 0.1633565862436872, 0.1578682710175261, 0.13396879703839626, 0.14860973616768947, 0.2968841678224744, 0.16030797919247963, 0.08254293933474488, 0.07516073060180939, 0.10128903514678333, 0.13263901531051492, 0.10327354775629305, 0.07320305379267777, 0.10784111929078577, 0.1930414237757332, 0.14512972652727063, 0.1452455728830948, 0.1972056029575079, 0.14839009189352526, 0.151716936576331, 0.1518021505299897, 0.18753054757153098, 0.19185842749350346, 0.1611372779394209, 0.22849189348050636, 0.1998446970726352, 0.158717697004764, 0.15930588983471317, 0.16901176721809152, 0.1802071515310537, 0.15549345317498176, 0.16686092288261078, 0.1824265009416115, 0.1861311816213933, 0.16958563918063752, 0.1100517092754264, 0.11324019085738946, 0.9637008029288283, 0.20192915064745398, 0.17810254726462404, 0.13470666881733773, 0.17029637142193899, 0.21392127068772093, 0.9620988017804513, 0.16867234351038118, 0.9721316485664419, 0.1462331249591432, 0.21324443825969186, 0.15608624341978028, 0.10451266150659033, 0.10479272549040997, 0.08308469029964582, 0.1546452303603666, 0.18223984506013624, 0.18151822635339265, 0.22435528773275282, 0.2227340455062642, 0.2116140563543636, 0.18562206300986894, 0.17409012885705544, 0.24718456839626834, 0.06631436017938452, 0.10429498480078259, 0.0645743749134986, 0.09308350312901548, 0.08189887538891838, 0.06691311610919437, 0.05382847686538894, 0.0798827051352049, 0.09102899424592414]}, "mutation_prompt": null}
{"id": "655fe31a-e684-4373-9861-43109f803177", "solution": "import numpy as np\n\nclass AdaptiveMemeticDE_GR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.8\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * norm_fit\n        return mutation_factor, crossover_rate\n\n    def gradient_based_refinement(self, x, func):\n        step_size = 1e-2\n        gradient = np.array([(func(x + step_size * np.eye(1, self.dim, i)[0]) - func(x)) / step_size for i in range(self.dim)])\n        x_new = x - step_size * gradient\n        x_new = np.clip(x_new, self.lb, self.ub)\n        return x_new\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                refined = self.gradient_based_refinement(self.pop[best_idx], func)\n                f_refined = func(refined)\n                self.func_evals += 1\n\n                if f_refined < self.fitness[best_idx]:\n                    self.fitness[best_idx] = f_refined\n                    self.pop[best_idx] = refined\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveMemeticDE_GR", "description": "Adaptive Memetic Differential Evolution with Gradient-based Refinement combining evolutionary diversity with gradient-guided local search to accelerate convergence.", "configspace": "", "generation": 24, "fitness": 0.3165736268094744, "feedback": "The algorithm AdaptiveMemeticDE_GR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.7962339980446987, 0.7948231458227316, 0.79145776893179, 0.7676088466256232, 0.792152928125113, 0.7751719980645261, 0.7885504593631636, 0.7867598558914393, 0.7641619661135783, 0.5752190742397196, 0.5648333355456092, 0.5669219651703885, 0.5835932937761995, 0.5585791836064593, 0.5650500503982567, 0.5579858449407356, 0.560121801465121, 0.5762545863960606, 0.5815182297307852, 0.5224805097661943, 0.5351226782773577, 0.5634899048865742, 0.5831753078438047, 0.4965740061597228, 0.5281313092224584, 0.5576281110397021, 0.4792732690327336, 0.15820845310087428, 0.5485328603096872, 0.4933291484572696, 0.514088042354327, 0.490945726760588, 0.4451780037466818, 0.4551846911084464, 0.4568305868634661, 0.1687942351822016, 0.9422962459537751, 0.9507572660928965, 0.9426181677171991, 0.9431452239531335, 0.9554017762877518, 0.927895137926973, 0.9101024200029079, 0.9307386481910469, 0.9524986270816066, 0.3378407764789617, 0.30492730892461695, 0.36546571466122846, 0.3108180331466234, 0.2961906190957949, 0.3304673095497045, 0.20791149851058677, 0.21628836333048163, 0.259784041694763, 0.21300087264690037, 0.35177200289571753, 0.3957913148069897, 0.5184986818984587, 0.45915442238167925, 0.4698929046923701, 0.4676038890979535, 0.5957642062345372, 0.3009444085480887, 0.17328054117027603, 0.15747923369451688, 0.22724990139452295, 0.17757176106828088, 0.28562437612799274, 0.1815115886425489, 0.14150194216865453, 0.1528822217240613, 0.1955307816087728, 0.12825066090569248, 0.14341963880890563, 0.1572137994531746, 0.13781090842416055, 0.14049461603146485, 0.17583444499284795, 0.13897994066407682, 0.1339868488590188, 0.1456394046623516, 0.015784313354823665, 0.00133107877580807, 0.002635614849344381, 0.001250073190443124, 9.999999999998899e-05, 9.999999999998899e-05, 0.008366403803662603, 9.999999999998899e-05, 0.0186260834184504, 0.09310406770529811, 0.09410965319269704, 0.11590713428375643, 0.06770455879704607, 0.08456615557390723, 0.09809433966851333, 0.1808636281421797, 0.12213703821086253, 0.08992924021620241, 0.04214974092469892, 0.024344695287946028, 0.034596837904187105, 0.0011385695061424395, 0.019059017684263546, 0.039195638818661394, 0.013456153018021388, 0.01766071642199729, 0.11093974264882023, 0.1321473255048955, 0.13203200230535728, 0.142023531078885, 0.13221653238734377, 0.15401093411657674, 0.1353612325287149, 0.180649276006417, 0.12808563763106995, 0.10721426577217097, 0.4858829459790531, 0.5379924876963074, 0.47837190879442604, 0.4725143656040639, 0.4493111638967322, 0.4593522874747882, 0.4837970530871649, 0.49349710494686017, 0.48850572185077445, 0.10133697137583242, 0.11251763244175106, 0.11533313704682402, 0.10967722120040457, 0.1019813891225072, 0.13159839499123405, 0.11503349786261274, 0.11825322451702502, 0.1282817977003844, 0.16034564459392509, 0.24682546731976573, 0.21728357821656497, 0.150417488711731, 0.23611234968876027, 0.15727516542922093, 0.22685882097389198, 0.2074239496167034, 0.17583074926460862, 0.3295768392546139, 0.33496671628565233, 0.36064917001160113, 0.3364300000283542, 0.3256214359539231, 0.36060816023593256, 0.3838941996706994, 0.4330423352379891, 0.37588661046111316, 0.23085629812556874, 0.22163974881922155, 0.26678198176470236, 0.20771377583587136, 0.20969054672988618, 0.23241454490714408, 0.24158989069812187, 0.2597144659150413, 0.25186174927621174, 0.22662841495159547, 0.19700432812372126, 0.20131721165970884, 0.192201308078499, 0.1942474920329288, 0.19855711226785666, 0.1998171850596724, 0.20019968711654823, 0.22231928668912582, 0.5581709144833857, 0.43726272420581236, 0.4861947898461023, 0.4100932729373148, 0.4049376587978951, 0.5399836056030722, 0.4162362534640289, 0.40240504453811354, 0.354289952780683, 0.27776855740779816, 0.3845626261770748, 0.5675626921090597, 0.6814115972741936, 0.3891018159852839, 0.6096502220471702, 0.1709566376915056, 0.16745365376209342, 0.5971236640658908, 0.4353815248778783, 0.20601878909931515, 0.20136786264577378, 0.3798129072635128, 0.20161795677658834, 0.4132057130578086, 0.1912097090962388, 0.2072200747430366, 0.2865881334111332, 0.1909563132770209, 0.19357961208373387, 0.17749523520084676, 0.1845740414320196, 0.1864642957973338, 0.18681662025090395, 0.1915264270536844, 0.19301966902312628, 0.19333915569814897, 0.08630475378543778, 0.08434699322387718, 0.10092259682230598, 0.095249117093823, 0.08989022133500224, 0.08633043247139993, 0.09137090785175028, 0.0870820456527861, 0.08941568275295919]}, "mutation_prompt": null}
{"id": "679b50b8-3d67-44fa-91a3-4a43a09f94f6", "solution": "import numpy as np\n\nclass EnhancedDynamicDE_SLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim  # Adjusted population size for improved diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.6\n        self.gamma = 2.2\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.85\n    \n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit) + 0.2\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit) + 0.1\n        return mutation_factor, crossover_rate\n    \n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n                \n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedDynamicDE_SLS", "description": "Enhanced Dynamic DE with Stochastic Local Search combines adaptive differential evolution with stochastic local search to balance exploration and exploitation effectively.", "configspace": "", "generation": 25, "fitness": 0.43119330334851824, "feedback": "The algorithm EnhancedDynamicDE_SLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.9754337199612098, 0.9585523987676401, 0.9732936588479092, 0.9622589675234364, 0.9686022392482949, 0.9639190249588776, 0.95867117349288, 0.9630352300222529, 0.9632365415978446, 0.9051845686812183, 0.8877979971344205, 0.9131871437064871, 0.9116922012979553, 0.8869211360031662, 0.940622549857777, 0.9300826135984288, 0.8948870772910182, 0.9387044636293749, 0.07597473041116298, 0.07358123689125662, 0.11359052492968624, 0.07591077269544844, 0.06503622376535367, 0.04294524122002219, 0.09096286613296178, 0.05484108033153612, 0.06322049430279209, 0.02353635159208356, 0.051694669283735895, 0.06499564279328585, 0.04928961387402664, 0.04621505715846974, 0.02069916753501644, 0.0613262808388878, 0.011961311057205548, 0.06083402433463159, 0.9577220396639085, 0.8087086147346156, 0.9622450652315628, 0.7745476587025335, 0.0993175433632657, 0.9243799678695593, 0.9354179609945625, 0.7875859501185118, 0.9874482128861615, 0.6306189589953142, 0.5619404950100186, 9.999999999998899e-05, 0.8342253142739722, 0.7244295264360593, 0.15798027332741826, 0.05190476541911082, 0.13113988235599172, 0.6219634723280032, 0.16736676521157767, 0.12783345518022338, 0.19476188958514873, 0.2517475501326063, 0.15584089449471938, 0.1442512627586977, 0.06631512040222365, 0.09345048941501988, 0.18357830318970647, 0.9257207741688553, 0.9364012783567529, 0.9102495173363158, 0.13517339995507627, 0.894396866518857, 0.9444351612159495, 0.894642467411559, 0.948191238112666, 0.9256028056361976, 0.9025371502668209, 0.12474644359147824, 0.9399301517340873, 0.13752194998618283, 0.9115616380794413, 0.9289945524714933, 0.9230792261562974, 0.9166300195050475, 0.1374685918237738, 0.9193148980483701, 0.8218498328695137, 0.092238095815381, 0.7003985939026218, 0.6163791920532271, 0.72666135558744, 0.8108408218758406, 0.8743775585623228, 0.9273245330668175, 0.8266540711635832, 0.8980970275806404, 0.8716641248623979, 0.8670115491307852, 0.8867668863641516, 0.8955579936874097, 0.8306083291240547, 0.855018303085878, 0.8887069463412687, 0.8691556202276681, 0.8540141296461595, 0.9253438078103592, 0.9078435898127337, 0.8712391261254069, 0.7909309324874948, 0.8633981490507611, 0.78473578041539, 0.9029685926366072, 0.031636238666520655, 0.04674382752441397, 0.04722287249835733, 0.697210365314795, 0.15871328830515918, 0.8266441153522356, 0.14430630686173918, 0.6456055068516569, 0.09616348302263145, 0.21139173569842418, 0.9381085398112078, 0.9585671852868393, 0.9532969524964211, 0.9520724125894077, 0.9576052815294189, 0.959089951274523, 0.9457641586142043, 0.962063818473024, 0.1137922702605163, 0.12796107989717043, 0.09447218814427782, 0.09821914833716239, 0.050236341258430905, 0.11978582487317313, 0.08103701178638034, 0.08718501446046789, 0.07339752734444194, 0.12159609168972563, 0.16890478129086017, 0.1618643244839968, 0.18424489966125246, 0.1344477484722565, 0.22000821973097973, 0.24545174773214118, 0.10580287369232155, 0.1298166300473269, 0.16894313710311926, 0.13154129410726878, 0.21436180872447208, 0.1869972364186283, 0.19101724771959616, 0.15421797946516858, 0.22504555925657654, 0.24524176239275863, 0.1677947164735759, 0.09020687259184179, 0.08715214658007642, 0.16289100286269476, 0.14879183687323716, 0.18336891515858744, 0.12697853284944216, 0.19342229240915854, 0.1650248130280899, 0.15314658869551712, 0.2876589298326412, 0.18880259043099612, 0.1480634794976119, 0.1690900442501787, 0.2156889968221607, 0.19675192004732367, 0.1974630014676061, 0.20468672896454476, 0.2163240459051743, 0.15796576186808708, 0.15740780000313048, 0.17727904196423971, 0.17927031992933373, 0.16199496499792954, 0.1770856875082636, 0.16670572451722998, 0.16637071827658767, 0.16256510823737458, 0.18826419837177144, 0.1887689753862669, 0.16833764195687073, 0.966056116836033, 0.20137466177388874, 0.20056281922543073, 0.14319819273561973, 0.16583390133122233, 0.10868024331680393, 0.43880333951152906, 0.1782357391039162, 0.07359278495198673, 0.10399000545773596, 0.16866658495221964, 0.1561613161493618, 0.9602162645627949, 0.9541949058408856, 0.21350120690087326, 0.19716782856483228, 0.17045582580845697, 0.3042016591051906, 0.2084904789509926, 0.2172320977676948, 0.16442984002868744, 0.19308351608813745, 0.20278375916159896, 0.21085437476076818, 0.07028135687438919, 0.055678401034852, 0.10130148301456521, 0.04303646471686173, 0.11378351663121788, 0.06079389884337394, 0.09494413249645128, 0.07367368227680415, 0.10347143771639111]}, "mutation_prompt": null}
{"id": "de4e55b2-177a-4f47-9e18-2cd6b295e5fa", "solution": "import numpy as np\n\nclass AdaptiveParticle_Evolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, dim))\n        self.alpha = 0.5\n        self.beta = 0.9\n        \n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = 0.5 + 0.5 * (1 - norm_fit)\n        return mutation_factor\n\n    def __call__(self, func):\n        pbest = self.pop.copy()\n        pbest_fitness = self.fitness.copy()\n        gbest_idx = np.argmin(self.fitness)\n        gbest = self.pop[gbest_idx]\n\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor = self.adaptive_parameters(self.fitness)\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.velocities[i] = (self.alpha * self.velocities[i] +\n                                      r1 * (pbest[i] - self.pop[i]) +\n                                      r2 * (gbest - self.pop[i]))\n                self.pop[i] += self.velocities[i]\n                self.pop[i] = np.clip(self.pop[i], self.lb, self.ub)\n\n                if np.random.rand() < mutation_factor[i]:\n                    dim_idx = np.random.randint(self.dim)\n                    self.pop[i, dim_idx] = np.random.uniform(self.lb, self.ub)\n\n                f_new = func(self.pop[i])\n                self.func_evals += 1\n                if f_new < self.fitness[i]:\n                    self.fitness[i] = f_new\n                    pbest[i] = self.pop[i]\n                    pbest_fitness[i] = f_new\n                    if f_new < self.fitness[gbest_idx]:\n                        gbest_idx = i\n                        gbest = self.pop[i]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveParticle_Evolution", "description": "Adaptive Particle-Based Evolutionary Optimization combining particle swarm dynamics with adaptive mutation for enhanced convergence.", "configspace": "", "generation": 26, "fitness": 0.15925457745239197, "feedback": "The algorithm AdaptiveParticle_Evolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.19.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.28878748572231516, 0.29271479317829396, 0.265273525179497, 0.2607193379960966, 0.25865798366263104, 0.2645228650274656, 0.2704202552077978, 0.24996714354610827, 0.26728111474799165, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06974369944632997, 0.06606941807366618, 0.09918253048903647, 0.08257466404290537, 0.06300663920718363, 0.07445269290606704, 0.08656420948484844, 0.07527591705714787, 0.08124187915198877, 0.06255970742017802, 0.05640313222201443, 0.055351833522612304, 0.08176088181798791, 0.06672883185906398, 0.07732696747456791, 0.0758681594860382, 0.05240113524848766, 0.054545452998578936, 0.9768789439392677, 0.9821140340503755, 0.9808711035942407, 0.9407730724449057, 0.9241484233236997, 0.9172019230063022, 0.9775946502226274, 0.9362447712375909, 0.9600023254462228, 0.119741309750791, 0.14472890752674483, 0.14098413095922713, 0.13765967333388485, 0.1451931407426995, 0.1328781408162567, 0.14394901588637188, 0.13984682893176736, 0.12453473236597346, 0.19663209651211122, 0.1851411056261172, 0.19086239329691657, 0.16192893811696818, 0.16556147848893, 0.1641321177027827, 0.20029536850270713, 0.16395986192195977, 0.1852953552665283, 0.0942200923113935, 0.08528543689845969, 0.06289757993612477, 0.060385755290898846, 0.08064650760260395, 0.05296586275824944, 0.08727047081661243, 0.07145189153601017, 0.04128450879240442, 0.0942862578320437, 0.06068447974300528, 0.07590160875585683, 0.07321190068519556, 0.08536269579556865, 0.06409528348351345, 0.07392761844671258, 0.0890551712494434, 0.07757969298188871, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06402041440211648, 0.0651694012528462, 0.10481855134061568, 0.048186960215289565, 0.03983762555560899, 0.0648468223473978, 0.05004348548066917, 0.09690092845113318, 0.0796319255222897, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010344811530982545, 0.029952633093735304, 0.023796048479473808, 0.015524105465612448, 0.04723244554508188, 0.02784397441209352, 0.008347208708910925, 0.04142543096874074, 0.028275007904111416, 0.26854251341977176, 0.259891598917124, 0.27322493832405137, 0.2669777681551547, 0.25248283575778363, 0.2602896772929342, 0.2647864492778599, 0.2682063714418754, 0.2953899946020865, 0.06440782617503205, 0.07224230842679857, 0.06290040410886699, 0.0805201735583927, 0.06705805376371388, 0.07868696220998794, 0.0853642898750997, 0.07076926168798325, 0.07057103789132979, 0.11909701597970324, 0.14945552820362895, 0.12985159996743045, 0.15669903194331403, 0.15837028104284379, 0.14647553395594737, 0.17888609363593988, 0.13726126764487856, 0.14299724323447194, 0.23223340375862778, 0.20783699677087875, 0.20164508534331738, 0.2151490312198916, 0.20146368655101865, 0.20364890835327099, 0.21244693296554573, 0.20542494297300917, 0.2140185410471217, 0.1452422117102493, 0.15468859568301319, 0.15187399886512598, 0.16594957728439386, 0.1282526757267306, 0.14701389199233195, 0.14642052557489493, 0.13876611359065993, 0.15329862675088968, 0.1931574031794382, 0.19042006545018964, 0.1832041576125507, 0.18598372057720503, 0.18399878094956434, 0.19949111212766302, 0.16956895978625341, 0.1848690731981919, 0.2050999044532984, 0.17603496722012912, 0.16683199476211208, 0.168438480536795, 0.1748165114817699, 0.16685593288144096, 0.16303750517714832, 0.16695576068072915, 0.1738703515848753, 0.17816832719746567, 0.28362548021753653, 0.1716124770738625, 0.17935150588782167, 0.2930650242192496, 0.2744394716521871, 0.21501303799130778, 0.2867810709677959, 0.12529619165537464, 0.35817403826075245, 0.22236550454804238, 0.2507819719352684, 0.19443218299557619, 0.17565338194583746, 0.14096254270781972, 0.18296617048431163, 0.20658765868640505, 0.1510682385044394, 0.22514527187722233, 0.17190957329425693, 0.1848603675233026, 0.18801365914152723, 0.17315828827634794, 0.183866263128577, 0.19713193878718382, 0.174941238317454, 0.19078811017401387, 0.1830231413308766, 0.07181026473610563, 0.0795753862087979, 0.08051070125572146, 0.0690563097909972, 0.06770403693449245, 0.07495579929923846, 0.07374154639559183, 0.0759280162755478, 0.06514335694045859]}, "mutation_prompt": null}
{"id": "fe3405ab-7dba-462b-b065-58cb4d73ecc4", "solution": "import numpy as np\n\nclass AdaptiveMemoryHybridDE_RLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.mutation_memory = np.full(self.pop_size, 0.8)\n        self.crossover_memory = np.full(self.pop_size, 0.9)\n\n    def adapt_parameters(self):\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.3:\n                self.mutation_memory[i] = np.clip(self.mutation_memory[i] + np.random.normal(0, 0.1), 0.5, 1.0)\n                self.crossover_memory[i] = np.clip(self.crossover_memory[i] + np.random.normal(0, 0.1), 0.5, 1.0)\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n        \n        while self.func_evals < self.budget:\n            self.adapt_parameters()\n            \n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + self.mutation_memory[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_memory[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                for _ in range(self.dim):\n                    random_idx = np.random.randint(self.pop_size)\n                    local_search = np.clip(self.pop[random_idx] + np.random.uniform(-0.1, 0.1, self.dim), self.lb, self.ub)\n                    f_local = func(local_search)\n                    self.func_evals += 1\n                    if f_local < self.fitness[random_idx]:\n                        self.pop[random_idx] = local_search\n                        self.fitness[random_idx] = f_local\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveMemoryHybridDE_RLS", "description": "Adaptive Memory-Based Hybrid DE with Randomized Local Search integrates adaptive memory for mutation strategy selection and random local search for enhanced convergence.", "configspace": "", "generation": 27, "fitness": 0.24931403310101044, "feedback": "The algorithm AdaptiveMemoryHybridDE_RLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.20.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.6566115452136583, 0.6152653419275791, 0.6482353288883436, 0.662743624663735, 0.6563499847383482, 0.6601558665518614, 0.6480521367979726, 0.6659498543508477, 0.660215512886473, 0.4223104234924764, 0.434763235012277, 0.4126255525074667, 0.39075645175061113, 0.40965302751473465, 0.41025613261295124, 0.39504744743130527, 0.400971794451637, 0.422334061801356, 0.12586722267934014, 0.11796316401377538, 0.11669007818250288, 0.12416485089308604, 0.1240487455445205, 0.13229610616312182, 0.13592317030980416, 0.12223036003235899, 0.1215734609575404, 0.10538615283258879, 0.12799724658030376, 0.10951825995424336, 0.10972485130952536, 0.1070873829944432, 0.13301423555035874, 0.11445920935930809, 0.11764671496473988, 0.10874976445623796, 0.972187566641078, 0.9333942284556113, 0.9238377419455315, 0.9320240623413212, 0.8913298301590196, 0.9500918956864537, 0.9768599430581554, 0.8660237014696368, 0.9484921661024135, 0.25931576734973427, 0.26647193218453635, 0.2631417920380693, 0.2417131748881045, 0.2609485015090035, 0.25848387190302635, 0.2779195846054242, 0.2832906204725856, 0.2692125715500614, 0.3983531727945223, 0.30361451258074046, 0.40684599223544493, 0.4816431129413664, 0.4149339093557567, 0.35278382704250344, 0.45054147570743364, 0.31779254767403575, 0.4258579518774537, 0.14429955008937945, 0.14233830862867036, 0.16892257125794785, 0.16132405904937464, 0.15517284974042667, 0.16905020008308624, 0.1595779288532333, 0.1549725347427806, 0.1930059127348711, 0.2013719180318856, 0.11361316589078674, 0.19925649229395026, 0.14016346100381272, 0.14392488263310788, 0.18698286643033457, 0.1439384951287479, 0.15151336781982538, 0.15595608615011047, 0.06360807721118145, 0.06896126215282306, 0.04166348389401542, 0.05620883751845307, 0.08607229131129757, 0.03695365135586037, 0.03448957955196841, 0.041974049670488456, 0.029293243137610392, 0.23927294151378187, 0.15606932309781163, 0.14567811007164932, 0.17203508953666402, 0.15348626777928986, 0.13985099143848712, 0.19749392803965415, 0.2122375438645353, 0.21893811662219398, 0.006281846770255672, 0.002801964410586666, 0.006139801598841421, 0.0034963174567957944, 0.008760724326415392, 0.0014725945925881945, 0.010469396508071993, 0.005552736167265038, 0.0027214259329839674, 0.12080755074014504, 0.1202039720874507, 0.11779203437993824, 0.14192630964118658, 0.12746234062860406, 0.12571486894897066, 0.1206696533322067, 0.12931147759997808, 0.12684633063113127, 0.43384074516996896, 0.4464880627973641, 0.45343440327488427, 0.4376270843347704, 0.44651323474128235, 0.4452948038742578, 0.4621529205836442, 0.4569226702683231, 0.46215502719341106, 0.10003597594613534, 0.09638574307413927, 0.09684879129097101, 0.09172081453303949, 0.10651992356450934, 0.10679478290878541, 0.09745544539708684, 0.11028942626225002, 0.08750200882444392, 0.17543327959428845, 0.24890347289526293, 0.17899734575776416, 0.1688570312085188, 0.16095984608074, 0.16831610160730437, 0.17863500191668158, 0.1589371094111306, 0.16586199809973678, 0.2564877042704383, 0.28481160432378905, 0.28014290012903875, 0.2653790105945939, 0.26262861060842024, 0.272028659819745, 0.2821268344547686, 0.2962293676531127, 0.2826824003976678, 0.18888754111445483, 0.17910199316422548, 0.18535460886499455, 0.1859707736576811, 0.18256424972387253, 0.18097013573068144, 0.19249639527694928, 0.225229652324465, 0.1925099086820573, 0.1927367118359008, 0.18975738786595342, 0.17289789014704815, 0.17951524869418956, 0.19723754890873757, 0.19920366031503878, 0.1969921275179154, 0.20669246452770274, 0.19833921789656184, 0.18817085453028115, 0.18951641832277633, 0.1921464688806207, 0.19626800068151862, 0.19518250698544515, 0.19079086069256557, 0.19999611747253676, 0.19058522396470667, 0.1939468711015524, 0.16774257674884951, 0.4955283240074184, 0.37048505007773946, 0.3833314012264182, 0.2129871439660984, 0.2844829808326318, 0.23823016873582004, 0.1531818156431164, 0.2306027305943955, 0.41548744864924836, 0.35630296827574093, 0.49192807479148215, 0.22266973602012663, 0.1916207729170607, 0.22515936043418427, 0.2055894965767623, 0.20544360234132797, 0.20859760465698396, 0.17974787007673787, 0.18912996265363902, 0.1962732085241652, 0.19597896838545448, 0.19786286494376992, 0.20479603051960582, 0.18141871411338228, 0.1853987939399816, 0.1903043832486695, 0.08009431589280591, 0.06307701586289094, 0.07010710784985985, 0.08705891975290503, 0.07471439591005713, 0.06661625860003917, 0.07418112104213193, 0.06901593768902081, 0.06637650455105737]}, "mutation_prompt": null}
{"id": "beee0c41-e557-438d-aba0-b8ec47245998", "solution": "import numpy as np\n\nclass AdaptiveHybridDE_SN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.9\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveHybridDE_SN", "description": "Adaptive Hybrid Differential Evolution with Stochastic Nelder-Mead optimization to enhance exploration and convergence through dynamic adjustments.", "configspace": "", "generation": 28, "fitness": 0.4377694057231935, "feedback": "The algorithm AdaptiveHybridDE_SN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.9765567015779058, 0.9772801989641262, 0.9794774045664253, 0.9765108022336558, 0.962854360533921, 0.976547195448076, 0.9725028292267196, 0.9670229113168569, 0.9654504307024038, 0.8807235795242215, 0.9353058450380384, 0.08186868848925988, 0.07056007685695131, 0.9290557031781972, 0.9366027755310461, 0.05646861280318349, 0.05695070023066495, 0.9571364549620138, 0.10131169928512807, 0.0989885624754957, 0.08144854341090468, 0.07151021899052434, 0.0492654572659762, 0.08445139317000672, 0.04194490422610486, 0.12059758612769933, 0.11357519218512702, 0.0734960730496288, 0.0650947068257528, 0.0496058499663814, 0.07115237490175441, 0.03443343544096422, 0.02585081913061238, 0.05177885809023952, 0.03638757404170134, 0.04059188273999881, 0.9105373152138039, 0.9479712352494916, 0.9895017940124192, 0.9609761843010647, 0.9308454481575252, 0.9632610413405357, 0.882709115564886, 0.8622244075056464, 0.9377927954602706, 0.8245152914531721, 0.872215168299906, 0.24373816913219326, 0.17897995386585697, 0.11791749382614247, 0.6677792453558576, 0.7219466698462114, 0.08856439324080079, 0.6541465956811322, 0.2121608551832267, 0.17723866029855584, 0.1721250406475736, 0.1581574610852584, 0.1090923695976811, 0.3958728181463401, 0.1089789554727264, 0.1332766420251399, 0.15229072899080387, 0.9543095765821421, 0.9440699831311077, 0.9430298420677843, 0.005710813623775679, 0.939241998888033, 0.9207823405147549, 0.14864921685935895, 0.9040540690557691, 0.9516836772662207, 0.9525752056278088, 0.9149898419161111, 0.9399770692786822, 0.9128249195944914, 0.9245777009833632, 0.1380144514194258, 0.9565711199176387, 0.13795274588137107, 0.9140653369894481, 0.9059015843355336, 0.9266052106006395, 0.8500598007596096, 0.9342002912107048, 0.9303807266222786, 0.862274693113896, 0.9381552538130826, 0.8773142333468109, 0.17427988197871525, 0.8776428618296719, 0.9115944753787458, 0.8901946973937515, 0.10776002561476439, 0.8717481666884888, 0.9325237221843483, 0.8697154864014508, 0.8415524207097611, 0.8698696777688071, 0.8563141136850272, 0.8738807435414204, 0.8498290645531753, 0.9322312344313936, 0.89024786904503, 0.9170798737392355, 0.8861852077644017, 0.872491301934532, 0.8860244956147956, 0.7691357691803382, 0.3128671925597234, 0.7677821457687987, 0.16550385270123336, 0.08081071100313453, 0.05771433139275883, 0.4363673180743617, 0.7075400905399486, 0.11030144892673821, 0.9705660413882441, 0.9598555934189046, 0.9694156226965978, 0.9584172572130558, 0.9601366929020003, 0.9631745053325135, 0.9600873519922978, 0.9694269137333558, 0.9646969106001534, 0.0714071781188037, 0.08410354369387973, 0.073820001527925, 0.07066778381029615, 0.049008177473640724, 0.10503726846591965, 0.0650845532674541, 0.057889379040619526, 0.0717456349663731, 0.18067924304806382, 0.10928228071622648, 0.16497104158233944, 0.1362657793189792, 0.20417494395765157, 0.16231917424929054, 0.1702200300318265, 0.1196145227058445, 0.18115503883764772, 0.18316157424019552, 0.17555545367714553, 0.1900639948995665, 0.17048076190710548, 0.17048032008401237, 0.20727519725330135, 0.19503486987193208, 0.2108247278292832, 0.2711907410027353, 0.12365644171329315, 0.11097273901970384, 0.11447586131358767, 0.15093092470581682, 0.08444537566784638, 0.11170812759642579, 0.14518984273541813, 0.15644018304626206, 0.17882273735671061, 0.2962981613865361, 0.21344167017358795, 0.18408107047515965, 0.23829051336359885, 0.18559868275959446, 0.19074647896034536, 0.19916343376020007, 0.23027825628050613, 0.2716805976846798, 0.1620891110952425, 0.17801876529565108, 0.17913044866640682, 0.15387155687910814, 0.1636066735999, 0.18445386467293, 0.18000918138486544, 0.165163631767812, 0.17285740803217142, 0.18859232294515105, 0.12195853274002366, 0.154316933385098, 0.9804140264587708, 0.20206774737867494, 0.20113205658705713, 0.14291454863066533, 0.165398768823813, 0.9790455129532607, 0.9737391016860366, 0.21393850221155597, 0.07360533375333811, 0.21306982504341765, 0.10978251361043423, 0.15703020327987616, 0.10509506209240083, 0.11007932132112475, 0.9606046170062305, 0.20845644238386052, 0.1827485843515827, 0.17452478939826, 0.2401519115096371, 0.22999936763682027, 0.22647792203886763, 0.21425714927958106, 0.19103122652367188, 0.2104966344364806, 0.06470576764233915, 0.06698371970111838, 0.06958655461544183, 0.09761680712914189, 0.12259869297742587, 0.07186652425828122, 0.05060216077738611, 0.07686865641292784, 0.061385815715216285]}, "mutation_prompt": null}
{"id": "94bfc4c2-93be-4ea6-b811-6833fc9113e3", "solution": "import numpy as np\n\nclass HybridDE_SIALR_SS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim  # Adjusted population size for better balance\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.6\n        self.gamma = 2.5\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.8\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (np.tanh(1 - norm_fit))\n        crossover_rate = self.base_crossover_rate * (np.cos(norm_fit * np.pi / 2))\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Swarm-Inspired Adaptive Learning Rate and Stochastic Search\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * np.random.rand() * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * np.random.rand() * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * np.random.rand() * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * np.random.rand() * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "HybridDE_SIALR_SS", "description": "Hybrid Differential Evolution with Swarm-Inspired Adaptive Learning Rate and Stochastic Search for improved convergence and escape from local minima.", "configspace": "", "generation": 29, "fitness": 0.08989058979264793, "feedback": "The algorithm HybridDE_SIALR_SS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.18548962027753668, 0.09617307197488423, 0.18673646700581326, 0.23449019994638431, 0.14899591472799, 0.19071562265635056, 0.17208717050862565, 0.23048228466276055, 0.18560745242825127, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03543183764063962, 0.04986466398400602, 0.07431381062189468, 0.05464313917740471, 0.042489226453919615, 0.034034666585531004, 0.08422188811147246, 0.03875275394805289, 0.04177079172927445, 0.02660235919202547, 0.03086024298294321, 0.048706578059870664, 0.0280292643776745, 0.048290464374123765, 0.020843572694162704, 0.03918582999347875, 0.017395461897804276, 0.020136767743669015, 0.07515860725637924, 0.05574257340916411, 0.06541663024303146, 0.0631080342128536, 0.08058301829662318, 0.07593850668635094, 0.07388387594701895, 0.2209277242294001, 0.060920781391182066, 0.06437078410826347, 0.10488785587442995, 9.999999999998899e-05, 0.07927091037185818, 0.02886810036796794, 0.035960448885000385, 0.10971508093259363, 0.03202711146686199, 9.999999999998899e-05, 0.16839515877576927, 0.1733704206419261, 0.1720525780125296, 0.20700066163184394, 0.22353951766869407, 0.17907771893333668, 0.07563068287921926, 0.11221221893305522, 0.12176406898233305, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10771942784019883, 0.0692517320469771, 0.06037218581050163, 9.999999999998899e-05, 9.999999999998899e-05, 0.016650127121324854, 0.06445040920447842, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08190299126371714, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07957913757527935, 0.06559850364679609, 0.1022607165198196, 0.0592117864295274, 0.06131590432171474, 0.03647377739243496, 0.10806888832143047, 0.0721215352318082, 0.06003716298409689, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005492397431212548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005331776110151787, 0.024224200189603473, 0.23182227075503858, 0.2154622289118877, 0.19423411978245386, 0.30569284279095477, 0.15277515356571625, 0.21421050368353423, 0.22920498867225203, 0.2629096158570632, 0.23280748039257282, 0.05358532782867842, 0.01650271169070583, 0.04954225827931025, 0.03985998638277011, 0.02661227534164612, 0.071029505058404, 0.03915244247768246, 0.05107006021942884, 0.05364389313602347, 0.10594210298954676, 0.1330676588407811, 0.15548418816669018, 0.15529755476767515, 0.13432633303638974, 0.1325515352995018, 0.12748228518644733, 0.09551635951204551, 0.08040638294075686, 0.14083305468791163, 0.1674122297044971, 0.19718237804969596, 0.1525696933886035, 0.1696583580330795, 0.1407514855858195, 0.16206455768876293, 0.18327601372083246, 0.15116540238416787, 0.08437621549663532, 0.08319595100633759, 0.16913357905887894, 0.1542115877062088, 0.1255352604639033, 0.09034233728012164, 0.11016424027943172, 0.12771187066319611, 0.08596285222195488, 0.20197030974539587, 0.1984473451056571, 0.1418517683192505, 0.18286509782810811, 0.16401265975442725, 0.15020170055584037, 0.16529296302242824, 0.19738291934174734, 0.1549926630081636, 0.16507851118061267, 0.16314612800159922, 0.14441887248718666, 0.1600174112906645, 0.14431123769023635, 0.17430101595624314, 0.14979262249054137, 0.15273324707499947, 0.14822697577333643, 0.11782154539707224, 0.1681702213786983, 0.10348853691292403, 0.11134129638234846, 0.12496911842785852, 0.141011106374211, 0.1217816489988609, 0.12063438399328463, 0.10544948611555172, 0.21292112464958468, 0.1439769582517294, 0.07184574680871514, 0.1682749127390225, 0.104772643964537, 0.1042456505065038, 0.064834977640155, 0.1097493898734252, 0.17123620801121908, 0.1678393212917636, 0.14128339807593915, 0.19167235411553218, 0.1743067616752556, 0.16207365063110646, 0.15151405541005936, 0.19400327929398087, 0.2340116843433666, 0.14836785737363445, 0.030322783500259187, 0.0828549078348324, 0.051325982910900736, 0.03955461089300627, 0.07934037628383539, 0.043292155338498395, 0.03996468293385458, 0.058873309052784095, 0.03352183287990429]}, "mutation_prompt": null}
{"id": "28cef098-0308-415b-b773-b3c7bcdf484a", "solution": "import numpy as np\n\nclass EnhancedHybridDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Adjusted population size\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.6  # Slightly increased contraction\n        self.gamma = 2.5  # Increased expansion factor\n        self.base_mutation_factor = 0.7  # Adjusted mutation factor\n        self.base_crossover_rate = 0.85  # Adjusted crossover rate\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def elitist_selection(self, trial, f_trial, i):\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.pop[i] = trial\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                self.elitist_selection(trial, f_trial, i)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.4 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "EnhancedHybridDE_ANM", "description": "Hybrid Differential Evolution with Adaptive Nelder-Mead enhanced by introducing dynamic scaling, self-adaptive mutation strategies, and elitist selection for improved convergence.", "configspace": "", "generation": 30, "fitness": 0.4261398308889611, "feedback": "The algorithm EnhancedHybridDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.32957949698386335, 0.9793147446375949, 0.9618306943312122, 0.9789699413334284, 0.07349328943328604, 0.9689543229899694, 0.9726177976106316, 0.9783346254938272, 0.9796175076256247, 0.9072668724505595, 0.9201551544897735, 0.9465910430530837, 0.06783447620226002, 9.999999999998899e-05, 0.9119824647883472, 0.8759361681420972, 0.9156844959932287, 0.9126962158406842, 0.07881538813272526, 0.13722451581531403, 0.09114424694984302, 0.10139956300339803, 0.05975208317251035, 0.12002810194978697, 0.07898572654535962, 0.12864882228105234, 0.034687431926893275, 0.038505460368260525, 0.13965204456898173, 0.08148169406864159, 0.08476266404703148, 0.02744634740141516, 0.06289207375608041, 0.0956638204700121, 0.02593919688807733, 0.030006010442212072, 0.9732872952194951, 0.9237930034179456, 0.8676237357306503, 0.9815351302592245, 0.8832787308505462, 0.9656943481375027, 0.9116737315434916, 0.8993697544423009, 0.9260826681952872, 0.3003900339858865, 0.8234174025512602, 0.9407433099751864, 0.21535027683276853, 0.49919000777335887, 0.9366692224817916, 0.9224172307530653, 0.8989630946066726, 0.7866132347835016, 0.14008785204510854, 0.06713017912970354, 0.14140551622706787, 0.17531355440461138, 0.1989299880748857, 0.20974707320049757, 0.0694928076463378, 0.11736238690985934, 0.17956603649868352, 0.9375693703487209, 0.13149600404862172, 0.12359441856201847, 0.9206512125963892, 0.9104695697890857, 0.9193489857201992, 0.9478629111228623, 0.1307562848662952, 0.13709419177484905, 0.13384641797568997, 0.13764037569062526, 0.13746713659829168, 0.9399361958520083, 0.9453780204121495, 0.9534208581452234, 0.9488167923727588, 0.9256518569408886, 0.0012837193205963437, 0.8841157134906235, 0.9151399106224634, 0.8912364408778275, 0.8667302932493202, 0.8499538932317205, 0.9033191761024277, 0.9003850433399996, 0.9225068484376165, 0.9325557965803517, 0.8343511710507804, 0.7997336839685654, 0.8644959969956618, 0.9175788808596655, 0.8592576438689987, 0.8467499748545604, 0.8156792882585965, 0.8754821516587953, 0.9131998638743004, 0.8819881011412354, 0.893378031091733, 0.8738595062554608, 0.926555122431522, 0.776078614840586, 0.931681735465571, 0.9273234775435589, 0.8750314196735087, 0.849356042536381, 0.36122761136440584, 0.15738628213950268, 0.09116211339888902, 0.6209892424491281, 0.8816292194386813, 0.595032011168203, 0.29917893902213266, 0.135971446375019, 0.13450857281569828, 0.9647507416037329, 0.9221517332786483, 0.9606068114238894, 0.9711793878730426, 0.9309012377434429, 0.964103258760076, 0.9583715491582163, 0.26488061744539326, 0.966567500483143, 0.042554950717108464, 0.11429593566030272, 0.1141439181924988, 0.09504324418786403, 0.07378745727932368, 0.1676428998645646, 0.11422038140696, 0.06128018262629176, 0.07395630454330004, 0.14463436173340616, 0.20412939720415035, 0.1634844577117769, 0.14819602424349998, 0.12777980880646866, 0.11844873849174797, 0.15277244797643563, 0.12909249481947538, 0.1795100389439498, 0.15731961693577645, 0.21146925874593547, 0.17400340547497783, 0.16851000365002822, 0.1464133619603858, 0.21410692855011426, 0.2545861310866767, 0.24603142844298964, 0.1600889641396388, 0.09698474738201346, 0.1891782207413265, 0.17590495865477207, 0.10936683258318769, 0.08859044562908969, 0.10173082362301888, 0.16339993075711645, 0.10844203343222503, 0.19288652902531866, 0.19792324311583664, 0.22437130905246072, 0.1482925569736181, 0.31817635495556773, 0.21201810060992765, 0.17320470156606227, 0.260666450949225, 0.2134070456611762, 0.19599716864290317, 0.19107825121808697, 0.15822185799243138, 0.17502919402441497, 0.17122838365273851, 0.17247951688340368, 0.19979590331195074, 0.182764376608607, 0.16669996869100068, 0.17710923924874078, 0.09094860505635183, 0.201317792437667, 0.15456248908837877, 0.18959429460590227, 0.20201565775480013, 0.20123265813967284, 0.14339101665127396, 0.12704281732794676, 0.15969316500199016, 0.3108228409196806, 0.21443339581712284, 0.07913229056507076, 0.9657448583352031, 0.16953455038347998, 0.15652553334128083, 0.10513461696384507, 0.10513218580611305, 0.9690388438127293, 0.16430554804020836, 0.19428537718707373, 0.21870526441558935, 0.1863446666840609, 0.20991965802931034, 0.19926445898942224, 0.25515079784800165, 0.1863128984603286, 0.1986819997067597, 0.08953859052948976, 0.08610139638134262, 0.06655885449603227, 0.0682633101200103, 0.07912267589948874, 0.08170616086729565, 0.055870729373517, 0.09603064945989481, 0.0985640058932924]}, "mutation_prompt": null}
{"id": "77a9fab7-bfb2-47e6-8138-1cc788884ea6", "solution": "import numpy as np\n\nclass QuantumAdaptiveDE_NM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim  # Slightly increased population size for diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.5\n        self.beta = 0.6\n        self.gamma = 2.5\n        self.quantum_perturbation = 0.05  # Quantum-inspired perturbation factor\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.8\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (0.9 - norm_fit)\n        crossover_rate = self.base_crossover_rate * (0.9 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters and quantum perturbation\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c) + self.quantum_perturbation * np.random.randn(self.dim), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Adaptive Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "QuantumAdaptiveDE_NM", "description": "Quantum-Inspired Adaptive Differential Evolution with Enhanced Nelder-Mead using probabilistic adaptation and quantum superposition states for broader exploration.", "configspace": "", "generation": 31, "fitness": 0.3534533818470091, "feedback": "The algorithm QuantumAdaptiveDE_NM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.33.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.966016318909602, 0.964438126082771, 0.9664452256068112, 0.9590826302375052, 0.16826187543823812, 0.9691791732326591, 0.9677678884601422, 0.9638522270815877, 0.9668634879854006, 0.7745087157889476, 0.8157112354595922, 0.6421653396874888, 0.15917366997904936, 0.7283184943695713, 0.8938722973670385, 0.8026180902627994, 0.9337576008450612, 0.9163609431872369, 0.11347815558117813, 0.08735018138513262, 0.08737957205485092, 0.051743951834764434, 0.07133190807594636, 0.11349642688412909, 0.10255224227714521, 0.1788978063440272, 0.08213761336638803, 0.059443874974815514, 0.07846713895327717, 0.04140132142766473, 0.07125740283131166, 0.02035791380589147, 0.13716178589983719, 0.08075600329820354, 0.07293377063418482, 0.021081449223246507, 0.8409584585343122, 0.07452166761298196, 0.7771841467415096, 0.9848251412447031, 0.8593631779598931, 0.9542717260482957, 0.8613327372361019, 0.9876013739651454, 0.9390658268997993, 0.19986595266317053, 0.09451872593906951, 0.20149947023270642, 0.4098752087608706, 0.11935042155686226, 0.013488305273658296, 0.17867455960851097, 0.3381824183660481, 0.1411126372507462, 0.23807671473005898, 0.18625454125643948, 0.14897000938433902, 0.1801936697274552, 0.20536410146236217, 0.07205449335231529, 0.05361282667679956, 0.13090214619371887, 0.14879667329037694, 0.9130411155216684, 0.13759075731900872, 0.9329392683131218, 0.8304584412623829, 9.999999999998899e-05, 0.9176985557027614, 0.9087267485681889, 0.8730879576218229, 0.8973265867945455, 0.8981166545752367, 0.9206644202226402, 0.13673703813452576, 0.9154106448921099, 0.8951767565286826, 0.13587198982847437, 0.9246637832767802, 0.8812807457790004, 0.8609817279895958, 0.5083841144758463, 0.09476989487958731, 0.3192301970197745, 0.6062309200773509, 0.30091383729402665, 0.7795509263531533, 0.1037567714085208, 0.8069420231791271, 0.6605911322896302, 0.20922840361803963, 0.10704064307201155, 0.6983526775949889, 0.7372768364150138, 0.11854927540625582, 0.8451318362630464, 0.15255993033840187, 0.1588393229871906, 0.13203862324567672, 0.35457264121663845, 0.7079965578985803, 0.6880977682315579, 0.7836386427287096, 0.8590892728315072, 0.7709521656752605, 0.7716729063360774, 0.7269535891748637, 0.6656316885008947, 0.0596260983593373, 0.03854654496026, 0.09903540171765546, 0.2964895142071893, 0.0820396363204523, 0.07810002945591166, 0.14384819006348348, 0.730693191877741, 0.12921819470116258, 0.17535174446412016, 0.9110509128608414, 0.9139188607254133, 0.941677493522713, 0.9313100319276125, 0.9187693841710489, 0.9056373729464746, 0.16606637111324785, 0.9330369245741328, 0.08017751049914257, 0.08102023806755954, 0.08737939545426965, 0.09446869573813088, 0.07107975792689636, 0.11291615787584142, 0.13709287857582475, 0.08116107054309452, 0.08760851465975339, 0.1114126630008021, 0.15774591232344104, 0.1516538297490191, 0.17048536591739571, 0.14832360931380095, 0.14162534269364313, 0.2397991924129491, 0.10642827814925382, 0.1771042569160225, 0.21196435051153417, 0.15866466758080155, 0.27804767344436354, 0.1568441670438231, 0.2152627549248758, 0.15941555331531976, 0.18628319457974918, 0.23995313711363264, 0.18482759532188453, 0.0820982321695185, 0.04611809759507646, 0.2392066241850126, 0.1031664237706531, 0.12792083070151494, 0.11627583994061219, 0.18594397737269885, 0.19043470064679935, 0.1615236232459092, 0.20830113419700447, 0.22995845579574348, 0.1967805351637245, 0.2347693818589388, 0.19672201704915793, 0.20251372231741183, 0.22745609096409758, 0.22066060796777098, 0.16250279842289617, 0.16273923672868373, 0.15279479917552197, 0.18492407996963645, 0.19929163746578216, 0.18059063896419214, 0.17922529300774004, 0.16057007770125742, 0.16785130579679386, 0.1560064906044285, 0.15913338962025847, 0.18854851818724017, 0.18853907182301677, 0.15354070932739794, 0.2016884079969249, 0.16827582827644816, 0.14312862526786707, 0.16489895494187456, 0.1224087420551494, 0.9450672107405755, 0.2139703659188955, 0.1285605861333734, 0.09450396465600897, 0.11030374325320114, 0.16814295996606765, 0.16830247103203544, 0.10469093228172499, 0.2132000473013953, 0.21610861773250878, 0.18049258610215513, 0.1955447647669849, 0.22477016640442615, 0.21274663435265528, 0.21211493182401786, 0.21901056526718976, 0.1750491082850273, 0.18853389576952262, 0.08536556367963344, 0.0891140864881883, 0.07173752825780955, 0.03127821502248773, 0.09467607739791728, 0.054558351023021534, 0.09875604719367836, 0.10514797426266598, 0.07710774030039125]}, "mutation_prompt": null}
{"id": "84e584bf-fac5-404b-99a4-348659db0eec", "solution": "import numpy as np\n\nclass AdaptiveDE_StochasticNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Adjusted population size for balance\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = 0.85\n        self.base_crossover_rate = 0.85\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * np.random.uniform(0.8, 1.2) * (1 - norm_fit)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            # Differential Evolution with adaptive parameters\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Stochastic Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = centroid + self.alpha * (centroid - simplex[-1])\n                    reflected = np.clip(reflected, self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = centroid + self.gamma * (reflected - centroid)\n                        expanded = np.clip(expanded, self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = centroid + self.beta * (simplex[-1] - centroid)\n                        contracted = np.clip(contracted, self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = simplex[0] + 0.5 * (simplex[j] - simplex[0])\n                                simplex[j] = np.clip(simplex[j], self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "AdaptiveDE_StochasticNM", "description": "Adaptive Differential Evolution with Stochastic Nelder-Mead using dynamic fitness-based and stochastic refinements for robust exploration and convergence.", "configspace": "", "generation": 32, "fitness": 0.39331845405929466, "feedback": "The algorithm AdaptiveDE_StochasticNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.36.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.9714050401025145, 0.9731598200623941, 0.9804692293118054, 0.9746609426497457, 0.9684910201491486, 0.974388846970708, 0.2971297082594768, 0.22443564974621, 0.981349403010507, 9.999999999998899e-05, 0.8527356861956159, 0.07811435836288272, 0.9244033636734876, 0.8780539461353919, 0.9444779627565539, 9.999999999998899e-05, 9.999999999998899e-05, 0.884183657530356, 0.0651785251594087, 0.13803591722009845, 0.08943079773404028, 0.06521105628894253, 0.03800907521067842, 0.06351758470972213, 0.06721490991604784, 0.0949867511474749, 0.09900816342841068, 0.039530818558696, 0.03812039086875685, 0.09700785543510215, 0.12459705011832434, 0.022838338857845364, 0.028367339157989613, 0.012520174298470188, 0.009729017859283151, 0.053451571957331856, 0.9892067046527989, 0.986940582404789, 0.9729212327440688, 0.9620760625097977, 0.919058076121398, 0.8925905810951278, 0.945702301583142, 0.9094554008832886, 0.9355125848661355, 0.23998278027120634, 0.7864155674284293, 0.6844850996130063, 0.08678566858771009, 0.6116528677465567, 0.8311253800909884, 0.25886400209044247, 0.788748482080017, 0.6851656074361783, 0.1261368969287021, 0.104366320372273, 0.12227875191644055, 0.18213069541091453, 0.11289247084232557, 0.05399986269640833, 0.08433794308427389, 0.15312500204011448, 0.23924168275496072, 0.9534439215751187, 0.13848151869301562, 0.13786307870969794, 0.9543455635743607, 0.12439381457289289, 0.1386479724275781, 0.13603333314507327, 0.13812697899485282, 0.9356208736898296, 0.2370962199311768, 0.8960784640799133, 0.13834496363942106, 0.1322438377607832, 0.9325167520330624, 0.9545526487984616, 0.13729571413900443, 0.1365639858747958, 0.9409508421980394, 0.9260696618143571, 0.913895377677867, 0.8190572828988395, 0.8693002215229022, 0.9545055027892648, 0.9000322638177848, 0.7819301269465035, 0.9172219935436565, 0.9350680440713164, 0.1377953749763663, 0.8764024727070095, 0.852171925645508, 0.13478983951976975, 0.9225477083110545, 0.8680351912083377, 0.8775755025165475, 0.8379544013372612, 0.8903906721244527, 0.865370053619361, 0.8768692805046785, 0.923077778826511, 0.9199857444681057, 0.8408271185432681, 0.93730709516712, 0.6767823742024236, 0.8414771568491092, 0.9241168085319623, 0.10215135894026173, 0.682024250336221, 0.050297389023501116, 0.007843750104115865, 0.044586744657085675, 0.8742315689805578, 0.2033352109785883, 0.35529990550261603, 0.10531813229333331, 0.9613137889859916, 0.9657613530409068, 0.967480173103947, 0.9586253279119946, 0.9648810152309035, 0.10918483211553998, 0.9655539999347338, 0.9528957518798382, 0.23571654814174003, 0.1079288905738669, 0.04655922608985508, 0.0694885912625921, 0.059573452807021754, 0.10783217342049867, 0.1255143428401303, 0.09451047505595311, 0.12071663360273943, 0.09511556474154281, 0.22413223252562542, 0.15083019671513698, 0.16223039504883308, 0.1455892139151812, 0.20772799003613696, 0.12112706830550957, 0.2881785218959594, 0.10426327362163779, 0.1454168635141807, 0.2159139210480594, 0.16104619154671196, 0.17625351314854942, 0.16322730580697986, 0.1951603214755646, 0.21507711293527287, 0.18305681227503956, 0.206389050504461, 0.1914522567213266, 0.1028598206264485, 0.11584518990690174, 0.19186756542433558, 0.17401817267236508, 0.0974106880943657, 0.22733692089310475, 0.20452570198501985, 0.17953319845514892, 0.1527666259442938, 0.3446487197008582, 0.17322618188485617, 0.25717070074551096, 0.20436292537137202, 0.2556101990803207, 0.19617330889778395, 0.24167457002758697, 0.2235579008581794, 0.20611427413579064, 0.15770556637790833, 0.15484384890086111, 0.15605090395886023, 0.17450410529929905, 0.16065685625450565, 0.1738594828781097, 0.16697021559786895, 0.18766716274866413, 0.16191104204518214, 0.1132189874067352, 0.9738797824202073, 0.9864659397920681, 0.18874738991277884, 0.20229470368622737, 0.1793661460174759, 0.14336338075865096, 0.1699965337248308, 0.11016296381925572, 0.43966502031128474, 0.2133640485187207, 0.07330859085571195, 0.1880975071512444, 0.15678358555040373, 0.1339543191058099, 0.10520996224309054, 0.2831590251817848, 0.9696901215557694, 0.16926070065294296, 0.19287050072801692, 0.2540431929568572, 0.2219059428257356, 0.20300099956730056, 0.2152783010798045, 0.24182628452901533, 0.20946292843741843, 0.17297565655161729, 0.11490118237661917, 0.05357766322980917, 0.09073523022167196, 0.03425468497110473, 0.07830951807245123, 0.12952444683010544, 0.05382290210481566, 0.05336675296774851, 0.10038660025748902]}, "mutation_prompt": null}
{"id": "1fcef688-bb02-436b-9bae-d908432e0acb", "solution": "import numpy as np\n\nclass QuantumInspiredDE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.7\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * np.exp(-norm_fit)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit**2)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "QuantumInspiredDE_ANM", "description": "Quantum-Inspired Differential Evolution with Adaptive Nelder-Mead using quantum superposition principles for enhanced search space exploration and exploitation balance.", "configspace": "", "generation": 33, "fitness": 0.4389278544784617, "feedback": "The algorithm QuantumInspiredDE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "cdd635fc-e288-49a2-a43b-df0592018284", "metadata": {"aucs": [0.9738281494774346, 0.974520405754077, 0.9792455274895469, 0.9673135978070511, 0.9618613688276998, 0.9719341793092209, 0.9758518363978574, 0.9729322110541546, 0.9618157258916272, 0.923909314517851, 0.9443966284695902, 0.04491761509853587, 0.937371552877405, 0.9075165616037052, 0.8815878758625527, 0.8834813838948683, 0.941063051607282, 0.9571364549620138, 0.05647924363650347, 0.07154605539741843, 0.08129868639447557, 0.04663307844958986, 0.05147968493434785, 0.07368950091457083, 0.04194490422610486, 0.11980481059726611, 0.13763080869037858, 0.025911157808338636, 0.04171727557845695, 0.07124618052682086, 0.05485151648182185, 0.04654269829817481, 9.999999999998899e-05, 0.03447206111957002, 0.05625875677901637, 0.05924279607117, 0.9153284571277498, 0.9792571839606351, 0.9896275720066324, 0.870273427448165, 0.9147028560898575, 0.9619674189039034, 0.8741441250242353, 0.9131451775182602, 0.09910131281444523, 0.21542030898709585, 0.7473305067651544, 0.11436906054660467, 0.8984923391103171, 0.42746427377743934, 0.8784093477039939, 0.35294329180958106, 0.3382267182409193, 0.6625307861599522, 0.21601065222364046, 0.19765257240785805, 0.15226085373819753, 0.2116574947839135, 0.1219848781037044, 0.14337548516713283, 0.08186764752161202, 0.12751047207246424, 0.1769680115282506, 0.8572956860188687, 0.9298067904418266, 0.9429808196166528, 0.8167923621109761, 0.13834210325512286, 0.9234729604337714, 0.1515636517274379, 0.13334698681949686, 0.9353291908143575, 0.9511897487863781, 0.9148635299975266, 0.9508941744915153, 0.02609809484165948, 0.9287716942933609, 0.13824294458884467, 0.9599452919391338, 0.9259657079922256, 0.9174194915664965, 0.9214792490992775, 0.8509409775505712, 0.8719056642511749, 0.8051401281761859, 0.8840216278960038, 0.9144278158948276, 0.9369239633706401, 0.8465545896517868, 0.940025321801694, 0.9032201865231128, 0.8968481945665683, 0.888736842879485, 0.10620246586859228, 0.9323764206729114, 0.9366578403559349, 0.893820939622491, 0.8835912798140608, 0.8880683212194218, 0.9337776833282613, 0.8737975738379189, 0.815904926607089, 0.7988433781890227, 0.9387911947870193, 0.9243617733311841, 0.911372634798823, 0.9051991196501279, 0.8536068694036114, 0.19062178490988413, 0.11167780444186215, 0.10493099141784223, 0.6872753199335035, 0.07403145323796656, 0.8319915855168449, 0.17737913079989098, 0.7026011855333048, 0.10380793475971173, 0.24717455937988964, 0.9718146980456086, 0.9552505830598489, 0.9376497309237102, 0.9625207748460264, 0.9670600055672146, 0.9538281237890591, 0.9672205741527706, 0.9576915951179459, 0.08395520216568952, 0.08390891813788437, 0.07384710796976524, 0.06728338386389388, 0.09886512970202077, 0.1226922618005809, 0.0629353306291458, 0.06294617332861507, 0.09121174986968672, 0.1609041554152515, 0.148692164769468, 0.15224086314548513, 0.1416954768874661, 0.1659484634487337, 0.13260222690527768, 0.19005861741247532, 0.19682913177998873, 0.1534630691982899, 0.1282102524919161, 0.1677442611477371, 0.18446266520003063, 0.2008145843108028, 0.15072859713598574, 0.15346816691792187, 0.18729718072414736, 0.22579097908382584, 0.13099373633489653, 0.1018707244112329, 0.11869276257660899, 0.17125908411083712, 0.17093550167110227, 0.13107019872744918, 0.15617626476003565, 0.14518984273541813, 0.10848142352819035, 0.13449506515317355, 0.2287040806270173, 0.15656525875892002, 0.14834908013966797, 0.38504182692369815, 0.23546913728439567, 0.2009763213911817, 0.2723186252128874, 0.2259987978105813, 0.21704943154130873, 0.19518591276632857, 0.17801876529565108, 0.1591461010326498, 0.16583679996629785, 0.16287849054857628, 0.18445386467293, 0.15220303035040195, 0.1876844819793625, 0.17876518426085863, 0.15841919958720319, 0.16792468277128447, 0.1488577239348755, 0.173017734586147, 0.17518114528900208, 0.15282345354327576, 0.14318541643059723, 0.16593518821440778, 0.9661488047243011, 0.9740736797997176, 0.21358759682536343, 0.9784693483057393, 0.07573472974898376, 0.12865391052377673, 0.09481550030654728, 0.2138425917368103, 0.07334138288598502, 0.9577942283817754, 0.21983368572829798, 0.2549428414855167, 0.18676266582751133, 0.21283337438195282, 0.27242042274744505, 0.18799614892336136, 0.20912455069120173, 0.16299303197732895, 0.2749728014047613, 0.10003758359590498, 0.07682187813711827, 0.08366610431425303, 0.06909710695654736, 0.10226895162022631, 0.07755239134077763, 0.07761691717156649, 0.07298016445709776, 0.09528278431277848]}, "mutation_prompt": null}
{"id": "e53cf343-861a-4a73-a851-941da77c173a", "solution": "import numpy as np\n\nclass QuantumInspiredDE_ANM_DPC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.2  # Increased for better exploration\n        self.beta = 0.6   # Adjusted for better contraction\n        self.gamma = 2.5  # Increased to test more aggressive expansion\n        self.base_mutation_factor = 0.8  # Slightly decreased for finer adjustments\n        self.base_crossover_rate = 0.8  # Increased for more crossover exploration\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * (1 - norm_fit)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit**1.5)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.choice(self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            # Dynamic Population Control\n            if self.func_evals < self.budget and np.min(self.fitness) < 0.1:\n                self.pop_size = max(3, self.pop_size // 2)\n                self.pop = self.pop[np.argsort(self.fitness)[:self.pop_size]]\n                self.fitness = self.fitness[np.argsort(self.fitness)[:self.pop_size]]\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "QuantumInspiredDE_ANM_DPC", "description": "Quantum-Inspired Differential Evolution with Adaptive Nelder-Mead and Dynamic Population Control for enhanced exploration-exploitation balance and efficiency.", "configspace": "", "generation": 34, "fitness": 0.408814348448657, "feedback": "The algorithm QuantumInspiredDE_ANM_DPC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.36.", "error": "", "parent_id": "1fcef688-bb02-436b-9bae-d908432e0acb", "metadata": {"aucs": [0.9776775667308135, 0.9764744906682156, 0.9752979265869095, 0.9626876905238294, 0.9688396410154738, 0.969131275449202, 0.9762277960263448, 0.28413885924500837, 0.9757041871898403, 0.8549582502830555, 0.8725169469195531, 0.08079565596622884, 0.9316033929609199, 0.8876292627074654, 0.8842895956724864, 0.9064773830847184, 0.9172518370886892, 0.9365481758494856, 0.03647956107076211, 0.08421243435223713, 0.0336139427838682, 0.0789344006667918, 0.06684349301245818, 0.06329979627045634, 0.07153705214252515, 0.10267615066367941, 0.12740006007555782, 0.06250475829219304, 0.03234691681930091, 0.14999467322455817, 0.059824594039369905, 0.06313369360838883, 0.01486333033624121, 0.04774658544335275, 0.030766705494208457, 0.04395176421947167, 0.8365966697420127, 0.9350941159944987, 0.9894926314194658, 0.8196980828968157, 0.9629734457974672, 0.8055847554700893, 0.9501703156207417, 0.9814056782320038, 0.9816439514227372, 0.676529301560185, 0.5499294493624964, 0.9113946106728686, 0.1512338480543085, 0.4266002391640441, 0.18627797171728078, 0.603524500429144, 0.8090050752357074, 0.48414145598564695, 0.21211047203021616, 0.17880656222835878, 0.17207647547785743, 0.22025248370673012, 0.17391503092998084, 0.21310455201343825, 0.09673502986630156, 0.22284573292819077, 0.15224303687443264, 0.8705853581179546, 0.9416408707951827, 0.13589170645973225, 9.999999999998899e-05, 0.13785588625384093, 0.896877419013239, 0.1480437560388338, 0.9020104120913843, 0.9468492751774815, 0.9585566821023169, 0.9257502650598853, 0.1375568581099924, 0.13393880264960079, 0.8871914311954227, 0.1381050327153336, 0.9495626171726634, 0.13733607972448425, 0.9142681796218504, 0.8412652608563314, 0.7957994036147045, 0.8559406580534613, 0.8940930110898739, 0.8897676319538534, 0.8665719317572252, 0.9180100536229241, 0.9038942608560788, 0.09649259790665388, 0.8842989982050382, 0.8339966042248698, 0.8684628121378483, 0.10751945437441268, 0.8451640958055514, 0.7972931980590776, 0.8339915170453058, 0.846316441836572, 0.8543413700775901, 0.8206425126518446, 0.8455420776995728, 0.8724773998717807, 0.9194838701629596, 0.919744353934726, 0.9218709716530753, 0.8393790858210332, 0.8427581729166066, 0.8778077772102575, 0.09849391037885613, 0.14607708432898203, 0.12959379459164755, 0.9109864687565117, 0.04010899230161302, 0.39709411086905944, 0.15411867212885477, 0.384898269689803, 0.1053082238384857, 0.2749722552049487, 0.2812506738146603, 0.9532195273993163, 0.9580137941912357, 0.9575000822078235, 0.9480705744624602, 0.9600035558132237, 0.9709584833188256, 0.9560146015817913, 0.07877377434666033, 0.05786247527815558, 0.07120307946939464, 0.0716050059061406, 0.12051905678710395, 0.08784144096385427, 0.0758285332065245, 0.06140922280614414, 0.06539047006769338, 0.124236342952312, 0.11941384135408883, 0.1438961026165798, 0.15740646435577532, 0.2542021255883061, 0.1784856438822119, 0.17327159042422902, 0.17637585384898224, 0.3283240263423376, 0.2355191775755161, 0.1306071305582931, 0.22504060489575362, 0.14410412657073413, 0.19194392893426826, 0.16462968073559314, 0.18192825783219158, 0.24199828970037263, 0.17857331197895632, 0.13094920152641176, 0.09008711353443144, 0.14371181368816066, 0.17412385830454202, 0.08428649244600106, 0.1742800543579408, 0.1544740857425395, 0.1633334744345104, 0.1510621103943378, 0.2495447249632925, 0.20255891671280524, 0.23384052414988554, 0.21203697810158506, 0.16041566192165646, 0.2590356306137718, 0.24098522892528051, 0.20053765832490578, 0.2532850095060204, 0.19417698022021546, 0.16391292136396063, 0.17003387878650533, 0.15719519439827523, 0.18599500663398383, 0.1783402464564109, 0.16477017965970975, 0.2588020055106557, 0.1633724599515557, 0.1888004812262294, 0.16779976227282423, 0.15316426882559264, 0.1359803707442525, 0.20018590372543899, 0.201281030109978, 0.14306702060195353, 0.1649087197414858, 0.4454648346772919, 0.3115069063752335, 0.21422692195435633, 0.07360622320447341, 0.10473538833925855, 0.1285750174865623, 0.15701733567332832, 0.09453658968721435, 0.09783280840258357, 0.9609949190580531, 0.168609025289561, 0.1764149217547054, 0.18936790937938375, 0.16661335610044914, 0.2720594351727653, 0.22831655567989684, 0.27728611347724474, 0.24002753605380356, 0.20728077280160562, 0.07643817270336573, 0.07687681265418689, 0.0804783518656712, 0.08987368212930846, 0.08214522333225593, 0.05130216513129504, 0.05564351219915842, 0.09308591444119607, 0.07936378113722165]}, "mutation_prompt": null}
{"id": "e2a3acbd-dd83-4e38-98ac-fd36a3756ca4", "solution": "import numpy as np\n\nclass QuantumInspiredDE_ANM_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.base_mutation_factor = 0.9\n        self.base_crossover_rate = 0.7\n\n    def adaptive_parameters(self, fitness):\n        norm_fit = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9)\n        mutation_factor = self.base_mutation_factor * np.exp(-norm_fit * 0.5)\n        crossover_rate = self.base_crossover_rate * (1 - norm_fit**1.5)\n        return mutation_factor, crossover_rate\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            self.func_evals += 1\n            if self.func_evals >= self.budget:\n                return self.pop[np.argmin(self.fitness)]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.pop[np.argmin(self.fitness)]\n\n                mutation_factor, crossover_rate = self.adaptive_parameters(self.fitness)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = np.clip(a + mutation_factor[i] * (b - c + np.random.uniform(-1, 1, self.dim)), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < crossover_rate[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n                \n                f_trial = func(trial)\n                self.func_evals += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.fitness)\n                simplex = np.array([self.pop[best_idx]] + [self.pop[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.fitness[best_idx]:\n                    self.pop[best_idx] = simplex[best_simplex_idx]\n                    self.fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.pop[np.argmin(self.fitness)]", "name": "QuantumInspiredDE_ANM_Improved", "description": "Quantum-Inspired Differential Evolution with Adaptive Nelder-Mead and Dynamic Mutation-Crossover Rates for versatile search space navigation.", "configspace": "", "generation": 35, "fitness": 0.4382393354686917, "feedback": "The algorithm QuantumInspiredDE_ANM_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "1fcef688-bb02-436b-9bae-d908432e0acb", "metadata": {"aucs": [0.9777713072531432, 0.97245624656871, 0.9769067177928159, 0.9783963578605989, 0.975990441321947, 0.9763996702233326, 0.9782754240703339, 0.9761111395973147, 0.9769271423113931, 0.9047287078585312, 0.9224465314132094, 0.9434692702683749, 0.9198632115001667, 0.9003762118673083, 0.9134795265433026, 0.057052013762282305, 0.910913061242625, 0.9281083920619808, 0.04639638365071519, 0.09488706357924326, 0.07614430340439593, 0.07341928864670211, 0.025171190252095244, 0.11435280325110286, 0.07164459476982066, 0.13789287560481844, 0.08758155454011651, 0.05473128524237714, 0.029893953177963173, 0.022866121193426237, 0.04073538002965271, 0.02201949118480495, 0.009737877704259379, 0.04634807561502241, 0.026645954026847884, 0.022874183963172978, 0.9740786074426353, 0.9885953402092722, 0.9614312220486362, 0.9728783281354662, 0.9164540565581856, 0.9670492721782091, 0.9885829820189054, 0.9529538958021498, 0.8562038118259658, 0.8020329183849608, 0.5148230873533155, 0.30416803114238034, 0.32616436435284923, 0.15515241803814495, 0.15472830988011588, 0.668046248306337, 0.7669430054802671, 0.6169404639017797, 0.18537716720551012, 0.20489445079412505, 0.17333143610521506, 0.3698014773630801, 0.16557399665410233, 0.17987477900365934, 0.08758061350343527, 0.11927450973563414, 0.167268572900244, 0.9013225505066562, 0.949663813144498, 0.8599347046125017, 0.10839854798048565, 0.13838950470259648, 0.9355856678005244, 0.9502467811129547, 0.9463710464054003, 0.951875232139542, 0.1309549840186477, 0.9511432216516907, 0.9406871315716192, 0.9434783207008834, 9.999999999998899e-05, 0.9591615174068134, 0.9629522478070804, 0.13641067268342288, 0.2036529168808463, 0.9164341479891657, 0.923339284846626, 0.9135065950926116, 0.9215434602166935, 0.12330420942740461, 0.810652454772615, 0.9020764959366531, 0.8640057789467612, 0.9316909367216377, 0.897427720170763, 0.8804509927942784, 0.1565496033220699, 0.8931345854651861, 0.9226727879582967, 0.893486470835696, 0.8025961096203025, 0.8769320091504375, 0.891317698218089, 0.9193314653649286, 0.9003435274876723, 0.9039140990037344, 0.9235416558829931, 0.1592839835166323, 0.931957840165465, 0.8328377693156213, 0.8272944211362925, 0.8507535002770923, 0.323870560680128, 0.4940151652089908, 0.12069330214978813, 0.2821919824913144, 0.05679658144576749, 0.3733793229401078, 0.16003344191700164, 0.6591919141335578, 0.08898962481303241, 0.9652544363277075, 0.9682145566627159, 0.9688389301602341, 0.9695924798836146, 0.9536170952783276, 0.9677514776019092, 0.9656958855867307, 0.95926040540315, 0.9638792561109392, 0.08711942249531568, 0.07301874204556114, 0.11998503522386583, 0.08727908211905744, 0.021415682447104123, 0.08784578176093127, 0.09880915941273449, 0.14970484545819696, 0.10369599502164295, 0.17122020177269148, 0.251844277692039, 0.1526322386236617, 0.1630722778851721, 0.17791672771880562, 0.1308881859744777, 0.15091802593485681, 0.18005396702344023, 0.1592784265177194, 0.1529676956418733, 0.22410556034279072, 0.24842154510442838, 0.17646789334094592, 0.1667642316779787, 0.1707265961534431, 0.1764672443972224, 0.2474104703548996, 0.1447750949031109, 0.10957840723008427, 0.08909838933966308, 0.1772808272788916, 0.11092451781407509, 0.18908221530746783, 0.13912876327132384, 0.15970475316712096, 0.2340881814140987, 0.10300191104710832, 0.23851088482951666, 0.22047160695518164, 0.14834135194133724, 0.2182200302827887, 0.21219131116747547, 0.3058021431803559, 0.1840629514649229, 0.22292288715742048, 0.2300107654781024, 0.15276237012514515, 0.17182261757921147, 0.1859283296758878, 0.1816966460416164, 0.1813303565136104, 0.1659974158312354, 0.18370931342883368, 0.16338816051907912, 0.1836063977091168, 0.2001971172471304, 0.16769838046945407, 0.16869463509994354, 0.17314567358152377, 0.20190588467176074, 0.11976266365663646, 0.14329364029979874, 0.1658105579883582, 0.1486828099371802, 0.9730745642980506, 0.21396368417364098, 0.1129466514391847, 0.21333340821649238, 0.21328358392165392, 0.16957998168121335, 0.9761886343447937, 0.9620274419617738, 0.9587838038191249, 0.21072797073457394, 0.16998118520349348, 0.22609291435402257, 0.19800819922948687, 0.20241039319404575, 0.19697428413742923, 0.2179135378532313, 0.2606003676591787, 0.2698582265345494, 0.0822558122878223, 0.04110033208826358, 0.06428402287641677, 0.06295189959986114, 0.1045379012118588, 0.08860836573224806, 0.11626156436817037, 0.11152677432725777, 0.10056967700775399]}, "mutation_prompt": null}
{"id": "b1e46895-4230-435d-87ca-438fc421d366", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_ANM", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using quantum superposition principles for enhanced search space exploration and exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.46564358743303036, "feedback": "The algorithm QuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47 with standard deviation 0.37.", "error": "", "parent_id": "1fcef688-bb02-436b-9bae-d908432e0acb", "metadata": {"aucs": [0.9801782246896628, 0.9773506548549438, 0.9762928330587138, 0.9749614148683319, 0.9760140733414094, 0.9806804527220537, 0.9763228820296073, 0.973828664519824, 0.9749657114106289, 0.8900204402699416, 0.9041991162875707, 0.08185785752540409, 0.906905607579257, 0.8998435773948251, 0.9253211534155724, 0.9190361351727717, 0.9471712097219888, 0.9479916398024998, 0.09912981473996829, 0.08464476238991447, 0.0716002402732463, 0.08474389731424758, 0.09499426898243968, 0.07740776112778947, 0.05665958808963656, 0.09914546116351008, 0.1383567544614147, 0.11347446462915123, 0.0655008442942564, 0.0832310129913032, 0.081648159680346, 0.10836890782096475, 0.036207837209879856, 0.0982816084093121, 0.05966244233299389, 0.07392798933452382, 0.9340770855754124, 0.9693004416352712, 0.899209733098111, 0.9141722675365463, 0.9087894696521318, 0.8717775762632716, 0.9878431360571169, 0.9223637279761758, 0.9032309296709281, 0.24480033238421406, 0.41819130978479147, 0.7128651096922527, 0.49048356180259456, 0.8964995932383478, 0.6262714434453949, 0.8893778658950713, 0.7633470947624388, 0.6938244981983901, 0.259306914896674, 0.18108491945215577, 0.13558940228821792, 0.1541860634539537, 0.19885815098946769, 0.19365550661896824, 0.17673612832440444, 0.11250655435150259, 0.07486500988603673, 0.9519766298290436, 0.8864520304769891, 0.9459968403291767, 0.9204849572505789, 0.13811485570581028, 0.9395331251364439, 0.9594093606995782, 0.13835636534997853, 0.9419884256374067, 0.9481168240134926, 0.947093535556995, 0.9057915790315988, 0.13822171354054302, 0.9452239812195733, 0.8449535983133651, 0.9344294095092491, 0.9494251765925069, 0.9265162422335795, 0.9115193292150991, 0.9242586713461014, 0.8831569683630437, 0.9274711274802225, 0.9066182457528243, 0.9234803582961062, 0.8951848511210314, 0.9019208299584548, 0.860688577862064, 0.1467624553605852, 0.9229114585705916, 0.9067686896138283, 0.8891851521113503, 0.837542132655189, 0.8370278770690066, 0.9240498108060388, 0.8499696355424022, 0.8666904013055153, 0.8688315100595915, 0.8524246986018387, 0.8918533054567284, 0.8852074907255356, 0.934296303463248, 0.8551146785004804, 0.7445997803229446, 0.8867654943046327, 0.9008978891040961, 0.3324512401934675, 0.22342840933956565, 0.12803187099731372, 0.32037217877896107, 0.13004422984480457, 0.3886985769502441, 0.5063431318813971, 0.22726839471473126, 0.9338507016662356, 0.9619369490668273, 0.9678440809284972, 0.9657792022339469, 0.964586715442002, 0.9489891718056624, 0.9670869053261167, 0.9660132678910146, 0.9686843929090798, 0.9510209474911309, 0.09123629211691564, 0.06325696805402281, 0.05644857873434217, 0.1284496075699041, 0.08170702419664955, 0.09874425868484071, 0.10260927806869169, 0.06339245382216818, 0.08807280432175413, 0.3430505786685194, 0.13023561890933777, 0.17631643610194891, 0.1518172875105589, 0.15453588034294585, 0.18245287936089816, 0.1797554602651471, 0.11322518102440793, 0.12181770640097334, 0.1649870864092392, 0.18910055881758858, 0.2343257704247037, 0.25914809756788293, 0.1704852858667889, 0.20411889484584267, 0.21870679340526544, 0.2584331566589919, 0.23885653137733198, 0.17905449628758707, 0.11755284044658454, 0.1401442301064908, 0.13684994796639516, 0.13946159921694212, 0.20651434231421362, 0.16032235414142337, 0.29399663718090074, 0.16691127463940303, 0.2316420074537785, 0.16026217274115295, 0.19207047313945813, 0.23359500065275374, 0.2435288446990076, 0.19664067757253, 0.28208259633529975, 0.1838310084634902, 0.1520545322043032, 0.16741819769189004, 0.18455309424250255, 0.17533126571657454, 0.16020480190314534, 0.18208905786878404, 0.18202757484175813, 0.1527392192899113, 0.16807142642635786, 0.1742588934380176, 0.7022364489786656, 0.12718463603165786, 0.14907469021974795, 0.9813987550443436, 0.20191375647678922, 0.17352712970886208, 0.14330959046480451, 0.16643078043596082, 0.16877252116779984, 0.9837213298861535, 0.21380494030788366, 0.4014219991504919, 0.21286915564006326, 0.16969930013851187, 0.15671357961556864, 0.07140653084673176, 0.10450685429489115, 0.967812388879714, 0.19556877910910564, 0.24883923659728258, 0.223105986784069, 0.20718502233711322, 0.23781427584864145, 0.1674561207880041, 0.20908564731149248, 0.17726419215687095, 0.20103938156455292, 0.11349599876503746, 0.09379338500737322, 0.07523424787335531, 0.06938657384925229, 0.07743013529454323, 0.07811522780526647, 0.10044861739465383, 0.07279876222739767, 0.08379983932839408]}, "mutation_prompt": null}
{"id": "d5369e04-bc5c-432c-a9d1-40866bfa1890", "solution": "import numpy as np\n\nclass AdaptiveQIPSO_ENM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim  # Increased population size for better exploration\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # Reduced initial velocity range\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.5  # Increased reflection coefficient for more aggressive exploration\n        self.beta = 0.4  # Decreased contraction coefficient for finer adjustments\n        self.gamma = 2.5  # Increased expansion coefficient for broader search\n        self.inertia_weight = 0.5  # Adjusted inertia weight for balance\n        self.cognitive_weight = 2.0  # Increased cognitive weight for individual exploitation\n        self.social_weight = 1.2  # Reduced social weight for less dependency on global best\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQIPSO_ENM", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Enhanced Nelder-Mead Refinement for robust exploration and exploitation.", "configspace": "", "generation": 37, "fitness": 0.19071696842369262, "feedback": "The algorithm AdaptiveQIPSO_ENM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.15640103715184905, 0.4331229623311844, 0.34143969942474317, 0.21721352076325884, 0.8130720863589407, 0.3339006809390216, 0.3063145026801608, 0.16694633743973153, 0.20155816762137935, 0.21266764828691653, 9.999999999998899e-05, 0.10196270821450559, 9.999999999998899e-05, 0.09033764657627674, 0.29767926806970746, 0.0365216314810356, 0.11128778786985094, 0.048955868862537, 0.08359512574491201, 0.08740958055154735, 0.09067173118018257, 0.09815762905363012, 0.0614167739653354, 0.10328020086395917, 0.05023180952831441, 0.09443884776306677, 0.08930759147285228, 0.056545055579113046, 0.03837606754509393, 0.0628194757318985, 0.12018615806022848, 0.046687630853545437, 0.0632593133831475, 0.07707228513314368, 0.07665506920170284, 0.1308425918855448, 0.9527654954135408, 0.9418604107436869, 0.9849544079180842, 0.9820141451048818, 0.9354273217329806, 0.9753798096791934, 0.9869042236961114, 0.9514512881014282, 0.9773280945026604, 0.13069453968678024, 0.2765154908409322, 0.14745588576228674, 0.22738426270811407, 0.11389061310424642, 0.2212231120996454, 0.12393648948734115, 0.07662582091738546, 0.08862801495629158, 0.20932959427475284, 0.22579202495478945, 0.17795008148009217, 0.21293754930529452, 0.1784321350302669, 0.20530450933278477, 0.1976687913937527, 0.11771164933944134, 0.15484559953248045, 0.15534041111279717, 0.1021085332188959, 9.999999999998899e-05, 0.1431349232851018, 0.20184191005326224, 0.06358112848788056, 0.08775945646316285, 9.999999999998899e-05, 0.13071405708672557, 9.999999999998899e-05, 0.13180280109617704, 0.12479062274396435, 0.12674408140879023, 0.1447214643256448, 0.16201315146854234, 0.13710862370836674, 0.007904001906768876, 0.13004830870550743, 0.15578239212125222, 0.04543507937297986, 0.11424688421562246, 0.07073386513627133, 0.039331809384285266, 0.36240083542673207, 0.130331600921336, 0.06392942849502037, 0.09617966735674632, 0.34835343822120923, 0.058162009136549564, 0.17276707124495683, 0.07295412888150676, 0.09519799920571481, 0.13234890265365284, 0.13984297498692344, 0.22093501175494856, 0.2763360124170815, 0.21576603376675163, 0.09517193587090444, 0.16445034917783563, 0.09526443984820399, 0.12880484821445648, 0.08978299572666093, 0.1464564986981708, 0.09995797231056636, 0.11272501422591052, 0.07208078770209392, 0.1468822063525015, 9.999999999998899e-05, 0.0004776044724221773, 0.06035639602974263, 0.09751516929085668, 0.16998954932719135, 0.16094188233218976, 0.11803719954409186, 0.3762057955271402, 0.234910075167304, 0.46242531500531536, 0.3557494138099543, 0.21702406213826209, 0.259679644414744, 0.3515057485401749, 0.21078964949168877, 0.38805297281099527, 0.08582878514792014, 0.08405650621100846, 0.05524226670835264, 0.10830422158390063, 0.07100199516086847, 0.16772642631411694, 0.16458092020709225, 0.08367852597778769, 0.10665742927821942, 0.10541469311940821, 0.12187538822135724, 0.14183838788479552, 0.15375384547706505, 0.18308378465050612, 0.1577044962146691, 0.10717010037373731, 0.13039297685063067, 0.10855740283087378, 0.15101648010686408, 0.2711299121390519, 0.20289957735126118, 0.17362248632969934, 0.20289318973755877, 0.16528765526931533, 0.1575655514940063, 0.18481401324999092, 0.20004390759274404, 0.2525481731293263, 0.20994899815601742, 0.13843061258331724, 0.19920525174866366, 0.139309725410813, 0.12271598992307042, 0.17565762148276842, 0.14338576833986028, 0.0929379627647815, 0.22303061162215576, 0.20697970968062884, 0.1478635562060614, 0.22236054521163584, 0.2355747215478502, 0.19939135397474128, 0.22437928503765703, 0.2840876527804813, 0.25016547402849443, 0.1674162795125239, 0.14819418927932781, 0.18235947515568074, 0.19943429947936253, 0.16500274276437865, 0.16887740457665845, 0.19721334268089497, 0.17452382420986545, 0.17751284584268945, 0.24100716471680184, 0.18822708684444478, 0.18892138509929768, 0.17355982737680953, 0.16932670912081682, 0.1413497146833168, 0.14287839296028493, 0.1261537855700683, 0.21321423181620525, 0.40369714924012556, 0.16943203646501537, 0.20274503603914862, 0.19921641701358694, 0.16950381226346467, 0.09460726110345496, 0.10259810081487264, 0.19171740983475494, 0.26789415638223424, 0.17816257539588476, 0.20300148100269, 0.16774219872602425, 0.25543577863201394, 0.20995726254258817, 0.18474875398321788, 0.21737871376393147, 0.22105601755502025, 0.19701998145572952, 0.10244108230924098, 0.0688698189884579, 0.09130875903252023, 0.06910782132902205, 0.0944368535102702, 0.07630596807263246, 0.08158267155359189, 0.06384415063907911, 0.08053527260041116]}, "mutation_prompt": null}
{"id": "a5ee5534-b173-4525-8ae2-7f5114eac078", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.4\n        self.gamma = 2.2\n        self.inertia_weight = 0.8\n        self.cognitive_weight = 1.6\n        self.social_weight = 1.4\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Enhanced Nelder-Mead using dynamic exploration-exploitation balance and simplex adjustments.", "configspace": "", "generation": 38, "fitness": 0.3497219637918914, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.32.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9693105503418912, 0.9468014033245393, 0.9743653645530042, 0.9708054345804406, 0.9703660078809409, 0.9643261029519393, 0.9525085115865678, 0.9703978844514037, 0.9329978353505214, 0.2228548083456714, 0.46639815069429935, 0.2427261663245449, 0.34322049538073274, 0.5319257809506736, 0.4025630927718502, 0.8598534509271742, 0.26392937477582934, 0.4011355245764615, 0.08096487037792688, 0.06932791433072671, 0.11377033557767247, 0.11383173500293065, 0.10376545522709602, 0.12861641978248717, 0.04790658729389541, 0.08580804339199044, 0.06694720041564683, 0.06767048572865042, 0.048789204313855805, 0.08158660556844011, 0.08710322254851721, 0.08139848751690026, 0.06689689410163502, 0.09432776228548245, 0.09893965748677325, 0.07877151983838371, 0.9864449037180285, 0.989350599908062, 0.9562233055449305, 0.9539870682043337, 0.09932422426198029, 0.9435956844945345, 0.9888558380738466, 0.9100040612925916, 0.9280377470016763, 0.09114769178354687, 0.07272457481789629, 0.15612694819565154, 0.15491711582327394, 0.3309931865226444, 0.30500807536733954, 0.17596130613930816, 0.2067209949526606, 0.2415613898568375, 0.26782133456512613, 0.21220548720112853, 0.13439510643325359, 0.09636962836250584, 0.17290272342126278, 0.17974735894212845, 0.08762095410649784, 0.11166415213257319, 0.11542793045793553, 0.8601657130700557, 0.8453996672259031, 0.8232775398381186, 0.8233690140652111, 0.8967447431776057, 0.9134794519075895, 0.9504610833738703, 0.9403533771911069, 0.894642459992958, 0.8558231941001379, 0.13792604577480794, 0.7644866318998144, 0.13673483439787215, 0.8040611719067141, 0.8661002045674571, 0.1376642317097767, 0.8869304047145714, 0.8526017381190656, 0.16589888915668782, 0.42816641810726896, 0.2378833703590819, 0.22236399631641257, 0.13824981905243516, 0.10562931373525464, 0.05571285300327122, 0.5730689397243578, 0.29142929231254844, 0.1164934057582464, 0.31361611657217914, 0.16676319789489358, 0.3514509712842824, 0.5788415008472627, 0.5688651667080437, 0.49550216966543525, 0.48622281659191824, 0.728904478919607, 0.2519068534248464, 0.32891281838094877, 0.7143403549534428, 0.9040853333708541, 0.5311890994459816, 0.9053144158413842, 0.5687326919884594, 0.5045093862483407, 0.6999488151138129, 0.44662965104739627, 0.23029744707450472, 0.122169542367768, 0.03932548050912865, 0.07177103431525811, 0.0618717047335654, 0.08899706160340193, 0.1983064689361146, 0.12406689536856719, 0.9401061605991335, 0.9178034607166865, 0.9422341753691041, 0.9143004572353922, 0.23018700771397393, 0.8925291878252493, 0.9133839534116759, 0.9364236719716676, 0.8901013422408479, 0.06829917467251523, 0.08158230021632895, 0.0494203542683348, 0.09903344039784989, 0.0815945434622487, 0.11460570154615723, 0.09126506261191147, 0.10559423878932706, 0.11951956511119166, 0.1508615994274225, 0.15737208151168958, 0.17405681669621098, 0.1253267872707613, 0.2756174874040431, 0.1875908329892504, 0.244867921845209, 0.21552512636640142, 0.13262623839953303, 0.24430482095113304, 0.18350981493335483, 0.20477542824618267, 0.17561615317274593, 0.2575178345356379, 0.1700794780160415, 0.1767097127036743, 0.30557111697274175, 0.29724094749095276, 0.15210072514989137, 0.15053164294430788, 0.16280329547769856, 0.16529839999573614, 0.1437752220877474, 0.12225984106446885, 0.09942624329753269, 0.19374165156590595, 0.2169575283482572, 0.18502438053938208, 0.23836260533340115, 0.17723206015824688, 0.17682505875068566, 0.1480652083506886, 0.2326311649158862, 0.18356549629033003, 0.21297655072605526, 0.301709096443156, 0.16051222858640246, 0.1745955925040118, 0.1879972424269275, 0.18642995352738057, 0.17169622508621674, 0.16012001135131304, 0.17164392567599784, 0.14982448921843095, 0.1904438711983636, 0.9624859965632911, 0.12751491940133786, 0.14869769912877506, 0.17148076622241437, 0.20191792195905456, 0.17040676899405194, 0.14334360875201835, 0.16631801759957765, 0.2141651370144093, 0.9833513345849558, 0.21465209799725704, 0.07272668262476911, 0.21231939530518784, 0.16963357497906184, 0.15345559782845952, 0.07166526564155828, 0.9152439980828265, 0.1690446521489395, 0.17426090684112072, 0.21319756155070935, 0.16441675431985237, 0.1931827819833326, 0.18759298173559824, 0.17367026924407059, 0.19093985273021807, 0.19296520497255742, 0.17148037901922053, 0.08321314311221972, 0.056438634196896986, 0.08163584240649868, 0.08136793082687577, 0.062401519004727235, 0.10084386934918077, 0.09391427523902363, 0.07244686436446368, 0.11414125531238295]}, "mutation_prompt": null}
{"id": "b85e5c67-7694-4523-a2db-71e08bca456f", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_DE_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.inertia_weight = 0.8\n        self.cognitive_weight = 1.3\n        self.social_weight = 1.7\n        self.cr = 0.9\n        self.f = 0.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        trial_vector = self.pop[i] + self.f * (self.pop[np.random.randint(self.pop_size)] - self.pop[np.random.randint(self.pop_size)])\n        crossover = np.random.rand(self.dim) < self.cr\n        self.pop[i] = np.clip(np.where(crossover, trial_vector, self.pop[i] + self.velocities[i]), self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + 1.0 * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + 2.0 * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + 0.5 * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_DE_ANM", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization and Differential Evolution with Nelder-Mead for enhanced exploration-exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.4370873112347715, "feedback": "The algorithm QuantumInspiredPSO_DE_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9771259748270537, 0.9681185791456173, 0.17672648805218194, 0.9776007508185797, 0.9755749532655733, 0.1347559443528067, 0.9783646421042017, 0.9740759638633666, 0.9730907100861974, 0.934544521803592, 0.8967129434368705, 0.9402641256884943, 0.9345459673533696, 0.9095734484576027, 0.9168235420333584, 0.9414015124235483, 0.9057575170530543, 0.056661309238143276, 0.07135694973756834, 0.06141031269664965, 0.07840589566997713, 0.13788302333055913, 0.03949856956558906, 0.11392073262346125, 0.09892621133814994, 0.055835442790084566, 0.04467148834063461, 0.07127659468678138, 0.11382504793754156, 0.05797498936534207, 0.07156168759769932, 0.06103700544113966, 0.0419363099541602, 0.09884794427622967, 0.041254413120164646, 0.05965127347446064, 0.9404757767087584, 0.9883543387444114, 0.9851102676456914, 0.9159627117879261, 0.9499012578297812, 0.9627438541734202, 0.9871899734603597, 0.9550709288376061, 0.9892737978974194, 0.6389599374280344, 0.05991483859869873, 0.06004893527123045, 0.7577114871582044, 0.5571134482166483, 0.3284433028216507, 0.8734818684671842, 0.13129909548905105, 0.08900252280072274, 0.1812412744126951, 0.2117023512407693, 0.14151292077072375, 0.11526477577119043, 0.21575634300818047, 0.16193606064180988, 0.152107539167323, 0.12135128565229825, 0.12885380181572037, 0.9372574644830712, 0.9361109674053805, 0.9012736800899988, 0.9448734875032845, 0.13804692031711752, 0.9424783787912828, 0.9477784834315538, 0.13772553378604568, 0.13623324675768833, 0.9521150796563951, 0.9334110656802448, 0.13808682060255828, 0.007205446658219761, 0.13828851254901908, 0.1381559109725271, 0.9470261589556027, 0.9379796945821788, 0.9388790644017527, 0.7809056084312003, 0.915390923194606, 0.929806289330587, 0.906609238333099, 0.9175943814496038, 0.919840315347837, 0.9369209081846809, 0.9169815229482703, 0.9267802190802077, 0.9026284197791432, 0.917875306523007, 0.8973082415506094, 0.9177306538654352, 0.8595571385324252, 0.9236587484551027, 0.8908042747630367, 0.8937655889622995, 0.8066184097358637, 0.8164891613105542, 0.9125073424267411, 0.875904255005122, 0.8880016407784987, 0.19706729092853248, 0.9179721387481888, 0.8308644476421219, 0.8709750098375068, 0.8445154278268538, 0.6689650197749695, 0.06371476760386141, 0.9011912577292842, 0.3806733052490172, 0.5248978467163372, 0.14702630848710374, 0.6241850629236722, 0.2646422464417094, 0.600977541832346, 0.962641135910362, 0.9685808758677031, 0.9616114211087445, 0.9645125575051308, 0.9441925733823315, 0.9618000835800256, 0.9636791224282164, 0.9629256998783424, 0.9649763423619884, 0.07846780249056506, 0.03070574593393116, 0.10319937371569043, 0.15044024074519258, 0.0839452544890209, 0.08811990007625159, 0.09104926797597268, 0.09106576271416322, 0.09872853710583118, 0.1939543266924969, 0.11029359000199745, 0.1812938713879223, 0.14482489650571428, 0.15486590599146943, 0.15459198094338877, 0.17519631415152548, 0.2403584936371198, 0.12798042162515444, 0.18925999297514828, 0.1828260249873953, 0.19990239284131972, 0.19236120705737225, 0.16318158600515031, 0.21006048160634305, 0.18926108096518224, 0.20001476611244984, 0.18106136486015967, 0.14249885714904265, 0.07117608598293701, 0.15372659837976643, 0.16020704203319058, 0.18894743368435285, 0.11105432598288756, 0.14396969885314648, 0.12396679826183976, 0.09572992484760912, 0.2782326579772698, 0.22725253702609804, 0.1497752369161499, 0.2402997404439866, 0.18282413567149047, 0.23732919855963597, 0.20513025485690262, 0.1866404105379853, 0.25552438599248495, 0.16058114969110449, 0.15916399715484675, 0.16217489091223591, 0.1800655943582924, 0.1804570418206577, 0.16140676069133986, 0.17535504602587904, 0.20535805476569458, 0.17789703723875605, 0.17295533553595321, 0.12718083305548733, 0.1546352894613392, 0.1731047865148908, 0.2015257658013646, 0.153988951663668, 0.1432892979109731, 0.1660857376751994, 0.9725891202333636, 0.3567923646806399, 0.2135640971761491, 0.9671773040745832, 0.15761562405676177, 0.16807040803674644, 0.15655977348322336, 0.9723610830261878, 0.15741103515024701, 0.962964864528329, 0.16946712383700413, 0.2519632704278537, 0.18759461913086128, 0.18244799341600115, 0.19954797140345182, 0.20904049815024373, 0.1997603907528246, 0.21414702324119417, 0.2204258302619202, 0.09177146264085245, 0.08057082332374488, 0.06338155204958507, 0.07570175989668548, 0.06889795358982265, 0.07278894883575215, 0.08478543688295836, 0.0974466474021356, 0.049523299849629665]}, "mutation_prompt": null}
{"id": "f7567afb-bd98-44e6-9872-1a19a8516aa6", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_EDINM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.2\n        self.social_weight = 1.7\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget and np.std(simplex_fitness) > 0.01:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_EDINM", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Enhanced Dynamic Inertia and Adaptive Nelder-Mead for improved exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.31868121912999076, "feedback": "The algorithm QuantumInspiredPSO_EDINM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.21.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.43797577638541463, 0.4358292882002899, 0.4096985207406748, 0.4275121216969945, 0.43132800659546455, 0.42302992840941755, 0.43164294636228406, 0.43088128213330135, 0.4125483605428222, 0.3800244375535766, 0.3450949317406329, 0.37491034945110624, 0.39501695775696044, 0.3490892193961983, 0.3770142125214987, 0.34173771775149053, 0.38229259412209404, 0.3871076717613544, 0.08701735507947594, 0.11442696485637227, 0.09894228847134634, 0.0832416312384221, 0.10086828212649035, 0.11007156049079947, 0.09227291738151144, 0.13807945367573504, 0.07556575808680244, 0.07513699075974423, 0.07890468851155563, 0.059860393924254796, 0.09011938343269199, 0.11428696307814246, 0.10654277457272332, 0.07688852300761373, 0.12872906084368385, 0.09731298223208273, 0.9851760730647088, 0.9916980784169809, 0.9851968559225772, 0.9889028481757696, 0.9753059124003565, 0.968072336726508, 0.9887905340243537, 0.9875363778355878, 0.9717635622335878, 0.4200068758791423, 0.3854988967859715, 0.3858932619610491, 0.42220788563865574, 0.4489700633022209, 0.43210446967393756, 0.4332965178825522, 0.33264913329723067, 0.4393984767887559, 0.9457170197539666, 0.8650980999752961, 0.8883117024435196, 0.8544053237932033, 0.9040222156268962, 0.20149988738462787, 0.30415723903940717, 0.6264886319480913, 0.8632198238337385, 0.35373386078027547, 0.13770476828708011, 0.36604646952163034, 0.3187505527127622, 0.2908795818150455, 0.2653117402450812, 0.3566916717294749, 0.13103017465406153, 0.1379391191676561, 0.3268183300292914, 0.13801523070717836, 0.3498322651781576, 0.2703688564668908, 0.4290958165630483, 0.3420997134979715, 0.36494634578893115, 0.3485333910894064, 0.137274520923779, 0.3571616757752809, 0.38324136363935635, 0.36567590066599653, 0.33087857200861215, 0.42006317962506834, 0.3475238826914421, 0.3801444298564134, 0.3852050647120342, 0.39984265229574134, 0.35636029427500215, 0.3473593351693467, 0.31298380412762794, 0.38648873268722816, 0.4338348332194869, 0.3826284639878754, 0.35076571295967773, 0.2750904014377231, 0.3800624300830393, 0.24539915679327762, 0.29912589325680916, 0.3546906226509543, 0.3697932475487241, 0.32606892890685535, 0.1871139057808242, 0.2137750715355632, 0.2700442687077861, 0.3586736293492456, 0.35497288866871723, 0.3333189653514681, 0.33819762405610077, 0.3552460559763182, 0.35604994239649546, 0.34816725139088345, 0.35417002454720603, 0.3504786797978673, 0.33971164234553397, 0.3972686932291035, 0.38361867285817774, 0.3863192350068222, 0.38896418958939616, 0.388284135821499, 0.3921408106900911, 0.3977986268607566, 0.4296991030249585, 0.39351979031106876, 0.07808479421345293, 0.11965914791753951, 0.12019595173049169, 0.11407956006982478, 0.10393494812455772, 0.1503101928303069, 0.12798329805929498, 0.1084786103438462, 0.12531770293198785, 0.17208206448681662, 0.12934344151771526, 0.22366324697195872, 0.2516700754958946, 0.4388565812741927, 0.16763763659612174, 0.32649746028554705, 0.15517353262649503, 0.39944688650660953, 0.3530872544678896, 0.37273652794714984, 0.33958191738796517, 0.25257172142993, 0.3727284024459394, 0.2853976735561531, 0.3172429493154797, 0.34186222192507, 0.17751663731749356, 0.15423218485278645, 0.31481464000453185, 0.2408741869748946, 0.2043936596650775, 0.1611707273746057, 0.2733614070904046, 0.274651123700575, 0.314293728275147, 0.23600601038448044, 0.2479586376274281, 0.22243650893917788, 0.21495525342199906, 0.16675360054264166, 0.17507837780277802, 0.1909471400406645, 0.21731160865431043, 0.1978592299879559, 0.22586371818531636, 0.20079176556516876, 0.2104206840029298, 0.17482225947213015, 0.1728600921332969, 0.2134686183518827, 0.19956692999931125, 0.2197172389974934, 0.18485050140052506, 0.18524737311023887, 0.16626216591459486, 0.16213076017707284, 0.15489114435217166, 0.5389868146637329, 0.20223159081869813, 0.5029300298448307, 0.14334679847665122, 0.16895196751368968, 0.21409221404268952, 0.5444178310786509, 0.21430849568155563, 0.5290617014535737, 0.3557874988972488, 0.4873594786511416, 0.15658774297010025, 0.19839791130084383, 0.2116208935555003, 0.24876387068512817, 0.2414294508674807, 0.21717167383198643, 0.2159087090074071, 0.21472728193721335, 0.26052742529078865, 0.2013012046229824, 0.26097941090351473, 0.22983505522903902, 0.24887311641502674, 0.06853448674257101, 0.06576781907692986, 0.0846559434630677, 0.08205265701004605, 0.07795343915522412, 0.09393074406167956, 0.09244260226101708, 0.11361556600979694, 0.07607559825398369]}, "mutation_prompt": null}
{"id": "2dfb512c-e6a9-4806-b406-01cfcad98eb0", "solution": "import numpy as np\n\nclass HybridDynamicPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = np.random.uniform(0.8, 1.5)\n        self.beta = np.random.uniform(0.3, 0.7)\n        self.gamma = np.random.uniform(1.5, 2.5)\n        self.inertia_weight = np.random.uniform(0.6, 0.9)\n        self.cognitive_weight = np.random.uniform(1.2, 1.7)\n        self.social_weight = np.random.uniform(1.2, 1.7)\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "HybridDynamicPSO_ANM", "description": "Hybrid Dynamic PSO with Adaptive Nelder-Mead and Randomized Exploration leverages dynamic parameters with stochastic adjustments for enhanced convergence and exploration balance.", "configspace": "", "generation": 41, "fitness": 0.4461928998468789, "feedback": "The algorithm HybridDynamicPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9786116320892222, 0.9817277738827235, 0.9775537071839743, 0.9805758546968384, 0.9723034631343884, 0.9788307329059907, 0.973646304345669, 0.9739019391568305, 0.9687259028422895, 0.890041554535117, 0.5783391723848523, 0.8558902625677536, 0.9117586107437157, 0.7343943075801066, 0.8540040639867383, 0.05720511208299561, 0.836716240817255, 0.8131293595098341, 0.16803585036525204, 0.11443150086189757, 0.11260538095515005, 0.06146761108649257, 0.07391144617240863, 0.13756116466020119, 0.052129977820898454, 0.11117707080525141, 0.0713977200783309, 0.05056012578809299, 0.09131122423528926, 0.03448404903244284, 0.07154258996330498, 0.047642226098118634, 0.08162945322247284, 0.05603640308008284, 0.08785543912037752, 0.06329245159659225, 0.9454178041313672, 0.9654583573639707, 0.9158368558174482, 0.9577120091281948, 0.9885807150533261, 0.9755207755982218, 0.9459601273752694, 0.9563360377453017, 0.98542701832868, 0.3445999550727874, 0.13846529834894794, 0.14531709472990684, 0.6292203749838137, 0.8241626619595099, 0.18277543716973477, 0.18516953287804927, 0.23058254143671286, 0.45249798846469547, 0.18731254238839423, 0.17400938642083041, 0.1582867154492391, 0.2105910213235297, 0.1751231500222803, 0.13157938791884205, 0.13149895141382295, 0.28642784123465204, 0.15273381948453568, 0.9074823391455399, 0.9430921382052531, 0.13835047995464334, 0.15600888283788605, 0.09379384983658978, 0.9472590569864655, 0.9457049810251376, 0.9460849930058179, 0.12272361693787881, 0.9505960848119163, 0.9327475602937945, 0.9202731153766833, 0.9632825116393957, 0.9467089685655206, 0.9174007366853134, 0.9582999832899918, 0.9120589600214409, 0.8446936336651002, 0.7563365004769054, 0.8487851784633275, 9.999999999998899e-05, 0.9317734231904753, 0.8164700114125777, 0.827628768507757, 0.8727771501326194, 0.8760488389917793, 0.8681498187216923, 0.8022845899582821, 0.8800331054029047, 0.887136196725315, 0.8082519211004852, 0.8930092228808818, 0.8923604641963038, 0.8400438230923981, 0.8001856600687227, 0.8465475462868177, 0.8897279313987434, 0.9160583270249972, 0.7978935936332466, 0.9003563071872713, 0.8439592222399628, 0.9422201809026707, 0.9096143579188252, 0.8571746714060016, 0.8414842793131312, 0.1065835198731685, 0.9380467106749724, 0.9284526589711056, 0.7478559985671602, 0.6984497410676921, 0.9273919197034995, 0.06019438946217048, 0.08691419539742584, 0.2110154750571367, 0.9720970666874749, 0.9556177510615813, 0.9632987499397483, 0.9723347731863586, 0.30657253783938343, 0.965889275922763, 0.9650016614291878, 0.9628355854574306, 0.9335238436762466, 0.11432857398533647, 0.08786600166903613, 0.045892974138238785, 0.1140199789516062, 0.03359492038958267, 0.040864685060365114, 0.06533813580436365, 0.15068070677514622, 0.10540337916565767, 0.13364390743805366, 0.20057482991533726, 0.16322385972432463, 0.12514326260280972, 0.2012693159452149, 0.15755241913788431, 0.3390675766432123, 0.12797764345481688, 0.17771151258917284, 0.20412066584134236, 0.19958525045219544, 0.20020683994356148, 0.1918329723045875, 0.17022725536105898, 0.15378530246431732, 0.19552353763102182, 0.2080446388979994, 0.2441331780251189, 0.13421511229305083, 0.1565394758711196, 0.13386460344424722, 0.14364427974447713, 0.11344452178808884, 0.12518366151052507, 0.12425198902333323, 0.16029540207318693, 0.17302400692489806, 0.2125648913340168, 0.1314127634329605, 0.1810909786473801, 0.2466561812323479, 0.2003179276484769, 0.20937901876143794, 0.25400682623292303, 0.23324050373115957, 0.19408549208571724, 0.1782163745635006, 0.1770672780421939, 0.1677632038078447, 0.1666391380372979, 0.15769403835206652, 0.17905105090306184, 0.18176466980477202, 0.18532170326709851, 0.19261588737530588, 0.10543655212044212, 0.12733762927731618, 0.1516385852092993, 0.2166060128983065, 0.20114267357505222, 0.20084785945557548, 0.14337385338081476, 0.16372352098100296, 0.3158045995432881, 0.9821086648255064, 0.21428822402669379, 0.07361834564522396, 0.9255392495076088, 0.16971521528021982, 0.15664358040086612, 0.21402278600849145, 0.968410017173803, 0.9658108021424507, 0.18904231586161147, 0.17069874330877732, 0.19065441752194934, 0.22873154983959398, 0.22654245510056137, 0.2090678346351975, 0.2081328310931495, 0.17740907805071893, 0.18997212850648826, 0.07020311082031272, 0.09398606719593483, 0.04820253106333161, 0.09176118694699031, 0.07033585967638123, 0.07111420688147951, 0.05965145796719895, 0.07451229360758282, 0.0705359056287711]}, "mutation_prompt": null}
{"id": "d7439361-099d-4d12-814d-70e7fa434948", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = max(20, 5 * dim)  # Increase population size for better diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Adjust reflection parameter for more aggressive search\n        self.beta = 0.4  # Adjust contraction parameter for better convergence\n        self.gamma = 1.5  # Adjust expansion parameter for higher exploration\n        self.inertia_weight = 0.8  # Increase inertia to maintain momentum\n        self.cognitive_weight = 1.3  # Balance cognitive weight\n        self.social_weight = 1.7  # Increase social weight for better convergence\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def crossover(self, parent1, parent2):\n        crossover_point = np.random.randint(1, self.dim)\n        child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        return np.clip(child, self.lb, self.ub)\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            # Update particles\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            # Hybrid optimization with Crossover and Nelder-Mead\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                # Crossover for further refinement\n                parent1, parent2 = simplex[np.argmin(simplex_fitness)], simplex[np.argmax(simplex_fitness)]\n                child = self.crossover(parent1, parent2)\n                f_child = func(child)\n                self.func_evals += 1\n\n                if f_child < np.max(simplex_fitness):\n                    simplex[np.argmax(simplex_fitness)] = child\n                    simplex_fitness[np.argmax(simplex_fitness)] = f_child\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumPSO_Hybrid", "description": "Adaptive Quantum-Influenced Particle Swarm Optimization with Hybrid Nelder-Mead-Genetic Algorithm Crossover for enhanced exploration and solution refinement.", "configspace": "", "generation": 42, "fitness": 0.3483253404150313, "feedback": "The algorithm AdaptiveQuantumPSO_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.34.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.1802525412181698, 0.9760018287401537, 0.19376812249081, 0.976772256701812, 0.9685726489648828, 0.9708645133329818, 0.9736719842853959, 0.9687476689913348, 0.23826798111392156, 0.8037951821899542, 0.7491733871466386, 9.999999999998899e-05, 9.999999999998899e-05, 0.8425260529337815, 0.07187583685000098, 0.06252030665968256, 0.7948251020481707, 0.8472074873560654, 0.11768450065966485, 0.0913706849648106, 0.14955764883036937, 0.04202774502039919, 0.08506087105297133, 0.07361110359976863, 0.06559751651339663, 0.09879619749354474, 0.1364344768240402, 0.06710501260108304, 0.08782972513454024, 0.018640074546793062, 0.048163747785919475, 0.03977898441042593, 0.023370518002634566, 0.06272036523205149, 0.042870784833024644, 0.06295986534463249, 0.9151823091721498, 0.9901070337962907, 0.9321309102725808, 0.8770385510164413, 0.9124225650051346, 0.9928512348893143, 0.9268346171025671, 0.9674532179104103, 0.9798948404759166, 0.4035696434467071, 0.09012741388545142, 0.175016164625434, 0.23769159091799585, 0.18210429386091576, 0.13184099153897189, 0.45081109020906895, 0.44232879370600164, 0.32348804331254855, 0.1602568143278128, 0.07971600812897195, 0.11594645578361651, 0.24613988865806513, 0.12038016497827286, 0.10076144924136754, 0.08413002078118093, 0.12484083407206381, 0.10838178308863133, 0.9084944191200152, 9.999999999998899e-05, 9.999999999998899e-05, 0.8955765005487485, 0.932226465596205, 0.8618144612631214, 0.9046252570669328, 0.9219712367948553, 0.16038055914902927, 0.9056047924574475, 0.916532387692706, 0.18935738857211803, 0.19022149142165112, 0.9045949365016837, 0.142543268765, 0.9278363991928527, 0.8216089272089362, 0.11821773412380132, 0.5235838725595741, 0.8269461564800447, 0.7864324480925322, 0.7666373550051171, 0.7615516369491342, 0.062435168663106166, 0.10971720111950267, 0.051974166157049195, 0.8130222656035493, 0.8254231047377757, 0.25356808879484827, 0.7856463428651984, 0.10581332051331627, 0.8364416441138008, 0.8538021322311368, 0.32502833741392, 0.8303442620107852, 0.13982747360466696, 0.9005819166493135, 0.7788979233274692, 0.767763197111087, 0.5515388870734943, 0.8376893647546697, 0.9203568122651087, 0.7129963931450547, 0.16697515849651878, 0.08285249063150257, 0.07099831039759208, 0.07120443502273244, 0.11979464588867705, 0.02037902611699005, 0.10334951689379779, 0.01855435529457372, 0.06286236924780586, 0.1451724461945767, 0.08769372021178456, 0.9530681994785475, 0.9467320605662997, 0.20874755808565115, 0.9491801734550476, 0.9635640748395593, 0.9473491510993922, 0.9515114854522091, 0.9488882008330661, 0.16681069502518875, 0.05518373995440595, 0.09159676345190515, 0.04287935209820881, 0.09898018294040989, 0.14835768101973557, 0.12116287280689886, 0.11840723833675038, 0.07637240906153331, 0.07417131521275189, 0.15278651175191715, 0.1584180438487156, 0.09924356960050595, 0.18630403358071812, 0.131287886785187, 0.1392890951250031, 0.17242193976256037, 0.157999913637905, 0.15773981787768065, 0.17220829017689376, 0.2465876886473427, 0.18762518112306992, 0.21480889696726524, 0.23646693407676989, 0.19730393804817536, 0.19292220234854995, 0.1851669115239386, 0.22562077088248156, 0.13079785877432137, 0.18380719463150208, 0.10446488953109823, 0.16656839039981497, 0.11234451473619178, 0.1907412271670853, 0.16416852407055194, 0.1706184354298479, 0.17501059216154047, 0.20659133048131084, 0.1777451131969685, 0.19479695960689392, 0.1693993006599962, 0.27305927584095646, 0.28131188991996303, 0.1969105853052534, 0.24435908973735554, 0.20621553125667014, 0.1460970752645795, 0.19406238043630442, 0.17160447329829198, 0.15991002977529656, 0.17204304459703657, 0.18858336725725544, 0.17167073279309275, 0.16520851988343, 0.19926779062293398, 0.967375444172658, 0.12753168055831376, 0.1551691994576775, 0.17370798322939063, 0.20203220472499928, 0.18447640707102342, 0.10004851163178885, 0.975492546782386, 0.17828182259296332, 0.08335896870935011, 0.15582420581773715, 0.11281890657719795, 0.1053496043130906, 0.17028155358118024, 0.17726295562921646, 0.1054479664383704, 0.9576818024356768, 0.9535560748358605, 0.17726995134171197, 0.1914517763172895, 0.2431946160034021, 0.1669854097847907, 0.22868254076967054, 0.19164623114910406, 0.21446445205553577, 0.24437528216979376, 0.24961861350078085, 0.1100130849686044, 0.053638520532473755, 0.063253136919729, 0.0752511245674643, 0.08028852670601094, 0.05683966288517095, 0.08527678352676415, 0.08053877473252047, 0.061532687648661155]}, "mutation_prompt": null}
{"id": "435076bf-5562-4211-8806-f6014adf0f56", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO_DynamicNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.5 + np.random.rand() * 0.5\n        self.cognitive_weight = 1.2 + np.random.rand() * 1.5\n        self.social_weight = 1.2 + np.random.rand() * 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumPSO_DynamicNM", "description": "Adaptive Quantum-Inspired Particle Swarm with Dynamic Nelder-Mead to enhance convergence by adjusting parameters based on diversity.", "configspace": "", "generation": 43, "fitness": 0.35934439593700984, "feedback": "The algorithm AdaptiveQuantumPSO_DynamicNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.34.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.19000520615748517, 0.2525756068379347, 0.24558222568866994, 0.973288091212951, 0.9782952861784902, 0.9792983046513727, 0.26942714679860313, 0.9811089367711087, 0.9766280276641544, 0.9009460628328316, 9.999999999998899e-05, 0.9002518605582235, 0.9421919091597282, 0.7360332505653724, 0.9332292465731807, 0.062287817511513466, 0.8249781518917283, 0.9245224085241386, 0.06679212030273796, 0.11012426399928321, 0.09824049539910973, 0.11347533851701397, 0.058606656659665135, 0.10324209799159578, 0.0648552239928285, 0.07875031356250017, 0.15065747701140264, 0.05735640705784406, 0.03866955270488448, 0.04191184987704477, 0.06735460185052922, 0.02105526256110657, 0.08754353471961152, 0.04853360179562771, 0.038381307989161506, 0.05643323021706692, 0.9874890808789811, 0.9266889196479268, 0.9400513197392486, 0.934920664209095, 0.9280295568474839, 0.9305455587172857, 0.9519537148619381, 0.9903817689600505, 0.9283471374328535, 0.5357522229635143, 0.22092478268576043, 0.10704924653013381, 0.49940751435171526, 0.14054890322859792, 0.5294153336005925, 0.7667763178629268, 0.3207080998700874, 0.8661820664432583, 0.1586375245793089, 0.11854586287899815, 0.18040480765430533, 0.21214413924828557, 0.1388843094629485, 0.10925085095999498, 0.13478134972072875, 0.13900394053905507, 0.22492999317435136, 0.07935613980365652, 0.1367025295487414, 0.13600388575649125, 0.8745973655909322, 0.13772732251580455, 0.94385781376797, 0.13142702864050626, 0.21585194679774367, 0.9510710322605174, 9.999999999998899e-05, 0.7709927411102201, 0.9534992108049334, 0.11636328293610387, 0.6143396042785758, 0.9089153211329668, 0.13475585388287714, 0.12855519832202267, 0.9438235504524941, 0.9106246242314788, 0.9382284421431707, 0.9261576737114346, 0.9466683026294886, 0.8240987290987563, 0.06227068337076602, 0.807497032529632, 0.8757115121742745, 0.8208730057954712, 0.7851180723574418, 0.07075585546901964, 0.89672674496344, 0.22039133967050317, 0.19782417984315026, 0.9031276997292147, 0.10035798196323098, 0.8283587756334063, 0.8655166521216496, 9.999999999998899e-05, 0.08372201615354768, 0.881213092154664, 0.9309124362151042, 0.7453748578110195, 0.9457056847815852, 0.8140031788871973, 0.8581386691598818, 0.8371894523486776, 0.20090391437936406, 0.1964520241603046, 0.36582272140890404, 0.5956707327344057, 0.06239220809110324, 0.804050097479092, 0.41084496329729914, 0.08945017370627395, 0.24854708831744388, 0.2177775368479391, 0.2155263764553742, 0.9694083838875396, 0.1943779225094393, 0.4417553946325169, 0.9625073514106255, 0.33895238354551704, 0.3306076102702289, 0.9668946679033125, 0.07895151287791491, 0.04275905121585688, 0.0651925573733051, 0.0714058237215549, 0.05244891126404505, 0.15043342449137398, 0.06285827792357901, 0.07583027291256317, 0.09134342364602221, 0.1443866924789965, 0.27162355052469833, 0.17031262828983396, 0.20504295836891484, 0.14981898380324088, 0.18362576592568158, 0.6532986368696624, 0.19586873952783967, 0.12485818045579422, 0.11599944096112558, 0.17753426741160583, 0.21484450345823103, 0.16406170171058132, 0.22297913929898372, 0.2224725345392079, 0.17806716955403923, 0.2688160567392269, 0.20953867895306277, 0.136525369911346, 0.13607221210178144, 0.21507271152686758, 0.07837469363334748, 0.22156320872478485, 0.19637981121110126, 0.1128542689975115, 0.12057983953377771, 0.11981123605750166, 0.250064360266409, 0.1666647109264462, 0.2575277135515748, 0.16304251689790383, 0.22653944217260125, 0.24087057579079685, 0.20276305064929256, 0.26896040364561735, 0.2507734424672623, 0.16994604177724282, 0.15910122381071756, 0.16500441717536563, 0.17706480197801333, 0.1792688651093376, 0.21310071760193028, 0.15108932309977552, 0.15949371011968838, 0.17134108826751893, 0.10527240034265828, 0.12707412979204002, 0.11328127721383863, 0.17332311430979663, 0.17211032929181258, 0.18061458538196928, 0.14345932180085452, 0.16414678080217637, 0.25021862818657625, 0.43998958719335457, 0.21301069685783713, 0.0736152349657414, 0.9393440252331313, 0.09254097502815695, 0.15642129351919853, 0.10518412478374684, 0.10495167694325591, 0.9661134587160476, 0.17405873048964038, 0.16260598347015598, 0.19205093810265705, 0.21062366868434168, 0.2050799744208638, 0.19161216713573626, 0.1989281530705106, 0.21644561438511323, 0.2349617543284621, 0.07098962949267629, 0.05390844080767454, 0.06726491541293089, 0.04713507232686842, 0.07991982541459797, 0.08630581361221379, 0.11647687154666853, 0.0830618969655772, 0.07102985464040468]}, "mutation_prompt": null}
{"id": "a16e2a95-0890-4a83-8857-4034300d8ae1", "solution": "import numpy as np\n\nclass QuantumEnhancedPSO_DANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.6\n        self.gamma = 2.2\n        self.inertia_weight = 0.6\n        self.cognitive_weight = 1.6\n        self.social_weight = 1.3\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumEnhancedPSO_DANM", "description": "Quantum-Superposition Enhanced Particle Swarm Optimization with Dynamic Adaptive Nelder-Mead for robust global and local search balance.", "configspace": "", "generation": 44, "fitness": 0.4040014289403235, "feedback": "The algorithm QuantumEnhancedPSO_DANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.36.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9732506682890333, 0.965544262316614, 0.9764900753583939, 0.9739310037365907, 0.1649066096804077, 0.9722216869632119, 0.9723564428064361, 0.9718121589307057, 0.9759199961837207, 0.9314981408860243, 0.8887613835075626, 0.9114043756909773, 0.9042824808216564, 0.8691609572746951, 0.9249321895157068, 0.06267828171005618, 0.8684284265324493, 0.9229200233458217, 0.12798646116967083, 0.10775575666305626, 0.1674758442476998, 0.059873405989119055, 0.06747045689261044, 0.11984389696678388, 0.08470764768117678, 0.07407580510947642, 0.11111803611943993, 0.07383954758396272, 0.05431078640280629, 0.13888708831239072, 0.07165224640207801, 0.09074769798273974, 0.061780689230566344, 0.04927705709764019, 0.02086521568313071, 0.047275320861013825, 0.88168303864841, 0.991497207142252, 0.8982979369654563, 0.8567124996729301, 0.8638641982404366, 0.8589231449880737, 0.9630773376779621, 0.8928123517759874, 0.9067283959131499, 0.6649054626921163, 0.7888469246496109, 0.78979719560833, 0.519924194432845, 0.18385498439495618, 0.4735659804289225, 0.41035339390187875, 0.37319984642869863, 0.8497857518931757, 0.20000922120586917, 0.23162147184478676, 0.18589482000189506, 0.2107493072877965, 0.12124181459511874, 0.1940343339322621, 0.13921732168811907, 0.12027139732570125, 0.09449807540993715, 0.9441998365489169, 0.11735778195590352, 0.6591431529261838, 0.05868585853136754, 0.8801726150667243, 0.888968162077532, 0.13862075136451424, 0.13779633427253435, 0.13841025932473217, 0.9061104376306198, 0.1343168654506648, 0.1386397022869683, 0.13838521131542825, 0.11682196793216348, 0.9285266088384039, 0.8930598061121485, 0.13667343052320247, 0.9425976801407865, 0.9306551694435332, 0.8456568835547749, 0.862935306625804, 0.8845153859197437, 0.13928692358805161, 0.9077928654602979, 0.8889358402833988, 0.8247626868000172, 0.9293327308961129, 0.9004435022622513, 0.7659189699566511, 0.8873217450224647, 0.8362322542444556, 0.774959503520402, 0.8531988513333374, 0.7905417627983476, 0.13971642157556452, 0.848591000364991, 0.7866521647800235, 0.8420417860948485, 0.8493879139424871, 0.9176225153973013, 0.9103490009480644, 0.9127122794679777, 0.8475722060348201, 0.17106747208497397, 0.8328882927531736, 0.1547234674878435, 0.08625063975471514, 0.21613285887580402, 0.2663532503289485, 0.14401112706952646, 0.0968186166845999, 0.1605800444106702, 0.1465002774127353, 0.08966319562273128, 0.9564728310127997, 0.18737916273173727, 0.9607860471903362, 0.9568233070795252, 0.20941098138012992, 0.9456364169882548, 0.952013916545872, 0.28218197545655777, 0.9631900393987719, 0.09880309988609193, 0.07615843754846341, 0.0649347611883091, 0.09146985527740181, 0.05788238655295552, 0.11466713246276528, 0.09836480732204822, 0.09459205827035855, 0.08815250940647334, 0.12461047276131032, 0.11197377299331979, 0.1553971623526853, 0.20664788173254056, 0.12716290073092185, 0.1709603580060033, 0.18345244014611717, 0.15535667541147613, 0.15036041844728765, 0.1946910228662413, 0.16873769772753822, 0.18138070521920946, 0.17847135557643157, 0.18199236906562988, 0.19073449376086193, 0.20677969685249142, 0.18830416503012215, 0.15786356549191005, 0.11200209541594197, 0.09598408071032793, 0.1622259624439597, 0.17522193819616572, 0.17552734446522122, 0.18959411540477755, 0.11250597103843518, 0.1538944528803371, 0.14042414948165738, 0.18092378457506209, 0.20074479804473688, 0.14891467377032108, 0.18831167653547143, 0.212411707716047, 0.2498963676945517, 0.20244126423053044, 0.21549391155043718, 0.19259701538170482, 0.1644581674089426, 0.17015245004536705, 0.18840885991928125, 0.1721777595046562, 0.17632126817101312, 0.20113614940764946, 0.16128731674491958, 0.15876325926283685, 0.1883809465553481, 0.9750558779800285, 0.12712451936388547, 0.1547140601446494, 0.9770494849334992, 0.17097644203189188, 0.20205689475558497, 0.143157188985663, 0.17008510199666782, 0.9813866269860261, 0.9811169288801042, 0.21459009803807239, 0.9815263918385491, 0.21399331487086692, 0.4969794786525181, 0.15678972632693, 0.10537335957474914, 0.12818540229273967, 0.2043964908092708, 0.2101603813620192, 0.1648821126869625, 0.27360399490618925, 0.21440771156223726, 0.16046995183336799, 0.1826464368883398, 0.22349284250357582, 0.21773912242922133, 0.2884485504596822, 0.2545493907443579, 0.04756566875742685, 0.09206119010348668, 0.03797747690365938, 0.06847761963603938, 0.08448783649886649, 0.09786858945017085, 0.0812334497251479, 0.09025946197842694]}, "mutation_prompt": null}
{"id": "d8597052-8502-47d0-aa26-cf908ff2c846", "solution": "import numpy as np\n\nclass QuantumInspiredADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def mutate(self, idx):\n        indices = [index for index in range(self.pop_size) if index != idx]\n        r1, r2, r3 = np.random.choice(indices, 3, replace=False)\n        mutant = np.clip(self.pop[r1] + self.F * (self.pop[r2] - self.pop[r3]), self.lb, self.ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(mask, mutant, target)\n        return trial\n\n    def update(self, idx, func):\n        target = self.pop[idx]\n        mutant = self.mutate(idx)\n        trial = self.crossover(target, mutant)\n        f_trial = func(trial)\n        self.func_evals += 1\n        if f_trial < self.personal_best_fitness[idx]:\n            self.personal_best_fitness[idx] = f_trial\n            self.personal_best[idx] = trial\n        if f_trial < self.global_best_fitness:\n            self.global_best_fitness = f_trial\n            self.global_best = trial\n        if f_trial < func(target):\n            self.pop[idx] = trial\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update(i, func)\n\n        return self.global_best", "name": "QuantumInspiredADE", "description": "Quantum-Inspired Adaptive Differential Evolution with Enhanced Exploration using quantum superposition principles and adaptive mutation strategies for a balanced search process.", "configspace": "", "generation": 45, "fitness": 0.2590209061195261, "feedback": "The algorithm QuantumInspiredADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.19.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.6211534269060974, 0.6075370963453592, 0.6154529792181898, 0.6139980149920263, 0.6163702427274851, 0.6424291424425399, 0.6685536277151111, 0.609637650605414, 0.6360218194976072, 0.2994392634572359, 0.38918845725355855, 0.3791126295349794, 0.40029101375616716, 0.37296998130856807, 0.40972065099290733, 0.3469584180449611, 0.3663413269657252, 0.3816286205431493, 0.0935061496268671, 0.10048538035385268, 0.11760051450659814, 0.07939105744350161, 0.09303594661104087, 0.10841738348959173, 0.1054490071687052, 0.10250779846417268, 0.10115869364452668, 0.07890721896170383, 0.09080016030201077, 0.0778430510707131, 0.08244107550322988, 0.07909357523456861, 0.09928729269545855, 0.08599797233353934, 0.0952384285674388, 0.0919862291308664, 0.7243320211818232, 0.836411453881535, 0.7886405249531138, 0.8892727165516459, 0.7731388123973326, 0.7635858300612912, 0.6966455451180087, 0.7015265275222257, 0.9244444498798843, 0.2631412739298856, 0.24813974060075772, 0.2508520697311305, 0.24905807087555276, 0.21580107188000652, 0.2598799108244296, 0.2504587811572506, 0.296108310766123, 0.31939508484194734, 0.5050589602751616, 0.5808846447360478, 0.5544471080513811, 0.5901079789085459, 0.6441829470102705, 0.5093486557421101, 0.6129589710697717, 0.6573996963745099, 0.5542954756676333, 0.19351968903421546, 0.1553152078764244, 0.15031306706455239, 0.16213590972648306, 0.15195103619942618, 0.17457651052427314, 0.17754262605768112, 0.17714039520767222, 0.17451379656630184, 0.15463249225761522, 0.21291674283363637, 0.19618115620984722, 0.15616088796849092, 0.13414901342243413, 0.17839519913286295, 0.19497846324078438, 0.2068807614413617, 0.1514010377119237, 0.16171367507634937, 0.1616064441690943, 0.14611986592697845, 0.1635606320285129, 0.14946612181070273, 0.1494947198741976, 0.1549266767262889, 0.13960505459803785, 0.17472453004273758, 0.26771361030632346, 0.2950962469322661, 0.25716182459625203, 0.2977184121214609, 0.2515075852914055, 0.2830655102654529, 0.29752047326755926, 0.36658016959149964, 0.26420285020869083, 0.057380259680105516, 0.027183029769680456, 0.03314417519902513, 0.07071471241986926, 0.04441594383683023, 0.05733354917528921, 0.06390691950396254, 0.050058784786166655, 0.05848916964007855, 0.16595120986572987, 0.1601798607178887, 0.14981290738348252, 0.1715820956623163, 0.18030611773203398, 0.176680901437116, 0.15118243370150453, 0.19336782516697137, 0.15989926612309668, 0.4906312483255786, 0.5151110493266735, 0.5309197004062202, 0.5012711556309378, 0.499283642167202, 0.5347910051416662, 0.49484494595985895, 0.4883498052843376, 0.5139874230928474, 0.08420094546890833, 0.09662384214359554, 0.08481189999329086, 0.07506995415511375, 0.0912350650103495, 0.09956202054031893, 0.09782447490799129, 0.0857047338536493, 0.09844076416266634, 0.14765581980741804, 0.12577027915805505, 0.14246968844826657, 0.1496647156461881, 0.15119144119566585, 0.1387780321294334, 0.15823394906451937, 0.12340853990664169, 0.12868050729267488, 0.2949690204143648, 0.29970960879967656, 0.3223138101591472, 0.26041573896370196, 0.2928602945348977, 0.30239164939450414, 0.2969026485677623, 0.32630592325683916, 0.32863598349025724, 0.23310025931871026, 0.22214059858372537, 0.22657216762160537, 0.23283385720626026, 0.20293138133416522, 0.23268200714666532, 0.22862412039407787, 0.23298354551566458, 0.22585804409532917, 0.18915057249774248, 0.202548885940655, 0.18378103324657036, 0.17394539284266852, 0.2027951134811251, 0.18156425515686814, 0.1919213951507298, 0.19962538558074983, 0.18969832950295062, 0.18460446279357634, 0.1803982605970923, 0.1773920463158063, 0.17448855406808705, 0.17714311360307944, 0.16867351152308452, 0.16685552449241425, 0.18203945733826477, 0.17671260943923683, 0.3513620088320226, 0.18061241057532829, 0.18244402294111972, 0.25467823730543293, 0.4513550471188742, 0.16732238664155885, 0.1907209889424264, 0.15236155459642453, 0.17222423684108512, 0.3788639755129035, 0.21457692579057142, 0.42563630145716114, 0.18062826379610253, 0.187347742424257, 0.4215444073191803, 0.29466835830345883, 0.14312088624811148, 0.2057038590895669, 0.181931000543875, 0.18215274786339186, 0.20204437074934123, 0.18012882451824497, 0.18326581066686498, 0.16414143184020702, 0.18822251988551453, 0.18393975967685416, 0.1782167498398911, 0.06827937032086395, 0.08056691459718934, 0.07502971280852744, 0.06568650131984488, 0.0753937008906973, 0.07678380212028679, 0.0760008474880085, 0.06940588062166442, 0.0725234632268763]}, "mutation_prompt": null}
{"id": "5f052409-fafa-4b4a-a70d-a74eb200a713", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Reduced population size for more focused search\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Slightly increased reflection coefficient\n        self.beta = 0.4  # Slightly decreased contraction coefficient\n        self.gamma = 1.8  # Slightly decreased expansion coefficient\n        self.inertia_max = 0.9  # Dynamic inertia max\n        self.inertia_min = 0.4  # Dynamic inertia min\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.6\n\n    def update_particle(self, i, func):\n        inertia_weight = self.inertia_min + (self.inertia_max - self.inertia_min) * ((self.budget - self.func_evals) / self.budget)\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Dynamic Inertia and Nelder-Mead for improved convergence and diversity balance.", "configspace": "", "generation": 46, "fitness": 0.3589443347093052, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.34.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9592294380749238, 0.9713238321430803, 0.9687736000356472, 0.965878667489408, 0.29862627873771763, 0.9656775467097591, 0.9754461635419975, 0.9622777392999114, 0.9651005257513581, 0.7550637957375939, 0.058047372127114416, 0.6214043989324516, 0.7536432634767358, 9.999999999998899e-05, 0.0273042799303459, 0.7046800324623357, 0.12057261469059799, 0.6463230613755288, 0.0667920330931212, 0.09578821589143371, 0.07653222981981977, 0.08469979106676384, 0.10870115999210739, 0.07190384691541762, 0.06553529125434965, 0.04539046409218772, 0.07962342810441736, 0.036525492782802926, 0.09418408155011693, 0.037062256462247256, 0.08705550271547313, 0.054582410159125905, 0.11227298674670805, 0.09111200564308042, 0.027282856024815172, 9.999999999998899e-05, 0.9798637294036833, 0.9917301993533975, 0.9377724126074887, 0.9582688731867236, 0.909873902423962, 0.9374177427426651, 0.9848656148598741, 0.9818763863515215, 0.9272176382736627, 0.23649823783233592, 0.08883139805366014, 0.1408092903151803, 0.23238741511475158, 0.15522709180853467, 0.13542054951420635, 0.24940493709270917, 0.11684230271647122, 0.2585296443576336, 0.23248329820168945, 0.24709817253130018, 0.25954917783356235, 0.3287200706463226, 0.17520901028716218, 0.14811900014446833, 0.0983279162265257, 0.0970807001467554, 0.06848830457889488, 0.9111228924617838, 0.11367129115296082, 0.08415470795396518, 0.1618846672068721, 0.9118845644060014, 0.8686812185406476, 0.8631412672493711, 0.13572282543446668, 0.8400466481938479, 0.8371640611168274, 0.9371436341748989, 0.13892208913783832, 0.8787899396896596, 0.2585088784667844, 0.854626718351323, 0.7914056787934372, 0.11058162486499168, 0.7877372213412772, 0.7169477843499439, 0.41360894497790845, 0.8103476023676046, 0.06174753906854491, 0.1680043324123479, 0.7920754853036694, 0.5432756812561911, 0.7413194830915624, 0.7971189958739142, 0.1682452939741832, 0.05082606928376443, 0.7184362006115772, 0.6610243717042931, 0.11017683962824887, 0.7327054987007878, 0.8665057488441588, 0.12260785259701079, 0.6582961941520848, 0.7703812661909748, 0.8525286639829502, 0.8333697724008732, 0.6124599628070473, 0.08860761302464015, 0.9324383417515584, 0.8177903060167833, 0.5930116843502372, 0.7626666429716045, 0.045391894439311575, 0.04277303627969575, 0.25325736768302776, 0.04913197029526051, 0.04459904485124333, 0.1065730159686693, 0.36290229600558854, 0.6192589170767016, 0.08751499644919858, 0.8016353913812534, 0.9456900877757177, 0.9216225493528247, 0.24050948535584127, 0.9076927375371919, 0.9160480987707275, 0.9613073595299896, 0.2953271807538812, 0.9294904446030583, 0.10263470866664082, 0.1382293457530006, 0.12033229568170722, 0.12406997300698985, 0.04664392225231351, 0.07192547307424813, 0.10392874274911523, 0.0876198715615839, 0.12649563543007347, 0.20919045786891122, 0.2860616493823114, 0.16958234731930466, 0.21202371171239065, 0.15443847262564814, 0.12939356866906981, 0.19400382225908952, 0.13308168135282106, 0.14245203249840976, 0.15987635534511302, 0.1829987584725482, 0.16483092973985936, 0.16869615471609545, 0.15211577485840522, 0.21030204058327318, 0.2019809511147358, 0.22128003586811662, 0.18671613644426066, 0.1763927145903248, 0.10778505007144523, 0.13894839691491945, 0.2037174477621535, 0.13296009867049485, 0.2370334996817438, 0.14709292651962247, 0.10750122732921041, 0.1177808291775837, 0.21250077078780005, 0.14651282425431, 0.187156383453688, 0.17096271571372168, 0.2544526629416387, 0.17512643860972565, 0.1810557951201872, 0.16574945006816355, 0.2822087974399644, 0.15724998913338928, 0.16002322425288207, 0.20083697866068162, 0.15904528839288357, 0.1700567836667518, 0.1642497051764199, 0.22238319762152392, 0.16532907768106975, 0.15579366363659553, 0.2011264537253794, 0.12723542869277094, 0.1548926985658059, 0.9720647765482952, 0.20240306549538778, 0.11731636949814639, 0.14344730397034278, 0.17021783422918957, 0.21041469984568106, 0.9599058064925866, 0.21485385413990454, 0.9521238857109564, 0.21173683664142062, 0.9739475116545832, 0.15755936550481764, 0.10534171218407085, 0.10451604343699006, 0.9608130541326005, 0.19618918308017053, 0.16471797118606735, 0.19322954991722285, 0.19333505356543312, 0.27546724948191426, 0.23122870284219466, 0.25868369176803807, 0.15522825729042178, 0.20372449836812, 0.08049580184962635, 0.07913410281946831, 0.08177061591860946, 0.048269411668446116, 0.07311454683617158, 0.07332280108248779, 0.019154978910987497, 0.03246584619905157, 0.08674689384538581]}, "mutation_prompt": null}
{"id": "9774876d-5ec8-4185-8d88-5a7cf1636fa4", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_ANM", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using quantum superposition principles for enhanced search space exploration and exploitation balance.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9801782246896628, 0.9773506548549438, 0.9762928330587138, 0.9749614148683319, 0.9760140733414094, 0.9806804527220537, 0.9763228820296073, 0.973828664519824, 0.9749657114106289, 0.8900204402699416, 0.9041991162875707, 0.08185785752540409, 0.906905607579257, 0.8998435773948251, 0.9253211534155724, 0.9190361351727717, 0.9471712097219888, 0.9479916398024998, 0.09912981473996829, 0.08464476238991447, 0.0716002402732463, 0.08474389731424758, 0.09499426898243968, 0.07740776112778947, 0.05665958808963656, 0.09914546116351008, 0.1383567544614147, 0.11347446462915123, 0.0655008442942564, 0.0832310129913032, 0.081648159680346, 0.10836890782096475, 0.036207837209879856, 0.0982816084093121, 0.05966244233299389, 0.07392798933452382, 0.9340770855754124, 0.9693004416352712, 0.899209733098111, 0.9141722675365463, 0.9087894696521318, 0.8717775762632716, 0.9878431360571169, 0.9223637279761758, 0.9032309296709281, 0.24480033238421406, 0.41819130978479147, 0.7128651096922527, 0.49048356180259456, 0.8964995932383478, 0.6262714434453949, 0.8893778658950713, 0.7633470947624388, 0.6938244981983901, 0.259306914896674, 0.18108491945215577, 0.13558940228821792, 0.1541860634539537, 0.19885815098946769, 0.19365550661896824, 0.17673612832440444, 0.11250655435150259, 0.07486500988603673, 0.9519766298290436, 0.8864520304769891, 0.9459968403291767, 0.9204849572505789, 0.13811485570581028, 0.9395331251364439, 0.9594093606995782, 0.13835636534997853, 0.9419884256374067, 0.9481168240134926, 0.947093535556995, 0.9057915790315988, 0.13822171354054302, 0.9452239812195733, 0.8449535983133651, 0.9344294095092491, 0.9494251765925069, 0.9265162422335795, 0.9115193292150991, 0.9242586713461014, 0.8831569683630437, 0.9274711274802225, 0.9066182457528243, 0.9234803582961062, 0.8951848511210314, 0.9019208299584548, 0.860688577862064, 0.1467624553605852, 0.9229114585705916, 0.9067686896138283, 0.8891851521113503, 0.837542132655189, 0.8370278770690066, 0.9240498108060388, 0.8499696355424022, 0.8666904013055153, 0.8688315100595915, 0.8524246986018387, 0.8918533054567284, 0.8852074907255356, 0.934296303463248, 0.8551146785004804, 0.7445997803229446, 0.8867654943046327, 0.9008978891040961, 0.3324512401934675, 0.22342840933956565, 0.12803187099731372, 0.32037217877896107, 0.13004422984480457, 0.3886985769502441, 0.5063431318813971, 0.22726839471473126, 0.9338507016662356, 0.9619369490668273, 0.9678440809284972, 0.9657792022339469, 0.964586715442002, 0.9489891718056624, 0.9670869053261167, 0.9660132678910146, 0.9686843929090798, 0.9510209474911309, 0.09123629211691564, 0.06325696805402281, 0.05644857873434217, 0.1284496075699041, 0.08170702419664955, 0.09874425868484071, 0.10260927806869169, 0.06339245382216818, 0.08807280432175413, 0.3430505786685194, 0.13023561890933777, 0.17631643610194891, 0.1518172875105589, 0.15453588034294585, 0.18245287936089816, 0.1797554602651471, 0.11322518102440793, 0.12181770640097334, 0.1649870864092392, 0.18910055881758858, 0.2343257704247037, 0.25914809756788293, 0.1704852858667889, 0.20411889484584267, 0.21870679340526544, 0.2584331566589919, 0.23885653137733198, 0.17905449628758707, 0.11755284044658454, 0.1401442301064908, 0.13684994796639516, 0.13946159921694212, 0.20651434231421362, 0.16032235414142337, 0.29399663718090074, 0.16691127463940303, 0.2316420074537785, 0.16026217274115295, 0.19207047313945813, 0.23359500065275374, 0.2435288446990076, 0.19664067757253, 0.28208259633529975, 0.1838310084634902, 0.1520545322043032, 0.16741819769189004, 0.18455309424250255, 0.17533126571657454, 0.16020480190314534, 0.18208905786878404, 0.18202757484175813, 0.1527392192899113, 0.16807142642635786, 0.1742588934380176, 0.7022364489786656, 0.12718463603165786, 0.14907469021974795, 0.9813987550443436, 0.20191375647678922, 0.17352712970886208, 0.14330959046480451, 0.16643078043596082, 0.16877252116779984, 0.9837213298861535, 0.21380494030788366, 0.4014219991504919, 0.21286915564006326, 0.16969930013851187, 0.15671357961556864, 0.07140653084673176, 0.10450685429489115, 0.967812388879714, 0.19556877910910564, 0.24883923659728258, 0.223105986784069, 0.20718502233711322, 0.23781427584864145, 0.1674561207880041, 0.20908564731149248, 0.17726419215687095, 0.20103938156455292, 0.11349599876503746, 0.09379338500737322, 0.07523424787335531, 0.06938657384925229, 0.07743013529454323, 0.07811522780526647, 0.10044861739465383, 0.07279876222739767, 0.08379983932839408]}, "mutation_prompt": null}
{"id": "01327d0a-ea51-404a-a11c-7a8299c0931b", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO_ENM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # Slightly reduced initial velocity\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.6  # Reduced inertia weight for better convergence\n        self.cognitive_weight = 1.7  # Increased cognitive weight\n        self.social_weight = 1.3  # Decreased social weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        \n        # Introduce random mutation for exploration\n        if np.random.rand() < 0.1:\n            self.pop[i] += np.random.normal(0, 0.1, self.dim)\n            self.pop[i] = np.clip(self.pop[i], self.lb, self.ub)\n\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO_ENM", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Enhanced Nelder-Mead and Mutation, introducing random mutations for improved exploration.", "configspace": "", "generation": 48, "fitness": 0.4584592228589347, "feedback": "The algorithm AdaptiveQuantumInspiredPSO_ENM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9724142427236646, 0.9784764202704043, 0.9739634451316971, 0.9794344977567366, 0.9767348398316237, 0.972375119635394, 0.9731886233609213, 0.9763955005722399, 0.9758436529349266, 0.9101174029059924, 0.9349031269652037, 0.08245996102182129, 0.90239119517215, 0.9004464874982621, 0.9291745122868404, 0.006960211762805701, 0.9096897494148173, 0.8671571133546786, 0.11315117317609169, 0.12858519568486104, 0.0716545748774764, 0.08187604281190286, 0.08171546860086842, 0.054271774144516005, 0.06178508175559838, 0.10856983446045743, 0.12060967990712834, 0.10323209276121048, 0.048732846463731216, 0.08169750332775005, 0.0839925395875134, 0.04306641772808906, 0.05618858598689569, 0.0736250412506515, 0.0670803725130763, 0.04414551396190414, 0.9614487137605117, 0.9361012898210821, 0.9845486412696385, 0.9601892495113559, 0.9392116430139522, 0.9872271980022057, 0.876457656052568, 0.9820876681561532, 0.8993174496540153, 0.9233926233733717, 0.78274490937179, 0.6026503519590757, 0.5602028961287937, 0.7077575179950962, 0.6333757826181021, 0.36541086399281864, 0.2778968862095582, 0.23746788946060982, 0.21226120181540753, 0.15120501016166965, 0.21213633648896713, 0.2139119034552026, 0.9827700885172629, 0.16018541854719637, 0.09941618067572111, 0.14988230161799787, 0.1922191633710142, 0.13122730819150474, 9.999999999998899e-05, 0.8893906632980756, 0.13808987649225268, 0.9155693189642902, 0.9527602709288623, 0.9545207133084863, 0.949333705046434, 0.13846070156652135, 0.9213527280479555, 0.9237131581415496, 0.9589904139092431, 0.9272870865851034, 0.12128974152271643, 0.9427052787788996, 0.9532316612572967, 0.9247489510248491, 0.9652731068019986, 0.8701545238228156, 0.9393387287594571, 0.8912766381845274, 0.9276084776099449, 0.9414827414512983, 0.8871440992183366, 0.925857036775641, 0.928655749425458, 0.8885621261644658, 0.9161352280571154, 0.9001400686781909, 0.8931598648031798, 0.8753325752672615, 0.8906746024390404, 0.8921824243035259, 0.8424420236391136, 0.8929229760266353, 0.8763298823919918, 0.8092105983448166, 0.9010750350518184, 0.9021579574677814, 0.951403495322537, 0.8437471552119753, 0.9486832698871906, 0.8156400604540952, 0.8631953269708079, 0.8394198125802621, 0.23224151490196532, 0.15362779434953877, 0.7873983319685545, 0.8357405596811056, 0.9145943902608265, 0.1900808001423392, 0.05064859490399465, 0.5754811862388194, 0.11557449606826864, 0.9705602621261861, 0.9714450962730695, 0.9691036935656848, 0.949336174152414, 0.9605990042092589, 0.9706673667889577, 0.9566640359959506, 0.9664674708070177, 0.9659828905552863, 0.09189780005039305, 0.040660123548265203, 0.09114874637359849, 0.06737468916708389, 0.04304850064819743, 0.08405172451744514, 0.1502982160403733, 0.09502389268960765, 0.08135873250795089, 0.13356527984634936, 0.15638008007601334, 0.1780308939550116, 0.14091344720461807, 0.17165296050011514, 0.1353282947135267, 0.18073617074382398, 0.12740276238459103, 0.15634412012415488, 0.15607862291584484, 0.21076338237314673, 0.2269477769129047, 0.1825153423368412, 0.19068394089614182, 0.20871097918376413, 0.1926731768359249, 0.3152150983276403, 0.17425696123730794, 0.13989248284936184, 0.1566457385046255, 0.15608235102110524, 0.19002479103611503, 0.12100982911318969, 0.2293501487408215, 0.14717069065398192, 0.113357025422267, 0.1759577270540974, 0.1827046440920459, 0.172042877740191, 0.2727553853125352, 0.26369132102566073, 0.19493900564473166, 0.23167722300819915, 0.23168989522450578, 0.22613569001901823, 0.19393851972396525, 0.16694010632871537, 0.15941702900601995, 0.171193029079856, 0.1719715321090164, 0.16993834519823559, 0.18410385451022226, 0.197074099492901, 0.1907821402508293, 0.1732304088440334, 0.07030528082694942, 0.10001653938754351, 0.15468830154468194, 0.9798099833478772, 0.20222090380227287, 0.20176045096034934, 0.14335066116398498, 0.16644767102949265, 0.15932072674749198, 0.9801243252320151, 0.21415540289003188, 0.07360863694000708, 0.10499978112448793, 0.5685204600236001, 0.10602089546825022, 0.1053102165904165, 0.9799897698042602, 0.1691029533607189, 0.23873130814850152, 0.1946305043607124, 0.21106178372360695, 0.19913427251494664, 0.17056535899651548, 0.18810862180988952, 0.2738963097103456, 0.18234566749534764, 0.22902957741341656, 0.07318325779265555, 0.0767906337697386, 0.09975225073842753, 0.05232628511466575, 0.10904287692152137, 0.11119814624844238, 0.07091332413617035, 0.07536039224834823, 0.08881749725971844]}, "mutation_prompt": null}
{"id": "63f95751-3e4f-43a9-981f-bd8b06808a65", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Start with higher inertia weight\n        self.cognitive_weight = 2.0  # Increase cognitive weight\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Gradually decrease inertia weight\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired PSO with Adaptive Nelder-Mead using dynamic inertia weights for improved convergence and exploration-exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.44113558491047666, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9751937141001927, 0.9753375332110876, 0.9797571231113383, 0.9753589768864341, 0.9754734202327927, 0.9802954200744273, 0.9803635532197862, 0.9811456393657656, 0.9735703719498787, 0.8648410533314742, 0.9295288586190456, 0.931850333818757, 0.8836439061282758, 0.05057447717487429, 0.897893008784302, 0.8822028211201935, 0.9364528067652736, 0.9389555616773994, 0.10778894763134139, 0.06186269938446187, 0.09878048866353217, 0.04086269494336614, 0.10857698714128128, 0.05343778087713813, 0.07374718870496855, 0.13822095269562595, 0.10343047274558226, 0.0911313574532554, 0.05650200353191337, 0.1140002941406314, 0.0949996081654716, 0.16735478732225761, 0.049078701921178025, 0.12006729530642535, 0.06739659795029451, 0.04661167013313061, 0.9899213826567493, 0.9341763863138, 0.9376119734167773, 0.9849654406510637, 0.9241617911116229, 0.8746004331092221, 0.9597264486881985, 0.9855159164405394, 0.9154888519107823, 0.37614193050664835, 0.7207794178000786, 0.795537244542155, 0.6794080412162109, 0.908685268528346, 0.35397694296764726, 0.9397646779576028, 0.08902419267975459, 0.5974192869935895, 0.15177947729665797, 0.22923351679487947, 0.21841996983817735, 0.2052435537780014, 0.21573314706700797, 0.2426856590446974, 0.1238288629096036, 0.11249833742203774, 0.06735466570633175, 0.13840921891916858, 0.1324812740051099, 0.9585854484717968, 0.9146515499163734, 0.13688959587849114, 0.9479396468450221, 0.960061133435929, 0.13754621586287963, 0.9482207079750462, 0.9530126533162362, 0.9496949023609487, 0.13702019625883044, 0.9453070507794985, 0.9435274720170861, 0.9060320543175808, 0.1375291172446771, 0.9399607599585366, 0.9238944214218465, 0.903627512991428, 0.10049155206005067, 0.8407444511054375, 0.943102344418717, 0.7665126443037028, 0.9229275477827588, 0.9400973973183372, 0.8990892926317907, 0.8771711813448029, 0.9026269313432458, 0.25948162036863165, 0.8987607253250178, 0.8539970066948047, 0.8510015198772607, 0.8571890391231938, 0.9052201028739781, 0.08348381967284846, 0.06111822992436866, 0.9052038312440606, 0.8505888296903678, 0.8839426448057228, 0.9209663486258377, 0.9418134173395962, 0.8947774152413646, 0.8651385650960858, 0.9149773706209684, 0.8780281777959574, 0.6883521572584683, 0.22202969317534194, 0.03223142936496026, 0.06920495096365853, 0.14822494483484538, 0.691934841516854, 0.08797910497109984, 0.18991675745155756, 0.08928639989184173, 0.9669807440101733, 0.9670402624842339, 0.9594691893540532, 0.9637864298894201, 0.961193833077364, 0.9651449080202843, 0.9689725456094372, 0.9671229447081513, 0.9529823744683965, 0.13808709472261949, 0.07891366475344408, 0.04931877052339462, 0.10850580417145961, 0.10338740549846281, 0.08183984562695734, 0.15012563003415325, 0.07160691910059358, 0.08800020709327094, 0.13498339623474453, 0.10248941533331435, 0.17286218550234334, 0.12620923907429493, 0.32125287408002945, 0.19097282631089874, 0.19334521890203737, 0.08789269359047636, 0.11786045008410095, 0.20107570970583766, 0.22429263768785235, 0.20862610817284477, 0.21430765891843317, 0.16207602876590133, 0.2074093601545045, 0.2185155676912539, 0.2263034704873691, 0.2404596139626266, 0.1762634589434411, 0.13950091544993304, 0.2949058397048572, 0.12068459890073768, 0.13625638553332775, 0.12767174532974845, 0.1261444785665926, 0.12060406553417946, 0.17485149811430578, 0.18057080913443424, 0.1504368009999687, 0.16160022876371716, 0.18534597592527957, 0.18133620806108897, 0.21756597388870436, 0.2428975607166307, 0.18309331700016152, 0.14762685665061126, 0.16191949230677094, 0.17171579869957876, 0.1879569885697302, 0.1720696165987694, 0.17341597069364267, 0.1637498005329029, 0.16398661455577945, 0.2149217371949632, 0.21422394784400645, 0.7096304268387821, 0.12734216102233442, 0.14883846813587776, 0.9812807642800123, 0.2018803332996978, 0.1730759996296274, 0.1432395617790997, 0.16577483738956722, 0.9622235729023295, 0.9790735551676408, 0.21447324592125494, 0.07181809581472132, 0.21305053269366803, 0.16988609556190637, 0.15708795954273425, 0.1012911310117044, 0.10489085918636576, 0.9667824791880095, 0.16640550292199896, 0.22951005916659173, 0.21457173126101714, 0.1675065305583896, 0.19899284818432972, 0.21819221492940855, 0.21503539964961815, 0.2537375949693018, 0.24622205762891713, 0.06962695032038968, 0.06298417342198681, 0.056394859860753654, 0.08142656375582591, 0.0691975369116542, 0.10944863507153968, 0.09773527460616838, 0.08320128992881493, 0.07675218246698146]}, "mutation_prompt": null}
{"id": "9b813746-ef2c-4359-a061-cea8f1176712", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # reduced population for faster convergence\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # adjusted velocity range\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # slightly increased reflection coefficient\n        self.beta = 0.6  # adjusted contraction coefficient\n        self.gamma = 1.8  # adjusted expansion coefficient\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * \\\n                         (self.budget - self.func_evals) / self.budget + self.inertia_weight_final\n        self.velocities[i] = (inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired PSO with Dynamic Inertia and Adaptive Nelder-Mead for balanced exploration-exploitation using adaptive parameters.", "configspace": "", "generation": 50, "fitness": 0.39272424753920004, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.37.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9659393374987016, 0.9768528479943555, 0.9727340564255924, 0.974442995222929, 0.9592360049865561, 0.9649212907449282, 0.346597622334478, 0.9691416247114895, 0.9775879144366674, 0.8844804539816418, 0.1651471886708874, 0.9226341224765741, 0.9042259667087772, 0.8919134983348763, 0.9270613385362771, 0.8917271402703417, 0.05578472112398791, 0.0553502683897672, 0.12886981591915558, 0.09915862795370611, 0.08455486845637583, 0.02373258215291263, 0.05979785083708122, 0.09908332806908571, 0.13823297266329593, 0.1277243078142759, 0.07409862524571997, 0.12838763939460118, 0.03074153066813856, 0.03759969047061573, 0.056192870073720536, 0.0713363872620505, 0.07167906261657297, 0.08740128173678963, 0.010826304770037654, 9.999999999998899e-05, 0.9454177716556681, 0.9918882461280601, 0.9327344773836492, 0.9912123248008005, 0.9049249520685501, 0.9448063202361906, 0.9902546359596914, 0.9912379781149789, 0.9912349052305903, 0.4214921427430651, 0.7231929360622309, 0.126588077944091, 0.15732877637648113, 0.17146976641042333, 0.610846645650392, 0.7507986920466638, 0.08915890242924907, 0.3523428237785786, 0.2194204791222516, 0.18428733416266818, 0.15649868799879574, 0.2981683411169225, 0.07537612529336579, 0.15071941476057504, 0.0680608648922284, 0.1763716959117404, 0.08512782228990057, 0.9501793288431348, 0.9032939224643979, 0.9124815445527816, 0.9421795009298167, 0.1380296887857887, 0.9510351321736591, 0.9298717865661809, 0.13608460793618338, 0.13612169546964192, 0.9364886656764326, 0.1363625545955931, 0.9194642886547364, 0.9556299495646742, 0.9550957675910866, 0.9515102465789569, 0.11975258798026567, 0.009823598836354752, 0.13698195837613436, 9.999999999998899e-05, 9.999999999998899e-05, 0.8951425548510568, 0.8859991307248103, 0.7339868247261927, 0.05831259418894208, 0.883334186679085, 0.8176949773522793, 0.9266779864476159, 0.9178157040027697, 0.8892124096016021, 0.8876824822948397, 0.8144923912767323, 0.8025135546245277, 0.2250290671977757, 0.0660794006858696, 0.8929178435668305, 0.8751309755872589, 0.8500327529290885, 0.8218748369882191, 0.8146784147587132, 0.9289775628916828, 0.9328481631681624, 0.0992672180640517, 9.999999999998899e-05, 0.8023063317642861, 0.8400644452050681, 0.42298851817061667, 0.6977662328026446, 0.15325205899120142, 0.00787849351804304, 0.09380151061902176, 0.20047869860318324, 0.48094824308361117, 0.17421646850361927, 0.16768374708214506, 0.9593374385117934, 0.9545528798346835, 0.9645559855328729, 0.965462898797405, 0.9488893217164867, 0.9541833273361866, 0.9574787006987575, 0.4845117250152221, 0.9435009011593654, 0.11416983643116052, 0.09407331117826145, 0.09922549013651494, 0.08794930447839266, 0.042787607237510406, 0.12026058671890527, 0.07852654308230689, 0.0673416351036451, 0.09090241788506226, 0.17873524192322132, 0.14949671021361932, 0.16417171791840812, 0.1757938408895927, 0.13588098412799277, 0.12980340378749666, 0.1323413441085073, 0.14353132616209363, 0.16131316805115747, 0.19661193630234475, 0.13009975175697697, 0.19913816595136535, 0.18031358107643425, 0.15160535704046685, 0.19806651648302032, 0.22626081011028765, 0.3154878876018523, 0.17795668269971798, 0.07499200369427694, 0.10557351221977018, 0.10956691526035578, 0.1182271682443965, 0.08642214269158666, 0.1313204688945938, 0.1834639431414954, 0.1620188550840106, 0.13114379102730223, 0.1892950526378243, 0.13977537677497387, 0.23870018159909456, 0.19251111577120217, 0.18999150064812897, 0.1919550307564395, 0.2236464383159773, 0.2627730347950694, 0.17231014145836743, 0.18611026356192484, 0.1697767000235113, 0.1663178845892247, 0.17215553680376217, 0.17971861319673388, 0.16929605387791635, 0.16098568323704643, 0.17055852784067882, 0.18383514026314374, 0.9764644468477244, 0.12724118690688557, 0.15488554887961037, 0.173405054559587, 0.20187791308651493, 0.20178672997569458, 0.14338562073322902, 0.1705571096956353, 0.21477093671894731, 0.9694751099106055, 0.17699297212513243, 0.10443700540169776, 0.10535978645346078, 0.9719323416541593, 0.12133158244098452, 0.10538424409574021, 0.10465310496299463, 0.9661307872576703, 0.18880804096841708, 0.24627014744444753, 0.19752140593808842, 0.17952712179085373, 0.1748732031606791, 0.2153100767573627, 0.2061105189167982, 0.18261232436356967, 0.22303592102280068, 0.12703854118657054, 0.07377659572016948, 0.06659090562220005, 0.033205275783699806, 0.050704174951359926, 0.09686432919535615, 0.08928717759397353, 0.05497267900548941, 0.07706824782307553]}, "mutation_prompt": null}
{"id": "146360a6-a613-45c9-ad50-ac479ba4c265", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_SANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.5 + np.random.rand() * 0.4\n        self.cognitive_weight = 1.0 + np.random.rand()\n        self.social_weight = 1.0 + np.random.rand()\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]) * np.random.rand(), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid) * np.random.rand(), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid) * np.random.rand(), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]) * np.random.rand(), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_SANM", "description": "Quantum-Inspired Particle Swarm Optimization with Stochastic Adaptive Nelder-Mead using dynamic weights and stochastic simplex adjustments for robust black box optimization.", "configspace": "", "generation": 51, "fitness": 0.09427165875224597, "feedback": "The algorithm QuantumInspiredPSO_SANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.19554240460637418, 0.15059271375453176, 0.17938170717353874, 0.1719326903758136, 0.2564793833516904, 0.2682877932627349, 0.1405413580154904, 0.17719336939267738, 0.14287560689760137, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05251778716595967, 0.05506716800432332, 0.041738815500595994, 0.046164461639113474, 0.05021926743799776, 0.06700018001818442, 0.05772770525219839, 0.07398682260963507, 0.07008487733064883, 0.02145842445873425, 0.03333178579623397, 0.037085140721122345, 0.06276047296027787, 0.02594312255779674, 0.051312540400588524, 0.08239619667081499, 0.022662838686859366, 0.04066323474271272, 0.10570903071965054, 0.07418718265024704, 0.14912523745744588, 0.08717905078788712, 0.06676799411003431, 0.11442918049700945, 0.09854187947709614, 0.05974158263805984, 0.12626196096248588, 0.09186200377014497, 0.11209828071219818, 0.00046257347168665586, 0.08877573984969134, 0.08406087691067499, 0.0451536211368222, 0.07901085694831766, 0.02392764226886246, 0.09090767027668611, 0.22430541721597586, 0.16914394806205946, 0.21196060375689996, 0.21728065603474866, 0.16896790620136748, 0.15214842315444543, 0.11083028009443119, 0.10965927949169019, 0.057068271916778435, 9.999999999998899e-05, 0.048050899010863346, 9.999999999998899e-05, 9.999999999998899e-05, 0.024584675370692866, 9.999999999998899e-05, 0.12140169690012736, 0.061032458603553774, 0.016826448159924845, 9.999999999998899e-05, 9.999999999998899e-05, 0.017131905139230907, 9.999999999998899e-05, 0.004859959675948211, 0.030694757937789086, 0.0017104484427803435, 0.08993787934382202, 0.08346025918757982, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.050874969440358075, 0.060042662598002394, 0.07643120715892004, 0.039323577246501595, 0.015094656974708243, 0.005129762079432498, 0.03702251750019658, 0.06479806118563813, 0.09202292149137559, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.020145741528990957, 9.999999999998899e-05, 9.999999999998899e-05, 0.028391360160367918, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16601581748231087, 0.20029188993541858, 0.30058406190095366, 0.31137682469513794, 0.1667435610164244, 0.19833298226832707, 0.20649226259537146, 0.19322865711773307, 0.21824805923442303, 0.04959126456658014, 0.08580471637682419, 0.0493808990249498, 0.09850070174084613, 0.053900273813598854, 0.07737370051376424, 0.05223696353712348, 0.04215773189372085, 0.047016918451038725, 0.10377340167755067, 0.10025833020922126, 0.16674553968469608, 0.1097737838704963, 0.12272423289758694, 0.13290858198403277, 0.16000865604904324, 0.1004444573845038, 0.09991997573791267, 0.16512656652678248, 0.17119472070777553, 0.1876841777458057, 0.16753120792148035, 0.1488799868644941, 0.18775139725646683, 0.15839061724799408, 0.22353690886004662, 0.15319688168273893, 0.10353467229611213, 0.1722066070037328, 0.13552693932183724, 0.1345807188671686, 0.1041204353476638, 0.14399835886592904, 0.10543426412764112, 0.17153549436001125, 0.0927904168247885, 0.1468220577033038, 0.18170218606324395, 0.15958925591570094, 0.1706107091350677, 0.2104809516837287, 0.1569900760221059, 0.15397052822429846, 0.2083623806913415, 0.169931473851488, 0.1659014459273772, 0.17399936089874213, 0.16394925830830964, 0.15240623515286533, 0.1581393860895003, 0.1620425056111624, 0.1642855445703928, 0.1592364538176203, 0.16157582063997633, 0.1684502757961429, 0.11189504973239817, 0.11060397987242776, 0.14686238252123063, 0.16988506261313085, 0.16483111331843336, 0.1419180418182555, 0.11036231848104239, 0.16901079116242057, 0.2467068655356932, 0.13699775730183372, 0.07188020679204998, 0.07407074095833488, 0.10927934649234561, 0.0750043630564935, 0.09452883899245568, 0.1048625652084838, 0.15888206028291274, 0.187513304402951, 0.19120646007502218, 0.1565338026326395, 0.16845371298302758, 0.16953634252265204, 0.17240749438232073, 0.18426604708029615, 0.18804142351206132, 0.1786728692045928, 0.04049045059111689, 0.05350787240512633, 0.06985639111205277, 0.05415484971689344, 0.05170743930124222, 0.08490293887327993, 0.08610853687543607, 0.04113776891458676, 0.0697147336750068]}, "mutation_prompt": null}
{"id": "cd4a4a20-8f0d-4795-a13d-8672984977cc", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_DNS_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Reduced population size for efficiency\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # Reduced initial velocity\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Adjusted alpha for better exploration\n        self.beta = 0.6  # Adjusted beta for better contraction\n        self.gamma = 2.2  # Adjusted gamma for more aggressive expansion\n        self.inertia_weight = 0.6  # Adjusted inertia for faster convergence\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight for better personal best attraction\n        self.social_weight = 1.8  # Adjusted social weight for better global best attraction\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                neighbors = self.get_neighbors(self.pop_size, best_idx)  # Dynamic Neighborhood Search\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[n] for n in neighbors])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best\n    \n    def get_neighbors(self, pop_size, idx):\n        left = (idx - 1) % pop_size\n        right = (idx + 1) % pop_size\n        return [left, right]", "name": "QuantumInspiredPSO_DNS_ANM", "description": "Quantum-Inspired Particle Swarm Optimization with Dynamic Neighborhood Search and Adaptive Nelder-Mead for improved exploration and exploitation.", "configspace": "", "generation": 52, "fitness": 0.11485700751806352, "feedback": "The algorithm QuantumInspiredPSO_DNS_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.17.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.17492039289627115, 0.182874824899949, 0.14969677564469386, 0.14420405380507695, 0.2151060611782194, 0.22391618714878436, 0.14130762319535317, 0.16626455824711606, 0.14510104542687474, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08818493415952888, 0.05175048703570684, 0.06661264182133908, 0.06341092424325012, 0.07817769679542685, 0.039615684870772716, 0.040847300032292644, 0.05312943902939693, 0.054239306154613254, 0.040077969269306735, 0.09736583063597715, 0.012981927173495333, 0.03365445955430546, 0.013174621802978792, 0.03906206509046073, 0.03057371301262357, 0.011230527554569214, 0.006710437525376034, 0.9896328004994227, 0.9919744187851869, 0.9915939297770365, 0.9909791135363549, 0.9912900560651534, 0.10230751749794453, 0.9861285977480125, 0.9918027712175517, 0.09220362768210211, 0.06298905244824493, 0.07609131678441339, 0.030640208019587223, 0.11655691369111176, 0.04636232673671825, 0.08450620814860432, 0.06323478646774716, 0.036252035257254844, 0.05583878340457249, 0.12588789065560047, 0.08215641176960198, 0.10450620145854994, 0.13668357984192792, 0.23890553143074666, 0.10236061641930105, 0.06536389831594258, 0.12870976281892288, 0.06566229364422982, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.018604115106271135, 0.05557228746941656, 0.08065022187412729, 0.015046370127881903, 0.018543151306905536, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10708675151220615, 9.999999999998899e-05, 0.02230103652540949, 0.012167390738428319, 0.005095766538106394, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05775212044019773, 0.0407858622415862, 0.1033793656182197, 0.06300096663995025, 0.018119223489026615, 0.040076497656576615, 0.0432203665413603, 0.0627037647260924, 0.03177618066351884, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024557362191159338, 0.20862118513337502, 0.14882897478615686, 0.2416592135755521, 0.22897664460401201, 0.12202820633369016, 0.18636175890117646, 0.21573327063382453, 0.24849373530303187, 0.2552419282214764, 0.02565911638558427, 0.05009717608779751, 0.06403332175404353, 0.04093904059376441, 0.0215286936379685, 0.04737852011766064, 0.028658720298760598, 0.0590751003222435, 0.06278993110545394, 0.15769783443495655, 0.11274604571569091, 0.15645047995000205, 0.1714350922848531, 0.13721470668558267, 0.0756030061537325, 0.1036544466244228, 0.08670286399552873, 0.10967654497883994, 0.15553911162531164, 0.1820941225941689, 0.15392765609125358, 0.16482475930277485, 0.13247684589490505, 0.15876582718699905, 0.15481332024886274, 0.20882661357994636, 0.15659148353144792, 0.06280821242140233, 0.08688543711908547, 0.16968573941247656, 0.1163198399741927, 0.14307184577072263, 0.12324428540280186, 0.10070355966250977, 0.10506655094738693, 0.10353006414262067, 0.20080127386075064, 0.12678605143073596, 0.16614770993193761, 0.1746446795461004, 0.1638747609541915, 0.14546268184839972, 0.19639155804780362, 0.14193747456613603, 0.1672167646256807, 0.1519548241340415, 0.17312661412295416, 0.15758041624454544, 0.1502928410849026, 0.17239479633641008, 0.17870584218249608, 0.15094093555328258, 9.999999999998899e-05, 0.17269566037391193, 0.09675458189524, 0.12458722820085555, 0.11308916627268517, 0.1639431963026915, 0.13689585674458138, 0.10868088350073779, 0.12003675649886625, 0.12247947192049236, 0.18713768263576358, 0.15088790872326463, 0.10949631535546156, 0.09093524107580597, 0.10187805019867024, 0.10044678781505045, 0.08563115589475201, 0.07160030372144044, 0.055178555431709686, 0.14797693065952766, 0.17853531739482875, 0.19447086310205264, 0.17930894179585266, 0.19506667787928855, 0.22493916656338275, 0.1656295500217615, 0.19541319924673572, 0.1454425044368487, 0.18535436147424644, 0.05079842017077296, 0.03222629543616695, 0.04099703583800329, 0.07375326906265256, 0.04164188711531536, 0.07873474195462726, 0.07310515554526087, 0.049103831840578316, 0.03978967407137701]}, "mutation_prompt": null}
{"id": "164a1542-ef99-42bd-b03c-e126434ea194", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 1.8  # Slightly reduced for exploration\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.diversity_thresh = 0.2  # New parameter for diversity preservation\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def measure_diversity(self):\n        # Measures diversity in the population\n        diversity = np.mean(np.std(self.pop, axis=0))  # Standard deviation based measure\n        return diversity\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    diversity = self.measure_diversity()\n                    if diversity < self.diversity_thresh:\n                        self.inertia_weight *= 1.05  # Increase inertia to encourage exploration\n                    else:\n                        self.inertia_weight *= 0.95  # Reduce inertia for more exploitation\n\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired PSO with Adaptive Nelder-Mead using diversity preservation and adaptive parameter tuning for robust search.", "configspace": "", "generation": 53, "fitness": 0.4628961435235967, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9801184081971885, 0.9773856855147244, 0.9768286847113041, 0.9744586146999183, 0.9765773129648787, 0.9805060943107214, 0.9799236185709455, 0.9737112310059561, 0.9797031229897233, 0.9328631730243452, 0.9248023349930556, 0.9373471163391629, 0.938127556999625, 0.9465751443232443, 0.9442474964424868, 0.9337105231349435, 0.9385676988319261, 0.9326983641745181, 0.09912117340306081, 0.08464823008412858, 0.07160283177953608, 0.08474426809128477, 0.09499010775021344, 0.0771767593597853, 0.05666021970927815, 0.09914760930751487, 0.13839056480079093, 0.10799082412554706, 0.06550132402948894, 0.08304691056196334, 0.08165558487811508, 0.10825125615019915, 0.03650569522342617, 0.0984137457827926, 0.059671531193196126, 0.07391859118564847, 0.9052162072646089, 0.9846610806948196, 0.9053310322720421, 0.9585791691345434, 0.9220918387398269, 0.8817789410052523, 0.9826780568728168, 0.9415211631627928, 0.8891013407128111, 0.3023332946658768, 0.736808477038034, 0.5360935002403318, 0.8067860336001034, 0.870294534247698, 0.8696132330362736, 0.6200041626501285, 0.5727685094657009, 0.5213792160135738, 0.259306914896674, 0.18108491945215577, 0.13558940228821792, 0.1541860634539537, 0.19885815098946769, 0.19365550661896824, 0.1786755814392056, 0.11250655435150259, 0.07486500988603673, 0.9525463438559368, 0.9032961598011415, 0.9548016889583694, 0.9195857738385343, 0.1381582972011045, 0.9470594236928922, 0.9609737016157759, 0.13829812864359958, 0.9496292434243245, 0.9435049991669239, 0.95335469121246, 0.13491393385942685, 0.13819742567375126, 0.9511818944182633, 0.04031152856235498, 0.9449046948557083, 0.9405669688326577, 0.9286925881791018, 0.91119294891184, 0.9394133809156044, 0.8063839248890713, 0.9244606692253191, 0.8529907774735989, 0.9019680349512722, 0.9230628807675757, 0.9330433250848131, 0.919142292928763, 0.9091810285597253, 0.9402641296527289, 0.8965739935384709, 0.8813593757730325, 0.8722887721103961, 0.8341034710329547, 0.12542157429738932, 0.9016530671390731, 0.8744763217267703, 0.8763048514711419, 0.8350820951175738, 0.8876304593565343, 0.9286123919391006, 0.9139338974986762, 0.8713712710961605, 0.7630987688282114, 0.8888317638078516, 0.9012519528065119, 0.3331094639465987, 0.2229169492280979, 0.1230977014192084, 0.3203721789722419, 0.13009915910890357, 0.5660411336775601, 0.05044691505669252, 0.22726839471473126, 0.8829347141210504, 0.960526993514, 0.9686160200443419, 0.9619078979251064, 0.9663773920055436, 0.9553656354133941, 0.9646858809237799, 0.9692549309164029, 0.9715830315494798, 0.9500807576224465, 0.0912422022075502, 0.06483151840905244, 0.05643971322061825, 0.1284525003892497, 0.08170506795341148, 0.0987763996674006, 0.1025241393600147, 0.063393961515404, 0.08807275859703945, 0.2730609723807339, 0.13023551400612654, 0.17612331041959806, 0.15246022068761356, 0.15453569401964506, 0.1824529001523023, 0.183888453576868, 0.11322511911863442, 0.12200877009680011, 0.1649870937300566, 0.18910041345947426, 0.23435971331114713, 0.2591480976460714, 0.17048296611865443, 0.20411615333745947, 0.21871489209480655, 0.30039132320758677, 0.23885653137974883, 0.17904758784759545, 0.11755306854373426, 0.14015347013570956, 0.13685117067432218, 0.13946244949296793, 0.20652940663187225, 0.1603222500586966, 0.29399677119523626, 0.16691126684513424, 0.2312063540775261, 0.16016912244018822, 0.19205147392827915, 0.2335948872722735, 0.2435429560551503, 0.19664888578446393, 0.2820825316157606, 0.18381417333416794, 0.15205496183199008, 0.16741744872540643, 0.18454837350739306, 0.17533120819928594, 0.16019730857841985, 0.1820898065762322, 0.18203187647535002, 0.1527394569066135, 0.1680672351825413, 0.1742801944128014, 0.7022363731134558, 0.12718609129942693, 0.14907469021974795, 0.98168241804554, 0.2019016467975271, 0.17352795472638916, 0.14330871085584518, 0.16642437989215864, 0.16879085042991593, 0.9835334917965208, 0.21380872491200775, 0.4014202584240194, 0.21317733505516823, 0.16970189098340338, 0.15672547524868619, 0.07140794291683561, 0.10456728597192266, 0.9680873093610876, 0.19555510737622728, 0.28340406028320975, 0.22310600921334023, 0.2061235341253751, 0.23747180203694018, 0.164483570044744, 0.20898346940341983, 0.17730672650149648, 0.20109900281963222, 0.11099863024181655, 0.09381017554623938, 0.075232968979147, 0.06939170405828843, 0.07748369287823753, 0.07811341331849198, 0.10044555785923459, 0.07279875737304087, 0.08379653290603606]}, "mutation_prompt": null}
{"id": "b0780b17-4fba-47a7-ba3c-e7541ab4d518", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Adjusted for better exploration\n        self.beta = 0.4  # Adjusted contraction rate\n        self.gamma = 2.5  # Adjusted expansion rate\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        inertia_adjustment = np.random.uniform(0.5, 1.2)\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * inertia_adjustment * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and stochastic inertia for improved exploration-exploitation balance.", "configspace": "", "generation": 54, "fitness": 0.3106143507681872, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.30.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9619221867496441, 0.9633962527297352, 0.9491222446186928, 0.9671852190954376, 0.9707340482311588, 0.9583368019883403, 0.9474409982411879, 0.9365844507911915, 0.9589836976916207, 0.20478921326079969, 0.23207593444342645, 0.08259271630057341, 0.3999257279548317, 0.18206898592105059, 0.1371711723655391, 0.14066756641606137, 0.10043349036599425, 0.10674790050123706, 0.09441993702239782, 0.09384452546544597, 0.1435312358862375, 0.07387935611584939, 0.049188354660381406, 0.10353693039396716, 0.06065872487662982, 0.09886248996399194, 0.047633715316850456, 0.07497062447440384, 0.06462896539096386, 0.039694744950751204, 0.029367359307231666, 0.07380559532392639, 0.0898136703528144, 0.09208588280658225, 0.05438891965069381, 0.08770111025157634, 0.9862202664273273, 0.9491945570297368, 0.9834807777879494, 0.9657979562360819, 0.9658689739159959, 0.9371816581899575, 0.9898998565863586, 0.9650325416908243, 0.9590738422083344, 0.17834284689177038, 0.2594822180524017, 0.2613715991394633, 0.18412812322539296, 0.1651995340447565, 0.3263939177468149, 0.24621307129291037, 0.13210789466498063, 0.1379786182333561, 0.2458878355149322, 0.16486552806429788, 0.21239131885870433, 0.162387847743929, 0.19692209040189768, 0.1717569953278033, 0.07966788868271957, 0.17818562233276958, 0.11670674043616325, 0.8890245650240043, 0.13665157488926416, 0.11297711196525961, 0.14434619951187055, 0.7724433551068663, 0.7545886381208569, 0.8673465804107165, 0.27133008637174805, 0.13622779507370508, 0.13888814663491578, 0.8702188515816532, 0.8843089966522755, 0.7261271025536892, 0.8839012417275449, 0.8544894858362742, 0.07780949470964371, 0.6420912422036129, 0.8727567975639016, 0.1595198002814141, 0.2436910609536671, 0.3463101889439085, 0.192197691678489, 0.09512495703013668, 0.12793737947109984, 0.011994764576400141, 0.18145593040608787, 0.30484168201476636, 0.23058128884935503, 0.14849299225582346, 0.18919878009093483, 0.16199834983963168, 0.021155289253322773, 0.20045123182851743, 0.23330387745735603, 0.21450511912428705, 0.2586821050139876, 0.711863069266451, 0.4998482165382344, 0.41285271594721873, 0.6782518357074053, 0.8082782649045379, 0.5104336011527866, 0.6162026477295999, 0.4676183556011668, 0.2936232793629935, 0.13090738799343016, 0.11698559031211875, 0.16772690365832077, 0.6632240928839204, 0.04752621463601914, 0.07713201087573962, 0.09525300430337225, 0.27802385593566536, 0.11341887570802212, 0.8306989080722862, 0.32566645657221094, 0.9114993574034768, 0.8131892985632261, 0.9002874362973389, 0.8457583576036093, 0.8078171622619035, 0.881708375842599, 0.6970720905445889, 0.06309861979092113, 0.10653707090878817, 0.05952815598323036, 0.09758362071875892, 0.0309882063862984, 0.09501871760839475, 0.10356509162668626, 0.1483534915472483, 0.0815714661517779, 0.15328840794970622, 0.15103457294652145, 0.17411050728863686, 0.2022493783878042, 0.3522810420210889, 0.15140490546473395, 0.1509961022140478, 0.13103444750387516, 0.12130188335143233, 0.2744691277123429, 0.3016882307581604, 0.216242931761918, 0.24530200370883937, 0.2154555211849385, 0.20120670105401273, 0.1659593481939512, 0.20177168429488634, 0.21550906399769887, 0.13000564818584404, 0.14849900602029031, 0.2136855292175711, 0.18694606128158198, 0.1986943186632265, 0.14325955830000836, 0.15957435938959674, 0.11416556614283768, 0.1487292294453697, 0.14428872551085936, 0.16842236289292434, 0.1482619819073261, 0.28088731424914126, 0.22480559816834744, 0.22547819435418592, 0.2003850158520427, 0.15094355035935803, 0.2748448044480897, 0.1696852215293918, 0.16845189733556476, 0.16363271175636762, 0.1628764030500952, 0.1668063743053041, 0.15798605055973147, 0.19323298122533505, 0.17790975245243468, 0.15305398585624863, 0.10521968767399736, 0.1272465006448099, 0.162344783386137, 0.17322469476718838, 0.2020222883161491, 0.20168053555159782, 0.12604646456038937, 0.1660050386523082, 0.4387283381759788, 0.9506561842633539, 0.21468064113788188, 0.07361744980449281, 0.9694401170283404, 0.16025205772349926, 0.1565424967090734, 0.10541310677988291, 0.10510063367755063, 0.1629385022904868, 0.1986131235500994, 0.2035118451948813, 0.1827322185553606, 0.21889565100910457, 0.20775671208475532, 0.191375591753716, 0.2533347278775363, 0.18194385182012462, 0.1987218813555408, 0.08512383917636124, 0.07085388820538485, 0.08010511010329624, 0.06951959154283016, 0.08504159070442907, 0.07526670502158173, 0.07938266044710185, 0.07001328434299026, 0.09851747777438191]}, "mutation_prompt": null}
{"id": "976f1552-b0c4-4817-a901-e3ee72d9cd73", "solution": "import numpy as np\n\nclass HybridQIPSO_DAENM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim  # Reduced population size for faster convergence\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # Reduced initial velocity range\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.1  # Slightly increased reflection coefficient\n        self.beta = 0.6  # Adjusted contraction coefficient\n        self.gamma = 2.1  # Slightly increased expansion coefficient\n        self.inertia_weight = 0.6  # Slightly decreased inertia weight\n        self.cognitive_weight = 1.6  # Slightly increased cognitive weight\n        self.social_weight = 1.4  # Slightly decreased social weight\n        self.adaptive_rate = 0.05  # New adaptive rate for dynamic adjustment\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Dynamic adaptation based on performance\n        self.inertia_weight *= (1 - self.adaptive_rate) if f_value > self.global_best_fitness else (1 + self.adaptive_rate)\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "HybridQIPSO_DAENM", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Dynamic Adaptation and Enhanced Nelder-Mead for robust global search and convergence.", "configspace": "", "generation": 55, "fitness": 0.4400702539855096, "feedback": "The algorithm HybridQIPSO_DAENM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9783465194067669, 0.9727367677028125, 0.9757240071018032, 0.9747775502839362, 0.17498536028829326, 0.9773003383915322, 0.9781522243543208, 0.9605664249068285, 0.9758504889490469, 0.8881246268246037, 0.10095406038082833, 0.901836180309665, 0.9060256844896084, 0.8702527625486606, 0.9393107820194979, 0.9311880976358037, 0.8999828626389302, 0.9358003206770604, 0.056534201483706026, 0.046780843747414314, 0.08455868571474734, 0.08187456952765204, 0.1084178513444376, 0.09917203017616882, 0.07653718017615052, 0.049436812346572157, 0.1676002142744727, 0.09895996035238841, 0.0565075983421266, 0.05484092282854558, 0.030225977168729656, 0.08713321569780819, 0.04071716350196364, 0.03321495956142628, 0.06322596439352546, 0.08165710560501616, 0.9589629752046432, 0.9916126153978894, 0.7516319056251227, 0.9164170519751996, 0.09960729012999525, 0.8800635522482176, 0.9086618806569642, 0.9355272178030721, 0.9580751508073558, 0.5744495838754556, 0.8704569650683505, 0.7973664206366501, 0.8529445835339929, 0.7882326406183563, 0.8706467568397451, 0.8243713799516739, 0.9420959265494501, 0.8420131722112241, 0.21241044510625728, 0.23168583323204384, 0.21205332131838261, 0.16264672967844984, 0.24326712893363978, 0.22093128619729874, 0.09954218456454, 0.14687173258605435, 0.08167885103023886, 0.9569963766744609, 0.12447847161152736, 0.9344596573629413, 0.9592544150508181, 0.9337158452574094, 0.9118350452602446, 0.13828527199752283, 0.13841262971973467, 0.9426891979401791, 0.1383814370212434, 0.9221637404429479, 0.13833566773591832, 0.13860535052918022, 0.11459153774732089, 0.9350951157223442, 0.9141383508385038, 0.13840726652876434, 0.942189288801627, 0.9396371157291122, 0.8483165451510764, 0.9032840949766464, 0.9153878394350545, 0.9173441247674079, 0.9145027217755934, 0.9300486015137901, 0.9159398763321678, 0.933131358236687, 0.14728000981580913, 0.8192332750347399, 0.8980093331705864, 0.8502534310745425, 0.8223753418919726, 0.8825905053629103, 0.8818955569980016, 0.1263056089630341, 0.8594933358542026, 0.8790068688900885, 0.8615039422912983, 0.9020413214473276, 0.9221167330090667, 0.9372254867811851, 0.9329133108740632, 0.8901120968810592, 0.16374386835895316, 0.8276188738355037, 0.36007986466353104, 0.035402107149099304, 0.24901911024823087, 0.6635762499716475, 0.4483576442518441, 0.11043128908005184, 0.6418923448024626, 0.08050120454155563, 0.08959600361235187, 0.9692516478174493, 0.9436735185184786, 0.9611829481532534, 0.3145131497347602, 0.9664876936160054, 0.962267582508535, 0.9570551864630976, 0.9596062490070192, 0.9584246885349494, 0.0950635517701508, 0.1211135000072201, 0.12104512681725377, 0.07390052380491419, 0.04386922948210026, 0.07180232869763858, 0.09903333023848593, 0.05214003279019963, 0.04958952806750727, 0.10495158873076194, 0.21259255387252907, 0.14624307429170136, 0.11859625143868324, 0.18097015859959542, 0.17383376246848892, 0.15586208730614892, 0.2002646765859929, 0.1660277437696137, 0.2523963672281154, 0.15908725961646397, 0.15946109546104037, 0.19858932569915155, 0.17491246796845517, 0.16489071697881608, 0.1862535157402906, 0.18534433551982576, 0.1863161694736989, 0.10234009175002323, 0.23218085065592342, 0.09411202506469218, 0.13269302486107348, 0.13885385450083665, 0.24159352951241675, 0.10612175298438065, 0.10688427314093585, 0.1265074162249139, 0.19853223291883781, 0.2037620805141006, 0.27575542637691464, 0.24816833995690601, 0.1551594962963223, 0.20315069753520765, 0.1955279755092394, 0.16943713464609955, 0.2497672471523581, 0.17027616227947218, 0.18792299934237855, 0.18020002486773357, 0.16450021197732845, 0.1808134124362294, 0.18441608218399452, 0.17015790071452974, 0.18436620104363044, 0.1616528969654959, 0.9780112354584616, 0.12721916747803663, 0.15460955895952577, 0.9806172058999314, 0.20117109324474414, 0.2014198872401025, 0.14329605465389827, 0.1700222088389115, 0.16873373649930268, 0.9758545477684688, 0.2138535883401531, 0.9765945973246237, 0.21373822522166452, 0.979712820848519, 0.157121784064432, 0.10537744326042497, 0.10463318510137654, 0.9765035445567098, 0.19712635721664296, 0.1993666195346948, 0.19376883980286808, 0.3767458957972626, 0.1904826436808411, 0.19215373956017934, 0.21116749909978427, 0.18958650128963384, 0.19729646105375054, 0.05500432283820378, 0.0829459077732374, 0.11236914445243529, 0.053978140570999145, 0.09518582407135778, 0.06899092970919207, 0.08814042160987812, 0.043665390803985016, 0.11150746910701914]}, "mutation_prompt": null}
{"id": "9c358ddb-e295-463f-a43a-999a9790b061", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ANM_DynamicInertia:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight_start = 0.9\n        self.inertia_weight_end = 0.4\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        inertia_weight = (self.inertia_weight_start - \n                          (self.inertia_weight_start - self.inertia_weight_end) * (self.func_evals / self.budget))\n        self.velocities[i] = (inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_ANM_DynamicInertia", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and Dynamic Inertia for improved exploration-exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.44500578237104604, "feedback": "The algorithm QuantumInspiredPSO_ANM_DynamicInertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9758515169711904, 0.9759724478421223, 0.9788201957807888, 0.9738720375403409, 0.9747300388462796, 0.9766313172085724, 0.9797158167582156, 0.9807834879171521, 0.9752891910358041, 0.9423700779176872, 0.04428599675615097, 0.9053600955998119, 0.9030007796762244, 0.04980201063529055, 0.9216760373907735, 0.9142170931750218, 0.9396451123817114, 0.057317004268419236, 0.10823540420184963, 0.06185860780916186, 0.12869321707891035, 0.040848329608055955, 0.10860398154564777, 0.05343383192403561, 0.06724002193522305, 0.138216182007743, 0.1084793654152798, 0.07136700021933051, 0.05650562900920997, 0.07862334234230439, 0.08470002056955617, 0.1375880512864005, 0.03952938901036962, 0.12024310037103036, 0.06739653076672913, 0.04660802962047006, 0.9899210912100255, 0.9275299390165259, 0.9141987922160661, 0.9849629202092889, 0.9192634509312274, 0.857933417806481, 0.9686577664833803, 0.9430466619615274, 0.8620038368556406, 0.2809547545456019, 0.7374215624963447, 0.7723064192183273, 0.27396532131048756, 0.5943419898008206, 0.7834413542891234, 0.6789501074753852, 0.0890616428492974, 0.8011266867557665, 0.1517786140008759, 0.21369066260255898, 0.17240159970096014, 0.20524391962380573, 0.21326019909108396, 0.39541595660684936, 0.12382974487676512, 0.11249833742203774, 0.06735466570633175, 0.1383581935673729, 0.1326816310628648, 0.9578303045349611, 0.9125202511794508, 0.9307739224014551, 0.934681899905331, 0.9609894870405128, 0.1375575835219397, 0.9404379781719167, 0.9493122677556801, 0.9487927560653636, 0.13746991253078555, 0.9474179748257354, 0.9446225411634963, 0.9277420245821381, 0.13789253945176638, 0.9499520272255012, 0.9197169782745749, 0.8992322533240692, 0.8315228951177269, 0.9403755537565663, 0.9281066227691719, 0.919738045978696, 0.8418871031297832, 0.9457463814787403, 0.8713001763525022, 0.9074469082185537, 0.8453921708311818, 0.2605195065933512, 0.8807750742399026, 0.8834298667225591, 0.8129853450182418, 0.8658755382915657, 0.8843272720014245, 0.08338747023945703, 0.06100521599424735, 0.909348123671838, 0.8505732075371559, 0.8841877527634354, 0.9345820519308825, 0.9430340380796584, 0.933713983355851, 0.8862900255234288, 0.9257919278413442, 0.8850022400054041, 0.16493785597362198, 0.7622229939625775, 0.6640977099862106, 0.06575874713574581, 0.14912931316838896, 0.4728209739798507, 0.08782682565172761, 0.4345842401671649, 0.6527049854500206, 0.9712104130335052, 0.9586546866996907, 0.9656956287865053, 0.9654465781930934, 0.9591905102637603, 0.9648665239708242, 0.965115927554734, 0.9622227148571124, 0.9539719073951358, 0.1380968414680035, 0.0789187260257006, 0.049317567068608126, 0.10851895817304302, 0.10346641030236137, 0.08180663403061117, 0.16735033496597318, 0.07163554116731374, 0.08800069054291648, 0.13333745247039186, 0.11212257474292586, 0.17248919435024923, 0.12388832759675095, 0.3260866129118657, 0.13113487083727926, 0.1789319128844027, 0.10728828927199119, 0.10765587982724556, 0.1967575587514485, 0.1774470856525059, 0.2009726167854754, 0.20342195742668356, 0.16740883315206478, 0.20104851867060725, 0.22555784506276455, 0.2375531015763196, 0.24386022615560987, 0.18231938601283537, 0.10586663280286668, 0.13733861560715543, 0.1288774642375563, 0.13301827805470623, 0.15269299339578846, 0.12566348198343547, 0.12060405107237115, 0.20051578500030975, 0.17037224492402425, 0.18882917248247788, 0.22025659406891795, 0.24707119522530607, 0.2333462010974281, 0.18474640776331408, 0.21656746385665515, 0.22831222245392013, 0.22978337475859634, 0.1619259126276793, 0.17171624769490168, 0.18796691554162404, 0.1720510843867702, 0.1756510982835462, 0.16374001151605322, 0.16969631902203053, 0.21491434955778654, 0.2002485142180932, 0.7094687993649706, 0.12734987049701574, 0.14882360547504792, 0.9817773218249116, 0.2018807641507916, 0.17323835809429033, 0.14323608198087656, 0.16577358195024738, 0.960667340078786, 0.9786709513288083, 0.21444803771490373, 0.07182782984072977, 0.21313457361507848, 0.1698873785780164, 0.15709329533144623, 0.06647722878794338, 0.1048727848409926, 0.9693647302424829, 0.20388805250903597, 0.23403477327711464, 0.21198345558894083, 0.17355062625685624, 0.26854084481341456, 0.18907841618454635, 0.21565589834428178, 0.32529103533727477, 0.2511258405265706, 0.08348585611891701, 0.05770751591520096, 0.05825429542230465, 0.07768742102938664, 0.06921754294989602, 0.10725453795215778, 0.0802825943996941, 0.08168951323051665, 0.049504391332530706]}, "mutation_prompt": null}
{"id": "869fabb1-0405-49fb-aae6-58dfa2d321ec", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            self.inertia_weight *= 0.99  # Dynamic inertia reduction\n\n            if np.random.rand() < 0.05:  # Random restart criterion\n                self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                self.personal_best = np.copy(self.pop)\n                self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired PSO with Adaptive Nelder-Mead using dynamic inertia and random restart to refine exploration and exploitation.", "configspace": "", "generation": 57, "fitness": 0.45294370862423117, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9799709075316007, 0.9818045214190182, 0.9800730781717758, 0.9774707693760782, 0.9806713044029156, 0.9647908143294919, 0.9753656747296179, 0.9763822806963977, 0.9776892653599649, 0.044604224482851174, 0.08228367300845163, 0.9160027520899736, 0.9234597427015486, 0.9063405559896092, 0.9121387045867613, 0.9242939775330239, 0.9121908270658169, 0.9290065133405305, 0.12073860504126188, 0.06186046701108039, 0.08091685612336585, 0.11438749858163666, 0.0878726956010818, 0.10339427393280332, 0.07118510005078915, 0.11445204635096384, 0.08787422153081736, 0.08429709077528202, 0.07136269186300193, 0.0842486417033228, 0.11941370364094606, 0.09090652934868759, 0.046213640556123536, 0.10845067604951164, 0.10349160307936855, 0.04502339552972867, 0.9203241493414407, 0.9588963467636538, 0.8871856545462048, 0.9508275617399994, 0.9484725482672878, 0.9289717646040887, 0.9458910905670018, 0.9343151291973916, 0.9760114227867902, 0.8402958322294071, 0.529411586906251, 0.6342523082618443, 0.6270393222155779, 0.7699162444600662, 0.5169344599182113, 0.436298198704028, 0.37376568485020667, 0.5670630703973492, 0.13088265296783297, 0.2272069901804371, 0.2118264801937494, 0.21202474781794722, 0.17851544987282086, 0.14740131513237142, 0.06905480390203445, 0.11166283421916956, 0.13884420724186186, 0.9525627444414319, 0.9124321023528075, 0.9223528013601786, 0.13548760887729772, 0.948977349484911, 0.9426234754284882, 0.9544938908852706, 0.9311381636950823, 0.9434882686134272, 0.95332196739328, 0.958654655179467, 0.9393385910344662, 0.9536606302995992, 0.9169139588022658, 0.13815030750459423, 0.9484977106194423, 0.9613544140113476, 0.9454602645353599, 0.8820771744829304, 0.8192738088566294, 0.883567873146835, 0.9402265609903228, 0.8277406894328898, 0.9340907106290277, 0.8897510658803354, 0.9040567421087385, 0.9065145494941729, 0.9095939681275504, 0.06988712571950306, 0.8981181052103008, 0.8849965702924475, 0.8664182786157216, 0.8542923706407186, 0.8668836594055556, 0.15965126504739835, 0.06995933665076393, 0.9155654805233084, 0.048634166542391166, 0.8920682903194429, 0.9340789086395307, 0.8277189077069733, 0.9180431637888079, 0.9084843293302829, 0.9142970046391746, 0.8629446905696608, 0.20422159307312027, 0.07749872130621227, 9.999999999998899e-05, 0.4112163633997208, 0.6579770477298461, 0.03893202443842869, 0.7322910853922517, 0.21470447339455323, 0.6096887499652169, 0.9644424710410348, 0.9710352252897168, 0.9710817613042261, 0.937450159465767, 0.9624803471211585, 0.9649698330717751, 0.963583471913358, 0.9577972230712943, 0.9671253935299168, 0.12872172094945233, 0.1503186378971273, 0.05791650975253049, 0.07589197522684898, 0.12060131446741162, 0.08205265283883567, 0.15029596651627686, 0.11421188833871654, 0.10840407545997022, 0.10648858838855468, 0.1351873236176907, 0.17218812247913517, 0.12391020134818043, 0.22746056958740046, 0.21613798402584405, 0.2000663692184993, 0.19083448497856514, 0.08858773318201407, 0.22567456034919597, 0.22493387532983178, 0.19584269293805956, 0.18134057157515948, 0.18116179968724422, 0.19460219371325194, 0.17159793976812, 0.22484931797218566, 0.28308699352883226, 0.2164071632592327, 0.14980374067277769, 0.21186111115828676, 0.12556268670856385, 0.12372387801413354, 0.12474797445625863, 0.13167082641035688, 0.1972793404216684, 0.20119335419811268, 0.2286064295095548, 0.1600428409292758, 0.18664725249842162, 0.2470369232958839, 0.18160266266179925, 0.19634917989234735, 0.2335851775222051, 0.2749008085188165, 0.14769976173779775, 0.1665251992750364, 0.159862793968768, 0.15158097118552183, 0.17595730867621429, 0.19244799741805785, 0.17495074178535974, 0.1642230023514215, 0.1538698383177829, 0.17087199143461507, 0.3398502545475859, 0.127249680442719, 0.14903312548117065, 0.9800953324631638, 0.2020583295762287, 0.17321650548056677, 0.14328444555224829, 0.1664255619604461, 0.9821295289162989, 0.9761367743006395, 0.21448040886144137, 0.07361529234582465, 0.2138227746692002, 0.16990985436976402, 0.15692941075879696, 0.10255400965448647, 0.10476364193094145, 0.9782542499884547, 0.17320433390560996, 0.1862945627632281, 0.26443586073975134, 0.16740399296338015, 0.21431199193969175, 0.22788280424073792, 0.22160598878902582, 0.2200535638328075, 0.192920300532896, 0.08617196165672025, 0.05668738505769666, 0.09142974559168127, 0.07856481279246741, 0.08172482781223245, 0.07026968728594674, 0.07662838124485183, 0.07004585911683703, 0.05265797516724302]}, "mutation_prompt": null}
{"id": "57e8393c-c8e2-42bf-afab-0a486c12708a", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ANM_DM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.6  # Adjusted weight for better exploration\n        self.cognitive_weight = 1.6  # Modified cognitive factor\n        self.social_weight = 1.4  # Adjusted social factor\n        self.mutation_rate = 0.2  # Differential mutation rate\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def differential_mutation(self, target_idx, func):\n        candidates = list(range(self.pop_size))\n        candidates.remove(target_idx)\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant_vector = self.pop[a] + self.mutation_rate * (self.pop[b] - self.pop[c])\n        mutant_vector = np.clip(mutant_vector, self.lb, self.ub)\n        f_value = func(mutant_vector)\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[target_idx]:\n            self.personal_best[target_idx] = mutant_vector\n            self.personal_best_fitness[target_idx] = f_value\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n                if np.random.rand() < 0.3:\n                    self.differential_mutation(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_ANM_DM", "description": "Hybrid Quantum-Inspired PSO with Adaptive Nelder-Mead and Differential Mutation for enhanced search diversity and convergence accuracy.", "configspace": "", "generation": 58, "fitness": 0.3860294933662236, "feedback": "The algorithm QuantumInspiredPSO_ANM_DM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.35.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9718857303243179, 0.9778821561708876, 0.35548245088572716, 0.978836493082733, 0.96865436512784, 0.9747403596058557, 0.9740051329852766, 0.9762121738945757, 0.20452105211340177, 0.8905271919434722, 0.9035327834194685, 0.9181010766807294, 0.09568193225860355, 0.940498950624256, 9.999999999998899e-05, 0.8962170503501288, 0.9168925284188881, 0.913112833896788, 0.10872628436268894, 0.05195069576433231, 0.0692132544759343, 0.059909550096976405, 0.07153795363122006, 0.16484074623298495, 0.11351622889967006, 0.07636648582778416, 0.09469243117418047, 0.06521510585716095, 0.07332093342364931, 0.047177728899552296, 0.08774379442836466, 0.04648539430060705, 0.05791125745032388, 0.05335908467866557, 0.0692318490623065, 0.036446280494801475, 0.8794818068899833, 0.9572129865167058, 0.9529882371521307, 0.9885451451625864, 0.9395034510521584, 0.9549109205053022, 0.9507338889288137, 0.9406071372870303, 0.8633071902593654, 0.29591439159179556, 0.7885041493285908, 0.5016804045726095, 0.8800096830716992, 0.7378964612669048, 0.37801869663820287, 0.8413042383004573, 0.578387440377307, 0.2781161259875323, 0.23187716247147505, 0.1706437147839066, 0.11246408769025962, 0.20586083991721593, 0.17899480650905242, 0.20924818351016805, 0.12696060874758552, 0.17715356333485, 0.22463582593771392, 0.13790465607157998, 0.9325258698151011, 9.999999999998899e-05, 9.999999999998899e-05, 0.9275770005374544, 0.1261561126038827, 0.9254493124484101, 0.1854301011428947, 0.14756793762445541, 0.13823897349867564, 0.9415263943688645, 0.14608737736302735, 0.9455400382974017, 0.9043790803813251, 0.1423548745198192, 0.9499110480933308, 0.16009112773565393, 0.1734887831988866, 0.37984412515140475, 0.8533449375904477, 0.09522003548425528, 0.8118556835336581, 0.90791546434893, 0.7256066170508626, 0.9210906853711753, 0.8511315325679067, 0.08810877926759708, 0.9353502286221483, 0.8851413073391148, 0.31119184950359735, 0.9148362877494656, 0.8656413009139857, 0.9069418316156098, 0.8760698997524918, 0.8323479963364268, 0.8409056986742927, 0.45391468548928804, 0.8176410832635622, 0.6521423532010762, 0.9149610879689969, 0.899638713394961, 0.1336776199033497, 0.8723211983452515, 0.899179019289527, 0.8425904086903966, 0.13658068707155657, 0.1612734760933725, 0.055010062858611875, 0.6606919092679862, 0.1473123444725477, 0.11234222113297077, 0.6181924507907741, 0.2518341756617801, 0.27501574996838196, 0.9654459461421411, 0.9735952304896068, 0.9517902951636465, 0.9654647005470639, 0.9657543887236091, 0.9636101293026235, 0.21773438072582652, 0.9678476844887224, 0.3605649256793174, 0.033519005844811045, 0.08470298649280739, 0.09454187481668819, 0.09115319067441363, 0.07079020356808086, 0.0716002174223972, 0.09413275930713372, 0.08745395222210373, 0.0581741913898528, 0.11750860219048842, 0.24927511440535022, 0.14312094543451526, 0.19879544963823814, 0.1562588748308884, 0.149121303097959, 0.182663377963593, 0.19693528523793424, 0.1632056097044795, 0.2299213671364596, 0.2714490093252021, 0.23436508281606505, 0.18576125860256687, 0.26213953210087815, 0.17816634483141824, 0.1588991150107527, 0.246411420295773, 0.1843722188566116, 0.1139323003876942, 0.17223843055697174, 0.19122149867444727, 0.09807647478675385, 0.14983382134806267, 0.16612295752161677, 0.13859058399365642, 0.1696393667690701, 0.12886348722431906, 0.16778380045088792, 0.18767575781387114, 0.14824366248707954, 0.15350002398986218, 0.19195186667371433, 0.2442894152239069, 0.216518224138034, 0.20169273861421655, 0.21018592314251838, 0.1700855127401102, 0.19059891011130325, 0.1540980383443764, 0.15662578756639156, 0.17966867247074225, 0.17397514481131837, 0.1794528765658715, 0.18000561336318588, 0.16688769374293244, 0.18850558976601228, 0.12738215573736889, 0.149052717217805, 0.9688306822510032, 0.20186400366449364, 0.2009727251418808, 0.14317037534762878, 0.16632593440075527, 0.1676685796837708, 0.966749689834452, 0.21398430068880347, 0.0736142526198661, 0.1052776095705743, 0.1659036931466804, 0.15626164982017143, 0.10487825794975703, 0.10524783108395841, 0.11373472096395254, 0.1688340745621545, 0.1694751115033476, 0.1974984871711708, 0.21105164824021705, 0.2146088643750239, 0.27357702343157975, 0.21285888486572524, 0.25624788594616443, 0.21293905102302402, 0.09494320009032486, 0.07214183229162663, 0.06752964402219785, 0.05591089119092918, 0.08695931181084438, 0.049508775700193075, 0.09896830532882228, 0.10324934356770588, 0.047856241027298574]}, "mutation_prompt": null}
{"id": "195fbbce-d322-4ac6-91ae-912e9640655e", "solution": "import numpy as np\n\nclass HybridQuantumInspiredPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.8\n        self.cognitive_weight = 1.7\n        self.social_weight = 1.3\n        self.f = 0.8\n        self.cr = 0.9\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.func_evals >= self.budget:\n                return\n\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.func_evals += 1\n\n            if f_trial < self.personal_best_fitness[i]:\n                self.pop[i] = trial\n                self.personal_best_fitness[i] = f_trial\n                self.personal_best[i] = trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best = trial\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                self.differential_evolution(func)\n\n        return self.global_best", "name": "HybridQuantumInspiredPSO_ADE", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Adaptive Differential Evolution using quantum principles for diverse exploration and adaptive crossover for exploitation balance.", "configspace": "", "generation": 59, "fitness": 0.17688350388028742, "feedback": "The algorithm HybridQuantumInspiredPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.19.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.30911775172650746, 0.2893605699463737, 0.2609011938129011, 0.4308127593947283, 0.41898956195899095, 0.33449778884427184, 0.39830063568241536, 0.3381878138727822, 0.38411855122242955, 0.009174715861213212, 0.0023017822802395838, 0.0031863311437849706, 0.021380312326052753, 0.008123573086088798, 0.04376259549189543, 0.006907784480886359, 0.004677790370786528, 9.999999999998899e-05, 0.0921446142150788, 0.1016809380425675, 0.062465015946445934, 0.09027649552302286, 0.07902860929667854, 0.08036145820411389, 0.07566023850507009, 0.086403118544083, 0.08942722672968906, 0.07999984119696835, 0.052820676786560994, 0.06617548015748564, 0.06868422100198657, 0.07074722853062809, 0.058422271550969684, 0.0891888208751811, 0.07402312244767595, 0.059644955222102336, 0.9839904399760068, 0.9759851913946941, 0.9844953698297291, 0.9834248282596423, 0.979758858918876, 0.976444667446804, 0.9843735778259874, 0.9749090331552933, 0.977528509116906, 0.17426819865571475, 0.13197124834365936, 0.18974107837081855, 0.1996514745024146, 0.13695755467222293, 0.1674692029906384, 0.20362104135509806, 0.11989473132650696, 0.16803627629097295, 0.20145470494941797, 0.21810068555503048, 0.2023345355921219, 0.1872732092827739, 0.17108254727382077, 0.18528032242580827, 0.19149951233406837, 0.23770693192340087, 0.220035461452741, 0.13120063993443232, 0.07347340088677179, 0.12240673420815329, 0.08551756208880201, 0.09450760669988956, 0.14666707157228898, 0.0837367600565827, 0.07948043499110113, 0.09820317245049459, 0.11328620762290154, 0.12501462286389342, 0.12322942818360971, 0.11170896862664392, 0.0688633181229994, 0.04959891929557525, 0.09291119519262048, 0.11495687217851824, 0.090374209398562, 9.999999999998899e-05, 9.999999999998899e-05, 0.07365743553039761, 0.00011533116884021588, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0593065393166049, 0.06265332926858791, 0.1123602729100357, 0.09477973566738507, 0.06933589001574714, 0.017426409359589723, 0.09154766249909085, 0.05547364027840851, 0.032058365786325926, 0.0007505934454651308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0023957737408168978, 9.999999999998899e-05, 0.057611515367280486, 0.007125642610985583, 0.007945911809268513, 0.02946581148523586, 0.05678670741122516, 0.04398935946184934, 0.04902713369489342, 0.040061627949321, 0.05121973879965647, 0.32748988031288795, 0.28684576274840334, 0.2838578866700123, 0.3442175342305187, 0.3527752540696252, 0.3514802162171652, 0.3483905419575434, 0.2676770093716032, 0.30456837896196054, 0.09524598879201662, 0.055931651630740764, 0.08688942920868392, 0.07297050886031609, 0.06876948785991321, 0.08193549674402545, 0.07933711051570713, 0.09357189107957764, 0.07944353201695209, 0.19548524289133795, 0.1921701375719599, 0.13273941551802948, 0.185167288179792, 0.15354355460718472, 0.151854701670173, 0.15750178181125485, 0.14937283056483797, 0.19100562713399827, 0.2245748118701525, 0.18489914153726594, 0.21857720056095142, 0.21365998986471213, 0.19718382555102254, 0.18783690989487478, 0.24932634795591935, 0.22627178953605676, 0.2647386590290495, 0.18398842543795613, 0.15552071500034237, 0.15900661796663262, 0.16595661512294246, 0.17347026334491933, 0.1441493059364406, 0.18482841838140784, 0.16640558504002168, 0.16355302043461384, 0.18029327242861004, 0.16572074734147624, 0.18752997943336913, 0.1743851909497367, 0.19323453200527219, 0.1967213611561507, 0.1690562816909038, 0.19087385209018015, 0.25691317204745145, 0.16867277215158538, 0.1749678185395167, 0.1809240997065018, 0.1726105098917451, 0.19752467393718676, 0.17204391329217728, 0.16680743081236737, 0.17995898149801082, 0.18189241270198886, 0.4836066512168332, 0.16586631479551928, 0.13022630987651773, 0.3919733674785214, 0.18333714778138288, 0.35040654424022477, 0.15832748537941022, 0.15659501442250112, 0.3486825270731866, 0.2935689800790827, 0.20148324980236054, 0.15907366329454198, 0.190396180574664, 0.26925479442645406, 0.18436225199977674, 0.22272540136815455, 0.20315390589390725, 0.3438988720701236, 0.175566957498969, 0.18309615921658695, 0.18395298428602525, 0.2092491613570393, 0.17480783595502836, 0.18514528382979456, 0.17578586686360032, 0.1879669074954453, 0.18583409718471144, 0.0659459660128674, 0.07437121075330999, 0.0723679436600867, 0.062269503038400065, 0.08517929506016209, 0.06796199859378427, 0.06678624067242367, 0.07874015441755877, 0.08057723568671049]}, "mutation_prompt": null}
{"id": "aaff3317-e5c5-4122-8b2f-4de6d81b95fc", "solution": "import numpy as np\n\nclass HybridQIPSO_DE_ALS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.inertia_weight = 0.6\n        self.cognitive_weight = 1.7\n        self.social_weight = 1.3\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.func_evals >= self.budget:\n                break\n            a, b, c = self.pop[np.random.choice(self.pop_size, 3, replace=False)]\n            mutant = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n            trial = np.copy(self.pop[i])\n            rand_idx = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < 0.9 or j == rand_idx:\n                    trial[j] = mutant[j]\n            f_trial = func(trial)\n            self.func_evals += 1\n            if f_trial < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_trial\n                self.personal_best[i] = trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best = trial\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            self.differential_evolution(func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + 1.0 * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + 2.0 * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + 0.5 * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "HybridQIPSO_DE_ALS", "description": "Hybrid Quantum-Inspired Particle Swarm and Differential Evolution with Adaptive Local Search for enhanced global and local exploration.", "configspace": "", "generation": 60, "fitness": 0.4034202578151121, "feedback": "The algorithm HybridQIPSO_DE_ALS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.36.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.20598688855128622, 0.9743713684450587, 0.9626687009893714, 0.9698461202046794, 0.9734679381868019, 0.972330844327514, 0.2169743090224856, 0.9555909924223469, 0.9511875695972877, 9.999999999998899e-05, 0.04473912605152308, 0.04452729738617889, 0.05013516868086387, 0.0505866163915043, 0.9042636408923428, 0.06385151862939165, 0.8941726639981861, 0.05676817288515579, 0.10683051048143555, 0.06303211461140967, 0.07864304573949521, 0.09592869096645495, 0.08701712610747869, 0.06515542415166309, 0.08751776756484397, 0.11410988827264668, 0.1278662223850182, 0.03684890086013548, 0.07579741531021045, 0.07087561341138249, 0.07115278088615429, 0.07533596621448191, 0.07845777768334428, 0.052033642608822483, 0.08709731476411509, 0.05916940370481738, 0.946957887419871, 0.8891934117016872, 0.9353072344920044, 0.913137104005456, 0.9180411037273175, 0.9798569342703164, 0.9250996789841799, 0.8920022289824112, 0.9069578636682684, 0.08121390506477943, 0.8052222812889983, 0.44707090254045767, 0.18163280448978436, 0.49636219762125733, 0.836006176582458, 0.5884023950043878, 0.8305276482221113, 0.6464246912299947, 0.1541371039385665, 0.2115981619070595, 0.3276482256387744, 0.1920167532701581, 0.25498284218447376, 0.24505756902612452, 0.09081400367849424, 0.15563414520313412, 0.18846078806270516, 0.1591053575419794, 0.957136124236113, 0.9475997362973235, 0.13499234307624608, 0.13743640762854337, 0.9407508136041579, 0.1932415646897111, 0.9583915238169584, 0.9301141331559802, 0.8589503085379322, 0.9274495248433737, 0.9535381949537387, 0.15648970249836802, 0.9466649098178305, 0.9236308550573837, 0.13705175248156998, 0.9291566304797518, 0.944105461003996, 0.8682031320922421, 0.9126617656857362, 0.8755685545164571, 0.8076654615446721, 0.8827191865852404, 0.8467456410799832, 0.8376502600558288, 0.8970162868663899, 0.8660293005209748, 0.20944415681291406, 0.9328020479989907, 0.9045165140570027, 0.08991694782694126, 0.8730801903153436, 0.9007330232156249, 0.8193546448930149, 0.9050921685971066, 0.8932345492646135, 0.16170038936294917, 0.8897259515176742, 0.9035299823036773, 0.7286569483835759, 0.8466727837360768, 0.9190273877044495, 0.9136127825210792, 0.8837890741195098, 0.8243069642661301, 0.6269365887247109, 0.8373745714828624, 0.10111987888308793, 0.07150518779184134, 0.12974653098382694, 0.9424155903169292, 0.10385385926424151, 0.4756541862561101, 0.10808267656168025, 0.17213981644425735, 0.9608624328616991, 0.9565966174702244, 0.9557577011759815, 0.9525942936968268, 0.9573705379169642, 0.2882366954224749, 0.9545047122098169, 0.9601295888321493, 0.07998335177914595, 0.05633704490970415, 0.10790871963014215, 0.06678593106682329, 0.11307570865205707, 0.16588815814295654, 0.08646685893264872, 0.14964033781595354, 0.1375035461821903, 0.16941695396983247, 0.18370451814031918, 0.16566975455961075, 0.17078090062814122, 0.2439736401844701, 0.17440992894171703, 0.1789733840909632, 0.10646286615984424, 0.13326623537216542, 0.2459632653006134, 0.1906886045937216, 0.23696773994511955, 0.22618990042752807, 0.3319713040743226, 0.1620860590374139, 0.1574955105660052, 0.23689907365536456, 0.1391874841071551, 0.13986396193860962, 0.15310304895925597, 0.14908995263923075, 0.15423299339907404, 0.21087584611597654, 0.16634691120738576, 0.13313540293059578, 0.158292337002515, 0.15332897131059364, 0.18242740703992233, 0.22400965161589004, 0.18272003207495102, 0.1808378681461219, 0.30535424966177316, 0.2601169069424294, 0.17741649739952814, 0.23364106957194786, 0.23389447234484861, 0.1849035185291048, 0.1793220597732066, 0.18454533845038656, 0.15295693798343069, 0.18210038246356175, 0.16410588998879339, 0.1767332768419383, 0.1879004653131049, 0.18787518801300307, 0.18042340944517032, 0.18893309015202409, 0.16012411216342093, 0.7095977273861783, 0.20172191455757948, 0.17007083283744795, 0.1430467403205754, 0.17919468818317597, 0.9730814943880145, 0.36727155830159064, 0.16957063766685954, 0.07360542445215801, 0.17383090552783764, 0.16919286322223215, 0.15664031428662673, 0.10487192980012483, 0.10492638973744273, 0.9755463414609898, 0.22589429798016458, 0.1712291040826609, 0.19843740606354554, 0.2553726035468584, 0.2456512761082571, 0.22993235538592816, 0.2672893178043305, 0.2070077959872626, 0.2115655727188409, 0.07873990399797492, 0.06271778259277494, 0.0715066699184328, 0.05594005927608692, 0.10061149470409614, 0.08041745368352438, 0.05287556904384616, 0.08385585883465152, 0.07290588347044591]}, "mutation_prompt": null}
{"id": "25c00350-7ce3-4916-9b2d-e5390f6e46d7", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = np.random.uniform(0.8, 1.2)\n        self.beta = np.random.uniform(0.4, 0.6)\n        self.gamma = np.random.uniform(1.8, 2.2)\n        self.inertia_weight = 0.6 + np.random.rand() * 0.2\n        self.cognitive_weight = 1.5 + np.random.rand() * 0.5\n        self.social_weight = 1.5 + np.random.rand() * 0.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO", "description": "Adaptive Quantum-Inspired PSO with Enhanced Local Search using randomized adaptive strategies for diverse exploration and precise exploitation.", "configspace": "", "generation": 61, "fitness": 0.4382324180178506, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.36.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9753034693398127, 0.9777460419655366, 0.9791999873955026, 0.9755464478265921, 0.9820992773806763, 0.9665402329690923, 0.9774967405962336, 0.28931034620925056, 0.9687073944864141, 0.9543261624785953, 0.9500263725813834, 0.8751425270382148, 0.9145309837507706, 0.927231579334806, 0.8876752798400567, 0.057072262657917094, 0.873240982576, 0.9255218816834613, 0.10335615881217985, 0.10821206438065456, 0.12876878285657845, 0.10863778530069179, 0.08466707319319944, 0.09498223211768764, 0.039762290068044104, 0.13821118442341263, 0.10266640342450462, 0.07141497731445123, 0.07143881320249579, 0.08782807525257996, 0.07625320421966586, 0.0579513745725897, 0.08464548952212281, 0.07893480005392717, 0.041885745577030176, 0.07261864802893725, 0.9466852527682004, 0.9695620021272734, 0.9579849911418937, 0.9303368312626678, 0.9634018194278788, 0.9261467511167714, 0.9240210166551952, 0.9549679025035455, 0.9181325819377624, 0.5697543884855183, 0.3219451352121262, 0.5344945206235532, 0.5434064451104845, 0.3157411248730223, 0.45763708157725824, 0.8007408516702283, 0.49300008778737114, 0.6302444231978362, 0.16815284076891823, 0.23192059087595684, 0.13643585120499735, 0.23915557851961167, 0.29100600108484376, 0.14544498878493872, 0.12024215415972761, 0.17797625908814574, 0.16813781712711662, 0.13832170823291667, 0.1368640483737139, 0.9529908141228602, 0.13711380592406663, 0.944621869652572, 0.13824557580850383, 0.21725764334181352, 0.1373515387184696, 0.9506138671146244, 0.9456317568202685, 0.13760500641628748, 0.1377408049925396, 0.9484682153854294, 0.9349275796034744, 0.9513021457154622, 0.9443085273784402, 0.9528778165834411, 0.8797845120770126, 0.9297791266663086, 0.06878884764422177, 0.8581141105501358, 0.9367875658957622, 0.730894653842002, 0.06375886474955827, 0.8544328685981134, 0.8102544082362495, 0.8596681073238637, 0.8579907380128104, 0.775488435296825, 0.8520093489559559, 0.869769092938058, 0.7025960045610237, 0.867839365168466, 0.8702854867250083, 0.9321017295956557, 0.885063063111509, 0.9226754823712479, 0.8309641794531017, 0.8511186630519285, 0.9363687072502892, 0.900486511950623, 0.9359607235131621, 0.8165034830193366, 0.9314011257438158, 0.8580569200320036, 0.6207429715776802, 0.42052351675147803, 0.14277068295652917, 0.8666890225695467, 0.5214561268390041, 0.665736784663727, 0.34763876731749155, 0.08708963104441358, 0.36800689224793626, 0.966632417046997, 0.9547482317373845, 0.9707314755238594, 0.9656210690964012, 0.9755863396109682, 0.2092614267068862, 0.9725559814074491, 0.9644717282862467, 0.9668348770841039, 0.06990541276047602, 0.16778641525890436, 0.09914676166378444, 0.1275948241285394, 0.04212482423614361, 0.08807272469149341, 0.1974164661218084, 0.11693861197088118, 0.15086535627891717, 0.12009462750612565, 0.1380634750458597, 0.13902624455593637, 0.21383257243590137, 0.19219598444160058, 0.16549828071560646, 0.15024227880042385, 0.11110906302983947, 0.16050833787478536, 0.12273880331331999, 0.27447517468788074, 0.21804090718766178, 0.2378469419956114, 0.17806653827588803, 0.18121667905912253, 0.19466220658206235, 0.22631868886281026, 0.20090536001482673, 0.23349274213207483, 0.1351582082857169, 0.1254337731611579, 0.12987693909972664, 0.11553726757190774, 0.12379033465857903, 0.12146212239722554, 0.24990931421033924, 0.19219883141361038, 0.2747137943341956, 0.16490101753553554, 0.1738677241135096, 0.14608502289502723, 0.3274314309598758, 0.15047662709136944, 0.2509750039235389, 0.1972772354682788, 0.22367162551705266, 0.15138938054183038, 0.1746917100542834, 0.17674495772643328, 0.17497124065510483, 0.1880475475462664, 0.19095646046708392, 0.1540904749215275, 0.1758801783978955, 0.1599492819636873, 0.9784584400150635, 0.12726317411266996, 0.154829008639486, 0.12504990388628956, 0.20214435306002299, 0.1702641821047366, 0.14351841430619083, 0.16635759438371278, 0.21423724795364008, 0.9765123254003836, 0.21436960970637398, 0.9688609854937447, 0.9404334039705554, 0.16987927729927688, 0.10797840080536203, 0.1713591660874928, 0.10534814431915274, 0.9803364778007078, 0.16956444718697217, 0.2047984219517912, 0.2157351535196831, 0.20030666536594122, 0.20517737346537734, 0.22643817892685336, 0.17803646362332526, 0.18712462959825715, 0.21263623669253506, 0.09816705724416297, 0.09860926935528169, 0.057995902614710215, 0.08804783602244082, 0.0858487841632466, 0.06995421088337539, 0.01952174733152401, 0.06298423209770065, 0.06447060941769245]}, "mutation_prompt": null}
{"id": "34d5cd04-8c5c-4245-9f42-a846afdc8bcb", "solution": "import numpy as np\n\nclass HybridGA_DE_ALR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.fitness = np.full(self.pop_size, float('inf'))\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.func_evals = 0\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.01\n    \n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.func_evals < self.budget:\n                f_value = func(self.pop[i])\n                self.func_evals += 1\n                self.fitness[i] = f_value\n                if f_value < self.best_fitness:\n                    self.best_fitness = f_value\n                    self.best_solution = self.pop[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.func_evals >= self.budget:\n                return\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n            crossover = np.random.rand(self.dim) < self.crossover_rate\n            trial_vector = np.where(crossover, mutant_vector, self.pop[i])\n            f_trial = func(trial_vector)\n            self.func_evals += 1\n            if f_trial < self.fitness[i]:\n                self.pop[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.best_fitness:\n                    self.best_fitness = f_trial\n                    self.best_solution = trial_vector\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = max(0.001, self.learning_rate * (1 - self.func_evals/self.budget))\n\n    def __call__(self, func):\n        self.evaluate_population(func)\n        while self.func_evals < self.budget:\n            self.differential_evolution(func)\n            self.adaptive_learning_rate()\n            if self.func_evals < self.budget:\n                self.pop = np.clip(self.pop + self.learning_rate * np.random.randn(*self.pop.shape), self.lb, self.ub)\n                self.evaluate_population(func)\n        return self.best_solution", "name": "HybridGA_DE_ALR", "description": "Hybrid Genetic Algorithm with Differential Evolution and Adaptive Learning Rate for enhanced exploration and convergence.", "configspace": "", "generation": 62, "fitness": 0.18345258429390135, "feedback": "The algorithm HybridGA_DE_ALR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.17.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.3797678375834411, 0.3673723050092781, 0.37605429252049194, 0.4376720800290014, 0.38694727985780564, 0.4309788766289142, 0.41082132463220256, 0.3997182265161183, 0.4113894009253204, 0.11806700411510085, 0.14437939635626262, 0.13272966823164367, 0.12593824260605302, 0.11594846610045118, 0.1232160113636892, 0.13315905412381868, 0.12204490818103386, 0.12879894077423037, 0.09408090439033845, 0.073061303114062, 0.07357213069827317, 0.07151170917235194, 0.08350147964634347, 0.08006042375320033, 0.10221285597451368, 0.08989120363257386, 0.0719669464069852, 0.07304583376195439, 0.05621108156161281, 0.0949127397731403, 0.08374907785128904, 0.08621832248705619, 0.06292022150855336, 0.070089757892148, 0.06258242375664791, 0.06040567947982578, 0.892300261991059, 0.9135075567715402, 0.7910422079760815, 0.8022816100150768, 0.8455518406802518, 0.9678198666909207, 0.8558891407035418, 0.8667697039492979, 0.9130729168892704, 0.16610719084796477, 0.17923008227595494, 0.14869446310027346, 0.1659743977905357, 0.1432999112532305, 0.17578698164036544, 0.20311854204712165, 0.18712415040621633, 0.17904970335873238, 0.21421615322806298, 0.25838464077051504, 0.22767886417003802, 0.30699270652471533, 0.23517138317840813, 0.2277229711790053, 0.2438871287713793, 0.21690649531258155, 0.23106580025840973, 0.1141092588553081, 0.1016719433232336, 0.11475030064583047, 0.11608812357765597, 0.09357759243974795, 0.10693897409000397, 0.10015381489475805, 0.11349834181950813, 0.11338059608396012, 0.08560265412857349, 0.10652227715880813, 0.07087018229091513, 0.10678276438444445, 0.10751284206040379, 0.08903328183371562, 0.11137943311121112, 0.10015414871190098, 0.09425385686349597, 0.01803969619912804, 0.028486431468487394, 0.02142874339396672, 0.0375108532072187, 0.023969415927678872, 0.025970289270491054, 0.028265576295702144, 0.013193807976904282, 0.025813489477287344, 0.12487374001067542, 0.1432723025470799, 0.14997135172725462, 0.13695876112894034, 0.09469248521446516, 0.14862847446688066, 0.12993243620653716, 0.13608406743056034, 0.13436555810248318, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031135496388090544, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0720121452487632, 0.07043674697575641, 0.07717910594733335, 0.06675784562730824, 0.07560428037615696, 0.08184107074912739, 0.07964305696807605, 0.09680487571353447, 0.07397188300621615, 0.3341066828559137, 0.3492206222003492, 0.36185515619999065, 0.37156882041760464, 0.34222664935435565, 0.34704535564822614, 0.38611451541570185, 0.3295395669256902, 0.3358850909526033, 0.08175936092419467, 0.08379835483715903, 0.06606583700788071, 0.08800282072001442, 0.07676165036737181, 0.08857260505668985, 0.06951949352377773, 0.07668594826797903, 0.06983523356434962, 0.14896750769208356, 0.1516759833538608, 0.148445448465936, 0.14886578661960925, 0.12490680925327668, 0.16209029388538, 0.1428340847259706, 0.17355105245832292, 0.1344484637718799, 0.2173832390353403, 0.225610024288046, 0.21884100478550617, 0.20091963792756096, 0.21148706515209093, 0.2209651506160154, 0.220224281903468, 0.2428238072014408, 0.22989869897458837, 0.15900439380748488, 0.17102131860386727, 0.14942552487730631, 0.15094952573937281, 0.15815890698017177, 0.15477029879385285, 0.16558210798319728, 0.17284771319339765, 0.1730155096700393, 0.19875288721797768, 0.1917244075918325, 0.19927916486867547, 0.1826118434261529, 0.20622912216014966, 0.21167037940401057, 0.19626641383958965, 0.1852866331381029, 0.20087361543925497, 0.16886583576534975, 0.15484120095869114, 0.16871447540504492, 0.17519525005933156, 0.16743131335160355, 0.16720961856936534, 0.17098993043176103, 0.1612524209731755, 0.16475966605939152, 0.2702021830039548, 0.22657252068214118, 0.156019991414029, 0.32980668876577357, 0.1722953323211921, 0.19226900888508636, 0.1954967229932396, 0.17073455328877174, 0.25090023489987257, 0.23187946472086707, 0.17562201932198074, 0.2683407269268544, 0.1513744284332077, 0.15578884601403675, 0.12958729672643732, 0.19223304838892163, 0.18885293542378, 0.1861181073260363, 0.19563315056182262, 0.2014230960807275, 0.1980803570499564, 0.19715842426756358, 0.20067087911291825, 0.1956546180926675, 0.20675108753255034, 0.19624289795619976, 0.1982916961663852, 0.06496871837257567, 0.06439247175681917, 0.06493859581555084, 0.07637890436109351, 0.07316129197879295, 0.06707333791889103, 0.07703039504117937, 0.06885411964389476, 0.06898415948089665]}, "mutation_prompt": null}
{"id": "affd9352-b021-4faf-b230-21953c1c6c16", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO_DualNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = min(10 * dim, budget // 2)\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.4\n        self.gamma = 2.5\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_weight = 1.7\n        self.social_weight = 1.3\n\n    def update_particle(self, i, func):\n        inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (self.func_evals / self.budget)\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO_DualNM", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Dual-Leverage Nelder-Mead for enhanced exploration and convergence efficiency.", "configspace": "", "generation": 63, "fitness": 0.31780461653218584, "feedback": "The algorithm AdaptiveQuantumInspiredPSO_DualNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.31.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9197713730296515, 0.9588618363362973, 0.953934572700795, 0.9727149636249655, 0.9604115629204467, 0.9545475474573984, 0.9779796730626906, 0.9714977982621591, 0.3323430411990542, 0.15683166329166254, 0.3585442121030613, 0.15843174864568177, 0.22068374209095332, 0.04897002951960294, 0.16535418823817805, 0.13591178339743115, 0.09165015776714414, 0.06526518911119783, 0.10862767894270997, 0.04550773275292486, 0.0630544999502668, 0.12067948839615072, 0.13787950021049034, 0.09495223123819285, 0.06159692493232305, 0.09749348738022867, 0.10353279631185719, 0.07608448561076442, 0.07363412318472151, 0.1198540778158742, 0.053139509660193984, 0.0846122310305032, 0.040440105930360404, 0.04652730832135421, 0.07158277315674355, 0.04794731209458625, 0.9892577786885994, 0.9575892671668619, 0.963359646632438, 0.9719059533127047, 0.9889235504181074, 0.9611133841916424, 0.988515788350657, 0.937076641499218, 0.899853633105736, 0.17669971508790827, 0.17787072266904236, 0.16364691703107614, 0.17659805280206475, 0.061331085411337916, 0.15593369912460053, 0.24346895511845856, 0.06381432134119336, 0.3015753537068935, 0.17390562650453778, 0.2121218207793708, 0.15225560532887705, 0.1305601334242339, 0.17461508600918785, 0.1611628417284724, 0.06795142254952535, 0.1800121622303168, 0.1309320299606601, 0.13756770288551, 0.7454189309573609, 0.8133637414232798, 0.11242531359483565, 0.8848083142227896, 0.6884605542327593, 0.9326207989081272, 0.6806190669443877, 0.8990633779873216, 0.7454725952024326, 0.8894908853857038, 0.13725350861471164, 0.7498109096966554, 0.7625983137479725, 0.7205714026991024, 0.1379726907648361, 0.13424620584681635, 0.13817285519834588, 0.1457386303529331, 0.4431405790923827, 0.3813092909555955, 0.20209673276888462, 0.06018321036276597, 0.24310710071176578, 0.2511224434166436, 0.2759500004925688, 0.31672103854380107, 0.09747278488872546, 0.07486917975459839, 0.3655926780751283, 0.2391843065174708, 0.22799304260864417, 0.05410250862516619, 0.18369227207764383, 0.2831401024580188, 0.08126889072210886, 0.35553954258206666, 0.5309922827367187, 0.6212860437513643, 0.49598997587298244, 0.8830881510201593, 0.5887837263324187, 0.7910968862096799, 0.6221922375383075, 0.28869700807888754, 0.1303011609503596, 0.08776155090972715, 0.20686846434742934, 0.04945018530751755, 0.01589793629542724, 0.047804212289094705, 0.6452134508097733, 0.059585604711854256, 0.13704253349321494, 0.8617921678190847, 0.9202974250975995, 0.8013197295734402, 0.8837170965632494, 0.8710591123565286, 0.8497225275801429, 0.914496870256289, 0.9018274273326011, 0.9288008690677532, 0.11392332668617078, 0.10315615862585203, 0.08358416048132333, 0.12070979234425105, 0.0634936490277016, 0.19109608014588964, 0.09698719220472263, 0.13775647829442095, 0.10236297929598626, 0.13117976491919803, 0.1834588977975451, 0.1693682697801383, 0.16775256231074798, 0.160577784670757, 0.1371456525568654, 0.13187037529696666, 0.12158910215667984, 0.13946531645229643, 0.16584355611074297, 0.21441601800483945, 0.22627041298641648, 0.19223991106604832, 0.20863357681434203, 0.1715421447878811, 0.1715662123020123, 0.2037788553312062, 0.2180000042676422, 0.14818891126846645, 0.09046292943005496, 0.23056361298636852, 0.1307659007448274, 0.09114504055291495, 0.10909391599353335, 0.1824172497101032, 0.2365367396891367, 0.15597025134902864, 0.26936981317465925, 0.22392080353645794, 0.22151667060283353, 0.17208661693554073, 0.18536777721878306, 0.17416416482559127, 0.23658146044730888, 0.15884254162755607, 0.2368159691703262, 0.16224089618522797, 0.15815133768188028, 0.19131237295930414, 0.16894458922689448, 0.16359676507967902, 0.1591309529015129, 0.17260341357491615, 0.18444075994594267, 0.1569157134507957, 0.9842535959234706, 0.1270324729887985, 0.08737676407888995, 0.9743797169671853, 0.20109123895445824, 0.11712296647924358, 0.14351490604207207, 0.1660832811488674, 0.1692101197576389, 0.9151055266306543, 0.2143353308951106, 0.07072403133115424, 0.2102404855818263, 0.16972326704886398, 0.15700854732389125, 0.2754353122387627, 0.10502400931904299, 0.948589943793983, 0.18707255830080416, 0.16954055228688936, 0.1916614649944518, 0.20929334386659293, 0.19362468512662534, 0.24303822703116273, 0.18937390303366441, 0.1784671696157042, 0.2088529645017605, 0.11031614089311459, 0.07494470526394648, 0.08216445423786023, 0.07647476246524021, 0.08882268823631423, 0.10610298661755801, 0.11756805967383555, 0.05348210088450123, 0.08968079895610148]}, "mutation_prompt": null}
{"id": "f592a5d4-f377-4268-8da4-abd91e122850", "solution": "import numpy as np\n\nclass MultiPhaseQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.6  # Adjusted contraction coefficient\n        self.gamma = 2.0\n        self.inertia_weight_max = 0.9  # Variable inertia weight\n        self.inertia_weight_min = 0.4\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        inertia_weight = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * self.func_evals / self.budget)\n        self.velocities[i] = (inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "MultiPhaseQuantumInspiredPSO_ANM", "description": "Multi-Phase Quantum-Inspired PSO with Adaptive Nelder-Mead using variable inertia weight and dynamic adaptation for improved convergence.", "configspace": "", "generation": 64, "fitness": 0.4606865982651218, "feedback": "The algorithm MultiPhaseQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9753125297311825, 0.9746523479355097, 0.9766504221866369, 0.9721175252253218, 0.978171803907811, 0.9781915727510034, 0.9767079500445401, 0.9784010389096186, 0.9731757785649064, 9.999999999998899e-05, 0.9147307921826979, 0.9106483823303123, 0.049424136804296914, 0.9237487441527048, 0.9053592758559176, 0.9382502175066394, 0.9421862365481197, 0.05703513030637419, 0.061579003309120695, 0.06182732035052452, 0.12056954537375897, 0.04801904091673148, 0.11437362024003672, 0.08773235931833512, 0.05991270900812706, 0.08783695040040507, 0.1965485133362731, 0.07371791631155389, 0.08458417443906696, 0.10285911953635574, 0.0990127723821328, 0.11335478687115919, 0.050343873090219815, 0.09885940955451877, 0.15040877444040912, 0.01389196852200314, 0.9899210912100255, 0.9170311918397055, 0.8756802162773137, 0.9551910295865874, 0.9338164620282091, 0.8843274728551774, 0.9457234200820641, 0.960928972761728, 0.8773476403008735, 0.8958362724655246, 0.5665079294586186, 0.8843706417873822, 0.8281081689538365, 0.5315934680629999, 0.689852008019969, 0.9434609280863181, 0.9007631133276421, 0.9052033565059473, 0.15114216023360427, 0.22044124993461678, 0.14296797285418616, 0.19096649470537996, 0.20236503891064628, 0.19883689081365907, 0.1264832089729867, 0.11249867201243613, 0.07572069817447502, 0.933194205734845, 0.90682990036273, 0.9401963481121066, 0.9121148226669852, 0.9233395730184274, 0.932864575958265, 0.9325188024968962, 0.1376006702205812, 0.9392543483452759, 0.9528692429118173, 0.9494468671291513, 0.9257543875197448, 0.9420442203160001, 0.13791895103288465, 0.9358948951669683, 0.9487310810478056, 0.9501191100966399, 0.9316661967361358, 0.9000899511018574, 0.10027316443047563, 0.9276175676408606, 0.9010719730001071, 0.8650035244132352, 0.9051956821376969, 0.9186830859615888, 0.9452016984129765, 0.9013085867047805, 0.8647816653576287, 0.34120160155336177, 0.8829572268759296, 0.8515858152461684, 0.900568397150577, 0.8406685876089087, 0.8516859764052098, 0.7683686208966113, 0.06088645334002396, 0.8965616413980323, 0.8599537398846714, 0.8792127929491219, 0.9214226766228276, 0.9354967087168465, 0.921422825165697, 0.8546426445944435, 0.909275861076307, 0.9186349367725232, 0.19974898683026798, 0.20314219195014638, 0.4439406120430469, 0.06561869136373477, 0.1487917407507492, 0.5029657675703592, 0.10590265886368155, 0.15429525336137961, 0.8028754992007618, 0.9621956569202086, 0.9622924290544378, 0.9562547856972933, 0.9685571422121534, 0.9500291893605615, 0.9610382041359449, 0.9674457099869281, 0.9656983935644576, 0.9525203637298866, 0.09880980739355438, 0.11414894079073312, 0.05974124832161343, 0.1142082782096957, 0.07150089581484476, 0.09921325129247383, 0.1382433565609743, 0.15044787395032433, 0.09922884180672498, 0.13073715598819213, 0.1275327490717496, 0.16210039302955281, 0.14081078838262695, 0.2670110057979277, 0.16403793052693383, 0.2186341463369692, 0.09625596998617092, 0.1124011667970064, 0.2004042713303812, 0.18104752527398893, 0.18255627953811815, 0.22977753215061447, 0.16637873469211806, 0.1796129084093211, 0.18446305041141053, 0.26056991675042684, 0.2158015490616595, 0.17167128371490947, 0.10868069949596049, 0.210797758904543, 0.12379095543337115, 0.1356010310319361, 0.1718329160973503, 0.23561120698180216, 0.12059783456603113, 0.1549534472990034, 0.20163231424181516, 0.1885192429942283, 0.24660262939735011, 0.24552175908449259, 0.24487385770646486, 0.17905233001004095, 0.23117080400990409, 0.20548338145868184, 0.23424684953658503, 0.1591138919529096, 0.18422633202768102, 0.16547309896156182, 0.19311068433504996, 0.21516172338035033, 0.1768256634934744, 0.1794099476917791, 0.17050685122642184, 0.17006809416863233, 0.5673263139985806, 0.1273232593297593, 0.14853715395852174, 0.9783502181515539, 0.20193287570483276, 0.17326939446280631, 0.14313774297762993, 0.16612909405891463, 0.9693417427204836, 0.9787400568446675, 0.21442586588200163, 0.07197509352208509, 0.21238850716123248, 0.16987996141601525, 0.15702688581630087, 0.10366676740777947, 0.10479882730185197, 0.9611779173972557, 0.2543215370546764, 0.18120451537083226, 0.22408749944042283, 0.17863223620948065, 0.16297351744389466, 0.19629287345398894, 0.2568218460612759, 0.275799323566595, 0.2426809472748781, 0.05710440378461701, 0.0658208537873366, 0.05557544783369317, 0.06604392756166222, 0.06920610480013767, 0.09929549281690142, 0.06781484381537661, 0.08062820695742667, 0.04753541958844576]}, "mutation_prompt": null}
{"id": "f38034ab-339b-4312-8a36-3b74f0f3738b", "solution": "import numpy as np\n\nclass HybridQIPSO_SADE_CE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.f = 0.5\n        self.cr = 0.9\n        self.chaotic_map = np.random.uniform(0, 1, self.dim)\n    \n    def chaotic_exploration(self):\n        self.chaotic_map = (self.chaotic_map * (1 - self.chaotic_map)) * 4\n        return self.lb + (self.ub - self.lb) * self.chaotic_map\n    \n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n    \n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.func_evals >= self.budget:\n                return\n            idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n            mutant = np.clip(self.pop[idxs[0]] + self.f * (self.pop[idxs[1]] - self.pop[idxs[2]]), self.lb, self.ub)\n            trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.pop[i])\n            f_trial = func(trial)\n            self.func_evals += 1\n            if f_trial < self.personal_best_fitness[i]:\n                self.pop[i] = trial\n                self.personal_best_fitness[i] = f_trial\n                self.personal_best[i] = trial\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best = trial\n    \n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                self.differential_evolution(func)\n                if self.func_evals < self.budget:\n                    chaotic_pos = self.chaotic_exploration()\n                    f_chaotic = func(chaotic_pos)\n                    self.func_evals += 1\n                    if f_chaotic < self.global_best_fitness:\n                        self.global_best_fitness = f_chaotic\n                        self.global_best = chaotic_pos\n\n        return self.global_best", "name": "HybridQIPSO_SADE_CE", "description": "Hybrid Quantum-Inspired PSO with Self-Adaptive Differential Evolution and Enhanced Exploration using chaotic map for diverse search space navigation.", "configspace": "", "generation": 65, "fitness": 0.21893458210854658, "feedback": "The algorithm HybridQIPSO_SADE_CE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.21.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.5406953934048402, 0.5235846594330575, 0.45626772801482096, 0.4920174473274508, 0.5777888867756238, 0.5570007175514632, 0.5348775493310215, 0.5579852949488148, 0.43565152806788265, 0.1449455569190261, 0.12285809639471823, 0.08098140668350129, 0.19792064278255705, 0.18744795486623633, 0.1506183364113597, 0.07679049792785553, 0.15188328502587556, 0.1567737833728119, 0.12070261003816318, 0.10815125472133824, 0.1009587933179088, 0.11355030720469605, 0.12088996893337922, 0.11831023911787653, 0.13287595208521574, 0.1213005326783686, 0.11799827791345396, 0.09642908550601148, 0.13377859878281906, 0.091844737826964, 0.092780702893693, 0.10309707662708056, 0.08832209884445619, 0.09703469700013378, 0.10635154090579513, 0.11126436808154283, 0.9835006378275758, 0.9850106244348286, 0.9827311829475007, 0.9760491056987866, 0.9833898242155648, 0.9755003426533516, 0.9777783710976361, 0.9831328648976314, 0.9847893734915002, 0.27217042560274163, 0.22090242745409572, 0.2953814674160491, 0.3156968849268744, 0.14563827572345778, 0.25466859590724256, 0.12230636343451429, 0.22039344679991235, 0.32105105988689764, 0.2971918897236324, 0.39564791765332963, 0.2056185337301516, 0.2594019256895701, 0.20051704542299809, 0.1993210804476433, 0.2654796451865704, 0.24231426128770395, 0.22611502825955354, 0.12769450491638146, 0.1413564682548658, 0.13847394908309485, 0.08344727542983388, 0.1449398964370775, 0.13500370451360755, 0.128840050588385, 0.12563280705553315, 0.1387174271074566, 0.1415745650782959, 0.11299925212754713, 0.11770227577600889, 0.15519679568406242, 0.1357308219390181, 0.1790240429227251, 0.15508999223040898, 0.15212553330911993, 0.13620731413294052, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022987479147283607, 0.023540552836962214, 0.12412638364755935, 0.040383810474972415, 0.08609854333814093, 0.03678073239602586, 0.026640448398119188, 0.02810476592291178, 0.049988321019126536, 0.1214706070508983, 0.06576482969359188, 9.999999999998899e-05, 0.016403916597217738, 0.0002611102785951003, 0.07259380387145575, 0.04070167325053331, 0.027689421816948556, 0.03344559384015633, 0.01745457731298139, 0.024557442274743324, 0.08163356288538104, 0.08487305494091124, 0.038079898446158, 0.04970355308774721, 0.03416477362826664, 0.0309920919379727, 0.04645734181341954, 0.04863471804178465, 0.0729864948955179, 0.46911474063524683, 0.45238021242156146, 0.39664956244496674, 0.43699178600281197, 0.4391077891781331, 0.3639785745781873, 0.3826890917113027, 0.4194156202995747, 0.40105942594541344, 0.10065204617397017, 0.10317063315735686, 0.1055472729205087, 0.10686043138249512, 0.10759508382086058, 0.10276525973014106, 0.08424137540232146, 0.09553363728461084, 0.11372223216965871, 0.13202904994808318, 0.2314485533112769, 0.1749725984959286, 0.22231982221928182, 0.17995340346351563, 0.19927660549376325, 0.286794362370867, 0.21830353285567095, 0.19732099936806557, 0.23098654676415786, 0.24815048487671798, 0.2647186745998922, 0.2684468654988371, 0.21797038622569287, 0.29187772419912694, 0.2549259631843518, 0.33339662419603133, 0.28137165793478613, 0.2131069217422571, 0.2347537403615746, 0.21038162786689085, 0.19876534011514158, 0.22429357898494395, 0.20666168149660147, 0.1989794774618805, 0.21265955297243655, 0.21170941159787626, 0.21159850643597355, 0.17563340164514651, 0.1863531912377543, 0.20595302933792037, 0.21301026967829428, 0.19094710706853402, 0.21091276495806044, 0.20404337977181508, 0.19677522026617722, 0.197135238884671, 0.2026782746556144, 0.21428606568263842, 0.1861524407383789, 0.20702227442405308, 0.18235101345566262, 0.23031562824208385, 0.3057811812680884, 0.21474401234981444, 0.8313075651321377, 0.17658328494799103, 0.15287011904550496, 0.7324095007152696, 0.1976515404605469, 0.19556047673216792, 0.13837376115023126, 0.16042367298320037, 0.20529013243723593, 0.35350523122360744, 0.20658514777602555, 0.196532540288602, 0.4143570170859354, 0.3718992123843078, 0.14978761591245182, 0.20610569397836553, 0.15311979391581354, 0.38751901185075377, 0.20107188082763905, 0.1696070481117995, 0.19484175052365693, 0.1877531075846186, 0.1878192705812034, 0.18352480976559005, 0.22908782541104245, 0.20854256865019338, 0.18740110919202457, 0.08456814497025733, 0.07302894394537873, 0.07942012863818071, 0.07638008607516622, 0.09014239141339875, 0.08908831967611786, 0.07582401466212252, 0.08424387383313137, 0.08439579163206035]}, "mutation_prompt": null}
{"id": "56d495f4-7375-4e51-acac-30814df66370", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO_MS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.4\n        self.gamma = 2.5\n        self.inertia_weight = 0.6\n        self.cognitive_weight = 1.7\n        self.social_weight = 1.7\n        self.diversity_threshold = 1e-3\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def diversity_control(self):\n        centroid = np.mean(self.pop, axis=0)\n        diversity = np.mean(np.linalg.norm(self.pop - centroid, axis=1))\n        return diversity > self.diversity_threshold\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n            \n            if not self.diversity_control():\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumPSO_MS", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Multistage Strategy for dynamic balance between exploration and exploitation using particle diversity metrics.", "configspace": "", "generation": 66, "fitness": 0.2791625532375286, "feedback": "The algorithm AdaptiveQuantumPSO_MS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.8200255257337972, 0.7899066146360625, 0.8070494277244086, 0.7512625539716277, 0.720366249248676, 0.728140569201697, 0.7708069270702916, 0.7707293929735209, 0.7017285805943623, 9.999999999998899e-05, 0.504976163618668, 0.3330375015140703, 0.4194664644029925, 0.590067165892325, 0.3447858930909401, 9.999999999998899e-05, 0.44612208846183143, 0.04592349997596756, 0.10508141119876169, 0.14562609389729364, 0.16625472218009585, 0.15660496853803074, 0.1566043806637628, 0.1348627130121991, 0.13735658986896493, 0.1699162213964608, 0.13876413700445667, 0.11051413511485375, 0.1288227278400378, 0.11795980212010526, 0.11737487780942868, 0.1264993718582964, 0.12848445870983882, 0.1285348888250908, 0.15696384425249288, 0.13804457379053003, 0.9886472091688813, 0.9843825883483538, 0.9898048460530576, 0.9895283374386695, 0.9876363611122877, 0.9855307762663503, 0.9895815346987813, 0.9872803921907467, 0.9868525156088583, 0.47967484244466896, 0.4826610102016533, 0.3869343903036876, 0.5117870599102998, 0.38675052641859164, 0.5027444506010272, 0.25120159539175546, 0.40481983573376434, 0.4165203021750693, 0.17101731809358556, 0.45066217660655883, 0.1689269616467176, 0.334861575207555, 0.268107745643958, 0.19094268596767217, 0.1461263562952907, 0.23321657244757144, 0.5243156163844185, 0.18048670637081354, 0.11639005070860764, 0.19583923298977202, 0.18541311366972402, 0.17725615829734453, 0.3491871600218004, 0.18620755821319146, 0.18208381940707918, 0.17600764446614725, 0.19728917563868353, 0.1851618340164547, 0.17946794999553117, 0.12508813203943914, 0.20669614906328726, 0.21272819947875554, 0.21467340007384839, 0.1933597488111931, 0.22907059476385017, 9.999999999998899e-05, 0.007306069331027176, 0.006666841341872676, 0.00425901362129677, 9.999999999998899e-05, 9.999999999998899e-05, 0.00355872170241911, 0.005522804265185033, 9.999999999998899e-05, 0.04789416433764404, 0.04366315419942657, 0.06733877337360683, 0.025114373512875265, 0.04535468670703524, 0.03176226907292434, 0.02996854460648357, 0.0625378092595591, 0.03399877579819344, 0.15174730261142355, 0.024526663255503123, 0.04247648546221372, 0.07592585784716976, 0.08223699748058311, 0.08398851175606104, 0.08570767515343636, 0.11842094000776338, 0.0800173312764878, 0.2609644920441516, 0.041071421273155995, 0.08433439588570768, 0.04828509143814408, 0.07183658376893165, 0.1265346610310104, 0.048560257951843044, 0.08013385303884735, 0.12312674427637882, 0.47551113077347407, 0.5007493098803438, 0.4792583739317937, 0.5384966660617972, 0.538522053143281, 0.505928235926946, 0.5354462379607359, 0.48717517026348867, 0.5375171027611031, 0.1004658588109747, 0.08435990404580151, 0.07301305496262189, 0.12349676569035561, 0.09120513721273493, 0.1060215953704644, 0.1228564020922831, 0.0929922010126738, 0.13014725382119574, 0.16055717865469743, 0.2244371379472273, 0.19901410467928926, 0.23757395865694475, 0.33720046951295946, 0.24012701563620142, 0.38984459097306545, 0.14202048985761484, 0.23929420568767779, 0.416693750919256, 0.41130161223643347, 0.24905054209195854, 0.33671664008122704, 0.24614712477618572, 0.3114977725832725, 0.3965507512661304, 0.40622277014133557, 0.4047673228353841, 0.323164251301271, 0.33777809726305064, 0.27608899282641863, 0.20603433512703506, 0.20361945405895687, 0.2017019084140721, 0.322660898852687, 0.2902552674640637, 0.16200170641111655, 0.23440494087012165, 0.24582482412955453, 0.2007060312567268, 0.1886325791753597, 0.2030086789908102, 0.21327527750634112, 0.22810516463442188, 0.20115656357855205, 0.20418252157598804, 0.19738413694392853, 0.1960797604202854, 0.21653143728623825, 0.584134611904091, 0.28931396791213304, 0.24123955498335314, 0.21252273236123598, 0.20926400025249114, 0.46081454828774693, 0.7915861903992305, 0.16767793316197144, 0.15403025410661975, 0.8764782222904457, 0.20056271194213893, 0.7811850663933948, 0.1421821408275158, 0.1636628760383637, 0.8440080730939757, 0.6904699329306175, 0.21023178472580362, 0.6595022965648798, 0.21227326720152928, 0.41905208295648977, 0.15225625603061765, 0.10453458860455345, 0.10489575963417486, 0.5416010822213788, 0.19402899067395563, 0.1936252373431665, 0.20162755576194868, 0.21213110794716772, 0.1784026987768168, 0.19229505595045182, 0.2142616801606564, 0.19479303829564343, 0.23956413826202339, 0.09392308579725772, 0.09464236168797036, 0.0876227764151084, 0.0839304442400498, 0.09815871557637634, 0.07919570038457313, 0.08001475066112285, 0.09575260907841843, 0.07985688385713585]}, "mutation_prompt": null}
{"id": "31d5ce52-5fa6-4f14-8395-ba26f67eb473", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ImprovedANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 8 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.6\n        self.gamma = 2.1\n        self.inertia_weight = 0.6\n        self.cognitive_weight = 1.6\n        self.social_weight = 1.4\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_ImprovedANM", "description": "Hybrid Quantum-Inspired Particle Swarm with Improved Adaptive Nelder-Mead leveraging dynamic adjustments for enhanced convergence.", "configspace": "", "generation": 67, "fitness": 0.4161904444051052, "feedback": "The algorithm QuantumInspiredPSO_ImprovedANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.37.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9735095277643881, 0.9716878485742736, 0.953392693351536, 0.9639779139454762, 0.17662095631122043, 0.9781206583822968, 0.9743926486380192, 0.9596849819323947, 0.9742051009655442, 0.9089072113559067, 0.8779297731148922, 0.8813116858738577, 0.9128691655000545, 0.888342987016836, 0.9108421075782397, 0.91011518433381, 0.9227937265494215, 9.999999999998899e-05, 0.15054045763405755, 0.07437417707963978, 0.032825773562758176, 0.06539136231631115, 0.05773863077856711, 0.16810418996110943, 0.0467395531097653, 0.06183334319038114, 0.16399434794315126, 0.0714000157011564, 0.0735455381060619, 0.07149619042984179, 0.08796225261405566, 0.09466342376554404, 0.06235992109921429, 0.029713351793330012, 0.08729747812469868, 0.032656098362365604, 0.8854795490187594, 0.991684775124481, 0.8464973613325304, 0.8876808738802133, 0.8450944890814753, 0.8705967519578435, 0.8691789363550144, 0.9226230811980262, 0.9021845811969843, 0.27064891886478903, 0.3895696145864558, 0.37279408759237276, 0.7455991546465235, 0.533653832636209, 0.4369530708235757, 0.08921543639428198, 0.7474901947065857, 0.8093604049569071, 0.212404400888773, 0.21194972295125392, 0.18688368447221582, 0.17573779163066194, 0.1788569809450148, 0.12748560575128998, 0.09738408960673028, 0.10770110548166378, 0.18114852839593054, 0.9520663434111379, 0.9054001584938808, 0.07682825685982864, 0.042003795885616646, 0.9403884357226369, 0.9294638772799048, 0.1387500923575179, 0.13798687855509872, 0.9215515665672974, 0.9338487786800916, 0.1351804119629706, 0.13840933320157744, 0.13863698363553756, 0.12403625335322288, 0.9320855922311441, 0.9459169558100492, 0.1670078975513981, 0.9006096635958646, 0.8884476834901158, 0.8734197773050479, 0.9207053725789619, 0.8846005362368332, 0.9167904756676221, 0.9050267412902202, 0.9036681596119468, 0.3598507830443398, 0.9328468372833364, 0.21068777112406423, 0.8382878323387728, 0.23893311640587667, 0.8819712067769367, 0.7841097879385739, 0.8751111605614452, 0.893780856648488, 0.12959127641082613, 0.8169038265198817, 0.9142541213574573, 0.844347216362743, 0.8525397638073693, 0.8888253685582865, 0.9226091565452557, 0.9286047188023285, 0.8851168676544559, 0.8289851723899591, 0.14483762532910294, 0.18607680742512134, 0.036895565054332335, 0.5610440012018135, 0.04116257811407864, 0.8904547037668453, 0.10978027575158322, 0.15055126017117437, 0.09178682310948283, 0.1014230460416764, 0.9654523672225389, 0.9596024270875383, 0.9656320895836692, 0.38199426819136617, 0.9605836986635832, 0.9574198324068441, 0.9556090078749173, 0.9503226436857741, 0.9638401404088149, 0.08465127714753329, 0.12057015493589696, 0.07452666290134546, 0.0716447350127506, 0.06667567216533699, 0.11432732739675289, 0.11075213129843797, 0.10318492645797417, 0.08480089242151168, 0.1263275671320615, 0.19644429924515983, 0.15492123892108733, 0.12542798312704162, 0.139719337533466, 0.1661765727092417, 0.15089273971397665, 0.1841844828631235, 0.12786306309668016, 0.18721142285437153, 0.133035818560858, 0.21389818734309252, 0.2212696011819063, 0.2134441764840228, 0.16491399099919746, 0.17116832363108736, 0.18525347363728095, 0.1692324694851226, 0.2356727047299122, 0.18644942210401572, 0.1430257650026584, 0.15466498168248577, 0.08924763732405494, 0.2208088421089084, 0.10826423919019579, 0.10852784699456353, 0.18110740503584788, 0.22818149023576018, 0.17989053035554425, 0.16193575205468602, 0.18474926283425397, 0.23399089633906023, 0.26261754272745175, 0.33607873207325667, 0.15479047573470073, 0.2267829344485186, 0.1820163289680351, 0.17287771759239057, 0.16706758720849324, 0.17765909578863026, 0.16402256490989164, 0.1712763944290615, 0.16065484476727232, 0.16674846880055216, 0.17394390573654295, 0.9732345519994844, 0.12721525506714082, 0.15495123713291337, 0.9766547083299109, 0.20147931794957008, 0.20120882349905822, 0.1431783136323378, 0.17026642500454725, 0.16852756444131356, 0.9783241623630372, 0.21361317725462647, 0.9762473734702034, 0.21342158083323925, 0.9803197167929018, 0.15708124560575454, 0.10534902944112601, 0.10505415711022836, 0.9707328879079079, 0.20931666939307703, 0.21729398520374466, 0.22681190544469987, 0.2522207950730291, 0.2202393296968529, 0.19302361197077944, 0.2643770196678027, 0.23036844199987194, 0.20062523945442623, 0.10541168011615376, 0.08542288704476508, 0.04094530873269664, 0.04523008925806937, 0.08008999174321396, 0.06064898942873864, 0.0714154140512091, 0.08194968641486089, 0.07736019734743294]}, "mutation_prompt": null}
{"id": "6d10f2b5-8865-4f30-a7fe-2c43d1307f94", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO_NM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_damp = 0.9\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            # Dynamic Inertia Weight Reduction\n            self.inertia_weight *= self.inertia_damp\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumPSO_NM", "description": "Adaptive Quantum-Inspired PSO with a dynamic Nelder-Mead approach for enhanced local and global search coordination using stochastic inertia.", "configspace": "", "generation": 68, "fitness": 0.46564358743303036, "feedback": "The algorithm AdaptiveQuantumPSO_NM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47 with standard deviation 0.37.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9801782246896628, 0.9773506548549438, 0.9762928330587138, 0.9749614148683319, 0.9760140733414094, 0.9806804527220537, 0.9763228820296073, 0.973828664519824, 0.9749657114106289, 0.8900204402699416, 0.9041991162875707, 0.08185785752540409, 0.906905607579257, 0.8998435773948251, 0.9253211534155724, 0.9190361351727717, 0.9471712097219888, 0.9479916398024998, 0.09912981473996829, 0.08464476238991447, 0.0716002402732463, 0.08474389731424758, 0.09499426898243968, 0.07740776112778947, 0.05665958808963656, 0.09914546116351008, 0.1383567544614147, 0.11347446462915123, 0.0655008442942564, 0.0832310129913032, 0.081648159680346, 0.10836890782096475, 0.036207837209879856, 0.0982816084093121, 0.05966244233299389, 0.07392798933452382, 0.9340770855754124, 0.9693004416352712, 0.899209733098111, 0.9141722675365463, 0.9087894696521318, 0.8717775762632716, 0.9878431360571169, 0.9223637279761758, 0.9032309296709281, 0.24480033238421406, 0.41819130978479147, 0.7128651096922527, 0.49048356180259456, 0.8964995932383478, 0.6262714434453949, 0.8893778658950713, 0.7633470947624388, 0.6938244981983901, 0.259306914896674, 0.18108491945215577, 0.13558940228821792, 0.1541860634539537, 0.19885815098946769, 0.19365550661896824, 0.17673612832440444, 0.11250655435150259, 0.07486500988603673, 0.9519766298290436, 0.8864520304769891, 0.9459968403291767, 0.9204849572505789, 0.13811485570581028, 0.9395331251364439, 0.9594093606995782, 0.13835636534997853, 0.9419884256374067, 0.9481168240134926, 0.947093535556995, 0.9057915790315988, 0.13822171354054302, 0.9452239812195733, 0.8449535983133651, 0.9344294095092491, 0.9494251765925069, 0.9265162422335795, 0.9115193292150991, 0.9242586713461014, 0.8831569683630437, 0.9274711274802225, 0.9066182457528243, 0.9234803582961062, 0.8951848511210314, 0.9019208299584548, 0.860688577862064, 0.1467624553605852, 0.9229114585705916, 0.9067686896138283, 0.8891851521113503, 0.837542132655189, 0.8370278770690066, 0.9240498108060388, 0.8499696355424022, 0.8666904013055153, 0.8688315100595915, 0.8524246986018387, 0.8918533054567284, 0.8852074907255356, 0.934296303463248, 0.8551146785004804, 0.7445997803229446, 0.8867654943046327, 0.9008978891040961, 0.3324512401934675, 0.22342840933956565, 0.12803187099731372, 0.32037217877896107, 0.13004422984480457, 0.3886985769502441, 0.5063431318813971, 0.22726839471473126, 0.9338507016662356, 0.9619369490668273, 0.9678440809284972, 0.9657792022339469, 0.964586715442002, 0.9489891718056624, 0.9670869053261167, 0.9660132678910146, 0.9686843929090798, 0.9510209474911309, 0.09123629211691564, 0.06325696805402281, 0.05644857873434217, 0.1284496075699041, 0.08170702419664955, 0.09874425868484071, 0.10260927806869169, 0.06339245382216818, 0.08807280432175413, 0.3430505786685194, 0.13023561890933777, 0.17631643610194891, 0.1518172875105589, 0.15453588034294585, 0.18245287936089816, 0.1797554602651471, 0.11322518102440793, 0.12181770640097334, 0.1649870864092392, 0.18910055881758858, 0.2343257704247037, 0.25914809756788293, 0.1704852858667889, 0.20411889484584267, 0.21870679340526544, 0.2584331566589919, 0.23885653137733198, 0.17905449628758707, 0.11755284044658454, 0.1401442301064908, 0.13684994796639516, 0.13946159921694212, 0.20651434231421362, 0.16032235414142337, 0.29399663718090074, 0.16691127463940303, 0.2316420074537785, 0.16026217274115295, 0.19207047313945813, 0.23359500065275374, 0.2435288446990076, 0.19664067757253, 0.28208259633529975, 0.1838310084634902, 0.1520545322043032, 0.16741819769189004, 0.18455309424250255, 0.17533126571657454, 0.16020480190314534, 0.18208905786878404, 0.18202757484175813, 0.1527392192899113, 0.16807142642635786, 0.1742588934380176, 0.7022364489786656, 0.12718463603165786, 0.14907469021974795, 0.9813987550443436, 0.20191375647678922, 0.17352712970886208, 0.14330959046480451, 0.16643078043596082, 0.16877252116779984, 0.9837213298861535, 0.21380494030788366, 0.4014219991504919, 0.21286915564006326, 0.16969930013851187, 0.15671357961556864, 0.07140653084673176, 0.10450685429489115, 0.967812388879714, 0.19556877910910564, 0.24883923659728258, 0.223105986784069, 0.20718502233711322, 0.23781427584864145, 0.1674561207880041, 0.20908564731149248, 0.17726419215687095, 0.20103938156455292, 0.11349599876503746, 0.09379338500737322, 0.07523424787335531, 0.06938657384925229, 0.07743013529454323, 0.07811522780526647, 0.10044861739465383, 0.07279876222739767, 0.08379983932839408]}, "mutation_prompt": null}
{"id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 69, "fitness": 0.4661383517357584, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47 with standard deviation 0.38.", "error": "", "parent_id": "b1e46895-4230-435d-87ca-438fc421d366", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "0ce299e3-98af-4277-9887-b6d1ed8ca475", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_DANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.1  # Slightly increased reflection coefficient\n        self.beta = 0.4   # Adjusted contraction coefficient\n        self.gamma = 1.9  # Modified expansion coefficient\n        self.inertia_weight = 0.9  # Initial inertia for wide exploration\n        self.cognitive_weight = 1.7  # Enhanced cognitive component\n        self.social_weight = 1.3  # Reduced social component\n        self.inertia_decay = 0.98  # Slightly increased decay factor\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Elastic inertia adjustment\n        self.inertia_weight = max(0.4, self.inertia_weight * self.inertia_decay)\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_DANM", "description": "Quantum-Inspired Particle Swarm Optimization with Dynamic Adaptive Nelder-Mead and Elastic Inertia Control for enhanced search adaptability and efficiency.", "configspace": "", "generation": 70, "fitness": 0.4119652644529292, "feedback": "The algorithm QuantumInspiredPSO_DANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.36.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9775886698782303, 0.9722826424940825, 0.9657754062794364, 0.9812071857931391, 0.9761863207228121, 0.9741684679765145, 0.9685546840308005, 0.97351820849027, 0.28031752386179154, 0.851354032005035, 0.831584318443169, 0.8345005071759413, 0.8230509486466611, 0.8591522666259521, 0.9072331763994103, 0.8154873677269452, 0.8752654909168055, 0.057344990579694555, 0.07119412546252879, 0.13708473797662646, 0.0713739966892214, 0.044238568428870306, 0.09117538572548378, 0.08141263495790096, 0.08092235665035075, 0.08476434539609567, 0.08178578637548328, 0.06336187301744667, 0.0644571457295644, 0.09230104433365682, 0.06332135026323127, 0.09471158196238849, 0.03352381389862735, 0.11424838846993657, 0.08769919036768603, 0.03349088898592778, 0.9560733766779195, 0.924718850085998, 0.9100325160766555, 0.938765829401643, 0.9582432411955661, 0.9478512052620864, 0.9821148398352815, 0.9568417647208307, 0.9831005425940308, 0.18155888948088672, 0.1824647135155889, 0.5500764973191797, 0.15459796030702744, 0.4661353470822842, 0.35898327136069164, 0.088813386200983, 0.34375295784275695, 0.09339791129309072, 0.1758997766097926, 0.1830545973882476, 0.14149594617861472, 0.08150050551568255, 0.15800407111068582, 0.27999780144471986, 0.0903440694059977, 0.17988813749739507, 0.22819141711519897, 0.13815336659522182, 0.9274533022537987, 0.931710400315431, 0.8505887772333846, 0.9270727518083811, 0.930144538815798, 0.9428561155236345, 0.13814816059853074, 0.9182830850769572, 0.9142539436962634, 0.13815839076543057, 0.13830376579941006, 0.13762968883750015, 0.9622989134596794, 0.13833619002192277, 0.13827591165279407, 0.13735446063761336, 0.9200100848115663, 0.6577692959373623, 0.7732567357160028, 0.8723827351747023, 0.8218184242737345, 0.8269683781684732, 0.894081761480972, 0.6824527545704769, 0.8848529459202172, 0.774171844576399, 0.32090338319256695, 0.8721875418945113, 0.8687612247851575, 0.8567129783377258, 0.13484302906537782, 0.8211422355327961, 0.8447788643355092, 0.8321769081375955, 0.8079998721252624, 0.862310319172152, 0.8046433993540135, 0.8657031727193009, 0.8990201877579385, 0.8789003341933621, 0.8250935617601358, 0.8621433653434639, 0.8663866954479167, 0.9346901948021881, 0.1551416381187557, 0.22520286001689893, 0.3032973241342555, 0.07994805066824207, 0.01530595252023903, 0.03928124889594309, 0.22084429165204045, 0.10209632737330854, 0.11435765670514242, 0.9491551752738886, 0.9323760281237379, 0.9488165165090094, 0.9519898673046416, 0.9344206530209175, 0.9539351915748611, 0.9560204721169625, 0.9344869686298516, 0.9700358252675145, 0.09389115289989913, 0.03556224574808753, 0.09476638893125, 0.09880766669531238, 0.08402364997024381, 0.10344980439446139, 0.0651248485735878, 0.09495447052813144, 0.1461606727669188, 0.11004722177081716, 0.2328417258097466, 0.15428792758160037, 0.15856751072900666, 0.1700121471164382, 0.17091178733288093, 0.178165736847133, 0.12295877275237066, 0.12701486999120148, 0.17572494583223308, 0.16697080117342467, 0.21441110779759687, 0.18189510539615927, 0.24680113451221208, 0.17764556057577086, 0.2455874276540092, 0.2295441923385122, 0.21509595973768603, 0.23849732535934431, 0.17326060109561914, 0.20215411156997642, 0.13986000306497337, 0.1653321201242146, 0.1069414797134206, 0.14107343898899039, 0.27203051736301054, 0.15127504328936736, 0.2023038713638412, 0.15668343134366236, 0.16143700578972497, 0.2329070178034368, 0.2265698123073575, 0.2603013925123612, 0.23756683620514252, 0.16453610266686014, 0.2099987830898583, 0.20502900336469454, 0.18454870943020174, 0.17261665474437105, 0.16884783652368063, 0.17077237637271958, 0.1747415630637208, 0.15590784921566903, 0.17775170199218415, 0.1761505798712878, 0.9805642080640159, 0.12718155315223956, 0.08884825533535046, 0.1734645854880904, 0.20195861499039758, 0.1636304226953771, 0.14348037597550434, 0.1660876410374249, 0.976964684211745, 0.9806512431771842, 0.21446998248915905, 0.07290123820341998, 0.21271557598602253, 0.16938777710771336, 0.15695310052527944, 0.9684709884479265, 0.10531372668744132, 0.98156154537448, 0.17309997059291615, 0.1381992846735216, 0.18309900137827095, 0.17630800093435572, 0.29108769351780384, 0.21760240152126276, 0.20760164943934722, 0.2926212979902575, 0.21006534679091027, 0.07886147257520115, 0.10960286107134976, 0.10137454207288232, 0.14145038087265205, 0.09995577633444352, 0.046381812172928805, 0.10017402328875613, 0.06385705753816895, 0.07079414159111963]}, "mutation_prompt": null}
{"id": "84dd3b83-9385-463f-921f-17d48da24f09", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ANM_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.5  # slight increase for more aggressive expansion\n        self.inertia_weight = 0.85  # start with slightly reduced inertia for faster convergence\n        self.cognitive_weight = 1.2  # reduced cognitive weight for better global search\n        self.social_weight = 1.8  # increased social weight for enhanced global attraction\n        self.inertia_decay = 0.98  # slightly increased decay factor for more dynamic convergence\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_ANM_Enhanced", "description": "Quantum-Inspired PSO with Adaptive Nelder-Mead and Dynamic Inertia using enhanced social-cognitive balance for robust optimization.", "configspace": "", "generation": 71, "fitness": 0.43442683993546016, "feedback": "The algorithm QuantumInspiredPSO_ANM_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.37.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.975052985443958, 0.9726918154477822, 0.9742863393054981, 0.9740605571279837, 0.9747858158279509, 0.9702441965079368, 0.1759547283315267, 0.9818155435705427, 0.370148052597306, 0.868515684083185, 0.9334403931934875, 0.7654450526960219, 0.9158457133901464, 0.9459028017591785, 0.30192405602313543, 0.8540188856729958, 0.9103542779267985, 0.902096009288806, 0.09839385720814275, 0.0990710350687748, 0.09464317016099266, 0.19614733033992016, 0.09899040093114508, 0.08765308161036023, 0.16739786532912682, 0.11368871252972801, 0.12875674051066943, 0.09471865874100782, 0.06303763880702296, 0.0984600602018012, 0.09109248098255307, 0.08755101463728554, 0.05187840272196953, 0.16514671918066104, 0.07380811021050393, 0.06512900418011125, 0.9885766658925137, 0.9614256014555256, 0.9473490645365161, 0.9861898163462749, 0.907190693320075, 0.8817583701634344, 0.9885251533256916, 0.9381432276327772, 0.9855167226510928, 0.657003061365317, 0.6645467472746797, 0.7571933050941556, 0.5808279227815374, 0.5896818329681122, 0.18149783422790555, 0.5611067950410427, 0.6662437542956872, 0.524420792221866, 0.14318133233034003, 0.16301312269129797, 0.11563388689846466, 0.23401857806014914, 0.16983213133504882, 0.15215180344630297, 0.08265464837620384, 0.11804338438278106, 0.05926441877555355, 0.9602410412294168, 0.13737563427481858, 0.13771630771824528, 0.13794341113323605, 0.9523726291550821, 0.937522452339367, 0.9451495152549889, 0.13831760434968454, 0.9264068172111828, 0.951544148939061, 0.1374829025999239, 0.9314995448876913, 0.138088146710155, 0.9490493085946138, 0.940988572974045, 0.1492553039030392, 0.9484963254798116, 0.9309000910598642, 0.884635726368339, 0.9398108851419992, 0.7608205150523796, 0.885294422665542, 0.8958396095637136, 0.9367211436701013, 0.8668946561691868, 0.8533372657177287, 0.9019642140792199, 0.8870624361804993, 0.155387681242094, 0.8047511592894583, 0.8733887856155647, 0.8307168774170768, 0.8137691410466712, 0.8569946400272292, 0.8501064578403424, 0.06350081817659503, 0.9158682445117321, 0.8070361652206907, 0.9229614374947914, 0.9380884112557138, 0.8946050339710686, 0.9322991025225196, 0.22316214535862566, 0.8516517476884856, 0.8986312886979507, 0.19296076836887555, 0.04730672448169171, 0.14000250267399827, 0.11494605730650198, 0.15129566408294992, 0.946763082441679, 0.6562261436177841, 0.8432436049075713, 0.3137023133774759, 0.9610280674847036, 0.9672108536757299, 0.9621950421043108, 0.9620552198161422, 0.956912997498638, 0.9670940897501883, 0.969257869048002, 0.9710367494442961, 0.9623121797400837, 0.12089036330274339, 0.07628209329940328, 0.08210242603815754, 0.09816168584692042, 0.12088382749173998, 0.07919999092354446, 0.07368207335897747, 0.10944736378291142, 0.10374586337458147, 0.15507092196404848, 0.23883604965556082, 0.17159695889890814, 0.19574225293386482, 0.2957025911090513, 0.22053587912223915, 0.18086222015544573, 0.10530607273289916, 0.11505282874411005, 0.2132883172925546, 0.17438966340473538, 0.2245705106681627, 0.1981044194452436, 0.18484906612883645, 0.17311571854420948, 0.1903950903673316, 0.26085819328562543, 0.24674286122577682, 0.1878685943393058, 0.07038740187968706, 0.13661246107319347, 0.11020588903870088, 0.11109590354490573, 0.10866884191137416, 0.15308679373396394, 0.16515048967214574, 0.13750721253152842, 0.25941233245069983, 0.1408107931996394, 0.14831132983243056, 0.2155061296118086, 0.17060543650636517, 0.17585639615238813, 0.215119707188267, 0.15680149763842655, 0.24418483395709678, 0.17380110776346192, 0.15723149600166253, 0.17421755848919707, 0.17493364072837903, 0.16919825705393154, 0.1847642113202489, 0.1673664373419429, 0.1739601249434547, 0.18837702843703308, 0.10559947761036381, 0.12723516154342507, 0.15458754758334037, 0.9826204515185099, 0.20203210924864312, 0.1702380721589971, 0.14340531066340167, 0.16628217031070125, 0.169146481701957, 0.9822407148206703, 0.21438772005185103, 0.7951334129890326, 0.21430236186656115, 0.16951764673295278, 0.157446276684582, 0.08116387150665338, 0.1051645184636173, 0.9466557703321703, 0.2086337133324725, 0.20065988322404504, 0.2680083849974032, 0.20906797562506663, 0.17230430156210919, 0.17860583225468163, 0.21879503504215914, 0.19171090412902858, 0.20584539141843428, 0.08926685810835311, 0.05796984791662074, 0.07344292020985721, 0.07116395870805514, 0.0823446902375583, 0.06098722457483219, 0.06388512213886788, 0.0700648641487247, 0.1174866751483542]}, "mutation_prompt": null}
{"id": "67878b11-e691-4a0a-abb2-699d1c26a0e6", "solution": "import numpy as np\n\nclass AdvancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim  # Increased population size for diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))  # Narrower initial velocity range\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Adjusted reflection coefficient\n        self.beta = 0.4  # Reduced contraction coefficient\n        self.gamma = 2.2  # Increased expansion coefficient\n        self.inertia_weight = 0.85  # Slightly lower inertia to balance exploration and exploitation\n        self.cognitive_weight = 2.0  # Increased emphasis on individual learning\n        self.social_weight = 1.2  # Slightly lower social influence\n        self.inertia_decay = 0.97  # Faster decay for quicker convergence\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdvancedQuantumInspiredPSO_ANM", "description": "Advanced Quantum-Inspired PSO with Nelder-Mead and Adaptive Dynamic Inertia for Enhanced Convergence.", "configspace": "", "generation": 72, "fitness": 0.3015264064749739, "feedback": "The algorithm AdvancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.29.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.8775647875631976, 0.9605653945693943, 0.9558776442103742, 0.9535867683303196, 0.9666177172462844, 0.9538822199341405, 0.9590202923965669, 0.1725830612122996, 0.9127834419895005, 0.04543559491271776, 0.6040475184082353, 0.3425680427905462, 9.999999999998899e-05, 0.5996548577542846, 0.20586318209525478, 9.999999999998899e-05, 0.36931007129831095, 0.08476476915215081, 0.1272780716479872, 0.06752491590093235, 0.12041251861578606, 0.07888646414415257, 0.08743502052518615, 0.09507971016138272, 0.06964699419528275, 0.09790928336624583, 0.11983555242814492, 0.06786616934190681, 0.0547967958579364, 0.056406880616845734, 0.09484128631347866, 0.06317852403650392, 0.07599476186060494, 0.09303939534065064, 0.10338322253028287, 0.06309951875971342, 0.9523737961636212, 0.9701055098720892, 0.9644630873423811, 0.9856000157027345, 0.9342419091357019, 0.9856983612239203, 0.9855680579843598, 0.943780199255449, 0.9586240524687181, 0.11686838759882956, 0.21441269847193412, 0.18044375107668675, 0.22920990395216534, 0.1832594045228455, 0.23320975185273862, 0.15202796358295456, 0.11760916903224372, 0.09273652204922578, 0.1786192099023186, 0.17526987943504158, 0.17646952170356311, 0.2234539269002933, 0.18844580907827735, 0.1684700392206756, 0.07470330791732227, 0.10869586105089679, 0.15487856824241752, 0.1371998904446573, 0.13386884253375397, 0.21222492861117181, 0.8112459137125912, 0.9131793612438108, 9.999999999998899e-05, 0.1966565837340808, 0.7635649568423851, 0.813101350360366, 0.1365429383950275, 0.13075412674016718, 0.13580996254247946, 0.06185200752765596, 0.9265599212428817, 0.23176911899815833, 0.1373932900484759, 0.008122075297433917, 0.8042484355989856, 0.205104612094145, 0.04339880058513512, 0.2160462641653289, 0.3464351414651805, 0.18339407971854194, 0.0753295395538296, 0.12257456575476156, 0.090882450003265, 0.0902020381387314, 0.09990997697413517, 0.09570817065186088, 0.6525923144328912, 0.18300178711767467, 0.4571148008065343, 0.580466059262822, 0.09900801283105576, 0.4658127908216929, 0.6713167620065621, 0.27375166747027446, 0.09733305116713853, 0.7509628500340813, 0.8123597787662358, 0.2793381657600723, 0.6549889355144971, 0.5952486431959918, 0.5182406248747353, 0.8039943444615149, 0.09507395025947973, 0.14590998047606574, 0.21307927007123206, 0.22541171184855835, 0.2594794692785156, 0.21959696611678559, 0.1619298269314764, 0.11715361125794332, 0.11640926358128911, 0.33249674111318384, 0.8588748385485789, 0.8927291561444408, 0.33871179412882313, 0.9238739227259084, 0.8899355864615583, 0.39629534275910305, 0.21275863928166172, 0.9741942705543541, 0.08969878870478332, 0.08392754826399684, 0.11369999406924669, 0.06529536156632076, 0.05189634030959711, 0.08771713102294088, 0.07202882160082502, 0.19294340920391484, 0.08188035865051402, 0.10297395702576817, 0.2079529601845983, 0.1683361975704194, 0.16000846934880397, 0.2084658144431395, 0.17446260975816474, 0.14327086391216526, 0.11423142319486723, 0.20868101089367186, 0.21802314285033075, 0.19169922143798945, 0.21915616973108865, 0.17743520824155823, 0.21917918491891286, 0.1759363791463895, 0.18828202065337696, 0.19744675233703823, 0.20018602070723823, 0.11217057498978988, 0.11450975619380788, 0.1849825529737812, 0.18351004382721614, 0.12596594964132457, 0.12314266718508604, 0.2313184650717871, 0.14126765158657695, 0.09861357546233918, 0.2924622060544225, 0.22018796930989415, 0.2084211275350637, 0.29540637687166926, 0.23617017694811315, 0.18905090187546714, 0.19600938952245062, 0.17846540324222293, 0.20991695537020383, 0.163964482675227, 0.1867721179998575, 0.15796076376316126, 0.19008553966557862, 0.21522989406693127, 0.16404464086449044, 0.17380597954621446, 0.17468140373559238, 0.1488356725897897, 0.6333300769967118, 0.18924164515432906, 0.1690013623051203, 0.1736605457726309, 0.18899530757564365, 0.16878115022635598, 0.14285884258723913, 0.1649482182627502, 0.9559257573713421, 0.9566481300010287, 0.21392620668798312, 0.21272472381220597, 0.4367635997407546, 0.16959622060656054, 0.1571140445580651, 0.10514845757199387, 0.9742980265837282, 0.9591170807916288, 0.20763433292635214, 0.17092420362539107, 0.20444411176722244, 0.18048104789828634, 0.18086517074096697, 0.20905179703418575, 0.2523502270258555, 0.1636678658477062, 0.22340017824350045, 0.10240592799382997, 0.06949385019105336, 0.07484018744289189, 0.05883135469249101, 0.1125124555853112, 0.09322140853820071, 0.0783006001364418, 0.12121753614951636, 0.07941136054563891]}, "mutation_prompt": null}
{"id": "469ccbad-c554-4161-a71a-0a9bee277edb", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "43bf3828-cf2f-405c-9c3e-acd761087f9e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "b058137c-38d8-48e8-9edf-aee3c923da4e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "1b37c84a-5607-42c4-90b7-69ff0a5de6fa", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_LayeredANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2\n        self.beta = 0.4\n        self.gamma = 2.5\n        self.inertia_weight = 0.8\n        self.cognitive_weight = 1.7\n        self.social_weight = 1.3\n        self.inertia_decay = 0.98\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        elite_group = int(0.1 * self.pop_size)\n        \n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_indices = np.argsort(self.personal_best_fitness)[:elite_group]\n                simplex = np.array([self.personal_best[idx] for idx in best_indices])\n                simplex_fitness = np.array([self.personal_best_fitness[idx] for idx in best_indices])\n                \n                while self.func_evals < self.budget and len(simplex) > 1:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                best_particle_idx = best_indices[best_simplex_idx]\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_particle_idx]:\n                    self.personal_best[best_particle_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_particle_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumInspiredPSO_LayeredANM", "description": "Quantum-Inspired PSO with Layered Adaptive Nelder-Mead using dynamic inertia scheduling and elite preservation for robust convergence.", "configspace": "", "generation": 76, "fitness": 0.3379771503454135, "feedback": "The algorithm QuantumInspiredPSO_LayeredANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.31.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9660393330266521, 0.9711824785054844, 0.9738690183787844, 0.9570141190913495, 0.9462021036939312, 0.9788932076556219, 0.9673719252658052, 0.9665723597177185, 0.9692217749817914, 0.25596933671448807, 0.05177051350680395, 0.13808978452954357, 0.9475897634969541, 0.21592415613826044, 0.28253966080993265, 0.4117105633816963, 0.13217558848318245, 0.6255406282677823, 0.10929392648075587, 0.10335890866895059, 0.07174554245157416, 0.1251966345909603, 0.11011887060474679, 0.11413921983999376, 0.11442540524030864, 0.06930024776991561, 0.11205680848606914, 0.05973020342591917, 0.04644536497266094, 0.059555332535631944, 0.0846976437598087, 0.03945149221397948, 0.033259342466106734, 0.09120998869944796, 0.1285261985988283, 0.054532674735195186, 0.9174293010647961, 0.9128366104192436, 0.9410915190792315, 0.9308933331363988, 0.9595337677964986, 0.9040518499596938, 0.8933486594490224, 0.9220574269706173, 0.9475281437618519, 0.3217177421382723, 0.1809687874305218, 0.14725181442154334, 0.14793367717795414, 0.11199169010427301, 0.3978359545014226, 0.11113328839794245, 0.27799746781203727, 0.22151844360402384, 0.13046300640151298, 0.18841790088351518, 0.21720768397953283, 0.22709572211567264, 0.23668304084635872, 0.16029572951961202, 0.09162400514555136, 0.1666346824597149, 0.17843592437120426, 0.136549227740284, 0.7907116941035353, 0.6621788496189241, 0.8278870173574479, 0.13844009438408444, 0.8875548590532407, 0.860223822161148, 0.1682679963255319, 0.8540250040307219, 0.9062347559501275, 0.8283338286679068, 0.7875093547035443, 0.8787016324929019, 0.7838668427549939, 0.7062916756980666, 0.13837178996283472, 0.7498040325037666, 0.7067048384039603, 0.32458236722897305, 0.21401280342014384, 0.13644716973776938, 0.09044694616569737, 0.08766085238364452, 0.1632558393832071, 0.34174937665441163, 0.10611842253295978, 0.2367528747156773, 0.31652046059882755, 0.23436522630076895, 0.1546138923138768, 0.3115183597332971, 0.6272792191699785, 0.18869562809699902, 0.1359658217657843, 0.2223132881987191, 0.46003974694156113, 0.666404869763261, 0.3274031170966011, 0.666187645280858, 0.6139439841612602, 0.1851248238922053, 0.5827762278941355, 0.43720864082156863, 0.4589179931359252, 0.4309034464735223, 0.19885761393535673, 0.23145148361941426, 0.11935504351767756, 0.15195769244367474, 0.12885995730093125, 0.18826212238054496, 0.08905209295291239, 0.0993799641857539, 0.08661747174223888, 0.9137528403629028, 0.9370900281602603, 0.9241747014889139, 0.9107198308235589, 0.9242637589747748, 0.8286691595098773, 0.8712001011527266, 0.7450994578018302, 0.8576026613110415, 0.08780991513785774, 0.10845634795138326, 0.11418014164134038, 0.06742580015601085, 0.07627040500834936, 0.12025128456363532, 0.1285432992393215, 0.12041281823683636, 0.08755793195980222, 0.11062763410270349, 0.22106015408133117, 0.18154696312753504, 0.1714127573175157, 0.3000250232327657, 0.23498398303319512, 0.25122515288157643, 0.13718511917312903, 0.09253212359055196, 0.13415250519780964, 0.2073394880019347, 0.2764783289467201, 0.20478114340881015, 0.18991059048399006, 0.14248437010333836, 0.21994807887082257, 0.2378442368645013, 0.24822929768698787, 0.21175344233653726, 0.17114067783017706, 0.23887896861080227, 0.1479016296501866, 0.10835167891056974, 0.2020725421780628, 0.18624117584341815, 0.16425634593993743, 0.1655587767055089, 0.186092491444817, 0.20540012071150493, 0.2099507035448337, 0.18892065407042058, 0.1909528294818823, 0.19038361233155487, 0.22396356624897096, 0.17975377176422502, 0.24767957144817287, 0.164091170793343, 0.17765618541880868, 0.19263377694542116, 0.17443548768477868, 0.17452182102029323, 0.15535316298056967, 0.18443117991603453, 0.1726965849653963, 0.18807251598150165, 0.805992088033443, 0.18925898254609785, 0.1692955304461502, 0.1734235410355477, 0.20171815845772112, 0.17027351795500578, 0.14324818659808047, 0.1658364720065365, 0.9805884679074234, 0.958327548311769, 0.21373300036204856, 0.2032612076508069, 0.21402385546824532, 0.1695669818046177, 0.1572924970622802, 0.10523249173035487, 0.09481611719856486, 0.9822428092023665, 0.222079261703782, 0.227972988401429, 0.18630848204599804, 0.1923399574244553, 0.16129431742715372, 0.22589286942152398, 0.20185559437353084, 0.21649031290190057, 0.19664631848593783, 0.08240681476268896, 0.08415256861357867, 0.10655102156221552, 0.08599741827074214, 0.08169040890209467, 0.06818370590013278, 0.10451086416013455, 0.07186693273102351, 0.0449442094127428]}, "mutation_prompt": null}
{"id": "3f9d3825-19f8-4c89-bbb1-0f62522bedf7", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "db82d70a-f303-4bec-bdb9-cc35dcf5012b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "df762bdf-1311-4a93-8296-ddcc5e82c381", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "ef8ea6eb-dc46-4ea3-a350-3d544094485d", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "f6ccf7fb-96d8-42df-8cc2-b726205dfe05", "solution": "import numpy as np\n\nclass QuantumEnhancedPSO_RANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim  # Slightly increased population for diversity\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Enhanced reflection coefficient\n        self.beta = 0.4  # Reduced contraction coefficient\n        self.gamma = 2.2  # Enhanced expansion coefficient\n        self.inertia_weight = 0.85  # Slightly reduced initial inertia for balance\n        self.cognitive_weight = 1.4  # Adjusted cognitive component\n        self.social_weight = 1.6  # Adjusted social component\n        self.inertia_decay = 0.98  # Adjusted decay factor for smoother inertia reduction\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Adjust inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumEnhancedPSO_RANM", "description": "Quantum-Enahnced Particle Swarm Optimization with Reinforced Adaptive Nelder-Mead using dynamic inertia scaling for optimal exploration-exploitation.", "configspace": "", "generation": 81, "fitness": 0.2908359732263964, "feedback": "The algorithm QuantumEnhancedPSO_RANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.28.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.25301969751516973, 0.9693056985311856, 0.9012924022155123, 0.19106545420540555, 0.2475098054623981, 0.9569222123829999, 0.9481117740152575, 0.35569976148625093, 0.9621113945203728, 0.11275927056334989, 0.19482939499628005, 0.44615666255297315, 0.5448656486676411, 0.41050217768626185, 0.5214741951768014, 9.999999999998899e-05, 0.4725533141973083, 0.3856138423948834, 0.12610328683400074, 0.07883147569949811, 0.037572440676141405, 0.06481037296953795, 0.045455011951606505, 0.080980151392397, 0.07121990680078083, 0.1093968938453076, 0.13783655407739537, 0.10762749950809525, 0.049520625847962574, 0.12759189136858806, 0.05050207770471482, 0.09288375806517202, 0.09470979215368347, 0.08729041561638728, 0.07223887919868299, 0.0295999651701635, 0.9211373179165327, 0.978279669460511, 0.9575216651643357, 0.9421743305812482, 0.9582150206223665, 0.9589876520601243, 0.9823808542712855, 0.9872913663552957, 0.9607094797238964, 0.36859775763876046, 0.1850145926863418, 0.20961239738685977, 0.158118244011358, 0.20654688886849548, 0.20912911824463964, 0.3047670998304649, 0.23106484349233192, 0.08930963453094376, 0.21275767412277546, 0.21707217386230782, 0.21162222163050814, 0.13672811690629183, 0.16056932156870152, 0.11458669220701978, 0.07370300471771885, 0.2928294952344681, 0.14216657594794246, 0.7760871589535834, 0.1351702323232099, 0.755751015395639, 0.12765299174980194, 0.13710206962780436, 0.1342398968226538, 0.13629945524055587, 0.8726170012757175, 0.8546312452315823, 0.0027415571753012236, 0.8237636102646653, 0.9008363945644469, 0.2161710477022396, 0.8452520630732565, 0.8858025415317046, 0.1353902700924704, 0.9403197307073982, 0.8414787475037231, 0.16234156217062212, 0.10590557932561229, 0.5756105242140706, 0.07039119022386697, 0.33158766084321145, 0.04578616815577263, 0.06562686363352044, 0.09861510767887216, 0.012851625160320013, 0.4996000599538576, 0.16720597773795998, 0.26299276159909246, 0.07030011286133309, 0.5437209991691119, 0.09967002798140334, 0.2408414746784061, 0.5039739847272962, 0.6704201649944328, 0.6689763949810169, 0.6108655961721599, 0.05627581382880831, 0.1260237176596838, 0.3810439957704146, 0.6958650802597283, 0.6935594320803589, 0.5104460117375009, 0.5011284894210553, 0.3253954006719788, 0.056385625675757334, 0.06572315792180794, 0.035908541017732776, 0.054600221923094105, 0.007064300820000979, 0.17240827856810736, 0.3484936189938541, 0.0940352995235626, 0.21902511562271476, 0.9002115861243697, 0.9437223053661309, 0.2549378499744548, 0.9260009616681448, 0.8070564783771201, 0.5298751103966393, 0.9201161452525984, 0.60798695983102, 0.08305242656012946, 0.07361654890418434, 0.0709623786971948, 0.08840904608165545, 0.09863418208603958, 0.08104073574172543, 0.1299578888647953, 0.04411366554273721, 0.09864861941840919, 0.16777922181212945, 0.10109831227540111, 0.14027081132760655, 0.22925679986542513, 0.19891352060035128, 0.17040574710993983, 0.16422008263226384, 0.16170391995781408, 0.1122835033562084, 0.19375458352011377, 0.14267082953548105, 0.1769364257681798, 0.1850212504021841, 0.28270401473816986, 0.15927828031418445, 0.2819796855731528, 0.22130235535472942, 0.1824839314122534, 0.10406869212759151, 0.10679919314242192, 0.17040363680848236, 0.1776485395249522, 0.13419608479445289, 0.13006948485539482, 0.14225758847175896, 0.11380524226363653, 0.11202259421170657, 0.16143497219083525, 0.16973211132053712, 0.1482909481392095, 0.14896340626301385, 0.19177034735957965, 0.1905392984682046, 0.2198363550534851, 0.1917892701093571, 0.2643462890732976, 0.1702937480915664, 0.17127244489651672, 0.17832121113310329, 0.168922566827308, 0.17304068154467056, 0.16331678233849944, 0.16166367000274007, 0.17068471618804504, 0.16464400108522337, 0.13535661696329682, 0.15190849498205006, 0.18934534091972077, 0.17267604249153123, 0.2001077823944606, 0.11713633128965562, 0.1432801808220634, 0.14388128778001263, 0.9754292297270568, 0.3497111551200657, 0.2138741822415252, 0.07361251463315455, 0.1643499861639961, 0.169697461104779, 0.15583663299428807, 0.10526388588531876, 0.10510372696933445, 0.1684019889517302, 0.22005287130780538, 0.1952641057531549, 0.22425626290617695, 0.2300031299658214, 0.1603452093796668, 0.15326445998782856, 0.27523649847983966, 0.179552404028829, 0.20634758201851822, 0.08273843132679959, 0.07676872393731249, 0.0656006098575308, 0.09157183746977904, 0.09632814915943111, 0.06466803247195307, 0.08462895887400956, 0.08619413036801993, 0.08130605595904694]}, "mutation_prompt": null}
{"id": "52ce5f1a-fea5-44e7-ac06-2beca3ab340c", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99\n        self.adaptive_factor = 0.05  # Introduce an adaptive factor\n\n    def adapt_learning_coefficients(self):\n        diversity = np.std(self.pop, axis=0).mean()\n        self.cognitive_weight = max(0.5, 1.5 - self.adaptive_factor * diversity)\n        self.social_weight = min(2.0, 1.5 + self.adaptive_factor * diversity)\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            self.adapt_learning_coefficients()\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM_Adaptive", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and adaptive learning coefficients for improved search efficiency.", "configspace": "", "generation": 82, "fitness": 0.44502560791294754, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9756239072985183, 0.9771808384203036, 0.9700645645889633, 0.9690634017908462, 0.9760290280069905, 0.9802178783882217, 0.9703749896282526, 0.9775296191015368, 0.9716401627230686, 0.9230095358738316, 0.9338476634745103, 0.8402207851828513, 0.9224837311207602, 0.9177001277496081, 0.8971494566877672, 0.9295992556760168, 0.9136531211212595, 0.9417018620193813, 0.0792903312888642, 0.06537213389122642, 0.08482934370558437, 0.06750547468265011, 0.08452300849927652, 0.05808253381443251, 0.09895263517764563, 0.12084661295782317, 0.10633663268553295, 0.06732079144740422, 0.07128383016610917, 0.06150109968561013, 0.07894109202857147, 0.07150488347830708, 0.06913523374559505, 0.10844331114036665, 0.06501222817557695, 0.08460018151841342, 0.9888817760532828, 0.97354408163711, 0.9158263922959816, 0.9682629187792089, 0.9197925203030047, 0.9184001565280681, 0.9494881398937843, 0.9389813946810369, 0.9112221629796101, 0.6028415526806574, 0.37570652371776614, 0.575267712490103, 0.41167257433611215, 0.6665681316162373, 0.7985701460414757, 0.8414626437275777, 0.5755999463815551, 0.4807249070693511, 0.21286823235234265, 0.17373598096534026, 0.13582607672353975, 0.18033048306817145, 0.12868316229818777, 0.39503640830854614, 0.08594958690964649, 0.11249226517380861, 0.04751969600614159, 0.13781682075292634, 0.9116553283218294, 0.9384662995161643, 0.13825950541131682, 0.13676637795443625, 0.19985277904761045, 0.9484271251594575, 0.13834139747606045, 0.9340463992852899, 0.9522753267759655, 0.9513121525487036, 0.9546605300720119, 0.9244071357402386, 0.9319611017787884, 0.943862795524295, 0.13836364417943914, 0.9657827949961071, 0.13710066349210914, 0.9057526142052476, 0.6309552919612218, 0.8490851370549553, 0.09063763255007729, 0.09001214671089564, 0.9155417626069029, 0.8732081325756599, 0.9257879247016756, 0.9137788644994093, 0.9091957976098997, 0.3616412231804026, 0.8949758069016497, 0.8647711617687514, 0.8811986488582647, 0.8854418943692, 0.870842714179524, 0.08531001355808165, 0.8771334281508322, 0.9004681118997105, 0.8481118364804798, 0.9283671730664053, 0.9364411838545545, 0.9332738955142907, 0.9372353048158902, 0.25248130508818434, 0.8619225967751113, 0.8546871666580192, 0.32378431038630173, 0.6766680677116061, 0.06857970770759025, 0.026549664095731118, 0.09375967892457016, 0.6373119251493331, 0.05981348597191505, 9.999999999998899e-05, 0.2904152170743388, 0.9668709654261252, 0.9683361146468459, 0.9546061798365589, 0.9490485264610218, 0.9660490320366973, 0.9615045647063434, 0.9636982740957319, 0.9721142488950866, 0.9737561507716419, 0.12084382764212132, 0.12059616900806136, 0.16753585641447566, 0.0912950182215796, 0.0985195777889859, 0.08780714119990551, 0.06441428519476411, 0.08169665907360724, 0.13694555563307953, 0.10854793488662107, 0.16805144361785118, 0.1403304469061435, 0.12448663653791159, 0.3250854144807951, 0.19576997075483304, 0.26317183020021373, 0.14843882821934218, 0.12594564164574018, 0.17203493492765864, 0.21149812334081086, 0.22585102873371798, 0.25175094556035515, 0.19798108905309308, 0.12926837266950642, 0.21884663581768926, 0.2157273540683149, 0.22757190215877177, 0.1560119732283367, 0.17934442448429622, 0.1801672045017556, 0.14892955084445747, 0.12591025910964238, 0.16010099255890797, 0.145652145138079, 0.16899389005671672, 0.19975695354385248, 0.24351787441074635, 0.1417163754432642, 0.2576837052812361, 0.17931523249195647, 0.2756883633713413, 0.16144793826634507, 0.2696707910844103, 0.2032403910978634, 0.2688906451466623, 0.18311690047912987, 0.15362699561269888, 0.15835078518704226, 0.16681481789998653, 0.1693895678706614, 0.16263381723415637, 0.15310581442924742, 0.20030988936523475, 0.1539023490138155, 0.9818231264639834, 0.1272476347479976, 0.15449025260036464, 0.9719841631861188, 0.20196068082863694, 0.1703534883243767, 0.143341259020223, 0.15593904536865755, 0.969495754887724, 0.9796401868547305, 0.21437481354260213, 0.9748530065522594, 0.2135476998681074, 0.16940327277386547, 0.15721787395911357, 0.08426171974858698, 0.10527068332851974, 0.9676796955163186, 0.24833098194330805, 0.18424274403621443, 0.24114530887944563, 0.22305544985425851, 0.29498855771575416, 0.17577596187660005, 0.19390077510682924, 0.2365028630753534, 0.2644722509026244, 0.08166478645650421, 0.06500881946427128, 0.11647066657569172, 0.07074675701265243, 0.07348491646612476, 0.06551407360665218, 0.07660795656039432, 0.07069914829875801, 0.08232274140043805]}, "mutation_prompt": null}
{"id": "78487c7c-9998-43bc-b0dd-89c835110848", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO_DNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.5  # Slightly increased gamma for enhanced exploration\n        self.inertia_weight = 0.85  # Reduced inertia for moderate exploration\n        self.cognitive_weight = 1.8  # Increased cognitive weight for better local search\n        self.social_weight = 1.5\n        self.inertia_decay = 0.98  # Slightly faster decay for quicker convergence\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO_DNM", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Dynamic Nelder-Mead and Stochastic Velocity Update.", "configspace": "", "generation": 83, "fitness": 0.4449510480088539, "feedback": "The algorithm AdaptiveQuantumInspiredPSO_DNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.37.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9780749637499636, 0.9741779482059605, 0.9761435193965938, 0.9788394832955948, 0.9786260284401076, 0.9762216942919767, 0.9671295525853214, 0.980484148839474, 0.22068894635891512, 0.9184115225528502, 0.9526466767490256, 0.04503808858406322, 0.9141771243795525, 0.9134168575052615, 0.9345424214615865, 0.0633378846151873, 0.9370973195113219, 0.8420382955767, 0.10846841864056156, 0.09140427306356291, 0.07147750661021746, 0.06716746957795461, 0.07879336222436484, 0.12050477690111205, 0.05353869090941776, 0.13830157139433508, 0.08156061907953704, 0.10841818773227296, 0.07383926082372527, 0.06514813176771495, 0.0913155738402327, 0.11358330050956644, 0.06927691555339932, 0.04655875361509043, 0.08463171812221193, 0.1141776111267534, 0.9866368725932038, 0.9863522794014103, 0.8874184260806782, 0.9511340599275138, 0.9389466519001414, 0.9369537777656495, 0.9228129705386438, 0.9258514995628228, 0.9782176221842219, 0.2705212721481879, 0.5657624404875643, 0.8575353261666374, 0.6895506696009379, 0.5141077319437288, 0.6325709401730719, 0.0889947631857434, 0.8592290454749001, 0.8119056542524372, 0.21249549306976512, 0.2744593701614777, 0.1355674926836533, 0.20919690206392638, 0.20388201474465506, 0.17901540702235086, 0.11869724539401505, 0.13767235054325888, 0.07458839369126724, 0.9483909688309055, 0.9090716396161462, 0.9460336051146008, 0.13324823765376004, 0.13819537401165705, 0.20647757816359402, 0.946800834498098, 0.9496901985094546, 0.9342817458214248, 0.9400806133888807, 0.9479189471981087, 0.13807396698330687, 0.1379766701760704, 0.9589198467956158, 0.09265206458075459, 0.13709352416247433, 0.9434543254842452, 0.9323342766167907, 0.8631050052404754, 0.8085558746909394, 0.8492694179477467, 0.8780425296386751, 0.8564911403743308, 0.8447594886294272, 0.8791293488066644, 0.8729737928337422, 0.8983670637345431, 0.8408302209803218, 0.934411197128891, 0.854306077597043, 0.8428199816796372, 0.8915166511832824, 0.8468769688324727, 0.8242498797638302, 0.825673353285569, 0.9020806343423672, 0.7736790296170823, 0.8507740202649614, 0.8579132733424933, 0.9129180071730685, 0.9230896294844522, 0.8437047699280645, 0.8275202951685849, 0.8902929140271689, 0.8982944229177744, 0.2672488832160923, 0.17649246203897506, 0.6245056053642191, 0.8076756307903986, 0.18089572404582288, 0.5257235602739551, 0.05019134114314461, 0.522917029395497, 0.5855393648898277, 0.9536124960182519, 0.953449383399958, 0.9599846776665218, 0.9697859096051235, 0.9642353789060065, 0.9556212561529603, 0.9682096670320461, 0.9651532123489879, 0.2602965985123754, 0.12862015804361815, 0.05968752771034547, 0.06938734694414672, 0.10318656009232763, 0.049369024812638385, 0.08790850565209007, 0.07118394776823311, 0.12876570993728964, 0.12818917457504286, 0.33160466221212304, 0.16540918755634815, 0.14663815763621424, 0.1668030049416066, 0.17757900236207824, 0.13995705290836835, 0.14981819835290877, 0.11477717269621757, 0.11329539285295687, 0.2237481538095063, 0.18106318314394176, 0.254397939198734, 0.2135932028602089, 0.20459572236023738, 0.16608405417008454, 0.17639734616329839, 0.2730703274956575, 0.24671237217576225, 0.11519614529328082, 0.12261535698727133, 0.25305319206584387, 0.13806194271107475, 0.09266713934449877, 0.1718033710193766, 0.2134282433436191, 0.12287552307953353, 0.13013156021570849, 0.20296367245545255, 0.1423843545972555, 0.1746907621015058, 0.25332857354561533, 0.19240757987847745, 0.2100659012122429, 0.28525252988955285, 0.3138954948229552, 0.15685626007186182, 0.19367731759713436, 0.15551422047955943, 0.16871900638519544, 0.1687059694481925, 0.16760941733007895, 0.17790581180899367, 0.15987541407116823, 0.16731658866975507, 0.1761460204926374, 0.38005165799958984, 0.12736576851763426, 0.1489914351499445, 0.9747025035648051, 0.20203227920642353, 0.17343027033682556, 0.14334377209987814, 0.16649631978373947, 0.9677541534722315, 0.9794780812031654, 0.21358438728060958, 0.43639058981379175, 0.21328744583203174, 0.16970903311488805, 0.15696790304634944, 0.10509821410405618, 0.1048632023683056, 0.967230883296714, 0.15923663202606408, 0.23327820121867748, 0.20502993171481443, 0.19665244539402071, 0.15714775759382704, 0.2685607646357421, 0.22009375764078176, 0.2116072883470288, 0.25542508594190205, 0.09944141286837005, 0.05399071565412539, 0.06792600309899788, 0.08382309169044055, 0.08427266463513128, 0.067884093506834, 0.053124193166079525, 0.07178074496617848, 0.08717135089960537]}, "mutation_prompt": null}
{"id": "dab46613-7c98-4a35-b35b-ec57bf44b8a7", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO_ENM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.995  # Slightly altered inertia decay for tuned balance\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO_ENM", "description": "Adaptive Quantum-Inspired PSO with Enhanced Nelder-Mead and Dynamic Interaction among Particles for Improved Exploration and Exploitation.", "configspace": "", "generation": 84, "fitness": 0.46013684989071313, "feedback": "The algorithm AdaptiveQuantumInspiredPSO_ENM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9766322351239822, 0.9764827550991045, 0.9793914327036403, 0.9745760579879436, 0.9790705091195236, 0.9804653928300814, 0.9761009134898178, 0.9749750766250825, 0.9756089442843219, 0.9490984063991282, 0.942224537800395, 0.947302907625198, 0.04978675503067986, 0.9517406774399478, 0.9417919100111004, 0.7588259103901712, 0.06313631045580537, 0.917386553523809, 0.15036033925357406, 0.08785106311488267, 0.1034008548938451, 0.045315696183962806, 0.11000099669408703, 0.06942052016857891, 0.03768495814733652, 0.16786230195089558, 0.0846035361005757, 0.059760604032263465, 0.10847557598004898, 0.09104315096802928, 0.12854384516112927, 0.07618995235316739, 0.033624733528680006, 0.06338285092628526, 0.059829921059078695, 0.013892923821712921, 0.9189657277244047, 0.9691753297983027, 0.9076263298459368, 0.9876667715475644, 0.9239850485527873, 0.8858321311654029, 0.9532226783407751, 0.9145757841653546, 0.9059518218549053, 0.6002537041776672, 0.8945519682252007, 0.6714686877656475, 0.5010431443937153, 0.9121912586587914, 0.7265079120732825, 0.5270008513875024, 0.08901108119320911, 0.6588108038246188, 0.1848166199261062, 0.2104360428599581, 0.18388156833106295, 0.15433573341061468, 0.17866775483644692, 0.3094661853035775, 0.07839580570029303, 0.11250085418934574, 0.07335790699599043, 0.9519094536421624, 0.9255705549407344, 0.9408320460754194, 0.9074002042994591, 0.1371822579387887, 0.9395824195168526, 0.9628476599519273, 0.9369025168824747, 0.9489314567444211, 0.9369429958294204, 0.9567533307474708, 0.13782657974415102, 0.13859367243966625, 0.9510481416608743, 0.9175770700874253, 0.10545062009539019, 0.9553406412388425, 0.9186242928132256, 0.8855703187925049, 0.8622393962161272, 0.8804937554710138, 0.9398475647378978, 0.8299091534714322, 0.8908571854607854, 0.8799899874854414, 0.903013712081615, 0.8920817587432798, 0.8901520711215102, 0.2504644741968429, 0.8910020047807204, 0.8928743908435873, 0.8134190977736555, 0.8849163497324746, 0.8666798037118094, 0.8339109622349958, 0.9202729875443377, 0.911178473419376, 0.8564023628894983, 0.8721532869559315, 0.9311433893811301, 0.9320828033575315, 0.9163808582492959, 0.870471088600961, 0.9249378064383514, 0.8880720305643641, 0.41895527913446384, 0.24045464173237063, 0.6927458236514188, 0.12342758809261434, 0.16969667077852324, 0.9141771558116301, 0.08783067969852254, 0.30599104229996554, 0.08719537984435688, 0.9630457876043435, 0.9613168224431332, 0.9606225438527596, 0.9686962407280232, 0.9576031889899138, 0.9676270323537677, 0.9672993729160266, 0.9722784883155405, 0.9517267607724822, 0.19698075768129308, 0.056598206613696855, 0.12079611978742, 0.12089642537537015, 0.08158431648891817, 0.08189523570022939, 0.06330851439362506, 0.06741759558761373, 0.1289870117968427, 0.21963790308015518, 0.19690122478721883, 0.15252286886013988, 0.14943881799740355, 0.23498543074811373, 0.23318547678294366, 0.21143217377913448, 0.089517064435228, 0.16332299913963766, 0.1980061460403899, 0.21395379308830065, 0.23290631943812867, 0.2585958521257602, 0.17706409226387276, 0.1889725765199073, 0.20036674612256078, 0.2572426616959066, 0.2313085915233274, 0.19797525905786806, 0.12812570503866716, 0.28669351388143705, 0.1625518439896838, 0.1375707341910576, 0.17780842124674057, 0.10717087337896614, 0.16603533962074613, 0.18286373217763907, 0.20469626346337277, 0.25931728924954967, 0.22547303702202748, 0.26435426772564974, 0.19474499024666647, 0.19135736571200213, 0.20979494493928164, 0.21898277336402538, 0.2641485150214927, 0.15713063835390362, 0.15996395452371637, 0.16335108798595033, 0.1782969226823563, 0.1736724714484701, 0.1638136968442483, 0.16391104092059472, 0.1617125781858173, 0.15019036012980613, 0.5525794678764884, 0.12734010738273405, 0.14830686201706555, 0.9826182371048312, 0.20188891377459672, 0.1732382491540575, 0.14329576894492657, 0.16570002109633075, 0.9664615497220936, 0.9796995632721189, 0.2143729296483693, 0.0718243889861977, 0.11546454202213985, 0.1698677683630433, 0.15711498873408603, 0.06716986816210302, 0.10474237906464767, 0.9596213101901834, 0.18949589476401052, 0.2362368143953295, 0.22930196368349287, 0.18127920216095006, 0.273904690447465, 0.16549087961500042, 0.22476657834700686, 0.16136270914157336, 0.23588842797351506, 0.06608561620932085, 0.07597650836661485, 0.10525106463794132, 0.07586111019122888, 0.10514350142474138, 0.08946074606425736, 0.03586775169951306, 0.06489768038909971, 0.06238487466071874]}, "mutation_prompt": null}
{"id": "891667b4-bbb5-4e68-ab3b-57d97b834e8a", "solution": "import numpy as np\n\nclass HybridQuantumInspiredPSO_ANM_AM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.8  # Slightly reduced initial inertia for controlled exploration\n        self.cognitive_weight = 1.7  # Increased cognitive component\n        self.social_weight = 1.3  # Reduced social component\n        self.inertia_decay = 0.98  # Adjusted decay factor\n        self.mutation_rate = 0.1  # Added mutation rate\n        self.mutation_strength = 0.5  # Strength of mutation\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n\n        # Apply mutation with a certain probability\n        if np.random.rand() < self.mutation_rate:\n            mutation = np.random.uniform(-self.mutation_strength, self.mutation_strength, self.dim)\n            self.pop[i] = np.clip(self.pop[i] + mutation, self.lb, self.ub)\n\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + \n                                   [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "HybridQuantumInspiredPSO_ANM_AM", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and Adaptive Mutation for enhanced exploration-exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.46327138041696875, "feedback": "The algorithm HybridQuantumInspiredPSO_ANM_AM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.2524731266393885, 0.9774869356446425, 0.9774393705345854, 0.9722339313755146, 0.9747839108401558, 0.982254767812101, 0.9779729594495302, 0.9726903870603097, 0.9803317788452715, 0.9416381943015235, 0.08264949025698698, 0.9007396942192132, 0.9546849980642257, 0.916467030283297, 0.9281235759151494, 0.9283559244321393, 0.9474950909865858, 0.9285713345925457, 0.06338987773603588, 0.10869010422696901, 0.08790718537849695, 0.11414708553586861, 0.05835830584021662, 0.08456865158313687, 0.07179483843398815, 0.1288034693739748, 0.0879390413899187, 0.035102948063594375, 0.06331037589841637, 0.07151318942558971, 0.07312878102878462, 0.09458970991874927, 0.054801587883646974, 0.15035392754506427, 0.14950173632202568, 0.08145750912728966, 0.9498752463322813, 0.920165995208416, 0.933862241221874, 0.9373724139976695, 0.942385500412899, 0.9181150331037464, 0.8990520593681386, 0.9028244656190151, 0.9217768904506365, 0.27611885895546207, 0.7834095898801324, 0.7117316193271143, 0.7812827672059409, 0.6573102653740956, 0.20934765414893441, 0.24198784011893526, 0.9248116478831883, 0.7926682613572116, 0.24576639489891172, 0.3368797523670263, 0.32831518194696163, 0.1969317281444778, 0.16683892822585844, 0.16337575330986853, 0.10914632459275198, 0.15323633068153486, 0.16833392224846122, 0.956705139648627, 0.13781546199511308, 0.933825468671144, 0.9147585105397238, 0.13150569907935405, 0.9380206289928279, 0.9318010322134948, 0.9550440496375162, 0.933372569439129, 0.9493833678222544, 0.9388499389121011, 0.13269315921416325, 0.944208105721049, 0.9285973981040785, 0.9301132928231296, 0.11528878087031713, 0.9419556260289493, 0.9399498544122835, 0.8895419950929859, 0.8569550319576871, 0.9296944756132537, 0.933187093140691, 0.9103266518149109, 0.9044373183656715, 0.06848458307117855, 0.9362049270060319, 0.9014603763833303, 0.8837179389140086, 0.8860070413398292, 0.9237403278557121, 0.9036645102655898, 0.8940635447327658, 0.8210358721050139, 0.8615882135344293, 0.8998872315617464, 0.896582428723668, 0.8632388013670348, 0.8641196914658059, 0.9294117972817375, 0.9468958393866503, 0.9457240294924317, 0.9078643517997284, 0.8694435247256572, 0.908821744685371, 0.8753073862530176, 0.20997736655910493, 0.4287892450711529, 0.2019133966309159, 0.8813332772919817, 0.08084401014341369, 0.4673109143151821, 0.9412506506398554, 0.5205499295302313, 0.7562381327552725, 0.9693099917688627, 0.9650702963971735, 0.9634859171838737, 0.9638399982827706, 0.9611599155789899, 0.9624108013537327, 0.9764618910155454, 0.9551651811353526, 0.9666762907088043, 0.07383688260623766, 0.02286540745263499, 0.0738320655657928, 0.056622435528851045, 0.08464027452396528, 0.10336178683252861, 0.07734873186535662, 0.04875940409181456, 0.0950164817583733, 0.1593784206434926, 0.2428135616024244, 0.1761781670443242, 0.18860052317617715, 0.13874300487879154, 0.12254571705768136, 0.15774092519306848, 0.21706140828128373, 0.22361259251990573, 0.2275802972851485, 0.221863894911015, 0.2562917034221105, 0.18345179121063604, 0.14722100254580295, 0.18738641190864114, 0.21111656758182207, 0.266285084558346, 0.17731960976331773, 0.14482423678745904, 0.21051660240994574, 0.14024445771785776, 0.1192610351507305, 0.14146918573478506, 0.19020770684466537, 0.14373437460611727, 0.1355434687145951, 0.14647700356811533, 0.2585859340251725, 0.22801354373173055, 0.14859280619710047, 0.22588319564415593, 0.21468144806727962, 0.23651345722558315, 0.21545650689613705, 0.19779190035161187, 0.2383705691455471, 0.15798442549418013, 0.1710924539739782, 0.16082018961363465, 0.15918734940418666, 0.1699590482954605, 0.1630586674226332, 0.14963473515500247, 0.1808020836178641, 0.18093832948331778, 0.9697421089692912, 0.12732635252092384, 0.14909005824769284, 0.970705151097528, 0.20243549266245175, 0.20166997745143267, 0.14324393248038647, 0.16629316070080602, 0.15947000325233662, 0.2814116119747423, 0.21453712182761975, 0.07362404357327434, 0.21386052272413314, 0.16979591250851755, 0.2130935585070306, 0.9623632103835131, 0.10512688757022937, 0.16881210283042858, 0.24667020017440489, 0.14041268219165193, 0.18553551772074062, 0.20790330589216233, 0.20915106694014918, 0.19427281309735267, 0.2134419199565798, 0.19777847137269444, 0.267675462798611, 0.08054142760125638, 0.045929770958771376, 0.07063931901978271, 0.07640791833857363, 0.09279100894936843, 0.08865780101347431, 0.10814450288823896, 0.10294710048214384, 0.08824229152868124]}, "mutation_prompt": null}
{"id": "d7fcafd4-0f68-4411-bb6a-84e8dbaacf1e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "68bdf0eb-aa04-481d-8342-7022f22da22f", "solution": "import numpy as np\n\nclass AdaptiveQuantumEnhancedPSO_DNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.8  # Adjusted initial inertia for balanced exploration\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.inertia_decay = 0.98  # Slightly increased decay for dynamic balancing\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumEnhancedPSO_DNM", "description": "Adaptive Quantum-Enhanced PSO with Dynamic Nelder-Mead and Inertia Variability for Efficient Search Space Exploration.", "configspace": "", "generation": 87, "fitness": 0.45324537609886123, "feedback": "The algorithm AdaptiveQuantumEnhancedPSO_DNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.38.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9814830665649358, 0.9659856234131252, 0.97728355482375, 0.9769900368527439, 0.9702075490423179, 0.9710368728497727, 0.9687581258112603, 0.979440539958125, 0.25411403629619533, 0.9222935230835168, 0.9409249118630688, 0.9260663075951521, 0.9421339165431202, 0.922095545614517, 0.9414039993243563, 0.9065738187074669, 0.9430460298613704, 0.06343372047212992, 0.09610277497542918, 0.10336986344804922, 0.11398275529907753, 0.15031629181447348, 0.1307606329968155, 0.09480152677542497, 0.0340315726309236, 0.10866011363012062, 0.1281107196562794, 0.031769672016671247, 0.05973544745968795, 0.09453362969315326, 0.09132238278927651, 0.06325846213077346, 0.030021913455660743, 0.029953683675738252, 0.06837322219437969, 0.045497444058087755, 0.9659375784933504, 0.9886984776146036, 0.9289227485293616, 0.9713285531337438, 0.9853603685451244, 0.9547726293913897, 0.9544478711605137, 0.966404919629572, 0.90831662799018, 0.2471110186470924, 0.806775225672673, 0.6859344211140102, 0.25901508067033696, 0.9317618823871733, 0.8464445681542314, 0.6588221943057989, 0.8445007054572992, 0.08907718744741377, 0.19362779475238123, 0.23200290305186733, 0.11028851061106693, 0.17479336764312525, 0.21436598690884368, 0.19392195363438458, 0.1122270218491731, 0.1089917440586633, 0.1469119484449093, 0.9568038308171211, 0.13401975755223616, 9.999999999998899e-05, 0.9251464568853734, 0.13822314497614152, 0.9035954615098774, 0.9490854516242115, 0.1376131211217485, 0.9459469283758993, 0.13519054482847492, 0.13736425683039455, 0.13840686177030403, 0.9231157427390919, 0.943570469902406, 0.943108610775554, 0.9385080654951385, 0.8386055040476588, 0.9207403470863451, 0.8907407259332746, 0.8988002748958984, 0.8768531868203197, 0.903820342625636, 0.9294636810947918, 0.9109573598945763, 0.9026968800412805, 0.9237946392299391, 0.8681907208024998, 0.9161115046867725, 0.9525311918276956, 0.8897884327826964, 0.8998672518295477, 0.9050620499725169, 0.7866430703051388, 0.7307643962675301, 0.9395828489316914, 0.8839158745129642, 0.8764335028506682, 0.8444645850402577, 0.8030541881018275, 0.9433455901167027, 0.8363850080373348, 0.9256526418603699, 0.8130004460357936, 0.8473167967329829, 0.834292065982601, 0.7647175274576751, 0.8946381510603506, 0.7371335670118324, 0.08697704704814224, 0.853319857438146, 0.5469210754746145, 0.06309658549108776, 0.8422679997389071, 0.2191928034207058, 0.9653014725545558, 0.9647417012582904, 0.9678352838527989, 0.964802284044925, 0.9677222353977167, 0.9659344715951264, 0.9681392810168727, 0.9626650606263757, 0.2910347881698797, 0.052103722246800266, 0.06490604612059503, 0.09880191594334287, 0.06543052079612044, 0.08774359455539582, 0.1281684829628339, 0.0761709753185763, 0.10834712293235604, 0.09902110712412526, 0.10626450077770078, 0.23783434377733303, 0.14855992472248725, 0.12153004714614257, 0.18929134234479927, 0.26245106562798315, 0.1480122949805205, 0.10091036647581964, 0.10051628091841591, 0.28393818957851646, 0.1628909172869495, 0.2672315507086638, 0.20394130197965255, 0.20919282028023467, 0.17197838078483707, 0.18619284815824289, 0.2412450280719648, 0.2689085607102799, 0.16195666482831383, 0.11622838727867368, 0.15962936142216544, 0.17877031351103656, 0.07332123122515, 0.1924062399916917, 0.14253312173106258, 0.17325855777264154, 0.190970652634619, 0.20086799513413178, 0.14434408390862752, 0.1815667028517023, 0.14829605594621376, 0.1647053384115197, 0.19992375240359395, 0.2066090304441487, 0.23480785998779785, 0.16429732654025997, 0.17380667684493434, 0.17983547514756848, 0.17932169361485517, 0.2016218234095769, 0.17748246049111205, 0.17524868795291937, 0.1689498302914606, 0.1751309455451323, 0.16640323257018774, 0.10557833173623443, 0.18858517389304164, 0.15481935551698056, 0.9844682779321665, 0.20201239230485812, 0.16852405936470716, 0.1432984734742686, 0.16630141501515538, 0.168680904324645, 0.9783938536597102, 0.2143698458064186, 0.07267413893819319, 0.21395227805562778, 0.16966111748501556, 0.15723328187586194, 0.9802291122874798, 0.12837019899942625, 0.9742525171287704, 0.19251188361620608, 0.21260711892659923, 0.19739613133956435, 0.16427145387480446, 0.20589384287860268, 0.17390565988279982, 0.2657974818700437, 0.20932685137030915, 0.24586592894556092, 0.09391525524295308, 0.08714457529439168, 0.08889599994188446, 0.08335674402891413, 0.07007906932030017, 0.10930327558386665, 0.044549841150315794, 0.08636471610911467, 0.09678234307291556]}, "mutation_prompt": null}
{"id": "b0f7f270-c865-4e52-93e3-52adc6b47915", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9  # Increased initial inertia for wider exploration\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99  # Decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Enhanced Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead using stochastic inertia reduction for dynamic exploration-exploitation adjustment.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9783575533909201, 0.9741426514455539, 0.9772193276642982, 0.9750746116428034, 0.9764235779558946, 0.9785744516831834, 0.9752573508277348, 0.971300932315566, 0.9735414289078447, 0.9424612362154163, 0.9368514106185086, 0.045083046270415816, 0.918782672959058, 0.8922178913963829, 0.8926174693388277, 0.9088174092727108, 0.9344495967203013, 0.9580108139764545, 0.07581071080228563, 0.09479309725766638, 0.07633290890505728, 0.05353796057917681, 0.07156970156532894, 0.11432296666925357, 0.04928557319062077, 0.1287905844244568, 0.0877322990807019, 0.0505652932275249, 0.0789830613118363, 0.11402006045353485, 0.06348254181631652, 0.14926081765379617, 0.056391182518433336, 0.12061397575148147, 0.05205807502875637, 0.030907257715574676, 0.9654486863890872, 0.9483884777423961, 0.8984430570420769, 0.9549501098245395, 0.9588878274912741, 0.8733432338581621, 0.9055731792415153, 0.9422070500291461, 0.9181656196007326, 0.6925789638576423, 0.3796243602369517, 0.6651595495756801, 0.7685676308637754, 0.880484928581121, 0.8795329375036831, 0.7125875923720844, 0.6273782472023155, 0.6672234796189634, 0.24715173409166213, 0.3231841686005419, 0.15231307445597264, 0.15432615220848078, 0.17865224218307918, 0.3431333472541833, 0.06516506872276129, 0.11195257513788004, 0.0776136634847564, 0.9506768262688933, 0.9098280360097564, 0.9505463919343176, 0.1340237839683085, 0.13769197020110802, 0.9406407724855325, 0.958489611418206, 0.9435037918147654, 0.9382968938373362, 0.9518315216004415, 0.9339970687448464, 0.13774626558874292, 0.13859674649119913, 0.9499741774179303, 0.1373006842790201, 0.9318501234081836, 0.9498380796287335, 0.9214867130588181, 0.8954302969001526, 0.8892276198692417, 0.798173954552898, 0.9096722496132528, 0.764426984225059, 0.9015453811414512, 0.8774624557736059, 0.9211211792420049, 0.9025331916029522, 0.8657982595940237, 0.24989264742537076, 0.8788692464557092, 0.8855062434240979, 0.8541987617451458, 0.8749222547076588, 0.8855242451509692, 0.8512319589514677, 0.9374920681949466, 0.8600015976262214, 0.8601461970157086, 0.8776754572410684, 0.9314933801379938, 0.9149126691261227, 0.9257959838365637, 0.8291247648920883, 0.9327846611299998, 0.8832872315421693, 0.32719513272474166, 0.19948335643901471, 0.15156323327552834, 0.26350823864913275, 0.11924290565794415, 0.895545556081327, 0.09006660149861967, 0.8110277749741492, 0.748336825350571, 0.9524684791776654, 0.9592871682664126, 0.959814072141204, 0.9671654295522116, 0.9651052755814167, 0.9650745726314258, 0.9711832394105482, 0.964345775787119, 0.9415446701636753, 0.1141423477805874, 0.0693635930877815, 0.09484928706099072, 0.13781591466929788, 0.09792442925731537, 0.09924376790208622, 0.10677439259995058, 0.06738784697004319, 0.061782609483145956, 0.17790389949761087, 0.2044889523104524, 0.15813111522477685, 0.14108067215170317, 0.37974474984366424, 0.14879847365801435, 0.1884868681491424, 0.11013193874552052, 0.17017396376554828, 0.35826035070875906, 0.23722315695732654, 0.2471539659486902, 0.25186063422613925, 0.16932497198236596, 0.20354099566605832, 0.17419569600640894, 0.2313540315156848, 0.234201358468491, 0.18158076357632702, 0.1313734620154957, 0.12099682516586885, 0.16062643878795224, 0.07921035102426144, 0.24707545196041403, 0.14586612054075632, 0.12638699932719755, 0.14611227195335652, 0.31348615482731057, 0.2271748336214261, 0.1482548588115773, 0.22231387907030808, 0.22837800892645999, 0.15595978301534685, 0.20276603526419934, 0.2013685867735595, 0.17329287886642064, 0.15850327279624088, 0.16138359552197523, 0.17150083729425858, 0.14656525302717016, 0.1777592399261534, 0.16774551202023813, 0.16315773714368675, 0.16038595559242552, 0.1662138976456461, 0.5431974784666485, 0.12733960510390296, 0.14886344179808786, 0.9796838896308507, 0.20196236514524868, 0.1733537723526204, 0.1433257945733254, 0.16643734418753087, 0.9777598078741943, 0.9828103211536594, 0.214426448883408, 0.4201457611980409, 0.1050415916510199, 0.16981999925275248, 0.157070432826393, 0.06929686703935223, 0.10460171512809535, 0.9611373868760689, 0.1707566665227358, 0.21355893856666497, 0.19491907144896015, 0.21753851199512242, 0.20486219538942063, 0.1676252407937382, 0.19471210498579417, 0.14602627388110412, 0.23471582397397928, 0.030492879952974894, 0.09878045820420833, 0.08686475535295413, 0.0599340583063146, 0.10581825063419548, 0.11079740450822173, 0.032390688249759436, 0.05992327685652887, 0.0929071996654105]}, "mutation_prompt": null}
{"id": "8592693b-32fc-45f1-8430-d7c93303c217", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.99\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        adaptive_cognitive = self.cognitive_weight * (1 - self.func_evals / self.budget)\n        adaptive_social = self.social_weight * (self.func_evals / self.budget)\n        \n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              adaptive_cognitive * r1 * (self.personal_best[i] - self.pop[i]) +\n                              adaptive_social * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + \n                                   [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and Dynamic Learning Rates for Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 89, "fitness": 0.3962967445737683, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.37.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.970297032542151, 0.9753383091578071, 0.2919024008505984, 0.9776057840755261, 0.9789929806253947, 0.9681809374452457, 0.9790778516926878, 0.17251710141573662, 0.9724422313267851, 0.931851259370499, 0.9471182868673595, 0.8540783697851193, 0.9275880257960488, 0.9042920716505752, 0.06979662982766732, 0.9418077793249384, 0.9234284798568252, 0.06362946121848423, 0.0670187249744435, 0.1469179723226851, 0.04408422306976423, 0.03651741576680412, 0.06917426148655736, 0.09446306814432992, 0.07897360626430494, 0.09905291647679315, 0.0547726775988876, 0.07595437238553149, 0.0384567393082802, 0.08747052640325159, 0.05652641722581597, 0.032646189112207846, 0.0760269248201455, 0.05139603358325673, 0.029995969441116488, 0.04770832577093009, 0.9123399194128868, 0.9873037519886964, 0.9666487025578172, 0.9514473036980358, 0.9421145756140097, 0.9207098790031305, 0.9121780258751271, 0.9022034453888619, 0.07466515879710045, 0.12101582705010128, 0.6431390361946467, 0.7988729055252285, 0.7822098488118825, 0.6999120565212655, 0.18297124997887715, 0.12811624478909778, 0.5596948784339251, 0.08898571192363602, 0.16769298080523443, 0.19667957538959258, 0.21155317877758084, 0.19568209884366738, 0.18761302161379023, 0.10998379963113925, 0.149122896743622, 0.13987052891720209, 0.03044036611643064, 0.9551975379869646, 0.1370454418520085, 0.9408321707929294, 0.9405792760335567, 0.25026154100705134, 0.8940569924273385, 0.9452132708490824, 0.9656865551713304, 0.8815146584242712, 0.13808222348624766, 0.1378523864549004, 0.9510647433202708, 0.9261623376110857, 0.9450426179950895, 0.13707185682408674, 0.13823011955397102, 0.13823173572734482, 0.9239145203424064, 0.8314131196356658, 0.9178533771671497, 0.09425839928306434, 0.8227499887137969, 0.9070813963776618, 0.9002362253237245, 0.9373880367451947, 0.9122387079902292, 0.22557005374565187, 0.841360612904372, 0.19109588416940315, 0.907033721295315, 0.9247380633745504, 0.7992025823136945, 0.8965183343509461, 0.8841715438501884, 0.9066847709497978, 0.14648395672779702, 0.8592073389218438, 0.8663268003277407, 0.9120051092828765, 0.9230670350007563, 0.9274463655347638, 0.930816852148293, 0.8943183536766004, 0.83036089020163, 0.8784863665002983, 0.18091806771932695, 0.10340318744690413, 0.06638761874763155, 0.00923261797645536, 0.5360811076481438, 0.11396059908233747, 0.541862050209285, 0.0782325270769183, 0.09828416624554726, 0.18608707195703422, 0.9685694562657031, 0.9421221649794721, 0.9657271348901739, 0.9641079383710186, 0.9633087947950278, 0.9578109430091564, 0.9655985191334626, 0.9667597689340275, 0.07139862849274925, 0.1081224674197252, 0.12848865978610624, 0.09486457059076381, 0.07372651510304973, 0.11389481473926155, 0.04512613146305866, 0.12822421521955008, 0.07403633261702758, 0.1437712274502283, 0.1613315977245895, 0.16178230053386977, 0.16279471875126728, 0.15962944173374838, 0.1363681623317352, 0.22928894141085743, 0.1899678716874067, 0.12637247197762558, 0.1431176439150913, 0.14603433458081705, 0.2043069911217943, 0.2505984901088878, 0.15838233242750355, 0.19988032353444818, 0.15457178995258858, 0.18521951147187599, 0.1716578334414538, 0.11988387934271794, 0.04108538725686173, 0.12954652033616143, 0.17778816721110668, 0.11451152448807222, 0.10142384043081476, 0.27284698193966017, 0.23916974755133658, 0.10776331388819582, 0.2597720925048935, 0.2412572146160601, 0.2029121935008087, 0.27276812549506857, 0.2232574043125085, 0.22637835864358236, 0.18172995306680373, 0.2019925814307676, 0.16064427942450488, 0.18590257917219222, 0.1658628210568297, 0.19933224560013107, 0.19177717588779986, 0.18987556039740316, 0.16145489571643434, 0.18235281772182965, 0.19974586663834137, 0.19108852646405616, 0.07154289699167404, 0.10828095176890151, 0.1425002202945217, 0.11489991169941727, 0.20195897272167707, 0.2009849814961775, 0.14330930767428696, 0.16642852931365704, 0.9752350672090879, 0.9782533794185944, 0.21411644709331712, 0.07261402574157871, 0.10495314021036961, 0.16923756732645856, 0.15690145719091508, 0.10040935981014609, 0.21365037619638227, 0.11301131570074685, 0.20393615904120788, 0.1413590071078804, 0.2170880473251624, 0.1768789323302119, 0.20597584136217006, 0.17279231314924415, 0.21879428947558044, 0.19398688198670055, 0.2072015332594196, 0.049839332349555066, 0.1141322394145684, 0.10111656514532785, 0.07021609442805166, 0.08556049561776058, 0.09314346662540718, 0.05685357594151297, 0.09316036314401044, 0.06181547644252461]}, "mutation_prompt": null}
{"id": "b3a96fd5-1c5f-4860-a94f-2848e613ea2e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.95  # Slightly increased decay for dynamic adjustment\n        self.adaptive_cognitive = 0.02  # Adaptive component for cognitive weight\n        self.adaptive_social = 0.02  # Adaptive component for social weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              (self.cognitive_weight + self.adaptive_cognitive) * r1 * (self.personal_best[i] - self.pop[i]) +\n                              (self.social_weight + self.adaptive_social) * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            self.adaptive_cognitive *= 1.1  # Increase if personal best improves\n        else:\n            self.adaptive_cognitive *= 0.9  # Decrease otherwise\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n            self.adaptive_social *= 1.1  # Increase if global best improves\n        else:\n            self.adaptive_social *= 0.9  # Decrease otherwise\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM_Adaptive", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and adaptive learning rates for enhanced exploration and exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.4497662473142891, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.38.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9809270177233891, 0.9699115953670532, 0.9686443521654954, 0.9774930950608732, 0.9732143544763603, 0.9744880530781527, 0.9774807754969267, 0.9792568053585161, 0.1507978636020414, 0.8955695260934861, 0.8820439676582175, 9.999999999998899e-05, 0.946698622701607, 0.9160638683810736, 0.8973668325597252, 0.9162728827023107, 0.9544537693581363, 0.0629630715387215, 0.07157884570445949, 0.09909582245854598, 0.10361749107294782, 0.046684495286250405, 0.08472488466760697, 0.12865764420572723, 0.05505190992469544, 0.1380050228369033, 0.0833923816030887, 0.0789016045876697, 0.06346761599559503, 0.09863511484327137, 0.05208763121059368, 0.19640136972445876, 0.03277166667834841, 0.1379451439976892, 0.05041024467579014, 0.04529648092213667, 0.9353663718587746, 0.9781022300993824, 0.9485904745545598, 0.9719241679409758, 0.933109272363514, 0.9320864242169082, 0.9862894758758731, 0.939096491424704, 0.9767235970170505, 0.6676023604136099, 0.5247276211319609, 0.6218939792097286, 0.6909679765328346, 0.5513000411709637, 0.6147576184031674, 0.8803398601905474, 0.807984600868533, 0.9000785507440228, 0.4089233253334882, 0.23089600204104688, 0.11210995602908425, 0.18094881231561866, 0.17975785381062237, 0.17854540511299655, 0.10382161762798603, 0.11162868327074249, 0.0933096455760637, 0.9465262068594689, 0.9108203449424829, 0.9477398913082674, 0.13808867191361895, 0.13758012354933946, 0.07382631478626134, 0.9579029591272502, 0.9334136554047395, 0.9475494569729046, 0.13852953710191773, 0.9572844870299083, 0.13829208031383056, 0.138159260737431, 0.9597851606562922, 0.8859889872191979, 0.9620535190476416, 0.9462583178610967, 0.9328479794803499, 0.9190418265601383, 0.8713600653443304, 0.8888018089329177, 0.8680547195730031, 0.020803386024025317, 0.9321590897018293, 0.9190658744979473, 0.8948804185687355, 0.9223850064629111, 0.12063233914247173, 0.15236571307781688, 0.8792952529842425, 0.8743206488740833, 0.8619110719066189, 0.8689422239439281, 0.8741603816064368, 0.9161256427878985, 0.9005837215874019, 0.8750375120700408, 0.875477389492136, 0.8110906963674074, 0.9328286874118404, 0.906447104002553, 0.9285714551015676, 0.17296865047535126, 0.8852287912531781, 0.864655242111448, 0.2522162667445722, 0.20011408688567656, 0.9337153052377387, 0.5848923846228694, 0.08904632886411112, 0.7355124407571898, 0.05923821991992406, 0.2132166198290424, 0.43801879990589965, 0.9660139667948251, 0.9607985531445442, 0.959256271128159, 0.963637996671017, 0.9529648601604097, 0.9652350437346455, 0.9735128122008755, 0.9572512020098612, 0.9677698590389623, 0.09900136362071121, 0.09878709102992655, 0.05645669946394427, 0.11411993783856655, 0.09852282861692296, 0.06529242815178327, 0.13814529242871976, 0.12079301844133228, 0.12849857444989954, 0.12959923967353348, 0.11594243538122095, 0.16109809336605307, 0.12113387760570182, 0.1525921583940424, 0.1415981300614596, 0.23640622406669576, 0.11335727013595565, 0.18472609950215113, 0.1650484954315209, 0.1664245151502841, 0.21770917138356916, 0.18513581475123397, 0.16457648497640964, 0.17290239577058986, 0.18736667462931134, 0.26455874733546525, 0.18467187715488143, 0.15618981532024556, 0.1414711740664567, 0.18642886819674276, 0.18677422687287248, 0.1363769058126929, 0.1415324057057391, 0.16327047786043514, 0.12313158012978365, 0.18237412034403855, 0.23602100118530667, 0.19843196761997062, 0.2687810934589394, 0.1776443974544678, 0.24388055725583768, 0.1915447068195808, 0.2329426373787875, 0.16469933910678025, 0.23038805755643854, 0.1709680445202144, 0.18220975439566578, 0.16553825477369577, 0.15357627370343852, 0.20252599474513022, 0.17273968537541606, 0.18567308822808826, 0.1689204699786815, 0.17158639307028956, 0.42093317891889437, 0.12728680378604895, 0.14901760861544877, 0.9824252431750982, 0.202168380811502, 0.17350102244872723, 0.14338539203217715, 0.1664911291440161, 0.9639353917965763, 0.9834545093199656, 0.21455867863650413, 0.9719945863159876, 0.21200472980331742, 0.16958851879205616, 0.15717219961143414, 0.9609176876086182, 0.10489630401873673, 0.982156704560857, 0.1659114873826304, 0.24898639331206873, 0.1731877631850266, 0.20096600201406123, 0.20849486364959335, 0.20742714112015148, 0.23604578586994918, 0.19468069025268497, 0.20286080552395547, 0.0519687753235486, 0.09422466582799038, 0.06836149082155785, 0.065302729739944, 0.07499704703746579, 0.09908543732854047, 0.07860200122514982, 0.08133454930119965, 0.07749056115011754]}, "mutation_prompt": null}
{"id": "cb6e2d7a-6aab-4a75-8808-8bd10e79f129", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM_Chaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Slightly increased reflection coefficient\n        self.beta = 0.4  # Slightly decreased contraction coefficient\n        self.gamma = 2.1  # Increased expansion coefficient\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.6\n        self.social_weight = 1.4\n        self.inertia_decay = 0.985  # Slightly more aggressive decay\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        chaos_factor = np.sin(self.func_evals)  # Applying a chaotic influence\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]) +\n                              chaos_factor * (self.ub - self.lb) * np.random.uniform(-0.1, 0.1, self.dim))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM_Chaos", "description": "Quantum-Inspired PSO with Adaptive Nelder-Mead and dynamic topology leveraging chaos theory for enhanced exploration-exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.3260061017667529, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM_Chaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.31.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9797083424365516, 0.9715324240662864, 0.9718621883622051, 0.9728067562187639, 0.9714303126124738, 0.9720436887788956, 0.9411325947129126, 0.9608600745393705, 0.9625102363679665, 0.1088724000784943, 0.5522942574831379, 0.22333146762422262, 0.4049663475137296, 0.3658746488219621, 0.38477630127069307, 0.11896151183206871, 0.37782495656754533, 0.36407870544005405, 0.10820112345953381, 0.08464986124486984, 0.058140696462735786, 0.08975272451704153, 0.12047688773569676, 0.1384626293998743, 0.07884876922678197, 0.045638048236684714, 0.10385183166353995, 0.06441744937062155, 0.06515083807648392, 0.06164380257700053, 0.051968244144854014, 0.08894708086485792, 0.045037020686039986, 0.08722526209027748, 0.07813869320845301, 0.07622484233355042, 0.9428135017547912, 0.9895532286177698, 0.9423258013501168, 0.9415874877796431, 0.9894601296120985, 0.9131916705433132, 0.9558167285638038, 0.9716065279200558, 0.9800558685236459, 0.2387140793319268, 0.11625444029309273, 0.20587287133066667, 0.17949853907220537, 0.1562817785689825, 0.27053068379035183, 0.3477423370184266, 0.11399131402514795, 0.16201417585360467, 0.15279058906837584, 0.21206646868781986, 0.18044947596977168, 0.1452328931800505, 0.1825530303479218, 0.11312664635730307, 0.23895117911273522, 0.13177825411727007, 0.1810896807747051, 0.13774423320556028, 0.933888401119769, 0.12845419972690508, 0.13730443587947683, 0.9000361613505331, 0.8634495107118503, 0.13692049963540998, 0.891041132313448, 0.8984851615535916, 0.13253238105077125, 0.9016282069728374, 0.13688839604959957, 0.0646503926989146, 0.8582568365551793, 0.8592685327618277, 0.13817797204651183, 0.13506372452254922, 0.8743938375844924, 0.4633721341955873, 0.09791679939722508, 0.14815841167266375, 0.03485450542818014, 0.49716319449631985, 0.2777810833122658, 0.19296801428494192, 0.7319528226452907, 0.3114081467676908, 0.07203029149350626, 0.5312837837556581, 0.09626769677870439, 0.15152296747031646, 0.7214569817807345, 0.26590376800465554, 0.135270946577269, 0.14990250166679875, 0.07703386814141244, 0.4014209111594125, 0.45091507355645455, 0.706823903132141, 0.1513775993562354, 0.08913868304441419, 0.642661730999948, 0.6564888573168774, 0.6811945816804905, 0.32204486205256955, 0.15629410390433895, 0.49116068438778304, 0.1689973993134345, 0.036128237278803876, 0.15218458985420003, 0.38689396020616873, 0.059513384888852716, 0.13491980144095672, 0.08654872477077657, 0.9447264213516833, 0.9082285373289711, 0.29223356459938754, 0.20990035679028018, 0.882675961156674, 0.9343963554848801, 0.9320117831257836, 0.9185705858135833, 0.9484028538390238, 0.06919667251687367, 0.06713477518250688, 0.08737147448940574, 0.0847030176712551, 0.049924552478820994, 0.19555352319804808, 0.09476464255708228, 0.1286138851952472, 0.0950775594872999, 0.10853351754853069, 0.1791921865175503, 0.17983445247621654, 0.19103351543246427, 0.1669352761417665, 0.14875012394351106, 0.18909076560485072, 0.21929343142075464, 0.20678667057293976, 0.18133658742764802, 0.1897940839553055, 0.2953983239943301, 0.24188328651797886, 0.1853033169660423, 0.13972182705289127, 0.21417095291399801, 0.3186190322211231, 0.1759750216566952, 0.26477394625323436, 0.1381777447443563, 0.14710034593318888, 0.19952504748739797, 0.09788978945804083, 0.10932779942045234, 0.2081372419970371, 0.1265481852678082, 0.18296843011201502, 0.1886430770823767, 0.13789906400972718, 0.206156659671913, 0.18846152739620492, 0.16682384087678492, 0.1573126061483956, 0.18451420481239444, 0.2357316383577559, 0.20271741600151805, 0.1643354390582945, 0.21493898026656677, 0.1763704486108647, 0.19366452437376358, 0.17383908020750838, 0.11179311389015945, 0.17453372200228967, 0.1721009170739548, 0.16419803216252116, 0.17806737582529097, 0.1265583830945669, 0.15119078343435643, 0.1728715152682263, 0.18337986752085156, 0.9550698296000237, 0.17929641442918054, 0.16534695459579385, 0.9685082410497461, 0.9718051848746744, 0.2144991267185251, 0.07251966193777093, 0.21416466904325793, 0.16926004771443082, 0.09439063743069986, 0.10544129078468645, 0.9321437919096832, 0.9366808699391979, 0.24749547865348054, 0.16752855530035848, 0.19510619521066497, 0.2850801110273421, 0.2276958987796378, 0.21102078648772937, 0.219239618203378, 0.1836858204294063, 0.20142797843697635, 0.11772523973130122, 0.09929362592559587, 0.05403138579229949, 0.07829594976349308, 0.06806729436443038, 0.08482694658779033, 0.08999932023991786, 0.10596056219812511, 0.05988942846366774]}, "mutation_prompt": null}
{"id": "37131961-f36e-4594-8664-cf836e1b1f39", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 15 * dim  # Adjusted population size for better exploration\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Adjusted reflection parameter for enhanced step size\n        self.beta = 0.6  # Adjusted contraction parameter for better local search\n        self.gamma = 2.2  # Adjusted expansion parameter for broadening the search\n        self.inertia_weight = 0.8  # Adjusted inertia for a balance of exploration and exploitation\n        self.cognitive_weight = 1.7  # Adjusted cognitive weight to focus more on individual exploration\n        self.social_weight = 1.3  # Adjusted social weight to reduce over-convergence\n        self.inertia_decay = 0.98  # Slightly stronger decay for faster convergence\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Quantum-Inspired PSO with Adaptive Nelder-Mead and stochastic inertia adaptation, integrating multi-strategy convergence acceleration.", "configspace": "", "generation": 92, "fitness": 0.39186784083275855, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.34.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9679874237708715, 0.20057030145149524, 0.9730227185875779, 0.974380803281472, 0.9681958456550437, 0.9726612130397199, 0.9717468118141078, 0.9696077739964387, 0.9741645758121893, 0.85434354278837, 0.11666747005126621, 0.8408528898318719, 0.8846607371018319, 0.7763536277758287, 0.8804474474716347, 0.9451861206168874, 0.37015567675322913, 0.8927397687071003, 0.11366972911407269, 0.08137779974671433, 0.13657432822209226, 0.0876825687666204, 0.16717503877325435, 0.06435415003733647, 0.08785621818924305, 0.07870046314262091, 0.14497374342631486, 0.0985050266938019, 0.13506741668213018, 0.08406198819667332, 0.06152926837755146, 0.091986546148637, 0.0803311321962139, 0.09445200331627024, 0.11301390887826346, 0.04280745562461452, 0.9061197642130018, 0.9296100393387207, 0.903980851037673, 0.7816432937718407, 0.8614285470217953, 0.7946042005744374, 0.9429419764818627, 0.8515214139292614, 0.9846997724453738, 0.39227590481191665, 0.58440190421435, 0.26784120610106454, 0.4493317024769874, 0.18564468318822314, 0.21046574183050037, 0.6637430858527467, 0.2531138035584164, 0.6405932801432863, 0.22300842392676024, 0.17337138468674307, 0.15909297401223188, 0.11162271499780363, 0.3421119386882091, 0.1783363174342285, 0.09700806666757711, 0.17313349908206732, 0.10422533925833355, 0.9151020424221441, 0.13242311165708776, 0.9071735437272695, 0.9076919274674556, 0.13708412475734422, 0.8729484986988417, 0.9332842204279457, 0.9138519719314986, 0.13698030098014946, 0.1369316868255348, 0.10638951745190539, 0.9306848792645488, 0.8995245609084788, 0.13636124308721287, 0.1372596759410981, 0.1371077762554732, 0.3263576356880741, 0.13700123693613242, 0.8752448637819427, 0.8957364212132463, 0.9188209071731195, 0.9133843950216696, 0.9127976641944008, 0.8697161301756878, 0.8763563888504127, 0.8770182313482294, 0.8908365506386627, 0.8179294630415811, 0.18775285985510304, 0.8845567902251459, 0.8209973052829667, 0.08075685753127959, 0.794211332525346, 0.8033250637835609, 0.742765090504609, 0.8264849186272984, 0.8334072410264886, 0.8353719676051822, 0.8974249860491108, 0.9163932667181617, 0.9135883624780332, 0.9327888940267339, 0.8134061294387367, 0.8612723362659956, 0.8689867983398953, 0.08497664519241976, 0.06532536315322413, 0.09144049490975159, 0.29933641122931376, 0.05484452024434017, 0.6820424493857146, 0.09487658119563525, 0.22975644774354875, 0.14149499734585513, 0.9624988917986851, 0.47012054424661787, 0.9556503316191516, 0.9433151857009734, 0.3704095687654577, 0.9539393605879831, 0.9418775575021304, 0.3995033056299935, 0.9597517535624376, 0.09880536578080734, 0.05576684148601674, 0.1135524432794418, 0.09489307352449883, 0.07291604776605076, 0.09112080294415592, 0.04409947600536401, 0.08379751619915499, 0.09872925054403092, 0.10610538884793319, 0.17124792527756194, 0.17260338532409747, 0.17131684465795438, 0.20398983364278644, 0.15545790985753338, 0.23649415853176237, 0.16820212413522118, 0.09686316259725769, 0.26304266482187777, 0.1346084097033412, 0.1672212652357008, 0.25089353356190025, 0.1510478728605682, 0.19628729170597692, 0.3288054819006242, 0.20018197405716753, 0.20428812835403976, 0.18325413295768478, 0.11740098337025173, 0.1286941154096285, 0.17893909789747198, 0.18026863190113707, 0.18011174826077025, 0.13244796381353185, 0.13306656221469326, 0.19310190636890845, 0.26251586746873734, 0.1529769916257725, 0.14839292147002348, 0.18201798752027654, 0.23821311363427866, 0.1771548179226491, 0.2947649602360498, 0.25916499565867457, 0.23020863361131416, 0.1742985411486747, 0.1720508611691972, 0.16345870291291809, 0.1743771451904298, 0.1563050503670942, 0.17682695984108654, 0.16751422282260975, 0.1623494848939796, 0.16879725635255471, 0.13186709005173125, 0.17833289601204871, 0.18893168166297614, 0.1595293753223188, 0.17825249346185323, 0.13680160430180655, 0.1430553567301749, 0.1547654420608786, 0.270598890514576, 0.9714909641695217, 0.21354713388116775, 0.07358854849758667, 0.1692616351870827, 0.16917654209742194, 0.15705360843927518, 0.16896702453193013, 0.7018023982497743, 0.15627525149888388, 0.17055520122862677, 0.20057530322377204, 0.23169895897710113, 0.16480769178699406, 0.18129040630271243, 0.16933519068752334, 0.2196532502820473, 0.19546198187466324, 0.21637842235108318, 0.0719458420598239, 0.07204095642554798, 0.08888759076840869, 0.08625488100853995, 0.07806629234190099, 0.05666527335757032, 0.10694267476144736, 0.056743737808030215, 0.10145525556701318]}, "mutation_prompt": null}
{"id": "f045b1eb-efa6-45f4-95ea-2e3fefc83c98", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim)) * 0.5  # Slightly reduced initial velocity\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.5  # Slightly increased expansion factor\n        self.inertia_weight = 0.85  # Reduced initial inertia for balance\n        self.cognitive_weight = 1.7  # Slightly increased cognitive weight\n        self.social_weight = 1.3  # Slightly decreased social weight\n        self.inertia_decay = 0.98  # More aggressive decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM_V2", "description": "Quantum-Inspired Particle Swarm Optimization enhanced with Adaptive Nelder-Mead and dynamic inertia tuning for improved exploration and convergence.", "configspace": "", "generation": 93, "fitness": 0.4454040562473363, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9791110283124431, 0.9792702918414233, 0.9696764718775266, 0.9810034990450122, 0.9719547905606317, 0.9743136578370845, 0.9812904284724234, 0.9789806075423174, 0.2685882481754024, 0.9098670960954984, 0.08271228772799599, 0.1220960576135367, 0.9088696082657989, 0.9224308306704666, 0.9452402632912853, 0.8973833538281928, 0.8970694528651609, 0.8942529791454877, 0.1144294876937485, 0.06168952159643981, 0.061449915141752354, 0.09895851025481028, 0.08160855674168521, 0.11382106712992113, 0.037563454379225925, 0.07887703858902773, 0.08485006806495454, 0.06721002299347567, 0.07157757739406623, 0.04652942478579847, 0.10848533386279091, 0.13765006255478562, 0.05036102707450174, 0.07202179345343918, 0.16464073737074691, 0.08168195222810626, 0.95644850263979, 0.9168364469213394, 0.967853637342888, 0.9496297532394212, 0.9287946192551256, 0.9070311724395682, 0.9842348216379555, 0.9355017722769183, 0.9602362313101878, 0.6812864656629958, 0.20533268095713242, 0.6687181678014409, 0.254277199976756, 0.5231951476547403, 0.5757638249178971, 0.5297916320834668, 0.07121045977328, 0.708858897088261, 0.3890342773721355, 0.18471037777407107, 0.1735771972642104, 0.15075446183604402, 0.2831667545392761, 0.2842816436866069, 0.13771108408499055, 0.23077740821673398, 0.10373011357642825, 0.9423820858768637, 0.945201443059896, 0.9339473737903676, 0.9016496831657305, 0.9345222770379492, 0.920616093499601, 0.9577090108843342, 0.9619619891157314, 0.9356046895931356, 0.9356278784862965, 0.1384909073688193, 0.13819788417258005, 0.9487195995422287, 0.9568468734394503, 0.13804050454261219, 0.9130093913611894, 0.13772528139427231, 0.9299277701673266, 0.8320067171692513, 0.9039822835110887, 0.842995203377055, 0.8535220029383439, 0.9188118903095713, 0.7947818899383642, 0.9374320198895345, 0.7962669356912031, 0.8637740944654627, 0.8321174532015713, 0.08373246106992827, 0.23538513175677112, 0.8670045503183657, 0.8103258203805631, 0.8159430647549073, 0.8169687873662261, 0.8141320628616775, 0.062167725486754755, 0.8541305250650286, 0.8046951226952989, 0.9032614367511784, 0.8887968576268508, 0.9191273493504903, 0.9190816068309204, 0.9097066713816335, 0.8365491575831133, 0.890358799441077, 0.20631173734857033, 0.5812267205999122, 0.32362771382805566, 0.549188815809907, 0.0364708007718213, 0.6414522886900245, 0.7866629706741128, 0.09312523149632101, 0.16520981542436153, 0.9682136789209161, 0.9631382788032362, 0.35885026668773345, 0.9686267664391267, 0.9518975147600476, 0.9553755829906174, 0.9706524506915455, 0.9616491933363406, 0.9655049947391546, 0.08468976367782577, 0.12054736995193449, 0.1142605414237452, 0.12873709652182264, 0.04537700441096293, 0.1679045416217908, 0.05179652042812577, 0.12072851658361383, 0.0715337214853371, 0.12021896195297832, 0.13864437254247008, 0.18761423711222602, 0.15208542250806845, 0.2608138940835386, 0.14407722745643337, 0.1765326557608199, 0.1472447831878786, 0.23595702215465775, 0.2358351501702327, 0.2486529888745932, 0.2875710244708043, 0.16600957059887678, 0.18816511064507202, 0.20711670865453213, 0.18347129773213533, 0.24177769749549627, 0.1798781404595038, 0.2309588374081919, 0.09287612004710155, 0.1141676540400518, 0.16003182874015254, 0.21880651142913277, 0.14108877825874366, 0.12767018244569595, 0.2522586518699709, 0.15745201940753029, 0.23159940355535036, 0.17742975342717726, 0.21112496692796234, 0.28694521633515246, 0.30582897281199317, 0.19660730834652718, 0.17072813062312286, 0.19893357912590148, 0.2719298675281562, 0.1748672250362563, 0.17198443076558156, 0.18704158609534938, 0.1707107468409147, 0.17550423738292897, 0.16853716452337753, 0.15716150469114654, 0.1636055642669637, 0.18549178678465306, 0.982547433399915, 0.12705171794039982, 0.1205356725012443, 0.9743222366829498, 0.20189999295327288, 0.1247272354002078, 0.14350995468664673, 0.1658446441659911, 0.16909752768295916, 0.9794622615921799, 0.2144516243159721, 0.07182533282307235, 0.21312426613265312, 0.16963007948065645, 0.1568099373608478, 0.9722657831055048, 0.10514446652238552, 0.9802338930711133, 0.24371787007946633, 0.16875060367390704, 0.27545082731510206, 0.19206985617754213, 0.2058804603674147, 0.19131412648621093, 0.1778189466480783, 0.2163267211351133, 0.2860119924109926, 0.1010051221750149, 0.07287005122869084, 0.07944431823512932, 0.08127458999476189, 0.11014939359290088, 0.1035687728238387, 0.1329178196228904, 0.0989884960761852, 0.10396431535383654]}, "mutation_prompt": null}
{"id": "8992856f-a0f5-4e6e-a112-843a5febe886", "solution": "import numpy as np\n\nclass AdaptiveLevyFlightPSO_DNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.8\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.6\n        self.inertia_decay = 0.98\n\n    def levy_flight(self, i):\n        beta = 1.5\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                   (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        levy_step = self.levy_flight(i)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]) +\n                              levy_step)\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveLevyFlightPSO_DNM", "description": "Adaptive Lvy Flight Particle Swarm Optimization with Dynamic Nelder-Mead integrates Lvy flights for enhanced exploration and adaptive Nelder-Mead for convergence.", "configspace": "", "generation": 94, "fitness": 0.33892803619010936, "feedback": "The algorithm AdaptiveLevyFlightPSO_DNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.34.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.32156699278908496, 0.9789075229808832, 0.9656835162347661, 0.9701622822619758, 0.9733803105024164, 0.9669881255231139, 0.2082229305298713, 0.9801511083015082, 0.9645150626510076, 0.898487043800137, 0.9190567177309598, 9.999999999998899e-05, 0.22037282639105493, 0.9004227973634118, 0.9413902536735965, 0.05373073368760761, 0.8752695922402022, 0.9042252063079598, 0.07333870532797138, 0.14969273361301716, 0.09887769734861818, 0.07905304982440542, 0.12456083483564873, 0.06489571851256948, 0.08779047714169863, 0.08741567937747896, 0.09770442383857936, 0.046890532737979274, 0.027635822254566622, 0.03706398423553836, 0.04681847687550622, 0.025900235761335155, 0.09778443609111642, 0.12084139883544975, 0.055632442404230265, 0.10210673860758268, 0.9898118937849503, 0.9599679444387806, 0.9180392715069927, 0.9629418215913101, 0.9876300109582767, 0.9922471666647603, 0.98491474956931, 0.988625226454894, 0.9817435599836114, 0.22980063385126992, 0.5749463765820869, 0.7059060309078458, 0.545365518716907, 0.15461038602635724, 0.6974471098607822, 0.18268054292061653, 0.08925783943599164, 0.1309883170211924, 0.1906396445321108, 0.15513890857488277, 0.11542664972930106, 0.2121939653519176, 0.1453908906014716, 0.23555417402241252, 0.07919477944157494, 0.23957775849114138, 0.1403813499148826, 0.12901175449128055, 0.935761924163211, 0.16613742630848427, 9.999999999998899e-05, 0.938751244415073, 0.13788085352894108, 0.26401331527571437, 0.13777757098145926, 0.9587475580052479, 0.1358081683532013, 0.9383122854073738, 0.05582011380247731, 0.9448607587739525, 0.9502200395308171, 0.05389842677645462, 0.03728303879896555, 0.13500787609121068, 9.999999999998899e-05, 0.8974826690807944, 0.8595355293983817, 0.07413394640913151, 0.869933765557503, 0.8911975877483581, 0.890193414520639, 0.16071366158285527, 0.8892151035140796, 0.12759341280423164, 0.8926041134112901, 0.9082995068401563, 0.09681778762731663, 0.05987784859137191, 0.8578626351686829, 0.820762814297867, 0.12746976627926254, 0.8376075055013409, 0.8734462194426925, 0.1279988946983791, 0.8656273319578108, 0.2902758318606583, 0.14571162871210286, 0.08851242608181364, 0.10966022238748396, 0.8136887944117893, 0.8771781482664647, 0.9126319148702243, 0.3349369207911175, 0.795106644323346, 0.7137599659253376, 0.25435276714717703, 0.8960059601360139, 0.09567240963696932, 0.10056187908045522, 0.11700256490961403, 0.0874108620011872, 0.19279525384030816, 0.9665883825870422, 0.24584230993724432, 0.9413079353147805, 0.9515579264168813, 0.49992449720395404, 0.6451051038010083, 0.9649467508742217, 0.3195827548945296, 0.12067946238721416, 0.06922270867631031, 0.09892717830287057, 0.08525144787076244, 0.1500156600129947, 0.0942979141841741, 0.09434317351920163, 0.06735553633515212, 0.06368999014996257, 0.12350449482747605, 0.14712622748461612, 0.1581464758659067, 0.13693051466790584, 0.16146940906784746, 0.1416732971014535, 0.22499330628959824, 0.08721238010279309, 0.10022508896534943, 0.1680907077684829, 0.18113171430616426, 0.18187976142858764, 0.14904423010947176, 0.15951753053091255, 0.21578399530875236, 0.19031104644915553, 0.18465434219057775, 0.1443795362593424, 0.15864779586443345, 0.22475077577460734, 0.15480661502685178, 0.10913675638121656, 0.09836534611947334, 0.11999211064880733, 0.08875577914183341, 0.10852319825708978, 0.1695436853737532, 0.2059337536428617, 0.18252344145785115, 0.18570277702499394, 0.18938180784434966, 0.2653692338912289, 0.1719520183280292, 0.25862845856265493, 0.2582637626905633, 0.29178050395081934, 0.1649874021570742, 0.17858592365858716, 0.1656826828707053, 0.15240443945275417, 0.1770471245641314, 0.22331315676551777, 0.16142408624354154, 0.1880831803389592, 0.15887967837898964, 0.10528939478438715, 0.12717717660118377, 0.15391405517579715, 0.1299419165987623, 0.2019080058519187, 0.10993952390368178, 0.14332012532843896, 0.16639184571368604, 0.3657659572455203, 0.18236376994424175, 0.21427608640251372, 0.1832786380448449, 0.1035584704205399, 0.16893736127642245, 0.15503533184499974, 0.10390957002594436, 0.10510346421467243, 0.17136426002255556, 0.22111764033783876, 0.16528419545731599, 0.207825964488346, 0.18028958336032086, 0.19248317995109132, 0.16753578094950894, 0.15512374062974743, 0.18050126612225503, 0.23937840019473422, 0.07226928678762601, 0.054692106085415415, 0.07725262348858963, 0.08999162986748521, 0.08975583634014728, 0.07246950035666577, 0.04253806257560211, 0.07187264863106069, 0.059232137388836925]}, "mutation_prompt": null}
{"id": "d0c795f0-1078-4b18-90ce-04a962b1f832", "solution": "import numpy as np\n\nclass HybridQIPSO_ANM_DSP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.3\n        self.beta = 0.4\n        self.gamma = 2.2\n        self.inertia_weight = 0.85\n        self.cognitive_weight = 1.4\n        self.social_weight = 1.6\n        self.inertia_decay = 0.98\n        self.selection_pressure = 0.7\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            indices = np.random.choice(self.pop_size, size=int(self.pop_size * self.selection_pressure), replace=False)\n            for i in indices:\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "HybridQIPSO_ANM_DSP", "description": "Hybrid Quantum-Inspired Particle Swarm Optimization with Adaptive Nelder-Mead and Dynamic Selection Pressure Adjustment for enhanced convergence.", "configspace": "", "generation": 95, "fitness": 0.2464418167581911, "feedback": "The algorithm HybridQIPSO_ANM_DSP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.20480410301602048, 0.8261771733734378, 0.9071232145011858, 0.739637282389165, 0.9453117491185021, 0.8654393800979825, 0.17590171302778868, 0.8732842717731765, 0.18308286676515695, 0.12768327039784477, 0.0646077164697213, 0.1420056415579538, 0.09399206074810795, 0.001355883276200287, 0.22265842243596756, 0.25849096705125985, 0.11925955020124379, 0.2208375974469171, 0.05176569891067484, 0.05327129202988112, 0.11563741432628738, 0.09714400386431588, 0.057316053820900215, 0.13195423572007803, 0.1506893722715471, 0.09259717214232932, 0.07164419013488132, 0.05877029776968046, 0.03160106402849683, 0.045151357600726305, 0.03315576286106969, 0.024496710344559913, 0.040487898462899685, 0.0739458475163276, 0.04629282439687599, 0.06747444290159998, 0.9896902482426856, 0.9640459668878671, 0.9556907575210996, 0.9620817008867534, 0.9129700750416785, 0.9524160250754174, 0.9696322923520106, 0.9255477370121401, 0.9643427798705284, 0.15869610383869748, 0.060436784216215345, 0.07073459395425763, 0.15503785570185735, 0.15519512771120514, 0.08915032958814151, 0.12903288774250854, 0.06071486716558028, 0.08695401295752092, 0.1266599902357648, 0.21205963858624532, 0.23184928264000715, 0.14063765537902195, 0.1042112961124585, 0.15034273145646349, 0.11236822002929625, 0.1478469749651069, 0.17991942928082405, 0.16971691604951922, 0.13141077450801353, 0.7929156903404933, 0.6544769882925783, 0.14353203675009008, 0.1382072389541389, 0.7135849284556157, 0.5014355213226049, 0.13808141009019326, 0.13500739991084798, 0.732516362484219, 0.181086572311841, 0.14258710466216196, 0.46919715986760857, 0.45972338318275496, 0.27989527120559365, 0.1852913028736417, 0.13954611292506347, 0.16324494396335743, 0.08449914534926106, 0.09871773572273013, 0.1885532732778452, 0.06027619137680007, 0.029584297233812284, 0.161269564384665, 0.06590312992387481, 0.07460223466219762, 0.09380392402104176, 0.11384417049710305, 0.11249933161424197, 0.11221553654068761, 0.09589619996985732, 0.2077992669618699, 0.13312047988400633, 0.11002922044968166, 0.08540435077369313, 0.04065565226998136, 0.04133276209156067, 0.472009637642982, 0.2722373761015563, 0.16512506901851998, 0.43533445379239943, 0.3114939160762715, 0.21696809205741308, 0.21737353653305325, 0.14681762437736834, 0.178542873728598, 0.06527215954784593, 0.09803940620855633, 0.08721310993587084, 0.05876878529014318, 0.08719120354436816, 0.11365991990659663, 0.13628324523767843, 0.7825668555808296, 0.878460097804889, 0.7721079598987, 0.4538891301405027, 0.43021434361992317, 0.523550376975543, 0.3866490151604739, 0.5486458336451703, 0.5179046890029155, 0.04195807907978122, 0.1169126340643617, 0.11366665829054512, 0.12083736121071853, 0.03701562060013164, 0.07955303560380833, 0.08626331796751696, 0.09509545338116643, 0.09494229189132952, 0.09578198608977295, 0.1398031581103505, 0.23974061791474144, 0.1867117830662257, 0.16217803087101512, 0.15398810516329509, 0.13396882192092108, 0.1797933565615475, 0.2037293711688919, 0.17503747353878463, 0.15677457555845908, 0.2639544342821004, 0.1989297279513058, 0.16263869916789697, 0.13202287509743127, 0.18480975834858748, 0.20595059466352827, 0.17814176743640187, 0.18234731532756676, 0.1351537062257514, 0.12840066601600442, 0.13506108713693976, 0.15156525575442759, 0.20941032549560812, 0.14144062706057736, 0.13633699688430767, 0.14853546877821333, 0.3187387506092887, 0.2407753067978764, 0.3123803249865933, 0.23386335777840017, 0.2889024018436178, 0.20165269100030747, 0.26406645493937353, 0.2016991087129998, 0.2723201836737721, 0.15549604138752016, 0.16252018076573227, 0.1704212686300809, 0.17174855610746909, 0.1627443608208401, 0.17401456043090324, 0.1703144043029724, 0.1782392408541309, 0.17615691513646614, 0.10507054305841479, 0.18826120601128649, 0.1689857390652122, 0.19620198843824344, 0.20215990525723804, 0.11727244646312085, 0.14314222886798833, 0.16618231183925325, 0.9788867493591601, 0.6562906003478729, 0.21383826114034732, 0.07358633483867083, 0.1092868873325673, 0.24584520202236015, 0.15610464484272635, 0.1699320477061841, 0.8121263889773238, 0.9548324970271105, 0.21299160496479075, 0.2073351838830323, 0.18499908892812322, 0.2454498673272104, 0.2211582402397998, 0.21690949363741963, 0.21468036494942833, 0.18705453866844146, 0.24292516763866367, 0.06867399448441358, 0.10851645855034309, 0.07149553747996473, 0.08137570353489032, 0.09680904635805831, 0.06956209879632402, 0.0761147968017658, 0.10795384885325876, 0.07382009243437515]}, "mutation_prompt": null}
{"id": "deb2040e-0625-4448-86af-69447ba5ffe9", "solution": "import numpy as np\n\nclass HybridPSO_AdaptiveNM_AL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = np.random.uniform(1.0, 2.0)  # Randomized social weight for adaptive learning\n        self.inertia_decay = 0.98  # Adjusted decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        # Decrease inertia weight for convergence\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "HybridPSO_AdaptiveNM_AL", "description": "Hybrid Particle Swarm with Adaptive Nelder-Mead and Adaptive Learning using stochastic inertia adjustment for dynamic exploration-exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.4612558314566484, "feedback": "The algorithm HybridPSO_AdaptiveNM_AL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9751971759913077, 0.9775484656858066, 0.9704452544911936, 0.9675058845480069, 0.9815786991961036, 0.9775282258868722, 0.976168854081219, 0.9802736492377239, 0.975165971435098, 0.08092145526050354, 0.9464564328252394, 0.9251547588457463, 0.9226479768882533, 0.9435667443622997, 0.8881505552508092, 0.9447333352531901, 0.9230549432940309, 0.9402910913488738, 0.09500664590219166, 0.1370887524113541, 0.08170179720422843, 0.08162981203492581, 0.04206528373306406, 0.04646984187024006, 0.15011783605967177, 0.11444259290907233, 0.09484036528427475, 0.09105938016283543, 0.07135177214725719, 0.0787928433264331, 0.07647887675644904, 0.12027714512494292, 0.06926269697471943, 0.07368322218642265, 0.08450252757305188, 0.05962537401049395, 0.9155844168113974, 0.9347927344116481, 0.9501801144552005, 0.9276698468618014, 0.9581206949507699, 0.9881431135694864, 0.9049244873595823, 0.898229459545036, 0.9572950386726559, 0.7381056698439734, 0.8936124596738368, 0.5573296220358606, 0.8086261509164012, 0.7230859007031532, 0.6673174391974094, 0.14007490822884616, 0.823210246962182, 0.8943445438211999, 0.23253835965779468, 0.9833620785029682, 0.1673648953784903, 0.21626798441003137, 0.16372383677360247, 0.9822246636409279, 0.0703396533543752, 0.14741901902773702, 0.32487683058047856, 0.942682704301355, 0.927322522171936, 0.8985292953350642, 0.14649210470324414, 0.961746642480992, 0.13760248684658605, 0.13746550964165816, 0.9429346745278225, 0.9572739179171441, 0.13844534732535907, 0.9404023801471273, 0.13288748183488808, 0.9509324568335416, 0.912337593280076, 0.9471918773079141, 0.9548485292370668, 0.9452765876972755, 0.13738253459914285, 9.999999999998899e-05, 0.8482373880497996, 0.8738960844904146, 0.7664512093228634, 0.8559911209002165, 0.8122080164771436, 0.895484546911482, 0.9412437287845965, 0.16117714432407104, 0.8960891006362848, 0.9453599202348021, 0.8392877437398104, 0.851046925253404, 0.9053014348207348, 0.8258059781343242, 0.8338901077667675, 0.8779880192158539, 0.8958469558276866, 0.8896553000415833, 0.9140209964031923, 0.8511119750073637, 0.9292427231453464, 0.9258019940297357, 0.9422275368096773, 0.9068595830138986, 0.9138340111873938, 0.8910962435227983, 0.2952391056221627, 0.20758716329794014, 0.7819592925145935, 0.6868737247168129, 0.13414340530036573, 0.19679659165006613, 0.08798779353955688, 0.16836092989072782, 0.08743383999546439, 0.9574474492197577, 0.9678971336862054, 0.9696573895001878, 0.9679090437235817, 0.9617063022528738, 0.9688692607190517, 0.9634357374530499, 0.9703059952915342, 0.9568080960788632, 0.09855610138732285, 0.09096358976336527, 0.07588494544479929, 0.056700685749250246, 0.08452594660859669, 0.07165307100932661, 0.150177423413283, 0.07897811354991535, 0.08169211209061689, 0.17408726041006706, 0.1836153293561602, 0.15389102306158764, 0.15738538665011748, 0.15196116765465228, 0.13625189108751978, 0.3520358689323819, 0.15360343081843608, 0.13907799185203218, 0.15703229815926711, 0.16662961758468386, 0.19694250181772388, 0.20422740768510228, 0.18190442756237213, 0.1882110070425711, 0.18904510642936811, 0.22059447416469458, 0.17243860065474204, 0.10762811071389056, 0.1692676229026161, 0.20813910116906864, 0.12898551896420307, 0.1584403986453543, 0.16140487079929844, 0.2338113837036334, 0.2164272882913596, 0.16720903749111926, 0.29538724614570677, 0.14005091681913195, 0.14830408120038485, 0.2077017502921361, 0.1717507940874382, 0.13051353679908972, 0.21528893911626368, 0.1837254431226767, 0.16084541100859606, 0.17667185284827158, 0.19467081908509176, 0.16918082421961012, 0.16937007858538367, 0.17833248617886732, 0.16023774269121027, 0.15600618052134363, 0.18430239109366287, 0.17383881988798655, 0.1890165730779092, 0.12699625101552103, 0.1546464690088729, 0.20177637883588861, 0.20203045358003846, 0.9782997936078751, 0.13759656395831987, 0.16609642087326137, 0.214029816108383, 0.9739375273474256, 0.21452100760477788, 0.07358405504189724, 0.21338501679378286, 0.16930276981791104, 0.9646549109544679, 0.9398511118896584, 0.10512559028699686, 0.9682503543876905, 0.2051753022418622, 0.14857977882577433, 0.19328156963542753, 0.1911736764436669, 0.16908592993840843, 0.1522036698194501, 0.2244980106517933, 0.17779688302776353, 0.20755582840049014, 0.08916455739099927, 0.08234648195208538, 0.07242381493798367, 0.0806701382149293, 0.07710714553175002, 0.052681703725198537, 0.08760598033881994, 0.05021172168207033, 0.07605781377057441]}, "mutation_prompt": null}
{"id": "d405dabf-d567-49e2-bb13-6ee1c4c6a89b", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_ANM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.0\n        self.beta = 0.5\n        self.gamma = 2.0\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.inertia_decay = 0.98  # Modified decay for inertia weight\n        self.mutation_rate = 0.1  # Added mutation rate\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        mutation_vector = (np.random.rand(self.dim) < self.mutation_rate) * np.random.uniform(-1, 1, self.dim)\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i] + mutation_vector, self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "EnhancedQuantumInspiredPSO_ANM", "description": "Quantum-inspired Particle Swarm Optimization with Adaptive Nelder-Mead using dynamic stochastic inertia and adaptive crossover mutation to enhance convergence.", "configspace": "", "generation": 97, "fitness": 0.3958058915244401, "feedback": "The algorithm EnhancedQuantumInspiredPSO_ANM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.35.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9809209012428052, 0.9802396549061179, 0.2073402055242658, 0.9778797691374397, 0.9648413612396459, 0.9739084402181001, 0.9799132710507846, 0.16578222235861462, 0.9777120686878061, 0.9381138472838295, 0.9038617447559807, 0.9096214727987585, 0.9109233168940877, 0.9521402944624852, 0.9302640786316976, 0.8687942355011955, 0.9356238004434506, 0.9417163308595, 0.09900198063443966, 0.08168904149967382, 0.11189482496057057, 0.12076852684910444, 0.06545110613669947, 0.047811692793325755, 0.07912583974844023, 0.06543723654249611, 0.0652228866143012, 0.08167633140863506, 0.045176973243421514, 0.087014001564794, 0.10877611041992352, 0.02914523110285172, 0.08374402807573555, 0.09069383788841656, 0.0815311400669978, 0.06725647292964254, 0.9200964832076519, 0.877667522721974, 0.8706732388915109, 0.9445664211660866, 0.8522791420415033, 0.9291120903466915, 0.9899244651145707, 0.8918587677666598, 0.9879699551516161, 0.6517953671712948, 0.8110889689057401, 0.41514172904468094, 0.1548264389566557, 0.476798325332634, 0.08104833362152364, 0.6561516685736173, 0.8623203246028622, 0.09838043978057609, 0.1885045456273089, 0.31403925682276457, 0.1565436145186312, 0.2854086228467879, 0.09519268157990768, 0.24968310154655704, 0.14282650790246154, 0.1425255564739153, 0.14695583237613552, 0.9223879617789074, 0.13708869960551362, 0.28502378323453714, 0.9318184167286163, 0.9533532373646629, 0.9261801524687991, 0.9577415563022481, 0.22039656358752246, 0.8366683957791425, 0.9453503759485217, 0.9223984704342122, 0.13230784037001575, 0.930401036947633, 0.13821737689959135, 0.15538991462531848, 0.9250079597763071, 0.8526360745336802, 0.17645171406460736, 0.9213110813960919, 0.7756037341791557, 0.8721293000258247, 0.919087552834321, 0.9329113900490567, 0.9371677303977414, 0.915717724455926, 0.5422086198006475, 0.0564380964612341, 0.9611969167326577, 0.2000426660825051, 0.14327118691307028, 0.9219951539546941, 0.7473507443105505, 0.1263769866870187, 0.8482187194799622, 0.8554218790492476, 0.21257379900244766, 0.90150909681326, 0.7779941446142301, 0.9443334203050995, 0.8869629676201554, 0.8520212595905323, 0.0998638763498646, 0.877914337774668, 0.11375593212993496, 0.7572796680182062, 0.19088942344508997, 9.999999999998899e-05, 0.5566229794633053, 0.5047445111623172, 0.6404976102406352, 0.05022411937666893, 0.10415364569601426, 0.8030916890941596, 0.17807300699389594, 0.9635173114411296, 0.9651004644183878, 0.2724086725815593, 0.9711039559532193, 0.20122507456859107, 0.4746940176998945, 0.9644873861397922, 0.9630914284674567, 0.2521531497203441, 0.09498386999291941, 0.07618659695195873, 0.08183981949733721, 0.07876943962140992, 0.10837369026061461, 0.059325188138696694, 0.07146927450492713, 0.13810861126499896, 0.06081025596894962, 0.11604558561021916, 0.14060994395142712, 0.1575094606464621, 0.1908689130418556, 0.2805609371779507, 0.1388814195105057, 0.4341659556160492, 0.10868341726881459, 0.1647976222186115, 0.218257842709358, 0.18674577739927067, 0.16916506519996422, 0.15925655629026714, 0.21184708325924484, 0.21406879914701227, 0.18077250389675703, 0.20862300147044321, 0.21356759748401044, 0.15774598778788662, 0.16236193005676047, 0.17051230311329657, 0.10329967888361447, 0.19190990908291983, 0.19146364685081763, 0.19545365932869185, 0.14794918689283243, 0.21804121500510654, 0.24860477678660597, 0.15212194345489571, 0.1483766664112991, 0.18888300467754826, 0.17429646153018363, 0.22174072728765315, 0.1869797273313598, 0.19638181245498276, 0.2078223598295802, 0.16931041563481686, 0.169213263085078, 0.16291639941550007, 0.160648491851082, 0.1802893881366876, 0.1690163099570584, 0.17750922553833626, 0.1690560781648046, 0.16934453829823526, 0.10540120914232243, 0.12718202810804558, 0.15473707548713134, 0.9811773979140923, 0.17301287327505888, 0.16821503165753715, 0.14333377831509975, 0.11037572237467719, 0.3304154233859853, 0.9786030844741369, 0.21381368760958652, 0.07361849693504297, 0.10527822594960867, 0.16951621356828162, 0.1530908287777627, 0.10531144100456191, 0.1047949685432582, 0.09060721382097892, 0.19037879755849973, 0.27380780329500853, 0.19345053794228428, 0.16494634731346014, 0.22521044672316504, 0.256303856962252, 0.22288246707398185, 0.20818365277710282, 0.2038115627896061, 0.07754237364201111, 0.0484479348660205, 0.08170193236248724, 0.042978549432826196, 0.07158230586829928, 0.1123942016724393, 0.03538555540055366, 0.06447390309844359, 0.0665126627010364]}, "mutation_prompt": null}
{"id": "f81df0f2-40cc-4a4c-a814-7a0283105882", "solution": "import numpy as np\n\nclass QuantumEnhancedPSO_DSI:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.2  # Slightly increased reflection coefficient\n        self.beta = 0.6   # Slightly increased contraction coefficient\n        self.gamma = 2.5  # Increased expansion coefficient for better exploration\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.4  # Adjusted cognitive weight\n        self.social_weight = 1.6     # Adjusted social weight with dynamic influence\n        self.inertia_decay = 0.98    # Modified decay factor for inertia weight\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        social_influence = self.social_weight * r2 * (self.global_best - self.pop[i])\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              social_influence)\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.5 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "QuantumEnhancedPSO_DSI", "description": "Quantum-Enhanced Particle Swarm Optimization with Adaptive Nelder-Mead and Dynamic Social Influence for Versatile Exploration-Exploitation Balance.", "configspace": "", "generation": 98, "fitness": 0.4450986433577804, "feedback": "The algorithm QuantumEnhancedPSO_DSI got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.37.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.9747947392104577, 0.9655484496192334, 0.9699561506624725, 0.9685530724090988, 0.9706846581415254, 0.9760755931340177, 0.9780372854480154, 0.974997833529794, 0.14357669670506912, 0.9228101263857059, 0.8981239822963067, 0.8992906902733148, 0.06978589928313594, 0.9210073520825816, 0.8991738936161445, 0.9321601583488451, 0.8572357765022733, 0.9094680160246541, 0.0915104278076051, 0.1140408948123035, 0.07394805716219, 0.16712266794802655, 0.08192707897688101, 0.07891909290618515, 0.09122946421325773, 0.031176717542190646, 0.1362380300954804, 0.076437432986874, 0.07148576183929145, 0.05334565913032241, 0.08449779482420783, 0.0757887028870089, 0.047638840666264115, 0.03353435715139563, 0.061262762621724365, 0.09875807589322882, 0.9890953640650256, 0.9893828048072519, 0.9108309264476835, 0.9840157864780354, 0.8442572632537823, 0.819642561969526, 0.9290448351926204, 0.9255231663057193, 0.8280755608312681, 0.2267538149524968, 0.6868204864439538, 0.653252830486172, 0.7702915472781822, 0.5298470861827173, 0.6019844310942855, 0.3178880860666905, 0.8098317403147537, 0.6868027993061695, 0.24716289230000876, 0.1631440905107191, 0.1322670872346129, 0.15415698016934143, 0.12044206043376582, 0.17007020951955087, 0.10402424344686423, 0.1124556689505074, 0.04534615702727829, 0.1384241896427053, 0.1352142416367207, 0.9331579426930181, 0.9393079404027921, 0.9252218523422404, 0.9482419952792279, 0.8932455864924325, 0.9153476283577586, 0.9259769964869676, 0.9508926081585591, 0.9321642091514877, 0.9268006057039307, 0.13809102841380305, 0.9332292161823112, 0.9339832228432918, 0.13793547996371724, 0.9459873967952346, 0.9281413043962443, 0.9237934918641357, 0.7955584700770539, 0.8108342135657988, 0.8429908960798943, 0.11363613404440764, 0.9272788316621576, 0.8525291021098869, 0.9067785993568166, 0.9054949723287887, 0.8560879274838781, 0.2762153010484959, 0.8080006478131189, 0.8446361943789094, 0.8520865929330689, 0.775098585357692, 0.6016163351776083, 0.8414815870760717, 0.856794850265882, 0.8595711810963375, 0.8353188703949123, 0.8932645372129441, 0.9110709207011344, 0.8712304974282481, 0.9158467903720389, 0.19988596408068526, 0.8152716737452279, 0.9049118749863198, 0.47215055387024296, 0.17984551183701747, 0.11342870164734908, 0.4954453296042197, 0.08184616426431146, 0.9360186727699861, 0.06174659858054943, 0.04902316642056015, 0.1949298554355855, 0.9558063930445441, 0.9651937612267858, 0.9547675630771145, 0.951923570820896, 0.9638077538183643, 0.961129624010078, 0.9609799718413143, 0.9583011039097119, 0.2012551602414595, 0.14929619631185798, 0.10827752791858603, 0.08170922833364325, 0.04842459579417513, 0.042902200248189915, 0.10824185605029524, 0.06328928125141753, 0.12863889725076427, 0.07408673350598105, 0.20152269818050506, 0.14719253474730798, 0.13679741593722772, 0.14306320449469623, 0.3030356221233611, 0.13852300816657592, 0.14970325814235408, 0.10468827177693951, 0.15100598804082288, 0.20122115785547534, 0.16870821559891325, 0.2791131346005682, 0.3894067988156915, 0.17278297073163396, 0.1584566865345154, 0.21933320355028196, 0.2675388188660779, 0.16388174400359878, 0.16690472778493382, 0.14045502135264798, 0.20760067736457954, 0.11039641464614358, 0.2085200871742019, 0.1688931295127042, 0.13353922078678282, 0.179590986073774, 0.22108590077184487, 0.19881942761435645, 0.23256738707761881, 0.19022005142364828, 0.19128946521658052, 0.263200286528422, 0.19698993260557063, 0.23394376127017724, 0.22540465829014056, 0.28234346299936686, 0.1616684362170805, 0.16280965307940876, 0.17155488654612405, 0.1628698171756856, 0.1720141025433639, 0.18193293696887414, 0.17128414995770613, 0.1612334708553953, 0.1753177887668198, 0.975323664424823, 0.1272206241372894, 0.1540519680970296, 0.978096184096931, 0.2019272830730271, 0.17030782505097708, 0.1433214290398278, 0.1663864478897027, 0.9769278470735534, 0.9790533356784709, 0.21444145577280893, 0.9732085042611798, 0.21313163632422338, 0.1694323450696531, 0.15699793237460868, 0.10376718062430723, 0.10522316938294263, 0.9715561793595494, 0.1843146257444549, 0.1988097562872304, 0.18809938109264634, 0.21648315927767048, 0.18862992332101047, 0.21466435437387021, 0.23022084050587244, 0.1623049253198342, 0.19075908522766682, 0.1308615974628463, 0.08196976879627049, 0.06174039884422322, 0.06975795158998332, 0.08623094568444434, 0.07564634545072424, 0.07127862686013453, 0.08398601177145937, 0.06308254829377746]}, "mutation_prompt": null}
{"id": "98eb1ac5-0c8b-4ef1-afec-b41f594143a8", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO_HNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 12 * dim\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (self.pop_size, dim))\n        self.personal_best = np.copy(self.pop)\n        self.personal_best_fitness = np.full(self.pop_size, float('inf'))\n        self.global_best = None\n        self.global_best_fitness = float('inf')\n        self.func_evals = 0\n        self.alpha = 1.5\n        self.beta = 0.4\n        self.gamma = 2.5\n        self.inertia_weight = 0.85\n        self.cognitive_weight = 2.0\n        self.social_weight = 1.3\n        self.inertia_decay = 0.97\n\n    def update_particle(self, i, func):\n        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                              self.cognitive_weight * r1 * (self.personal_best[i] - self.pop[i]) +\n                              self.social_weight * r2 * (self.global_best - self.pop[i]))\n        self.pop[i] = np.clip(self.pop[i] + self.velocities[i], self.lb, self.ub)\n        f_value = func(self.pop[i])\n        self.func_evals += 1\n        if f_value < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n        if f_value < self.global_best_fitness:\n            self.global_best_fitness = f_value\n            self.global_best = self.pop[i]\n        self.inertia_weight *= self.inertia_decay\n\n    def __call__(self, func):\n        for i in range(self.pop_size):\n            f_value = func(self.pop[i])\n            self.func_evals += 1\n            self.personal_best_fitness[i] = f_value\n            self.personal_best[i] = self.pop[i]\n            if f_value < self.global_best_fitness:\n                self.global_best_fitness = f_value\n                self.global_best = self.pop[i]\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                if self.func_evals >= self.budget:\n                    return self.global_best\n                self.update_particle(i, func)\n\n            if self.func_evals < self.budget:\n                best_idx = np.argmin(self.personal_best_fitness)\n                simplex = np.array([self.personal_best[best_idx]] + [self.personal_best[np.random.randint(self.pop_size)] for _ in range(self.dim)])\n                simplex_fitness = np.array([func(p) for p in simplex])\n                self.func_evals += len(simplex)\n\n                while self.func_evals < self.budget:\n                    order = np.argsort(simplex_fitness)\n                    simplex = simplex[order]\n                    simplex_fitness = simplex_fitness[order]\n\n                    centroid = np.mean(simplex[:-1], axis=0)\n                    reflected = np.clip(centroid + self.alpha * (centroid - simplex[-1]), self.lb, self.ub)\n                    f_reflected = func(reflected)\n                    self.func_evals += 1\n\n                    if f_reflected < simplex_fitness[0]:\n                        expanded = np.clip(centroid + self.gamma * (reflected - centroid), self.lb, self.ub)\n                        f_expanded = func(expanded)\n                        self.func_evals += 1\n\n                        if f_expanded < f_reflected:\n                            simplex[-1] = expanded\n                            simplex_fitness[-1] = f_expanded\n                        else:\n                            simplex[-1] = reflected\n                            simplex_fitness[-1] = f_reflected\n                    elif f_reflected < simplex_fitness[-2]:\n                        simplex[-1] = reflected\n                        simplex_fitness[-1] = f_reflected\n                    else:\n                        contracted = np.clip(centroid + self.beta * (simplex[-1] - centroid), self.lb, self.ub)\n                        f_contracted = func(contracted)\n                        self.func_evals += 1\n\n                        if f_contracted < simplex_fitness[-1]:\n                            simplex[-1] = contracted\n                            simplex_fitness[-1] = f_contracted\n                        else:\n                            for j in range(1, len(simplex)):\n                                simplex[j] = np.clip(simplex[0] + 0.6 * (simplex[j] - simplex[0]), self.lb, self.ub)\n                                simplex_fitness[j] = func(simplex[j])\n                            self.func_evals += len(simplex) - 1\n\n                best_simplex_idx = np.argmin(simplex_fitness)\n                if simplex_fitness[best_simplex_idx] < self.personal_best_fitness[best_idx]:\n                    self.personal_best[best_idx] = simplex[best_simplex_idx]\n                    self.personal_best_fitness[best_idx] = simplex_fitness[best_simplex_idx]\n\n        return self.global_best", "name": "AdaptiveQuantumInspiredPSO_HNM", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Hierarchical Nelder-Mead for enhanced exploration-exploitation balance and dynamic simplex adjustment.", "configspace": "", "generation": 99, "fitness": 0.19273788814773146, "feedback": "The algorithm AdaptiveQuantumInspiredPSO_HNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8f5da5cb-ea73-4e01-a183-3b8629d49c57", "metadata": {"aucs": [0.3029800312949117, 0.2243022376955066, 0.3312685623120386, 0.3034698089992336, 0.56986401156907, 0.2921723944483451, 0.34048561879787, 0.32382799628617265, 0.26894002255769667, 0.12455477245837387, 0.04055004227865411, 0.1131705683798595, 0.021405401686852343, 9.999999999998899e-05, 0.4615381480466493, 0.05399299127169088, 0.15719471731902357, 0.1337052418743444, 0.1374875392567716, 0.07500320514849568, 0.05813473088439203, 0.04789838728613416, 0.059334307368160255, 0.08193368155966874, 0.14682308966279778, 0.1039027895848692, 0.06155812484288359, 0.05945235991477038, 0.034322949408676195, 0.08665371998914229, 0.11358292585903984, 0.065072474623868, 0.029722846033428896, 0.09037046570709484, 0.07272007241701339, 0.04916395910927529, 0.9327387845707269, 0.9215778335070314, 0.9856595099049572, 0.09953797390682906, 0.9846522540957918, 0.9833808104271303, 0.9732049997301407, 0.9824474037900798, 0.9863734278002267, 0.21950575921950666, 0.15336190990250909, 0.300138905601399, 0.08583387090295658, 0.1351936789971292, 0.1709539232050653, 0.08801996050847716, 0.11196946340873659, 0.08949004126497528, 0.17738992266034415, 0.18469345882974353, 0.2298837591708618, 0.19739457177164388, 0.13557742977958276, 0.10903485453155592, 0.08789525041250323, 0.15116601096910487, 0.1819524285251134, 0.11225560028971682, 0.13335106045484768, 0.1303187222802198, 0.14542987309457334, 0.1361469567361402, 0.1763763464412439, 0.2516706230790171, 0.15678894116677844, 0.13845770288985082, 9.999999999998899e-05, 0.010373986030974502, 0.19561356786844197, 0.1988413077171124, 0.13404423445667002, 0.102194377981081, 0.13581790209784594, 0.4157958645137222, 0.11212287759656969, 0.07418750366877158, 0.1145540765307751, 0.15764321552266225, 0.03595960246273666, 0.047957697978589064, 0.06272707218655282, 0.05510913695364528, 0.011175525531030184, 0.012938180180425252, 0.14197583267670033, 0.15203529281410044, 0.3099380695707936, 0.0885579531486268, 0.056970918476589416, 0.19883006148012528, 0.10562620209011753, 0.2066503914989286, 0.23998075192011992, 0.07766237203904858, 0.07776407767617766, 0.13028696652445448, 0.24159961149173548, 0.10503022210855939, 0.24685972774552656, 0.3364122134880042, 0.08618861423582458, 0.10455509584494138, 0.14966698457980288, 0.2818284691950995, 0.1777851868680611, 0.1509689628530797, 0.18877845588002184, 0.02588010143149877, 0.2915656310614356, 0.12656430067169278, 0.10827991087804023, 0.20839223543563334, 0.5578889310408754, 0.29493469972675757, 0.38430728732870634, 0.25936272387160353, 0.32865478474433363, 0.2703309177650106, 0.17460088391804152, 0.21660811773877453, 0.11130867632191765, 0.06736008693278095, 0.05802966850026858, 0.0766594399008036, 0.07344247721516117, 0.1551391712324406, 0.05925033395089119, 0.08737711244737112, 0.11356278797456831, 0.1225990903753078, 0.2053020911605291, 0.14649495229798026, 0.19586782254923718, 0.22212140670655844, 0.1470472420133443, 0.15850264130900393, 0.09201791117175584, 0.12041657307313092, 0.16895979967862218, 0.18957194206297523, 0.24363895983153627, 0.18884784953285016, 0.24984362224573065, 0.1579721050150833, 0.2041317014654881, 0.19461091540499986, 0.21557453048565212, 0.1295004574901485, 0.13539011517160127, 0.13764881831319176, 0.1447181647916581, 0.18192177536711374, 0.15911301133737998, 0.19536785293879222, 0.12047657153125524, 0.09390402202594328, 0.2888376143395972, 0.2293423619887458, 0.14797310106895933, 0.17789248528894808, 0.26378579269113833, 0.18938474844486686, 0.21103638375083256, 0.2233315019510903, 0.3019330124432251, 0.17706149767428792, 0.17012740387649938, 0.17892404902946657, 0.16369695373057547, 0.17189230956133073, 0.15586741412792382, 0.17500333209421026, 0.17942131234391467, 0.17427996564901493, 0.2863554683040864, 0.1890457341814753, 0.16602960428969704, 0.16735025445548546, 0.2002377636307564, 0.3515527290865471, 0.14260263072065738, 0.16216736267231502, 0.32128745885572585, 0.38048020470861443, 0.17192237760093, 0.208143022485624, 0.21238861154082256, 0.16934708748686733, 0.14973857350261421, 0.09862579659310289, 0.09430014770191208, 0.212534336234513, 0.18278966175273503, 0.207413683297913, 0.15798643526469147, 0.2037307645883517, 0.18431719755149345, 0.25125920653020584, 0.18497303496434392, 0.274752882642076, 0.27203309936085296, 0.09384835776713663, 0.03411169716465812, 0.05621453488720907, 0.09336602721997422, 0.06387938344006638, 0.07404836628695666, 0.07485417914387071, 0.09807406885372527, 0.07917584640855313]}, "mutation_prompt": null}
